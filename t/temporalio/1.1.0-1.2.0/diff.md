# Comparing `tmp/temporalio-1.1.0.tar.gz` & `tmp/temporalio-1.2.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "temporalio-1.1.0.tar", max compression
+gzip compressed data, was "temporalio-1.2.0.tar", max compression
```

## Comparing `temporalio-1.1.0.tar` & `temporalio-1.2.0.tar`

### file list

```diff
@@ -1,461 +1,484 @@
--rw-r--r--   0        0        0     1108 2023-02-21 18:22:49.010218 temporalio-1.1.0/LICENSE
--rw-r--r--   0        0        0    65532 2023-02-21 18:22:49.010218 temporalio-1.1.0/README.md
--rw-r--r--   0        0        0      899 2023-02-21 18:22:49.010218 temporalio-1.1.0/build.py
--rw-r--r--   0        0        0     6369 2023-02-21 18:22:49.010218 temporalio-1.1.0/pyproject.toml
--rw-r--r--   0        0        0      423 2023-02-21 18:22:49.010218 temporalio-1.1.0/temporalio/__init__.py
--rw-r--r--   0        0        0    14172 2023-02-21 18:22:49.010218 temporalio-1.1.0/temporalio/activity.py
--rw-r--r--   0        0        0       36 2023-02-21 18:22:49.010218 temporalio-1.1.0/temporalio/api/__init__.py
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.010218 temporalio-1.1.0/temporalio/api/batch/__init__.py
--rw-r--r--   0        0        0      336 2023-02-21 18:22:49.010218 temporalio-1.1.0/temporalio/api/batch/v1/__init__.py
--rw-r--r--   0        0        0     5919 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/batch/v1/message_pb2.py
--rw-r--r--   0        0        0     7644 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/batch/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/__init__.py
--rw-r--r--   0        0        0      286 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/v1/__init__.py
--rw-r--r--   0        0        0     5853 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2.py
--rw-r--r--   0        0        0    11757 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2.pyi
--rw-r--r--   0        0        0      158 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/command/__init__.py
--rw-r--r--   0        0        0     1666 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/command/v1/__init__.py
--rw-r--r--   0        0        0    28323 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/command/v1/message_pb2.py
--rw-r--r--   0        0        0    47695 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/command/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/__init__.py
--rw-r--r--   0        0        0      444 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/v1/__init__.py
--rw-r--r--   0        0        0     1540 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/v1/grpc_status_pb2.py
--rw-r--r--   0        0        0     1462 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/v1/grpc_status_pb2.pyi
--rw-r--r--   0        0        0    11410 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/v1/message_pb2.py
--rw-r--r--   0        0        0    13775 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/common/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/dependencies/__init__.py
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/dependencies/gogoproto/__init__.py
--rw-r--r--   0        0        0    22341 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py
--rw-r--r--   0        0        0    15976 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/__init__.py
--rw-r--r--   0        0        0     1978 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/__init__.py
--rw-r--r--   0        0        0     2619 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/batch_operation_pb2.py
--rw-r--r--   0        0        0     3777 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/batch_operation_pb2.pyi
--rw-r--r--   0        0        0     3244 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/command_type_pb2.py
--rw-r--r--   0        0        0     4989 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/command_type_pb2.pyi
--rw-r--r--   0        0        0     2980 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/common_pb2.py
--rw-r--r--   0        0        0     4571 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/common_pb2.pyi
--rw-r--r--   0        0        0     6256 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/event_type_pb2.py
--rw-r--r--   0        0        0    20000 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/event_type_pb2.pyi
--rw-r--r--   0        0        0     9198 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/failed_cause_pb2.py
--rw-r--r--   0        0        0    17562 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/failed_cause_pb2.pyi
--rw-r--r--   0        0        0     1847 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/interaction_type_pb2.py
--rw-r--r--   0        0        0     2506 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/interaction_type_pb2.pyi
--rw-r--r--   0        0        0     2747 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/namespace_pb2.py
--rw-r--r--   0        0        0     4174 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/namespace_pb2.pyi
--rw-r--r--   0        0        0     2353 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/query_pb2.py
--rw-r--r--   0        0        0     3983 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/query_pb2.pyi
--rw-r--r--   0        0        0     1699 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/reset_pb2.py
--rw-r--r--   0        0        0     2543 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/reset_pb2.pyi
--rw-r--r--   0        0        0     2149 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/schedule_pb2.py
--rw-r--r--   0        0        0     5644 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/schedule_pb2.pyi
--rw-r--r--   0        0        0     2151 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/task_queue_pb2.py
--rw-r--r--   0        0        0     4744 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/task_queue_pb2.pyi
--rw-r--r--   0        0        0     1839 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/update_pb2.py
--rw-r--r--   0        0        0     2717 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/update_pb2.pyi
--rw-r--r--   0        0        0     7735 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/workflow_pb2.py
--rw-r--r--   0        0        0    15052 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/enums/v1/workflow_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/errordetails/__init__.py
--rw-r--r--   0        0        0      974 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/errordetails/v1/__init__.py
--rw-r--r--   0        0        0    12041 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/errordetails/v1/message_pb2.py
--rw-r--r--   0        0        0    10149 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/errordetails/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/failure/__init__.py
--rw-r--r--   0        0        0      530 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/failure/v1/__init__.py
--rw-r--r--   0        0        0     9303 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/failure/v1/message_pb2.py
--rw-r--r--   0        0        0    16245 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/failure/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/filter/__init__.py
--rw-r--r--   0        0        0      236 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/filter/v1/__init__.py
--rw-r--r--   0        0        0     4569 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/filter/v1/message_pb2.py
--rw-r--r--   0        0        0     4131 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/filter/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/history/__init__.py
--rw-r--r--   0        0        0     4568 2023-02-21 18:22:49.014218 temporalio-1.1.0/temporalio/api/history/v1/__init__.py
--rw-r--r--   0        0        0    72330 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/history/v1/message_pb2.py
--rw-r--r--   0        0        0   144824 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/history/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/interaction/__init__.py
--rw-r--r--   0        0        0      129 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/interaction/v1/__init__.py
--rw-r--r--   0        0        0     4385 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/interaction/v1/message_pb2.py
--rw-r--r--   0        0        0     7155 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/interaction/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/namespace/__init__.py
--rw-r--r--   0        0        0      300 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/namespace/v1/__init__.py
--rw-r--r--   0        0        0     9474 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/namespace/v1/message_pb2.py
--rw-r--r--   0        0        0    11857 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/namespace/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/__init__.py
--rw-r--r--   0        0        0     1423 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/__init__.py
--rw-r--r--   0        0        0    17555 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0    15203 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0     2899 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0    17632 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0     8793 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/query/__init__.py
--rw-r--r--   0        0        0      159 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/query/v1/__init__.py
--rw-r--r--   0        0        0     3696 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/query/v1/message_pb2.py
--rw-r--r--   0        0        0     5000 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/query/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/replication/__init__.py
--rw-r--r--   0        0        0      214 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/replication/v1/__init__.py
--rw-r--r--   0        0        0     4122 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/replication/v1/message_pb2.py
--rw-r--r--   0        0        0     4288 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/replication/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/schedule/__init__.py
--rw-r--r--   0        0        0      732 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/schedule/v1/__init__.py
--rw-r--r--   0        0        0    18729 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/schedule/v1/message_pb2.py
--rw-r--r--   0        0        0    38470 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/schedule/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/taskqueue/__init__.py
--rw-r--r--   0        0        0      440 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/taskqueue/v1/__init__.py
--rw-r--r--   0        0        0     8605 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/taskqueue/v1/message_pb2.py
--rw-r--r--   0        0        0    11329 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/taskqueue/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/__init__.py
--rw-r--r--   0        0        0      814 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/__init__.py
--rw-r--r--   0        0        0     7303 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0     4609 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0     2532 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0    14985 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0     9065 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/update/__init__.py
--rw-r--r--   0        0        0       77 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/update/v1/__init__.py
--rw-r--r--   0        0        0     2026 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/update/v1/message_pb2.py
--rw-r--r--   0        0        0     2795 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/update/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/version/__init__.py
--rw-r--r--   0        0        0      123 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/version/v1/__init__.py
--rw-r--r--   0        0        0     4064 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/version/v1/message_pb2.py
--rw-r--r--   0        0        0     5233 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/version/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/workflow/__init__.py
--rw-r--r--   0        0        0      476 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/workflow/v1/__init__.py
--rw-r--r--   0        0        0    15290 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/workflow/v1/message_pb2.py
--rw-r--r--   0        0        0    24112 2023-02-21 18:22:49.018218 temporalio-1.1.0/temporalio/api/workflow/v1/message_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/__init__.py
--rw-r--r--   0        0        0     8507 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/__init__.py
--rw-r--r--   0        0        0   120477 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2.py
--rw-r--r--   0        0        0   176488 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi
--rw-r--r--   0        0        0      158 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.py
--rw-r--r--   0        0        0     1185 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi
--rw-r--r--   0        0        0    11814 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2.py
--rw-r--r--   0        0        0     1274 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2.pyi
--rw-r--r--   0        0        0   130737 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py
--rw-r--r--   0        0        0    63075 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi
--rw-r--r--   0        0        0    70531 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/Cargo.lock
--rw-r--r--   0        0        0      834 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/Cargo.toml
--rw-r--r--   0        0        0      122 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/__init__.py
--rw-r--r--   0        0        0     3601 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/client.py
--rw-r--r--   0        0        0      144 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/__init__.py
--rw-r--r--   0        0        0      336 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_result/__init__.py
--rw-r--r--   0        0        0     6377 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py
--rw-r--r--   0        0        0     9337 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi
--rw-r--r--   0        0        0      171 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_task/__init__.py
--rw-r--r--   0        0        0     5708 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py
--rw-r--r--   0        0        0    11485 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi
--rw-r--r--   0        0        0     1435 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/bridge/__init__.py
--rw-r--r--   0        0        0    33694 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/bridge/bridge_pb2.py
--rw-r--r--   0        0        0    35620 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi
--rw-r--r--   0        0        0      407 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/child_workflow/__init__.py
--rw-r--r--   0        0        0     5891 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py
--rw-r--r--   0        0        0     9150 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi
--rw-r--r--   0        0        0      102 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/common/__init__.py
--rw-r--r--   0        0        0     1679 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/common/common_pb2.py
--rw-r--r--   0        0        0     1438 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/common/common_pb2.pyi
--rw-r--r--   0        0        0     4203 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2.py
--rw-r--r--   0        0        0     2437 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2.pyi
--rw-r--r--   0        0        0      158 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2_grpc.py
--rw-r--r--   0        0        0       76 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2_grpc.pyi
--rw-r--r--   0        0        0      101 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/external_data/__init__.py
--rw-r--r--   0        0        0     2107 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/external_data/external_data_pb2.py
--rw-r--r--   0        0        0     3700 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/health/__init__.py
--rw-r--r--   0        0        0      132 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/health/v1/__init__.py
--rw-r--r--   0        0        0     3055 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/health/v1/health_pb2.py
--rw-r--r--   0        0        0     2546 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/health/v1/health_pb2.pyi
--rw-r--r--   0        0        0     1138 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/__init__.py
--rw-r--r--   0        0        0    22669 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py
--rw-r--r--   0        0        0    42150 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi
--rw-r--r--   0        0        0     1318 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/__init__.py
--rw-r--r--   0        0        0    34488 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py
--rw-r--r--   0        0        0    59411 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi
--rw-r--r--   0        0        0      165 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_completion/__init__.py
--rw-r--r--   0        0        0     3488 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py
--rw-r--r--   0        0        0     3582 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi
--rw-r--r--   0        0        0     1926 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/runtime.py
--rw-r--r--   0        0        0      196 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/Dockerfile
--rwxr-xr-x   0        0        0       45 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/build.sh
--rw-r--r--   0        0        0      616 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml
--rw-r--r--   0        0        0      963 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml
--rw-r--r--   0        0        0      839 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml
--rw-r--r--   0        0        0     1850 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml
--rw-r--r--   0        0        0      168 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.cargo/config.toml
--rw-r--r--   0        0        0       39 2023-02-21 18:22:50.042208 temporalio-1.1.0/temporalio/bridge/sdk-core/.git
--rw-r--r--   0        0        0      263 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/.gitignore
--rw-r--r--   0        0        0     7864 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/ARCHITECTURE.md
--rw-r--r--   0        0        0       63 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/CODEOWNERS
--rw-r--r--   0        0        0      100 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/LICENSE.txt
--rw-r--r--   0        0        0     4249 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/README.md
--rw-r--r--   0        0        0      555 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md
--rw-r--r--   0        0        0     1029 2023-02-21 18:22:51.482194 temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml
--rw-r--r--   0        0        0   112308 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg
--rw-r--r--   0        0        0     3212 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md
--rw-r--r--   0        0        0      982 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/LICENSE.txt
--rw-r--r--   0        0        0    46522 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/lib.rs
--rw-r--r--   0        0        0     5633 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/metrics.rs
--rw-r--r--   0        0        0    32214 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/raw.rs
--rw-r--r--   0        0        0    24682 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/retry.rs
--rw-r--r--   0        0        0     6852 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs
--rw-r--r--   0        0        0     2949 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/LICENSE.txt
--rw-r--r--   0        0        0     2426 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs
--rw-r--r--   0        0        0     5120 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/abstractions.rs
--rw-r--r--   0        0        0    35381 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs
--rw-r--r--   0        0        0     8101 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs
--rw-r--r--   0        0        0     3882 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs
--rw-r--r--   0        0        0    34616 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs
--rw-r--r--   0        0        0     3130 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs
--rw-r--r--   0        0        0    30076 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs
--rw-r--r--   0        0        0     2452 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs
--rw-r--r--   0        0        0     9465 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs
--rw-r--r--   0        0        0     4233 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs
--rw-r--r--   0        0        0    76044 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs
--rw-r--r--   0        0        0    18278 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs
--rw-r--r--   0        0        0    10613 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/lib.rs
--rw-r--r--   0        0        0     1852 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs
--rw-r--r--   0        0        0     9552 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs
--rw-r--r--   0        0        0    15879 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs
--rw-r--r--   0        0        0     8078 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs
--rw-r--r--   0        0        0     6553 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs
--rw-r--r--   0        0        0     6402 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs
--rw-r--r--   0        0        0    15363 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs
--rw-r--r--   0        0        0    15446 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs
--rw-r--r--   0        0        0     2692 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs
--rw-r--r--   0        0        0    30924 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs
--rw-r--r--   0        0        0    24154 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs
--rw-r--r--   0        0        0    42888 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs
--rw-r--r--   0        0        0    19404 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs
--rw-r--r--   0        0        0     3331 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs
--rw-r--r--   0        0        0    12286 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/client.rs
--rw-r--r--   0        0        0    21419 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs
--rw-r--r--   0        0        0     1238 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs
--rw-r--r--   0        0        0     3844 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs
--rw-r--r--   0        0        0    21265 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs
--rw-r--r--   0        0        0    32926 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs
--rw-r--r--   0        0        0    10471 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs
--rw-r--r--   0        0        0     5325 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs
--rw-r--r--   0        0        0    33108 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs
--rw-r--r--   0        0        0     4175 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs
--rw-r--r--   0        0        0     5097 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs
--rw-r--r--   0        0        0     3902 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs
--rw-r--r--   0        0        0    56932 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs
--rw-r--r--   0        0        0    11069 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs
--rw-r--r--   0        0        0     5501 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs
--rw-r--r--   0        0        0    27195 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs
--rw-r--r--   0        0        0    15841 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs
--rw-r--r--   0        0        0    14871 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs
--rw-r--r--   0        0        0     7817 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs
--rw-r--r--   0        0        0     9073 2023-02-21 18:22:51.490194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs
--rw-r--r--   0        0        0     3425 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs
--rw-r--r--   0        0        0    51996 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs
--rw-r--r--   0        0        0     8770 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs
--rw-r--r--   0        0        0     7018 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs
--rw-r--r--   0        0        0    27294 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs
--rw-r--r--   0        0        0    46231 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs
--rw-r--r--   0        0        0     4831 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs
--rw-r--r--   0        0        0     3261 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs
--rw-r--r--   0        0        0    40900 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs
--rw-r--r--   0        0        0      816 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt
--rw-r--r--   0        0        0     3876 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/errors.rs
--rw-r--r--   0        0        0     6176 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/lib.rs
--rw-r--r--   0        0        0     5718 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs
--rw-r--r--   0        0        0     7278 2023-02-21 18:22:51.486194 temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/worker.rs
--rw-r--r--   0        0        0     7987 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/etc/deps.svg
--rw-r--r--   0        0        0       51 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/etc/dynamic-config.yaml
--rw-r--r--   0        0        0      574 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml
--rw-r--r--   0        0        0      173 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/etc/prometheus.yaml
--rwxr-xr-x   0        0        0      204 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/etc/regen-depgraph.sh
--rw-r--r--   0        0        0      574 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt
--rw-r--r--   0        0        0      126 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/README.md
--rw-r--r--   0        0        0      609 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt
--rw-r--r--   0        0        0    25113 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs
--rw-r--r--   0        0        0      191 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/progress.rs
--rw-r--r--   0        0        0      299 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.rs
--rw-r--r--   0        0        0      387 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.stderr
--rw-r--r--   0        0        0      892 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs
--rw-r--r--   0        0        0      202 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.rs
--rw-r--r--   0        0        0      331 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.stderr
--rw-r--r--   0        0        0      686 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs
--rw-r--r--   0        0        0      619 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs
--rw-r--r--   0        0        0      862 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs
--rw-r--r--   0        0        0      584 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs
--rw-r--r--   0        0        0      562 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr
--rw-r--r--   0        0        0      649 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs
--rw-r--r--   0        0        0      307 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.rs
--rw-r--r--   0        0        0      161 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.stderr
--rw-r--r--   0        0        0      184 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.rs
--rw-r--r--   0        0        0      189 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.stderr
--rw-r--r--   0        0        0      176 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.rs
--rw-r--r--   0        0        0      181 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.stderr
--rw-r--r--   0        0        0      366 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt
--rw-r--r--   0        0        0     8058 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs
--rw-r--r--   0        0        0      103 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/src/lib.rs
--rw-r--r--   0        0        0     3277 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin
--rw-r--r--   0        0        0     2532 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin
--rw-r--r--   0        0        0      924 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin
--rw-r--r--   0        0        0      711 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin
--rwxr-xr-x   0        0        0      213 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/integ-with-otel.sh
--rw-r--r--   0        0        0       55 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/Dockerfile
--rw-r--r--   0        0        0      336 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/docker-compose.yml
--rw-r--r--   0        0        0      223 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/pipeline.yml
--rw-r--r--   0        0        0      172 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/CODEOWNERS
--rw-r--r--   0        0        0      227 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/PULL_REQUEST_TEMPLATE.md
--rw-r--r--   0        0        0     1097 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml
--rw-r--r--   0        0        0       21 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.gitignore
--rw-r--r--   0        0        0     1108 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE
--rw-r--r--   0        0        0     2925 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile
--rw-r--r--   0        0        0      151 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/README.md
--rw-r--r--   0        0        0     1225 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml
--rw-r--r--   0        0        0       99 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/buf.yaml
--rw-r--r--   0        0        0       80 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.mod
--rw-r--r--   0        0        0      478 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.sum
--rw-r--r--   0        0        0     1350 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go
--rw-r--r--   0        0        0     4974 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto
--rw-r--r--   0        0        0      216 2023-02-21 18:22:51.494194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/go.mod
--rw-r--r--   0        0        0     3791 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto
--rw-r--r--   0        0        0    12946 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto
--rw-r--r--   0        0        0     4711 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto
--rw-r--r--   0        0        0     1916 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto
--rw-r--r--   0        0        0     2763 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto
--rw-r--r--   0        0        0     2062 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto
--rw-r--r--   0        0        0     9829 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto
--rw-r--r--   0        0        0     6617 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto
--rw-r--r--   0        0        0     1707 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/interaction_type.proto
--rw-r--r--   0        0        0     1944 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto
--rw-r--r--   0        0        0     2098 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto
--rw-r--r--   0        0        0     1821 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto
--rw-r--r--   0        0        0     3212 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto
--rw-r--r--   0        0        0     2619 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto
--rw-r--r--   0        0        0     1775 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto
--rw-r--r--   0        0        0     5083 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto
--rw-r--r--   0        0        0     3815 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto
--rw-r--r--   0        0        0     4728 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto
--rw-r--r--   0        0        0     2068 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto
--rw-r--r--   0        0        0    39212 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto
--rw-r--r--   0        0        0     3284 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/interaction/v1/message.proto
--rw-r--r--   0        0        0     3926 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto
--rw-r--r--   0        0        0     4269 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto
--rw-r--r--   0        0        0     4034 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto
--rw-r--r--   0        0        0     2587 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto
--rw-r--r--   0        0        0     2212 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto
--rw-r--r--   0        0        0    17214 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto
--rw-r--r--   0        0        0     3937 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto
--rw-r--r--   0        0        0     2367 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto
--rw-r--r--   0        0        0     6858 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto
--rw-r--r--   0        0        0    48291 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto
--rw-r--r--   0        0        0    22628 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto
--rw-r--r--   0        0        0     2416 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto
--rw-r--r--   0        0        0     2670 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto
--rw-r--r--   0        0        0     2919 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto
--rw-r--r--   0        0        0     2342 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto
--rw-r--r--   0        0        0      459 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/common/common.proto
--rw-r--r--   0        0        0     1249 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto
--rw-r--r--   0        0        0     1522 2023-02-21 18:22:51.498194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto
--rw-r--r--   0        0        0    11974 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto
--rw-r--r--   0        0        0    14570 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto
--rw-r--r--   0        0        0      867 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto
--rw-r--r--   0        0        0     2854 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile
--rw-r--r--   0        0        0     1120 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml
--rw-r--r--   0        0        0      137 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/buf.yaml
--rw-r--r--   0        0        0     4974 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto
--rw-r--r--   0        0        0     2178 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto
--rw-r--r--   0        0        0     4494 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto
--rw-r--r--   0        0        0       27 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/rustfmt.toml
--rw-r--r--   0        0        0     1188 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt
--rw-r--r--   0        0        0     8019 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs
--rw-r--r--   0        0        0      979 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs
--rw-r--r--   0        0        0     1789 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs
--rw-r--r--   0        0        0    30476 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/lib.rs
--rw-r--r--   0        0        0      523 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs
--rw-r--r--   0        0        0    11736 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs
--rw-r--r--   0        0        0    23564 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs
--rw-r--r--   0        0        0    22554 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs
--rw-r--r--   0        0        0      795 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml
--rw-r--r--   0        0        0     1127 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt
--rw-r--r--   0        0        0     4171 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs
--rw-r--r--   0        0        0      334 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/constants.rs
--rw-r--r--   0        0        0    20227 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs
--rw-r--r--   0        0        0     9060 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs
--rw-r--r--   0        0        0    79581 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs
--rw-r--r--   0        0        0     1160 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs
--rw-r--r--   0        0        0      422 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/utilities.rs
--rw-r--r--   0        0        0      747 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml
--rw-r--r--   0        0        0    57189 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs
--rw-r--r--   0        0        0     1093 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs
--rw-r--r--   0        0        0    22892 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs
--rw-r--r--   0        0        0     1353 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs
--rw-r--r--   0        0        0     4426 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs
--rw-r--r--   0        0        0     8180 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs
--rw-r--r--   0        0        0     1352 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs
--rw-r--r--   0        0        0     4681 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs
--rw-r--r--   0        0        0    15917 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs
--rw-r--r--   0        0        0     3276 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs
--rw-r--r--   0        0        0    33716 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs
--rw-r--r--   0        0        0     1996 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs
--rw-r--r--   0        0        0     1681 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs
--rw-r--r--   0        0        0     1719 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs
--rw-r--r--   0        0        0     1541 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs
--rw-r--r--   0        0        0     1904 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs
--rw-r--r--   0        0        0     1770 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs
--rw-r--r--   0        0        0    27272 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs
--rw-r--r--   0        0        0     1658 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs
--rw-r--r--   0        0        0     3465 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs
--rw-r--r--   0        0        0     7503 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs
--rw-r--r--   0        0        0     3002 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs
--rw-r--r--   0        0        0     5269 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs
--rw-r--r--   0        0        0     3107 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs
--rw-r--r--   0        0        0     4029 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs
--rw-r--r--   0        0        0     2530 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs
--rw-r--r--   0        0        0    20708 2023-02-21 18:22:51.502194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs
--rw-r--r--   0        0        0     6478 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/load_tests.rs
--rw-r--r--   0        0        0     3907 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/main.rs
--rw-r--r--   0        0        0     2866 2023-02-21 18:22:51.506194 temporalio-1.1.0/temporalio/bridge/sdk-core/tests/runner.rs
--rw-r--r--   0        0        0    17436 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/src/client.rs
--rw-r--r--   0        0        0     2502 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/src/lib.rs
--rw-r--r--   0        0        0     5871 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/src/runtime.rs
--rw-r--r--   0        0        0     5564 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/src/testing.rs
--rw-r--r--   0        0        0    10805 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/src/worker.rs
--rw-r--r--   0        0        0     2392 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/testing.py
--rw-r--r--   0        0        0    12894 2023-02-21 18:22:49.022218 temporalio-1.1.0/temporalio/bridge/worker.py
--rw-r--r--   0        0        0   174661 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/client.py
--rw-r--r--   0        0        0     8897 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/common.py
--rw-r--r--   0        0        0       57 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/contrib/__init__.py
--rw-r--r--   0        0        0    24052 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/contrib/opentelemetry.py
--rw-r--r--   0        0        0    52324 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/converter.py
--rw-r--r--   0        0        0     9418 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/exceptions.py
--rw-r--r--   0        0        0        0 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/py.typed
--rw-r--r--   0        0        0     6326 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/runtime.py
--rw-r--r--   0        0        0    28537 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/service.py
--rw-r--r--   0        0        0      207 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/testing/__init__.py
--rw-r--r--   0        0        0     6588 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/testing/_activity.py
--rw-r--r--   0        0        0    23598 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/testing/_workflow.py
--rw-r--r--   0        0        0     4313 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/types.py
--rw-r--r--   0        0        0     1709 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/__init__.py
--rw-r--r--   0        0        0    39659 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_activity.py
--rw-r--r--   0        0        0    12027 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_interceptor.py
--rw-r--r--   0        0        0    12890 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_replayer.py
--rw-r--r--   0        0        0    29509 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_worker.py
--rw-r--r--   0        0        0    14191 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_workflow.py
--rw-r--r--   0        0        0    76745 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/_workflow_instance.py
--rw-r--r--   0        0        0     2481 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/workflow_sandbox/__init__.py
--rw-r--r--   0        0        0    17707 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/workflow_sandbox/_importer.py
--rw-r--r--   0        0        0     1817 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/workflow_sandbox/_in_sandbox.py
--rw-r--r--   0        0        0    40240 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/workflow_sandbox/_restrictions.py
--rw-r--r--   0        0        0     6734 2023-02-21 18:22:49.026218 temporalio-1.1.0/temporalio/worker/workflow_sandbox/_runner.py
--rw-r--r--   0        0        0   133186 2023-02-21 18:22:49.030218 temporalio-1.1.0/temporalio/workflow.py
--rw-r--r--   0        0        0    75539 1970-01-01 00:00:00.000000 temporalio-1.1.0/setup.py
--rw-r--r--   0        0        0    66862 1970-01-01 00:00:00.000000 temporalio-1.1.0/PKG-INFO
+-rw-r--r--   0        0        0     1108 2023-05-01 12:07:40.748777 temporalio-1.2.0/LICENSE
+-rw-r--r--   0        0        0    66076 2023-05-01 12:07:40.748777 temporalio-1.2.0/README.md
+-rw-r--r--   0        0        0      899 2023-05-01 12:07:40.748777 temporalio-1.2.0/build.py
+-rw-r--r--   0        0        0     6369 2023-05-01 12:07:40.748777 temporalio-1.2.0/pyproject.toml
+-rw-r--r--   0        0        0      423 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/__init__.py
+-rw-r--r--   0        0        0    14172 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/activity.py
+-rw-r--r--   0        0        0       36 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/__init__.py
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/__init__.py
+-rw-r--r--   0        0        0      336 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/__init__.py
+-rw-r--r--   0        0        0     5919 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.py
+-rw-r--r--   0        0        0     7644 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/__init__.py
+-rw-r--r--   0        0        0      286 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/__init__.py
+-rw-r--r--   0        0        0     5853 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.py
+-rw-r--r--   0        0        0    11757 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/__init__.py
+-rw-r--r--   0        0        0     1476 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/__init__.py
+-rw-r--r--   0        0        0    25839 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/message_pb2.py
+-rw-r--r--   0        0        0    44096 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/command/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/__init__.py
+-rw-r--r--   0        0        0      604 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/__init__.py
+-rw-r--r--   0        0        0     1540 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.py
+-rw-r--r--   0        0        0     1462 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.pyi
+-rw-r--r--   0        0        0    13347 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/message_pb2.py
+-rw-r--r--   0        0        0    16350 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/common/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/__init__.py
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/__init__.py
+-rw-r--r--   0        0        0    22341 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py
+-rw-r--r--   0        0        0    15976 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/__init__.py
+-rw-r--r--   0        0        0     1917 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/__init__.py
+-rw-r--r--   0        0        0     2619 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.py
+-rw-r--r--   0        0        0     3777 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.pyi
+-rw-r--r--   0        0        0     3050 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.py
+-rw-r--r--   0        0        0     4307 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.pyi
+-rw-r--r--   0        0        0     2980 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.py
+-rw-r--r--   0        0        0     4571 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.pyi
+-rw-r--r--   0        0        0     6323 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.py
+-rw-r--r--   0        0        0    19994 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.pyi
+-rw-r--r--   0        0        0     9630 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.py
+-rw-r--r--   0        0        0    18937 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.pyi
+-rw-r--r--   0        0        0     2747 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.py
+-rw-r--r--   0        0        0     4174 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.pyi
+-rw-r--r--   0        0        0     2353 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.py
+-rw-r--r--   0        0        0     3983 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.pyi
+-rw-r--r--   0        0        0     1699 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.py
+-rw-r--r--   0        0        0     2543 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.pyi
+-rw-r--r--   0        0        0     2149 2023-05-01 12:07:40.752776 temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.py
+-rw-r--r--   0        0        0     5644 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.pyi
+-rw-r--r--   0        0        0     2151 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.py
+-rw-r--r--   0        0        0     4744 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.pyi
+-rw-r--r--   0        0        0     2140 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.py
+-rw-r--r--   0        0        0     4852 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/update_pb2.pyi
+-rw-r--r--   0        0        0     7735 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.py
+-rw-r--r--   0        0        0    15052 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/__init__.py
+-rw-r--r--   0        0        0      974 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/__init__.py
+-rw-r--r--   0        0        0    12041 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.py
+-rw-r--r--   0        0        0    10149 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/__init__.py
+-rw-r--r--   0        0        0      530 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/__init__.py
+-rw-r--r--   0        0        0     9303 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.py
+-rw-r--r--   0        0        0    16245 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/__init__.py
+-rw-r--r--   0        0        0      236 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/__init__.py
+-rw-r--r--   0        0        0     4569 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.py
+-rw-r--r--   0        0        0     4131 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/__init__.py
+-rw-r--r--   0        0        0     4622 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/__init__.py
+-rw-r--r--   0        0        0    73415 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/message_pb2.py
+-rw-r--r--   0        0        0   149420 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/history/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/__init__.py
+-rw-r--r--   0        0        0      129 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/__init__.py
+-rw-r--r--   0        0        0     4385 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.py
+-rw-r--r--   0        0        0     7155 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/__init__.py
+-rw-r--r--   0        0        0      300 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/__init__.py
+-rw-r--r--   0        0        0    10762 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.py
+-rw-r--r--   0        0        0    12925 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/__init__.py
+-rw-r--r--   0        0        0     1423 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/__init__.py
+-rw-r--r--   0        0        0    17665 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0    15710 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0     2899 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0    17632 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0     8793 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/__init__.py
+-rw-r--r--   0        0        0       63 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/__init__.py
+-rw-r--r--   0        0        0     2034 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.py
+-rw-r--r--   0        0        0     3657 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/__init__.py
+-rw-r--r--   0        0        0      159 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/__init__.py
+-rw-r--r--   0        0        0     3696 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/message_pb2.py
+-rw-r--r--   0        0        0     5000 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/query/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/__init__.py
+-rw-r--r--   0        0        0      214 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/__init__.py
+-rw-r--r--   0        0        0     4122 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.py
+-rw-r--r--   0        0        0     4288 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/__init__.py
+-rw-r--r--   0        0        0      732 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/__init__.py
+-rw-r--r--   0        0        0    18729 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.py
+-rw-r--r--   0        0        0    38470 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/__init__.py
+-rw-r--r--   0        0        0      122 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/__init__.py
+-rw-r--r--   0        0        0     1979 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.py
+-rw-r--r--   0        0        0     4074 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/sdk/v1/task_complete_metadata_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/taskqueue/__init__.py
+-rw-r--r--   0        0        0      422 2023-05-01 12:07:40.756777 temporalio-1.2.0/temporalio/api/taskqueue/v1/__init__.py
+-rw-r--r--   0        0        0     8133 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.py
+-rw-r--r--   0        0        0    10314 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/__init__.py
+-rw-r--r--   0        0        0      814 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/__init__.py
+-rw-r--r--   0        0        0     7303 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0     4609 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0     2532 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0    14985 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0     9065 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/__init__.py
+-rw-r--r--   0        0        0      308 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/__init__.py
+-rw-r--r--   0        0        0     7265 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/message_pb2.py
+-rw-r--r--   0        0        0    11510 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/update/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/__init__.py
+-rw-r--r--   0        0        0      123 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/__init__.py
+-rw-r--r--   0        0        0     4064 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/message_pb2.py
+-rw-r--r--   0        0        0     5233 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/version/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/__init__.py
+-rw-r--r--   0        0        0      476 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/__init__.py
+-rw-r--r--   0        0        0    15395 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.py
+-rw-r--r--   0        0        0    24729 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/__init__.py
+-rw-r--r--   0        0        0     8749 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/__init__.py
+-rw-r--r--   0        0        0   128676 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.py
+-rw-r--r--   0        0        0   195808 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.py
+-rw-r--r--   0        0        0     1185 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi
+-rw-r--r--   0        0        0    12060 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.py
+-rw-r--r--   0        0        0     1274 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.pyi
+-rw-r--r--   0        0        0   133717 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py
+-rw-r--r--   0        0        0    65016 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi
+-rw-r--r--   0        0        0    75582 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/Cargo.lock
+-rw-r--r--   0        0        0      834 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/Cargo.toml
+-rw-r--r--   0        0        0      122 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/__init__.py
+-rw-r--r--   0        0        0     3601 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/client.py
+-rw-r--r--   0        0        0      144 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/__init__.py
+-rw-r--r--   0        0        0      336 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/__init__.py
+-rw-r--r--   0        0        0     6517 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py
+-rw-r--r--   0        0        0     9319 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi
+-rw-r--r--   0        0        0      171 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/__init__.py
+-rw-r--r--   0        0        0     5900 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py
+-rw-r--r--   0        0        0    11710 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi
+-rw-r--r--   0        0        0     1435 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/__init__.py
+-rw-r--r--   0        0        0    33694 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.py
+-rw-r--r--   0        0        0    35620 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi
+-rw-r--r--   0        0        0      407 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/__init__.py
+-rw-r--r--   0        0        0     6028 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py
+-rw-r--r--   0        0        0     9065 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi
+-rw-r--r--   0        0        0      102 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/__init__.py
+-rw-r--r--   0        0        0     1808 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.py
+-rw-r--r--   0        0        0     1438 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.pyi
+-rw-r--r--   0        0        0     4340 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.py
+-rw-r--r--   0        0        0     2437 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.pyi
+-rw-r--r--   0        0        0      158 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2_grpc.py
+-rw-r--r--   0        0        0       76 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2_grpc.pyi
+-rw-r--r--   0        0        0      145 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/__init__.py
+-rw-r--r--   0        0        0     2882 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.py
+-rw-r--r--   0        0        0     4346 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.760777 temporalio-1.2.0/temporalio/bridge/proto/health/__init__.py
+-rw-r--r--   0        0        0      132 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/__init__.py
+-rw-r--r--   0        0        0     3055 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.py
+-rw-r--r--   0        0        0     2546 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.pyi
+-rw-r--r--   0        0        0     1138 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/__init__.py
+-rw-r--r--   0        0        0    22930 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py
+-rw-r--r--   0        0        0    42958 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi
+-rw-r--r--   0        0        0     1318 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/__init__.py
+-rw-r--r--   0        0        0    34647 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py
+-rw-r--r--   0        0        0    59232 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi
+-rw-r--r--   0        0        0      165 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/__init__.py
+-rw-r--r--   0        0        0     3971 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py
+-rw-r--r--   0        0        0     4425 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi
+-rw-r--r--   0        0        0     1961 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/runtime.py
+-rw-r--r--   0        0        0      198 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/Dockerfile
+-rwxr-xr-x   0        0        0       45 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/build.sh
+-rw-r--r--   0        0        0      616 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml
+-rw-r--r--   0        0        0      963 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml
+-rw-r--r--   0        0        0      839 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml
+-rw-r--r--   0        0        0     1600 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml
+-rw-r--r--   0        0        0      523 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.cargo/config.toml
+-rw-r--r--   0        0        0       39 2023-05-01 12:07:41.304783 temporalio-1.2.0/temporalio/bridge/sdk-core/.git
+-rw-r--r--   0        0        0      695 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.github/workflows/heavy.yml
+-rw-r--r--   0        0        0      278 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/.gitignore
+-rw-r--r--   0        0        0     7864 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/ARCHITECTURE.md
+-rw-r--r--   0        0        0       36 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/CODEOWNERS
+-rw-r--r--   0        0        0      100 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/LICENSE.txt
+-rw-r--r--   0        0        0     4911 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/README.md
+-rw-r--r--   0        0        0      555 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md
+-rw-r--r--   0        0        0     1029 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml
+-rw-r--r--   0        0        0   112308 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg
+-rw-r--r--   0        0        0     3212 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md
+-rw-r--r--   0        0        0      982 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/LICENSE.txt
+-rw-r--r--   0        0        0    53761 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/lib.rs
+-rw-r--r--   0        0        0     6081 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/metrics.rs
+-rw-r--r--   0        0        0    32570 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/raw.rs
+-rw-r--r--   0        0        0    25022 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/retry.rs
+-rw-r--r--   0        0        0     6852 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs
+-rw-r--r--   0        0        0     3569 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/LICENSE.txt
+-rw-r--r--   0        0        0     2426 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs
+-rw-r--r--   0        0        0      836 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions/take_cell.rs
+-rw-r--r--   0        0        0    12182 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/abstractions.rs
+-rw-r--r--   0        0        0    39245 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs
+-rw-r--r--   0        0        0     8003 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs
+-rw-r--r--   0        0        0    10823 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs
+-rw-r--r--   0        0        0    39633 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs
+-rw-r--r--   0        0        0     3130 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs
+-rw-r--r--   0        0        0    30792 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs
+-rw-r--r--   0        0        0     2452 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs
+-rw-r--r--   0        0        0     9544 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs
+-rw-r--r--   0        0        0     4233 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs
+-rw-r--r--   0        0        0    94977 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs
+-rw-r--r--   0        0        0    21721 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs
+-rw-r--r--   0        0        0     8574 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/internal_flags.rs
+-rw-r--r--   0        0        0    10566 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/lib.rs
+-rw-r--r--   0        0        0     1852 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs
+-rw-r--r--   0        0        0     9552 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs
+-rw-r--r--   0        0        0    15879 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs
+-rw-r--r--   0        0        0     7392 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs
+-rw-r--r--   0        0        0     6553 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs
+-rw-r--r--   0        0        0     6400 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs
+-rw-r--r--   0        0        0    16399 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs
+-rw-r--r--   0        0        0    16464 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs
+-rw-r--r--   0        0        0     3055 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs
+-rw-r--r--   0        0        0    32518 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs
+-rw-r--r--   0        0        0    22866 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs
+-rw-r--r--   0        0        0     3324 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_task_poller_stream.rs
+-rw-r--r--   0        0        0    49177 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs
+-rw-r--r--   0        0        0    28757 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs
+-rw-r--r--   0        0        0     4017 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs
+-rw-r--r--   0        0        0    13150 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client.rs
+-rw-r--r--   0        0        0    25181 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs
+-rw-r--r--   0        0        0     1203 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs
+-rw-r--r--   0        0        0     3770 2023-05-01 12:07:41.316783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs
+-rw-r--r--   0        0        0    73489 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/history_update.rs
+-rw-r--r--   0        0        0    34072 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs
+-rw-r--r--   0        0        0    10483 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs
+-rw-r--r--   0        0        0     5365 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs
+-rw-r--r--   0        0        0    36281 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs
+-rw-r--r--   0        0        0     4187 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs
+-rw-r--r--   0        0        0     5137 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs
+-rw-r--r--   0        0        0     3903 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs
+-rw-r--r--   0        0        0    62534 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs
+-rw-r--r--   0        0        0    11457 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs
+-rw-r--r--   0        0        0     5524 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs
+-rw-r--r--   0        0        0    31795 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs
+-rw-r--r--   0        0        0    15993 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs
+-rw-r--r--   0        0        0    14721 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs
+-rw-r--r--   0        0        0     7813 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs
+-rw-r--r--   0        0        0    14499 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/upsert_search_attributes_state_machine.rs
+-rw-r--r--   0        0        0     3069 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs
+-rw-r--r--   0        0        0    59636 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs
+-rw-r--r--   0        0        0     8693 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs
+-rw-r--r--   0        0        0     7766 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs
+-rw-r--r--   0        0        0    55315 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs
+-rw-r--r--   0        0        0    53007 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs
+-rw-r--r--   0        0        0     4561 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs
+-rw-r--r--   0        0        0     5425 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_extraction.rs
+-rw-r--r--   0        0        0     3213 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs
+-rw-r--r--   0        0        0     4024 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/saved_wf_inputs.rs
+-rw-r--r--   0        0        0      509 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream/tonic_status_serde.rs
+-rw-r--r--   0        0        0    29983 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs
+-rw-r--r--   0        0        0      885 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt
+-rw-r--r--   0        0        0     2912 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/errors.rs
+-rw-r--r--   0        0        0     6826 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/lib.rs
+-rw-r--r--   0        0        0     5542 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs
+-rw-r--r--   0        0        0     8185 2023-05-01 12:07:41.312783 temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/worker.rs
+-rw-r--r--   0        0        0     7987 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/deps.svg
+-rw-r--r--   0        0        0       51 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/dynamic-config.yaml
+-rw-r--r--   0        0        0      574 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml
+-rw-r--r--   0        0        0      173 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/prometheus.yaml
+-rwxr-xr-x   0        0        0      204 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/etc/regen-depgraph.sh
+-rw-r--r--   0        0        0      574 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt
+-rw-r--r--   0        0        0      126 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/README.md
+-rw-r--r--   0        0        0      609 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.320783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt
+-rw-r--r--   0        0        0    26246 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs
+-rw-r--r--   0        0        0      191 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/progress.rs
+-rw-r--r--   0        0        0      299 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.rs
+-rw-r--r--   0        0        0      387 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dupe_transitions_fail.stderr
+-rw-r--r--   0        0        0      892 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs
+-rw-r--r--   0        0        0      202 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.rs
+-rw-r--r--   0        0        0      331 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/forgot_name_fail.stderr
+-rw-r--r--   0        0        0      686 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs
+-rw-r--r--   0        0        0      619 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs
+-rw-r--r--   0        0        0      862 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs
+-rw-r--r--   0        0        0      584 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs
+-rw-r--r--   0        0        0      562 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr
+-rw-r--r--   0        0        0      649 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs
+-rw-r--r--   0        0        0      307 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.rs
+-rw-r--r--   0        0        0      161 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/struct_event_variant_fail.stderr
+-rw-r--r--   0        0        0      184 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.rs
+-rw-r--r--   0        0        0      189 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_more_item_event_variant_fail.stderr
+-rw-r--r--   0        0        0      176 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.rs
+-rw-r--r--   0        0        0      181 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/tuple_zero_item_event_variant_fail.stderr
+-rw-r--r--   0        0        0      366 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt
+-rw-r--r--   0        0        0     6524 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/src/lib.rs
+-rw-r--r--   0        0        0      103 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/src/lib.rs
+-rw-r--r--   0        0        0     1206 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/ends_empty_wft_complete.bin
+-rw-r--r--   0        0        0     1853 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-16_history.bin
+-rw-r--r--   0        0        0     3277 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin
+-rw-r--r--   0        0        0     2532 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin
+-rw-r--r--   0        0        0      924 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin
+-rw-r--r--   0        0        0     1701 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/old_change_marker_format.bin
+-rw-r--r--   0        0        0      711 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin
+-rwxr-xr-x   0        0        0      213 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/integ-with-otel.sh
+-rw-r--r--   0        0        0       55 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/Dockerfile
+-rw-r--r--   0        0        0      336 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/docker-compose.yml
+-rw-r--r--   0        0        0      223 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.buildkite/pipeline.yml
+-rw-r--r--   0        0        0      234 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/CODEOWNERS
+-rw-r--r--   0        0        0      227 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/PULL_REQUEST_TEMPLATE.md
+-rw-r--r--   0        0        0      587 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/publish-docs.yml
+-rw-r--r--   0        0        0     1097 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml
+-rw-r--r--   0        0        0       21 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.gitignore
+-rw-r--r--   0        0        0     1108 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE
+-rw-r--r--   0        0        0     2970 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile
+-rw-r--r--   0        0        0      151 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/README.md
+-rw-r--r--   0        0        0     1225 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml
+-rw-r--r--   0        0        0      241 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/buf.yaml
+-rw-r--r--   0        0        0       80 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.mod
+-rw-r--r--   0        0        0      478 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/go.sum
+-rw-r--r--   0        0        0     1350 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go
+-rw-r--r--   0        0        0     4974 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto
+-rw-r--r--   0        0        0      216 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/go.mod
+-rw-r--r--   0        0        0     3791 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto
+-rw-r--r--   0        0        0    12498 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto
+-rw-r--r--   0        0        0     5835 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto
+-rw-r--r--   0        0        0     1916 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto
+-rw-r--r--   0        0        0     2465 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto
+-rw-r--r--   0        0        0     2062 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto
+-rw-r--r--   0        0        0     9826 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto
+-rw-r--r--   0        0        0     7183 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto
+-rw-r--r--   0        0        0     1944 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto
+-rw-r--r--   0        0        0     2098 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto
+-rw-r--r--   0        0        0     1821 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto
+-rw-r--r--   0        0        0     3212 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto
+-rw-r--r--   0        0        0     2619 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto
+-rw-r--r--   0        0        0     2961 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto
+-rw-r--r--   0        0        0     5083 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto
+-rw-r--r--   0        0        0     3815 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto
+-rw-r--r--   0        0        0     4728 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto
+-rw-r--r--   0        0        0     2068 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto
+-rw-r--r--   0        0        0    41215 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto
+-rw-r--r--   0        0        0     4024 2023-05-01 12:07:41.324783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto
+-rw-r--r--   0        0        0     4347 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto
+-rw-r--r--   0        0        0     4034 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto
+-rw-r--r--   0        0        0     2427 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto
+-rw-r--r--   0        0        0     2587 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto
+-rw-r--r--   0        0        0     2212 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto
+-rw-r--r--   0        0        0    17214 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto
+-rw-r--r--   0        0        0     3142 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/sdk/v1/task_complete_metadata.proto
+-rw-r--r--   0        0        0     3714 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto
+-rw-r--r--   0        0        0     3985 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/update/v1/message.proto
+-rw-r--r--   0        0        0     2367 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto
+-rw-r--r--   0        0        0     7039 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto
+-rw-r--r--   0        0        0    55999 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto
+-rw-r--r--   0        0        0    23413 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto
+-rw-r--r--   0        0        0     2416 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto
+-rw-r--r--   0        0        0     2716 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto
+-rw-r--r--   0        0        0     3066 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto
+-rw-r--r--   0        0        0     2322 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto
+-rw-r--r--   0        0        0      516 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/common/common.proto
+-rw-r--r--   0        0        0     1313 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto
+-rw-r--r--   0        0        0     1726 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto
+-rw-r--r--   0        0        0    12378 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto
+-rw-r--r--   0        0        0    14553 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto
+-rw-r--r--   0        0        0     1230 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto
+-rw-r--r--   0        0        0     2854 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile
+-rw-r--r--   0        0        0     1120 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml
+-rw-r--r--   0        0        0      137 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/buf.yaml
+-rw-r--r--   0        0        0     4974 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto
+-rw-r--r--   0        0        0     2178 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto
+-rw-r--r--   0        0        0     4494 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto
+-rw-r--r--   0        0        0       27 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/rustfmt.toml
+-rw-r--r--   0        0        0     1231 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt
+-rw-r--r--   0        0        0     8019 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs
+-rw-r--r--   0        0        0      979 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs
+-rw-r--r--   0        0        0     1789 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs
+-rw-r--r--   0        0        0    31037 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/lib.rs
+-rw-r--r--   0        0        0      523 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs
+-rw-r--r--   0        0        0    11961 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs
+-rw-r--r--   0        0        0    24000 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs
+-rw-r--r--   0        0        0    23056 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs
+-rw-r--r--   0        0        0      861 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml
+-rw-r--r--   0        0        0     1127 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt
+-rw-r--r--   0        0        0     5362 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs
+-rw-r--r--   0        0        0      334 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/constants.rs
+-rw-r--r--   0        0        0    20979 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs
+-rw-r--r--   0        0        0     9296 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs
+-rw-r--r--   0        0        0    89510 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs
+-rw-r--r--   0        0        0     1289 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs
+-rw-r--r--   0        0        0      422 2023-05-01 12:07:41.328783 temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/utilities.rs
+-rw-r--r--   0        0        0      779 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml
+-rw-r--r--   0        0        0    50608 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/canned_histories.rs
+-rw-r--r--   0        0        0     1091 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs
+-rw-r--r--   0        0        0    25400 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs
+-rw-r--r--   0        0        0     1617 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/wf_input_saver.rs
+-rw-r--r--   0        0        0     1148 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/workflows.rs
+-rw-r--r--   0        0        0     4751 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs
+-rw-r--r--   0        0        0     8767 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/heavy_tests.rs
+-rw-r--r--   0        0        0      118 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/activity_functions.rs
+-rw-r--r--   0        0        0     1353 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs
+-rw-r--r--   0        0        0     5118 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs
+-rw-r--r--   0        0        0     8263 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs
+-rw-r--r--   0        0        0     9785 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/metrics_tests.rs
+-rw-r--r--   0        0        0     3333 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs
+-rw-r--r--   0        0        0    11544 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs
+-rw-r--r--   0        0        0     5117 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs
+-rw-r--r--   0        0        0    34711 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs
+-rw-r--r--   0        0        0     1996 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs
+-rw-r--r--   0        0        0     1717 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs
+-rw-r--r--   0        0        0     1629 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs
+-rw-r--r--   0        0        0     4091 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/child_workflows.rs
+-rw-r--r--   0        0        0     1986 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs
+-rw-r--r--   0        0        0     1628 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs
+-rw-r--r--   0        0        0    24856 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs
+-rw-r--r--   0        0        0     1616 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs
+-rw-r--r--   0        0        0     4337 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs
+-rw-r--r--   0        0        0     9832 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs
+-rw-r--r--   0        0        0     3038 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs
+-rw-r--r--   0        0        0     5449 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs
+-rw-r--r--   0        0        0     2947 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs
+-rw-r--r--   0        0        0     3906 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs
+-rw-r--r--   0        0        0     2614 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs
+-rw-r--r--   0        0        0    20756 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs
+-rw-r--r--   0        0        0     3365 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/main.rs
+-rw-r--r--   0        0        0     3998 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/runner.rs
+-rw-r--r--   0        0        0      850 2023-05-01 12:07:41.332783 temporalio-1.2.0/temporalio/bridge/sdk-core/tests/wf_input_replay.rs
+-rw-r--r--   0        0        0    17680 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/client.rs
+-rw-r--r--   0        0        0     2502 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/lib.rs
+-rw-r--r--   0        0        0     6008 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/runtime.rs
+-rw-r--r--   0        0        0     5570 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/testing.rs
+-rw-r--r--   0        0        0    11057 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/src/worker.rs
+-rw-r--r--   0        0        0     2392 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/testing.py
+-rw-r--r--   0        0        0    12926 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/bridge/worker.py
+-rw-r--r--   0        0        0   174661 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/client.py
+-rw-r--r--   0        0        0     8897 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/common.py
+-rw-r--r--   0        0        0       57 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/contrib/__init__.py
+-rw-r--r--   0        0        0    24052 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/contrib/opentelemetry.py
+-rw-r--r--   0        0        0    52438 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/converter.py
+-rw-r--r--   0        0        0     9418 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/exceptions.py
+-rw-r--r--   0        0        0        0 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/py.typed
+-rw-r--r--   0        0        0     6510 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/runtime.py
+-rw-r--r--   0        0        0    28842 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/service.py
+-rw-r--r--   0        0        0      207 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/__init__.py
+-rw-r--r--   0        0        0     6588 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/_activity.py
+-rw-r--r--   0        0        0    23598 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/testing/_workflow.py
+-rw-r--r--   0        0        0     4313 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/types.py
+-rw-r--r--   0        0        0     1832 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/worker/__init__.py
+-rw-r--r--   0        0        0    37852 2023-05-01 12:07:40.764777 temporalio-1.2.0/temporalio/worker/_activity.py
+-rw-r--r--   0        0        0    12027 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_interceptor.py
+-rw-r--r--   0        0        0    12986 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_replayer.py
+-rw-r--r--   0        0        0    30426 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_worker.py
+-rw-r--r--   0        0        0    14858 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_workflow.py
+-rw-r--r--   0        0        0    76745 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/_workflow_instance.py
+-rw-r--r--   0        0        0     2481 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/__init__.py
+-rw-r--r--   0        0        0    17707 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_importer.py
+-rw-r--r--   0        0        0     1817 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_in_sandbox.py
+-rw-r--r--   0        0        0    40240 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_restrictions.py
+-rw-r--r--   0        0        0     6734 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/worker/workflow_sandbox/_runner.py
+-rw-r--r--   0        0        0   133562 2023-05-01 12:07:40.768777 temporalio-1.2.0/temporalio/workflow.py
+-rw-r--r--   0        0        0    76549 1970-01-01 00:00:00.000000 temporalio-1.2.0/setup.py
+-rw-r--r--   0        0        0    67406 1970-01-01 00:00:00.000000 temporalio-1.2.0/PKG-INFO
```

### Comparing `temporalio-1.1.0/LICENSE` & `temporalio-1.2.0/LICENSE`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/README.md` & `temporalio-1.2.0/README.md`

 * *Files 2% similar despite different names*

```diff
@@ -1,8 +1,8 @@
-![Temporal Python SDK](scripts/_img/banner.svg)
+![Temporal Python SDK](https://assets.temporal.io/w/py-banner.svg)
 
 [![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)
 [![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)
 [![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)
 
 [Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to
 execute asynchronous, long-running business logic in a scalable and resilient way.
@@ -88,14 +88,16 @@
       - [Activity Context](#activity-context)
         - [Heartbeating and Cancellation](#heartbeating-and-cancellation)
         - [Worker Shutdown](#worker-shutdown)
       - [Testing](#testing-1)
     - [Workflow Replay](#workflow-replay)
     - [OpenTelemetry Support](#opentelemetry-support)
     - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)
+    - [Known Compatibility Issues](#known-compatibility-issues)
+      - [gevent Patching](#gevent-patching)
 - [Development](#development)
     - [Building](#building)
       - [Prepare](#prepare)
       - [Build](#build)
       - [Use](#use)
     - [Local SDK development environment](#local-sdk-development-environment)
       - [Testing](#testing-2)
@@ -1226,14 +1228,24 @@
 [Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.
 
 To support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python
 versions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest
 protobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as
 [Passthrough Modules](#passthrough-modules).
 
+### Known Compatibility Issues
+
+Below are known compatibility issues with the Python SDK.
+
+#### gevent Patching
+
+When using `gevent.monkey.patch_all()`, asyncio event loops can get messed up, especially those using custom event loops
+like Temporal. See [this gevent issue](https://github.com/gevent/gevent/issues/982) and
+[this Python SDK issue](https://github.com/temporalio/sdk-python/issues/59) for more details.
+
 # Development
 
 The Python SDK is built to work with Python 3.7 and newer. It is built using
 [SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.
 
 ### Building
```

### Comparing `temporalio-1.1.0/build.py` & `temporalio-1.2.0/build.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/pyproject.toml` & `temporalio-1.2.0/pyproject.toml`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 [tool.poetry]
 name = "temporalio"
-version = "1.1.0"
+version = "1.2.0"
 description = "Temporal.io Python SDK"
 license = "MIT"
 authors = ["Temporal Technologies Inc <sdk@temporal.io>"]
 readme = "README.md"
 homepage = "https://github.com/temporalio/sdk-python"
 repository = "https://github.com/temporalio/sdk-python"
 documentation = "https://docs.temporal.io/docs/python"
```

### Comparing `temporalio-1.1.0/temporalio/activity.py` & `temporalio-1.2.0/temporalio/activity.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/batch/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/batch/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/batch/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/cluster/v1/message_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/command/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/command/v1/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,40 +1,36 @@
 from .message_pb2 import (
-    AcceptWorkflowUpdateCommandAttributes,
     CancelTimerCommandAttributes,
     CancelWorkflowExecutionCommandAttributes,
     Command,
     CompleteWorkflowExecutionCommandAttributes,
-    CompleteWorkflowUpdateCommandAttributes,
     ContinueAsNewWorkflowExecutionCommandAttributes,
     FailWorkflowExecutionCommandAttributes,
     ModifyWorkflowPropertiesCommandAttributes,
+    ProtocolMessageCommandAttributes,
     RecordMarkerCommandAttributes,
-    RejectWorkflowUpdateCommandAttributes,
     RequestCancelActivityTaskCommandAttributes,
     RequestCancelExternalWorkflowExecutionCommandAttributes,
     ScheduleActivityTaskCommandAttributes,
     SignalExternalWorkflowExecutionCommandAttributes,
     StartChildWorkflowExecutionCommandAttributes,
     StartTimerCommandAttributes,
     UpsertWorkflowSearchAttributesCommandAttributes,
 )
 
 __all__ = [
-    "AcceptWorkflowUpdateCommandAttributes",
     "CancelTimerCommandAttributes",
     "CancelWorkflowExecutionCommandAttributes",
     "Command",
     "CompleteWorkflowExecutionCommandAttributes",
-    "CompleteWorkflowUpdateCommandAttributes",
     "ContinueAsNewWorkflowExecutionCommandAttributes",
     "FailWorkflowExecutionCommandAttributes",
     "ModifyWorkflowPropertiesCommandAttributes",
+    "ProtocolMessageCommandAttributes",
     "RecordMarkerCommandAttributes",
-    "RejectWorkflowUpdateCommandAttributes",
     "RequestCancelActivityTaskCommandAttributes",
     "RequestCancelExternalWorkflowExecutionCommandAttributes",
     "ScheduleActivityTaskCommandAttributes",
     "SignalExternalWorkflowExecutionCommandAttributes",
     "StartChildWorkflowExecutionCommandAttributes",
     "StartTimerCommandAttributes",
     "UpsertWorkflowSearchAttributesCommandAttributes",
```

### Comparing `temporalio-1.1.0/temporalio/api/command/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/command/v1/message_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,23 +26,20 @@
 )
 from temporalio.api.enums.v1 import (
     workflow_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_workflow__pb2,
 )
 from temporalio.api.failure.v1 import (
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
-from temporalio.api.interaction.v1 import (
-    message_pb2 as temporal_dot_api_dot_interaction_dot_v1_dot_message__pb2,
-)
 from temporalio.api.taskqueue.v1 import (
     message_pb2 as temporal_dot_api_dot_taskqueue_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n%temporal/api/command/v1/message.proto\x12\x17temporal.api.command.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a(temporal/api/enums/v1/command_type.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a)temporal/api/interaction/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\xfb\x04\n%ScheduleActivityTaskCommandAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x1f\n\x17request_eager_execution\x18\x0c \x01(\x08J\x04\x08\x03\x10\x04"H\n*RequestCancelActivityTaskCommandAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03"o\n\x1bStartTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"^\n*CompleteWorkflowExecutionCommandAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n&FailWorkflowExecutionCommandAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"0\n\x1c\x43\x61ncelTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t"]\n(CancelWorkflowExecutionCommandAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xaf\x01\n7RequestCancelExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xa7\x02\n0SignalExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x06 \x01(\x08\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"v\n/UpsertWorkflowSearchAttributesCommandAttributes\x12\x43\n\x11search_attributes\x18\x01 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"`\n)ModifyWorkflowPropertiesCommandAttributes\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xbf\x02\n\x1dRecordMarkerCommandAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.command.v1.RecordMarkerCommandAttributes.DetailsEntry\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xc3\x06\n/ContinueAsNewWorkflowExecutionCommandAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x07 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12@\n\tinitiator\x18\x08 \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\t \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\n \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rcron_schedule\x18\x0b \x01(\t\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xdd\x06\n,StartChildWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12.\n\x06header\x18\x0e \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x0f \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x10 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\x8b\x01\n%AcceptWorkflowUpdateCommandAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x31\n\x05input\x18\x02 \x01(\x0b\x32".temporal.api.interaction.v1.Input"\x8f\x01\n\'CompleteWorkflowUpdateCommandAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x33\n\x06output\x18\x02 \x01(\x0b\x32#.temporal.api.interaction.v1.Output"\x8b\x01\n%RejectWorkflowUpdateCommandAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\x82\x11\n\x07\x43ommand\x12\x38\n\x0c\x63ommand_type\x18\x01 \x01(\x0e\x32".temporal.api.enums.v1.CommandType\x12s\n)schedule_activity_task_command_attributes\x18\x02 \x01(\x0b\x32>.temporal.api.command.v1.ScheduleActivityTaskCommandAttributesH\x00\x12^\n\x1estart_timer_command_attributes\x18\x03 \x01(\x0b\x32\x34.temporal.api.command.v1.StartTimerCommandAttributesH\x00\x12}\n.complete_workflow_execution_command_attributes\x18\x04 \x01(\x0b\x32\x43.temporal.api.command.v1.CompleteWorkflowExecutionCommandAttributesH\x00\x12u\n*fail_workflow_execution_command_attributes\x18\x05 \x01(\x0b\x32?.temporal.api.command.v1.FailWorkflowExecutionCommandAttributesH\x00\x12~\n/request_cancel_activity_task_command_attributes\x18\x06 \x01(\x0b\x32\x43.temporal.api.command.v1.RequestCancelActivityTaskCommandAttributesH\x00\x12`\n\x1f\x63\x61ncel_timer_command_attributes\x18\x07 \x01(\x0b\x32\x35.temporal.api.command.v1.CancelTimerCommandAttributesH\x00\x12y\n,cancel_workflow_execution_command_attributes\x18\x08 \x01(\x0b\x32\x41.temporal.api.command.v1.CancelWorkflowExecutionCommandAttributesH\x00\x12\x99\x01\n=request_cancel_external_workflow_execution_command_attributes\x18\t \x01(\x0b\x32P.temporal.api.command.v1.RequestCancelExternalWorkflowExecutionCommandAttributesH\x00\x12\x62\n record_marker_command_attributes\x18\n \x01(\x0b\x32\x36.temporal.api.command.v1.RecordMarkerCommandAttributesH\x00\x12\x89\x01\n5continue_as_new_workflow_execution_command_attributes\x18\x0b \x01(\x0b\x32H.temporal.api.command.v1.ContinueAsNewWorkflowExecutionCommandAttributesH\x00\x12\x82\x01\n1start_child_workflow_execution_command_attributes\x18\x0c \x01(\x0b\x32\x45.temporal.api.command.v1.StartChildWorkflowExecutionCommandAttributesH\x00\x12\x8a\x01\n5signal_external_workflow_execution_command_attributes\x18\r \x01(\x0b\x32I.temporal.api.command.v1.SignalExternalWorkflowExecutionCommandAttributesH\x00\x12\x88\x01\n4upsert_workflow_search_attributes_command_attributes\x18\x0e \x01(\x0b\x32H.temporal.api.command.v1.UpsertWorkflowSearchAttributesCommandAttributesH\x00\x12s\n)accept_workflow_update_command_attributes\x18\x0f \x01(\x0b\x32>.temporal.api.command.v1.AcceptWorkflowUpdateCommandAttributesH\x00\x12w\n+complete_workflow_update_command_attributes\x18\x10 \x01(\x0b\x32@.temporal.api.command.v1.CompleteWorkflowUpdateCommandAttributesH\x00\x12{\n-modify_workflow_properties_command_attributes\x18\x11 \x01(\x0b\x32\x42.temporal.api.command.v1.ModifyWorkflowPropertiesCommandAttributesH\x00\x12s\n)reject_workflow_update_command_attributes\x18\x12 \x01(\x0b\x32>.temporal.api.command.v1.RejectWorkflowUpdateCommandAttributesH\x00\x42\x0c\n\nattributesB\x8e\x01\n\x1aio.temporal.api.command.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/command/v1;command\xaa\x02\x19Temporalio.Api.Command.V1\xea\x02\x1cTemporalio::Api::Command::V1b\x06proto3'
+    b'\n%temporal/api/command/v1/message.proto\x12\x17temporal.api.command.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a(temporal/api/enums/v1/command_type.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\xfb\x04\n%ScheduleActivityTaskCommandAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x1f\n\x17request_eager_execution\x18\x0c \x01(\x08J\x04\x08\x03\x10\x04"H\n*RequestCancelActivityTaskCommandAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03"o\n\x1bStartTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"^\n*CompleteWorkflowExecutionCommandAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n&FailWorkflowExecutionCommandAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"0\n\x1c\x43\x61ncelTimerCommandAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t"]\n(CancelWorkflowExecutionCommandAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xaf\x01\n7RequestCancelExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xa7\x02\n0SignalExternalWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x06 \x01(\x08\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"v\n/UpsertWorkflowSearchAttributesCommandAttributes\x12\x43\n\x11search_attributes\x18\x01 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"`\n)ModifyWorkflowPropertiesCommandAttributes\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xbf\x02\n\x1dRecordMarkerCommandAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.command.v1.RecordMarkerCommandAttributes.DetailsEntry\x12.\n\x06header\x18\x03 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xc3\x06\n/ContinueAsNewWorkflowExecutionCommandAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x07 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12@\n\tinitiator\x18\x08 \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\t \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\n \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rcron_schedule\x18\x0b \x01(\t\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xdd\x06\n,StartChildWorkflowExecutionCommandAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12.\n\x06header\x18\x0e \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x0f \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x10 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"6\n ProtocolMessageCommandAttributes\x12\x12\n\nmessage_id\x18\x01 \x01(\t"\x89\x0f\n\x07\x43ommand\x12\x38\n\x0c\x63ommand_type\x18\x01 \x01(\x0e\x32".temporal.api.enums.v1.CommandType\x12s\n)schedule_activity_task_command_attributes\x18\x02 \x01(\x0b\x32>.temporal.api.command.v1.ScheduleActivityTaskCommandAttributesH\x00\x12^\n\x1estart_timer_command_attributes\x18\x03 \x01(\x0b\x32\x34.temporal.api.command.v1.StartTimerCommandAttributesH\x00\x12}\n.complete_workflow_execution_command_attributes\x18\x04 \x01(\x0b\x32\x43.temporal.api.command.v1.CompleteWorkflowExecutionCommandAttributesH\x00\x12u\n*fail_workflow_execution_command_attributes\x18\x05 \x01(\x0b\x32?.temporal.api.command.v1.FailWorkflowExecutionCommandAttributesH\x00\x12~\n/request_cancel_activity_task_command_attributes\x18\x06 \x01(\x0b\x32\x43.temporal.api.command.v1.RequestCancelActivityTaskCommandAttributesH\x00\x12`\n\x1f\x63\x61ncel_timer_command_attributes\x18\x07 \x01(\x0b\x32\x35.temporal.api.command.v1.CancelTimerCommandAttributesH\x00\x12y\n,cancel_workflow_execution_command_attributes\x18\x08 \x01(\x0b\x32\x41.temporal.api.command.v1.CancelWorkflowExecutionCommandAttributesH\x00\x12\x99\x01\n=request_cancel_external_workflow_execution_command_attributes\x18\t \x01(\x0b\x32P.temporal.api.command.v1.RequestCancelExternalWorkflowExecutionCommandAttributesH\x00\x12\x62\n record_marker_command_attributes\x18\n \x01(\x0b\x32\x36.temporal.api.command.v1.RecordMarkerCommandAttributesH\x00\x12\x89\x01\n5continue_as_new_workflow_execution_command_attributes\x18\x0b \x01(\x0b\x32H.temporal.api.command.v1.ContinueAsNewWorkflowExecutionCommandAttributesH\x00\x12\x82\x01\n1start_child_workflow_execution_command_attributes\x18\x0c \x01(\x0b\x32\x45.temporal.api.command.v1.StartChildWorkflowExecutionCommandAttributesH\x00\x12\x8a\x01\n5signal_external_workflow_execution_command_attributes\x18\r \x01(\x0b\x32I.temporal.api.command.v1.SignalExternalWorkflowExecutionCommandAttributesH\x00\x12\x88\x01\n4upsert_workflow_search_attributes_command_attributes\x18\x0e \x01(\x0b\x32H.temporal.api.command.v1.UpsertWorkflowSearchAttributesCommandAttributesH\x00\x12h\n#protocol_message_command_attributes\x18\x0f \x01(\x0b\x32\x39.temporal.api.command.v1.ProtocolMessageCommandAttributesH\x00\x12{\n-modify_workflow_properties_command_attributes\x18\x11 \x01(\x0b\x32\x42.temporal.api.command.v1.ModifyWorkflowPropertiesCommandAttributesH\x00\x42\x0c\n\nattributesB\x8e\x01\n\x1aio.temporal.api.command.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/command/v1;command\xaa\x02\x19Temporalio.Api.Command.V1\xea\x02\x1cTemporalio::Api::Command::V1b\x06proto3'
 )
 
 
 _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ScheduleActivityTaskCommandAttributes"
 ]
 _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
@@ -85,22 +82,16 @@
 )
 _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ContinueAsNewWorkflowExecutionCommandAttributes"
 ]
 _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "StartChildWorkflowExecutionCommandAttributes"
 ]
-_ACCEPTWORKFLOWUPDATECOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "AcceptWorkflowUpdateCommandAttributes"
-]
-_COMPLETEWORKFLOWUPDATECOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "CompleteWorkflowUpdateCommandAttributes"
-]
-_REJECTWORKFLOWUPDATECOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "RejectWorkflowUpdateCommandAttributes"
+_PROTOCOLMESSAGECOMMANDATTRIBUTES = DESCRIPTOR.message_types_by_name[
+    "ProtocolMessageCommandAttributes"
 ]
 _COMMAND = DESCRIPTOR.message_types_by_name["Command"]
 ScheduleActivityTaskCommandAttributes = _reflection.GeneratedProtocolMessageType(
     "ScheduleActivityTaskCommandAttributes",
     (_message.Message,),
     {
         "DESCRIPTOR": _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES,
@@ -259,46 +250,24 @@
         "DESCRIPTOR": _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES,
         "__module__": "temporal.api.command.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.command.v1.StartChildWorkflowExecutionCommandAttributes)
     },
 )
 _sym_db.RegisterMessage(StartChildWorkflowExecutionCommandAttributes)
 
-AcceptWorkflowUpdateCommandAttributes = _reflection.GeneratedProtocolMessageType(
-    "AcceptWorkflowUpdateCommandAttributes",
-    (_message.Message,),
-    {
-        "DESCRIPTOR": _ACCEPTWORKFLOWUPDATECOMMANDATTRIBUTES,
-        "__module__": "temporal.api.command.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.command.v1.AcceptWorkflowUpdateCommandAttributes)
-    },
-)
-_sym_db.RegisterMessage(AcceptWorkflowUpdateCommandAttributes)
-
-CompleteWorkflowUpdateCommandAttributes = _reflection.GeneratedProtocolMessageType(
-    "CompleteWorkflowUpdateCommandAttributes",
-    (_message.Message,),
-    {
-        "DESCRIPTOR": _COMPLETEWORKFLOWUPDATECOMMANDATTRIBUTES,
-        "__module__": "temporal.api.command.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.command.v1.CompleteWorkflowUpdateCommandAttributes)
-    },
-)
-_sym_db.RegisterMessage(CompleteWorkflowUpdateCommandAttributes)
-
-RejectWorkflowUpdateCommandAttributes = _reflection.GeneratedProtocolMessageType(
-    "RejectWorkflowUpdateCommandAttributes",
+ProtocolMessageCommandAttributes = _reflection.GeneratedProtocolMessageType(
+    "ProtocolMessageCommandAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _REJECTWORKFLOWUPDATECOMMANDATTRIBUTES,
+        "DESCRIPTOR": _PROTOCOLMESSAGECOMMANDATTRIBUTES,
         "__module__": "temporal.api.command.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.command.v1.RejectWorkflowUpdateCommandAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.command.v1.ProtocolMessageCommandAttributes)
     },
 )
-_sym_db.RegisterMessage(RejectWorkflowUpdateCommandAttributes)
+_sym_db.RegisterMessage(ProtocolMessageCommandAttributes)
 
 Command = _reflection.GeneratedProtocolMessageType(
     "Command",
     (_message.Message,),
     {
         "DESCRIPTOR": _COMMAND,
         "__module__": "temporal.api.command.v1.message_pb2"
@@ -372,46 +341,42 @@
     ]._serialized_options = b"\230\337\037\001"
     _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES.fields_by_name[
         "workflow_task_timeout"
     ]._options = None
     _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES.fields_by_name[
         "workflow_task_timeout"
     ]._serialized_options = b"\230\337\037\001"
-    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 375
-    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 1010
-    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 1012
-    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 1084
-    _STARTTIMERCOMMANDATTRIBUTES._serialized_start = 1086
-    _STARTTIMERCOMMANDATTRIBUTES._serialized_end = 1197
-    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1199
-    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1293
-    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1295
-    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1386
-    _CANCELTIMERCOMMANDATTRIBUTES._serialized_start = 1388
-    _CANCELTIMERCOMMANDATTRIBUTES._serialized_end = 1436
-    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1438
-    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1531
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1534
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1709
-    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1712
-    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 2007
-    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_start = 2009
-    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_end = 2127
-    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_start = 2129
-    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_end = 2225
-    _RECORDMARKERCOMMANDATTRIBUTES._serialized_start = 2228
-    _RECORDMARKERCOMMANDATTRIBUTES._serialized_end = 2547
-    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_start = 2467
-    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_end = 2547
-    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 2550
-    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 3385
-    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 3388
-    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 4249
-    _ACCEPTWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_start = 4252
-    _ACCEPTWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_end = 4391
-    _COMPLETEWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_start = 4394
-    _COMPLETEWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_end = 4537
-    _REJECTWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_start = 4540
-    _REJECTWORKFLOWUPDATECOMMANDATTRIBUTES._serialized_end = 4679
-    _COMMAND._serialized_start = 4682
-    _COMMAND._serialized_end = 6860
+    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 332
+    _SCHEDULEACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 967
+    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_start = 969
+    _REQUESTCANCELACTIVITYTASKCOMMANDATTRIBUTES._serialized_end = 1041
+    _STARTTIMERCOMMANDATTRIBUTES._serialized_start = 1043
+    _STARTTIMERCOMMANDATTRIBUTES._serialized_end = 1154
+    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1156
+    _COMPLETEWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1250
+    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1252
+    _FAILWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1343
+    _CANCELTIMERCOMMANDATTRIBUTES._serialized_start = 1345
+    _CANCELTIMERCOMMANDATTRIBUTES._serialized_end = 1393
+    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1395
+    _CANCELWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1488
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1491
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1666
+    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 1669
+    _SIGNALEXTERNALWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 1964
+    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_start = 1966
+    _UPSERTWORKFLOWSEARCHATTRIBUTESCOMMANDATTRIBUTES._serialized_end = 2084
+    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_start = 2086
+    _MODIFYWORKFLOWPROPERTIESCOMMANDATTRIBUTES._serialized_end = 2182
+    _RECORDMARKERCOMMANDATTRIBUTES._serialized_start = 2185
+    _RECORDMARKERCOMMANDATTRIBUTES._serialized_end = 2504
+    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_start = 2424
+    _RECORDMARKERCOMMANDATTRIBUTES_DETAILSENTRY._serialized_end = 2504
+    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 2507
+    _CONTINUEASNEWWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 3342
+    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_start = 3345
+    _STARTCHILDWORKFLOWEXECUTIONCOMMANDATTRIBUTES._serialized_end = 4206
+    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_start = 4208
+    _PROTOCOLMESSAGECOMMANDATTRIBUTES._serialized_end = 4262
+    _COMMAND._serialized_start = 4265
+    _COMMAND._serialized_end = 6194
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/command/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/command/v1/message_pb2.pyi`

 * *Files 3% similar despite different names*

```diff
@@ -30,15 +30,14 @@
 import google.protobuf.internal.containers
 import google.protobuf.message
 import sys
 import temporalio.api.common.v1.message_pb2
 import temporalio.api.enums.v1.command_type_pb2
 import temporalio.api.enums.v1.workflow_pb2
 import temporalio.api.failure.v1.message_pb2
-import temporalio.api.interaction.v1.message_pb2
 import temporalio.api.taskqueue.v1.message_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
 
@@ -851,91 +850,30 @@
         ],
     ) -> None: ...
 
 global___StartChildWorkflowExecutionCommandAttributes = (
     StartChildWorkflowExecutionCommandAttributes
 )
 
-class AcceptWorkflowUpdateCommandAttributes(google.protobuf.message.Message):
+class ProtocolMessageCommandAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    META_FIELD_NUMBER: builtins.int
-    INPUT_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def input(self) -> temporalio.api.interaction.v1.message_pb2.Input: ...
-    def __init__(
-        self,
-        *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        input: temporalio.api.interaction.v1.message_pb2.Input | None = ...,
-    ) -> None: ...
-    def HasField(
-        self, field_name: typing_extensions.Literal["input", b"input", "meta", b"meta"]
-    ) -> builtins.bool: ...
-    def ClearField(
-        self, field_name: typing_extensions.Literal["input", b"input", "meta", b"meta"]
-    ) -> None: ...
-
-global___AcceptWorkflowUpdateCommandAttributes = AcceptWorkflowUpdateCommandAttributes
-
-class CompleteWorkflowUpdateCommandAttributes(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    META_FIELD_NUMBER: builtins.int
-    OUTPUT_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def output(self) -> temporalio.api.interaction.v1.message_pb2.Output: ...
+    MESSAGE_ID_FIELD_NUMBER: builtins.int
+    message_id: builtins.str
+    """The message ID of the message to which this command is a pointer."""
     def __init__(
         self,
         *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        output: temporalio.api.interaction.v1.message_pb2.Output | None = ...,
+        message_id: builtins.str = ...,
     ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal["meta", b"meta", "output", b"output"],
-    ) -> builtins.bool: ...
     def ClearField(
-        self,
-        field_name: typing_extensions.Literal["meta", b"meta", "output", b"output"],
+        self, field_name: typing_extensions.Literal["message_id", b"message_id"]
     ) -> None: ...
 
-global___CompleteWorkflowUpdateCommandAttributes = (
-    CompleteWorkflowUpdateCommandAttributes
-)
-
-class RejectWorkflowUpdateCommandAttributes(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    META_FIELD_NUMBER: builtins.int
-    FAILURE_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
-    def __init__(
-        self,
-        *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
-    ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal["failure", b"failure", "meta", b"meta"],
-    ) -> builtins.bool: ...
-    def ClearField(
-        self,
-        field_name: typing_extensions.Literal["failure", b"failure", "meta", b"meta"],
-    ) -> None: ...
-
-global___RejectWorkflowUpdateCommandAttributes = RejectWorkflowUpdateCommandAttributes
+global___ProtocolMessageCommandAttributes = ProtocolMessageCommandAttributes
 
 class Command(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMMAND_TYPE_FIELD_NUMBER: builtins.int
     SCHEDULE_ACTIVITY_TASK_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     START_TIMER_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
@@ -946,18 +884,16 @@
     CANCEL_WORKFLOW_EXECUTION_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     RECORD_MARKER_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     CONTINUE_AS_NEW_WORKFLOW_EXECUTION_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     START_CHILD_WORKFLOW_EXECUTION_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     UPSERT_WORKFLOW_SEARCH_ATTRIBUTES_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    ACCEPT_WORKFLOW_UPDATE_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    COMPLETE_WORKFLOW_UPDATE_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    PROTOCOL_MESSAGE_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     MODIFY_WORKFLOW_PROPERTIES_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    REJECT_WORKFLOW_UPDATE_COMMAND_ATTRIBUTES_FIELD_NUMBER: builtins.int
     command_type: temporalio.api.enums.v1.command_type_pb2.CommandType.ValueType
     @property
     def schedule_activity_task_command_attributes(
         self,
     ) -> global___ScheduleActivityTaskCommandAttributes: ...
     @property
     def start_timer_command_attributes(
@@ -1004,29 +940,22 @@
         self,
     ) -> global___SignalExternalWorkflowExecutionCommandAttributes: ...
     @property
     def upsert_workflow_search_attributes_command_attributes(
         self,
     ) -> global___UpsertWorkflowSearchAttributesCommandAttributes: ...
     @property
-    def accept_workflow_update_command_attributes(
+    def protocol_message_command_attributes(
         self,
-    ) -> global___AcceptWorkflowUpdateCommandAttributes: ...
-    @property
-    def complete_workflow_update_command_attributes(
-        self,
-    ) -> global___CompleteWorkflowUpdateCommandAttributes: ...
+    ) -> global___ProtocolMessageCommandAttributes: ...
     @property
     def modify_workflow_properties_command_attributes(
         self,
-    ) -> global___ModifyWorkflowPropertiesCommandAttributes: ...
-    @property
-    def reject_workflow_update_command_attributes(
-        self,
-    ) -> global___RejectWorkflowUpdateCommandAttributes: ...
+    ) -> global___ModifyWorkflowPropertiesCommandAttributes:
+        """16 is available for use - it was used as part of a prototype that never made it into a release"""
     def __init__(
         self,
         *,
         command_type: temporalio.api.enums.v1.command_type_pb2.CommandType.ValueType = ...,
         schedule_activity_task_command_attributes: global___ScheduleActivityTaskCommandAttributes
         | None = ...,
         start_timer_command_attributes: global___StartTimerCommandAttributes
@@ -1049,48 +978,40 @@
         | None = ...,
         start_child_workflow_execution_command_attributes: global___StartChildWorkflowExecutionCommandAttributes
         | None = ...,
         signal_external_workflow_execution_command_attributes: global___SignalExternalWorkflowExecutionCommandAttributes
         | None = ...,
         upsert_workflow_search_attributes_command_attributes: global___UpsertWorkflowSearchAttributesCommandAttributes
         | None = ...,
-        accept_workflow_update_command_attributes: global___AcceptWorkflowUpdateCommandAttributes
-        | None = ...,
-        complete_workflow_update_command_attributes: global___CompleteWorkflowUpdateCommandAttributes
+        protocol_message_command_attributes: global___ProtocolMessageCommandAttributes
         | None = ...,
         modify_workflow_properties_command_attributes: global___ModifyWorkflowPropertiesCommandAttributes
         | None = ...,
-        reject_workflow_update_command_attributes: global___RejectWorkflowUpdateCommandAttributes
-        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "accept_workflow_update_command_attributes",
-            b"accept_workflow_update_command_attributes",
             "attributes",
             b"attributes",
             "cancel_timer_command_attributes",
             b"cancel_timer_command_attributes",
             "cancel_workflow_execution_command_attributes",
             b"cancel_workflow_execution_command_attributes",
             "complete_workflow_execution_command_attributes",
             b"complete_workflow_execution_command_attributes",
-            "complete_workflow_update_command_attributes",
-            b"complete_workflow_update_command_attributes",
             "continue_as_new_workflow_execution_command_attributes",
             b"continue_as_new_workflow_execution_command_attributes",
             "fail_workflow_execution_command_attributes",
             b"fail_workflow_execution_command_attributes",
             "modify_workflow_properties_command_attributes",
             b"modify_workflow_properties_command_attributes",
+            "protocol_message_command_attributes",
+            b"protocol_message_command_attributes",
             "record_marker_command_attributes",
             b"record_marker_command_attributes",
-            "reject_workflow_update_command_attributes",
-            b"reject_workflow_update_command_attributes",
             "request_cancel_activity_task_command_attributes",
             b"request_cancel_activity_task_command_attributes",
             "request_cancel_external_workflow_execution_command_attributes",
             b"request_cancel_external_workflow_execution_command_attributes",
             "schedule_activity_task_command_attributes",
             b"schedule_activity_task_command_attributes",
             "signal_external_workflow_execution_command_attributes",
@@ -1102,38 +1023,34 @@
             "upsert_workflow_search_attributes_command_attributes",
             b"upsert_workflow_search_attributes_command_attributes",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "accept_workflow_update_command_attributes",
-            b"accept_workflow_update_command_attributes",
             "attributes",
             b"attributes",
             "cancel_timer_command_attributes",
             b"cancel_timer_command_attributes",
             "cancel_workflow_execution_command_attributes",
             b"cancel_workflow_execution_command_attributes",
             "command_type",
             b"command_type",
             "complete_workflow_execution_command_attributes",
             b"complete_workflow_execution_command_attributes",
-            "complete_workflow_update_command_attributes",
-            b"complete_workflow_update_command_attributes",
             "continue_as_new_workflow_execution_command_attributes",
             b"continue_as_new_workflow_execution_command_attributes",
             "fail_workflow_execution_command_attributes",
             b"fail_workflow_execution_command_attributes",
             "modify_workflow_properties_command_attributes",
             b"modify_workflow_properties_command_attributes",
+            "protocol_message_command_attributes",
+            b"protocol_message_command_attributes",
             "record_marker_command_attributes",
             b"record_marker_command_attributes",
-            "reject_workflow_update_command_attributes",
-            b"reject_workflow_update_command_attributes",
             "request_cancel_activity_task_command_attributes",
             b"request_cancel_activity_task_command_attributes",
             "request_cancel_external_workflow_execution_command_attributes",
             b"request_cancel_external_workflow_execution_command_attributes",
             "schedule_activity_task_command_attributes",
             b"schedule_activity_task_command_attributes",
             "signal_external_workflow_execution_command_attributes",
@@ -1159,16 +1076,14 @@
             "cancel_workflow_execution_command_attributes",
             "request_cancel_external_workflow_execution_command_attributes",
             "record_marker_command_attributes",
             "continue_as_new_workflow_execution_command_attributes",
             "start_child_workflow_execution_command_attributes",
             "signal_external_workflow_execution_command_attributes",
             "upsert_workflow_search_attributes_command_attributes",
-            "accept_workflow_update_command_attributes",
-            "complete_workflow_update_command_attributes",
+            "protocol_message_command_attributes",
             "modify_workflow_properties_command_attributes",
-            "reject_workflow_update_command_attributes",
         ]
         | None
     ): ...
 
 global___Command = Command
```

### Comparing `temporalio-1.1.0/temporalio/api/common/v1/grpc_status_pb2.py` & `temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/common/v1/grpc_status_pb2.pyi` & `temporalio-1.2.0/temporalio/api/common/v1/grpc_status_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/common/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/common/v1/message_pb2.py`

 * *Files 13% similar despite different names*

```diff
@@ -19,15 +19,15 @@
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     common_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n$temporal/api/common/v1/message.proto\x12\x16temporal.api.common.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a"temporal/api/enums/v1/common.proto"T\n\x08\x44\x61taBlob\x12:\n\rencoding_type\x18\x01 \x01(\x0e\x32#.temporal.api.enums.v1.EncodingType\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c"=\n\x08Payloads\x12\x31\n\x08payloads\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x89\x01\n\x07Payload\x12?\n\x08metadata\x18\x01 \x03(\x0b\x32-.temporal.api.common.v1.Payload.MetadataEntry\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c\x1a/\n\rMetadataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01"\xbe\x01\n\x10SearchAttributes\x12S\n\x0eindexed_fields\x18\x01 \x03(\x0b\x32;.temporal.api.common.v1.SearchAttributes.IndexedFieldsEntry\x1aU\n\x12IndexedFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x90\x01\n\x04Memo\x12\x38\n\x06\x66ields\x18\x01 \x03(\x0b\x32(.temporal.api.common.v1.Memo.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x94\x01\n\x06Header\x12:\n\x06\x66ields\x18\x01 \x03(\x0b\x32*.temporal.api.common.v1.Header.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"8\n\x11WorkflowExecution\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"\x1c\n\x0cWorkflowType\x12\x0c\n\x04name\x18\x01 \x01(\t"\x1c\n\x0c\x41\x63tivityType\x12\x0c\n\x04name\x18\x01 \x01(\t"\xdd\x01\n\x0bRetryPolicy\x12\x39\n\x10initial_interval\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x1b\n\x13\x62\x61\x63koff_coefficient\x18\x02 \x01(\x01\x12\x39\n\x10maximum_interval\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x18\n\x10maximum_attempts\x18\x04 \x01(\x05\x12!\n\x19non_retryable_error_types\x18\x05 \x03(\tB\x89\x01\n\x19io.temporal.api.common.v1B\x0cMessageProtoP\x01Z#go.temporal.io/api/common/v1;common\xaa\x02\x18Temporalio.Api.Common.V1\xea\x02\x1bTemporalio::Api::Common::V1b\x06proto3'
+    b'\n$temporal/api/common/v1/message.proto\x12\x16temporal.api.common.v1\x1a\x1egoogle/protobuf/duration.proto\x1a!dependencies/gogoproto/gogo.proto\x1a"temporal/api/enums/v1/common.proto"T\n\x08\x44\x61taBlob\x12:\n\rencoding_type\x18\x01 \x01(\x0e\x32#.temporal.api.enums.v1.EncodingType\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c"=\n\x08Payloads\x12\x31\n\x08payloads\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x89\x01\n\x07Payload\x12?\n\x08metadata\x18\x01 \x03(\x0b\x32-.temporal.api.common.v1.Payload.MetadataEntry\x12\x0c\n\x04\x64\x61ta\x18\x02 \x01(\x0c\x1a/\n\rMetadataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\x0c:\x02\x38\x01"\xbe\x01\n\x10SearchAttributes\x12S\n\x0eindexed_fields\x18\x01 \x03(\x0b\x32;.temporal.api.common.v1.SearchAttributes.IndexedFieldsEntry\x1aU\n\x12IndexedFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x90\x01\n\x04Memo\x12\x38\n\x06\x66ields\x18\x01 \x03(\x0b\x32(.temporal.api.common.v1.Memo.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x94\x01\n\x06Header\x12:\n\x06\x66ields\x18\x01 \x03(\x0b\x32*.temporal.api.common.v1.Header.FieldsEntry\x1aN\n\x0b\x46ieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"8\n\x11WorkflowExecution\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t"\x1c\n\x0cWorkflowType\x12\x0c\n\x04name\x18\x01 \x01(\t"\x1c\n\x0c\x41\x63tivityType\x12\x0c\n\x04name\x18\x01 \x01(\t"\xdd\x01\n\x0bRetryPolicy\x12\x39\n\x10initial_interval\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x1b\n\x13\x62\x61\x63koff_coefficient\x18\x02 \x01(\x01\x12\x39\n\x10maximum_interval\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x18\n\x10maximum_attempts\x18\x04 \x01(\x05\x12!\n\x19non_retryable_error_types\x18\x05 \x03(\t"F\n\x10MeteringMetadata\x12\x32\n*nonfirst_local_activity_execution_attempts\x18\r \x01(\r"9\n\x12WorkerVersionStamp\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12\x11\n\tbundle_id\x18\x02 \x01(\t"-\n\x19WorkerVersionCapabilities\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\tB\x89\x01\n\x19io.temporal.api.common.v1B\x0cMessageProtoP\x01Z#go.temporal.io/api/common/v1;common\xaa\x02\x18Temporalio.Api.Common.V1\xea\x02\x1bTemporalio::Api::Common::V1b\x06proto3'
 )
 
 
 _DATABLOB = DESCRIPTOR.message_types_by_name["DataBlob"]
 _PAYLOADS = DESCRIPTOR.message_types_by_name["Payloads"]
 _PAYLOAD = DESCRIPTOR.message_types_by_name["Payload"]
 _PAYLOAD_METADATAENTRY = _PAYLOAD.nested_types_by_name["MetadataEntry"]
@@ -39,14 +39,19 @@
 _MEMO_FIELDSENTRY = _MEMO.nested_types_by_name["FieldsEntry"]
 _HEADER = DESCRIPTOR.message_types_by_name["Header"]
 _HEADER_FIELDSENTRY = _HEADER.nested_types_by_name["FieldsEntry"]
 _WORKFLOWEXECUTION = DESCRIPTOR.message_types_by_name["WorkflowExecution"]
 _WORKFLOWTYPE = DESCRIPTOR.message_types_by_name["WorkflowType"]
 _ACTIVITYTYPE = DESCRIPTOR.message_types_by_name["ActivityType"]
 _RETRYPOLICY = DESCRIPTOR.message_types_by_name["RetryPolicy"]
+_METERINGMETADATA = DESCRIPTOR.message_types_by_name["MeteringMetadata"]
+_WORKERVERSIONSTAMP = DESCRIPTOR.message_types_by_name["WorkerVersionStamp"]
+_WORKERVERSIONCAPABILITIES = DESCRIPTOR.message_types_by_name[
+    "WorkerVersionCapabilities"
+]
 DataBlob = _reflection.GeneratedProtocolMessageType(
     "DataBlob",
     (_message.Message,),
     {
         "DESCRIPTOR": _DATABLOB,
         "__module__": "temporal.api.common.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.common.v1.DataBlob)
@@ -189,14 +194,47 @@
         "DESCRIPTOR": _RETRYPOLICY,
         "__module__": "temporal.api.common.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.common.v1.RetryPolicy)
     },
 )
 _sym_db.RegisterMessage(RetryPolicy)
 
+MeteringMetadata = _reflection.GeneratedProtocolMessageType(
+    "MeteringMetadata",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _METERINGMETADATA,
+        "__module__": "temporal.api.common.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.common.v1.MeteringMetadata)
+    },
+)
+_sym_db.RegisterMessage(MeteringMetadata)
+
+WorkerVersionStamp = _reflection.GeneratedProtocolMessageType(
+    "WorkerVersionStamp",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _WORKERVERSIONSTAMP,
+        "__module__": "temporal.api.common.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.common.v1.WorkerVersionStamp)
+    },
+)
+_sym_db.RegisterMessage(WorkerVersionStamp)
+
+WorkerVersionCapabilities = _reflection.GeneratedProtocolMessageType(
+    "WorkerVersionCapabilities",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _WORKERVERSIONCAPABILITIES,
+        "__module__": "temporal.api.common.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.common.v1.WorkerVersionCapabilities)
+    },
+)
+_sym_db.RegisterMessage(WorkerVersionCapabilities)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\031io.temporal.api.common.v1B\014MessageProtoP\001Z#go.temporal.io/api/common/v1;common\252\002\030Temporalio.Api.Common.V1\352\002\033Temporalio::Api::Common::V1"
     _PAYLOAD_METADATAENTRY._options = None
     _PAYLOAD_METADATAENTRY._serialized_options = b"8\001"
     _SEARCHATTRIBUTES_INDEXEDFIELDSENTRY._options = None
     _SEARCHATTRIBUTES_INDEXEDFIELDSENTRY._serialized_options = b"8\001"
@@ -236,8 +274,14 @@
     _WORKFLOWEXECUTION._serialized_end = 1003
     _WORKFLOWTYPE._serialized_start = 1005
     _WORKFLOWTYPE._serialized_end = 1033
     _ACTIVITYTYPE._serialized_start = 1035
     _ACTIVITYTYPE._serialized_end = 1063
     _RETRYPOLICY._serialized_start = 1066
     _RETRYPOLICY._serialized_end = 1287
+    _METERINGMETADATA._serialized_start = 1289
+    _METERINGMETADATA._serialized_end = 1359
+    _WORKERVERSIONSTAMP._serialized_start = 1361
+    _WORKERVERSIONSTAMP._serialized_end = 1418
+    _WORKERVERSIONCAPABILITIES._serialized_start = 1420
+    _WORKERVERSIONCAPABILITIES._serialized_end = 1465
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/common/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/common/v1/message_pb2.pyi`

 * *Files 8% similar despite different names*

```diff
@@ -404,7 +404,83 @@
             b"maximum_interval",
             "non_retryable_error_types",
             b"non_retryable_error_types",
         ],
     ) -> None: ...
 
 global___RetryPolicy = RetryPolicy
+
+class MeteringMetadata(google.protobuf.message.Message):
+    """Metadata relevant for metering purposes"""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    NONFIRST_LOCAL_ACTIVITY_EXECUTION_ATTEMPTS_FIELD_NUMBER: builtins.int
+    nonfirst_local_activity_execution_attempts: builtins.int
+    """Count of local activities which have begun an execution attempt during this workflow task,
+    and whose first attempt occurred in some previous task. This is used for metering
+    purposes, and does not affect workflow state.
+
+    (-- api-linter: core::0141::forbidden-types=disabled
+        aip.dev/not-precedent: Negative values make no sense to represent. --)
+    """
+    def __init__(
+        self,
+        *,
+        nonfirst_local_activity_execution_attempts: builtins.int = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "nonfirst_local_activity_execution_attempts",
+            b"nonfirst_local_activity_execution_attempts",
+        ],
+    ) -> None: ...
+
+global___MeteringMetadata = MeteringMetadata
+
+class WorkerVersionStamp(google.protobuf.message.Message):
+    """Identifies the version(s) of a worker that processed a task"""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    BUILD_ID_FIELD_NUMBER: builtins.int
+    BUNDLE_ID_FIELD_NUMBER: builtins.int
+    build_id: builtins.str
+    """An opaque whole-worker identifier"""
+    bundle_id: builtins.str
+    """Set if the worker used a dynamically loadable bundle to process
+    the task. The bundle could be a WASM blob, JS bundle, etc.
+    """
+    def __init__(
+        self,
+        *,
+        build_id: builtins.str = ...,
+        bundle_id: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "build_id", b"build_id", "bundle_id", b"bundle_id"
+        ],
+    ) -> None: ...
+
+global___WorkerVersionStamp = WorkerVersionStamp
+
+class WorkerVersionCapabilities(google.protobuf.message.Message):
+    """Identifies the version(s) that a worker is compatible with when polling or identifying itself"""
+
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    BUILD_ID_FIELD_NUMBER: builtins.int
+    build_id: builtins.str
+    """An opaque whole-worker identifier"""
+    def __init__(
+        self,
+        *,
+        build_id: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self, field_name: typing_extensions.Literal["build_id", b"build_id"]
+    ) -> None: ...
+
+global___WorkerVersionCapabilities = WorkerVersionCapabilities
```

### Comparing `temporalio-1.1.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py` & `temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi` & `temporalio-1.2.0/temporalio/api/dependencies/gogoproto/gogo_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/enums/v1/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,21 +5,20 @@
 from .failed_cause_pb2 import (
     CancelExternalWorkflowExecutionFailedCause,
     ResourceExhaustedCause,
     SignalExternalWorkflowExecutionFailedCause,
     StartChildWorkflowExecutionFailedCause,
     WorkflowTaskFailedCause,
 )
-from .interaction_type_pb2 import InteractionType
 from .namespace_pb2 import ArchivalState, NamespaceState, ReplicationState
 from .query_pb2 import QueryRejectCondition, QueryResultType
 from .reset_pb2 import ResetReapplyType
 from .schedule_pb2 import ScheduleOverlapPolicy
 from .task_queue_pb2 import TaskQueueKind, TaskQueueType
-from .update_pb2 import WorkflowUpdateResultAccessStyle
+from .update_pb2 import UpdateWorkflowExecutionLifecycleStage
 from .workflow_pb2 import (
     ContinueAsNewInitiator,
     HistoryEventFilterType,
     ParentClosePolicy,
     PendingActivityState,
     PendingWorkflowTaskState,
     RetryState,
@@ -35,15 +34,14 @@
     "CancelExternalWorkflowExecutionFailedCause",
     "CommandType",
     "ContinueAsNewInitiator",
     "EncodingType",
     "EventType",
     "HistoryEventFilterType",
     "IndexedValueType",
-    "InteractionType",
     "NamespaceState",
     "ParentClosePolicy",
     "PendingActivityState",
     "PendingWorkflowTaskState",
     "QueryRejectCondition",
     "QueryResultType",
     "ReplicationState",
@@ -53,12 +51,12 @@
     "ScheduleOverlapPolicy",
     "Severity",
     "SignalExternalWorkflowExecutionFailedCause",
     "StartChildWorkflowExecutionFailedCause",
     "TaskQueueKind",
     "TaskQueueType",
     "TimeoutType",
+    "UpdateWorkflowExecutionLifecycleStage",
     "WorkflowExecutionStatus",
     "WorkflowIdReusePolicy",
     "WorkflowTaskFailedCause",
-    "WorkflowUpdateResultAccessStyle",
 ]
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/batch_operation_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/batch_operation_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/batch_operation_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/command_type_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.py`

 * *Files 15% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b"\n(temporal/api/enums/v1/command_type.proto\x12\x15temporal.api.enums.v1*\x9a\x06\n\x0b\x43ommandType\x12\x1c\n\x18\x43OMMAND_TYPE_UNSPECIFIED\x10\x00\x12'\n#COMMAND_TYPE_SCHEDULE_ACTIVITY_TASK\x10\x01\x12-\n)COMMAND_TYPE_REQUEST_CANCEL_ACTIVITY_TASK\x10\x02\x12\x1c\n\x18\x43OMMAND_TYPE_START_TIMER\x10\x03\x12,\n(COMMAND_TYPE_COMPLETE_WORKFLOW_EXECUTION\x10\x04\x12(\n$COMMAND_TYPE_FAIL_WORKFLOW_EXECUTION\x10\x05\x12\x1d\n\x19\x43OMMAND_TYPE_CANCEL_TIMER\x10\x06\x12*\n&COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION\x10\x07\x12;\n7COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION\x10\x08\x12\x1e\n\x1a\x43OMMAND_TYPE_RECORD_MARKER\x10\t\x12\x33\n/COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION\x10\n\x12/\n+COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION\x10\x0b\x12\x33\n/COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION\x10\x0c\x12\x32\n.COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES\x10\r\x12'\n#COMMAND_TYPE_ACCEPT_WORKFLOW_UPDATE\x10\x0e\x12)\n%COMMAND_TYPE_COMPLETE_WORKFLOW_UPDATE\x10\x0f\x12+\n'COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES\x10\x10\x12'\n#COMMAND_TYPE_REJECT_WORKFLOW_UPDATE\x10\x11\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x43ommandTypeProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3"
+    b"\n(temporal/api/enums/v1/command_type.proto\x12\x15temporal.api.enums.v1*\xc0\x05\n\x0b\x43ommandType\x12\x1c\n\x18\x43OMMAND_TYPE_UNSPECIFIED\x10\x00\x12'\n#COMMAND_TYPE_SCHEDULE_ACTIVITY_TASK\x10\x01\x12-\n)COMMAND_TYPE_REQUEST_CANCEL_ACTIVITY_TASK\x10\x02\x12\x1c\n\x18\x43OMMAND_TYPE_START_TIMER\x10\x03\x12,\n(COMMAND_TYPE_COMPLETE_WORKFLOW_EXECUTION\x10\x04\x12(\n$COMMAND_TYPE_FAIL_WORKFLOW_EXECUTION\x10\x05\x12\x1d\n\x19\x43OMMAND_TYPE_CANCEL_TIMER\x10\x06\x12*\n&COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION\x10\x07\x12;\n7COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION\x10\x08\x12\x1e\n\x1a\x43OMMAND_TYPE_RECORD_MARKER\x10\t\x12\x33\n/COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION\x10\n\x12/\n+COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION\x10\x0b\x12\x33\n/COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION\x10\x0c\x12\x32\n.COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES\x10\r\x12!\n\x1d\x43OMMAND_TYPE_PROTOCOL_MESSAGE\x10\x0e\x12+\n'COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES\x10\x10\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x43ommandTypeProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3"
 )
 
 _COMMANDTYPE = DESCRIPTOR.enum_types_by_name["CommandType"]
 CommandType = enum_type_wrapper.EnumTypeWrapper(_COMMANDTYPE)
 COMMAND_TYPE_UNSPECIFIED = 0
 COMMAND_TYPE_SCHEDULE_ACTIVITY_TASK = 1
 COMMAND_TYPE_REQUEST_CANCEL_ACTIVITY_TASK = 2
@@ -30,19 +30,17 @@
 COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION = 7
 COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION = 8
 COMMAND_TYPE_RECORD_MARKER = 9
 COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION = 10
 COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION = 11
 COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION = 12
 COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES = 13
-COMMAND_TYPE_ACCEPT_WORKFLOW_UPDATE = 14
-COMMAND_TYPE_COMPLETE_WORKFLOW_UPDATE = 15
+COMMAND_TYPE_PROTOCOL_MESSAGE = 14
 COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES = 16
-COMMAND_TYPE_REJECT_WORKFLOW_UPDATE = 17
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\020CommandTypeProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _COMMANDTYPE._serialized_start = 68
-    _COMMANDTYPE._serialized_end = 862
+    _COMMANDTYPE._serialized_end = 772
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/command_type_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/command_type_pb2.pyi`

 * *Files 16% similar despite different names*

```diff
@@ -55,22 +55,16 @@
     COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION: _CommandType.ValueType  # 7
     COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION: _CommandType.ValueType  # 8
     COMMAND_TYPE_RECORD_MARKER: _CommandType.ValueType  # 9
     COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION: _CommandType.ValueType  # 10
     COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION: _CommandType.ValueType  # 11
     COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION: _CommandType.ValueType  # 12
     COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES: _CommandType.ValueType  # 13
-    COMMAND_TYPE_ACCEPT_WORKFLOW_UPDATE: _CommandType.ValueType  # 14
-    """Indicates that an update has been accepted for processing workflow code"""
-    COMMAND_TYPE_COMPLETE_WORKFLOW_UPDATE: _CommandType.ValueType  # 15
-    """Indicates that an update has completed and carries either the success or
-    failure outcome of said update.
-    """
+    COMMAND_TYPE_PROTOCOL_MESSAGE: _CommandType.ValueType  # 14
     COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES: _CommandType.ValueType  # 16
-    COMMAND_TYPE_REJECT_WORKFLOW_UPDATE: _CommandType.ValueType  # 17
 
 class CommandType(_CommandType, metaclass=_CommandTypeEnumTypeWrapper):
     """Whenever this list of command types is changed do change the function shouldBufferEvent in mutableStateBuilder.go to make sure to do the correct event ordering."""
 
 COMMAND_TYPE_UNSPECIFIED: CommandType.ValueType  # 0
 COMMAND_TYPE_SCHEDULE_ACTIVITY_TASK: CommandType.ValueType  # 1
 COMMAND_TYPE_REQUEST_CANCEL_ACTIVITY_TASK: CommandType.ValueType  # 2
@@ -81,16 +75,10 @@
 COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION: CommandType.ValueType  # 7
 COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION: CommandType.ValueType  # 8
 COMMAND_TYPE_RECORD_MARKER: CommandType.ValueType  # 9
 COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION: CommandType.ValueType  # 10
 COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION: CommandType.ValueType  # 11
 COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION: CommandType.ValueType  # 12
 COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES: CommandType.ValueType  # 13
-COMMAND_TYPE_ACCEPT_WORKFLOW_UPDATE: CommandType.ValueType  # 14
-"""Indicates that an update has been accepted for processing workflow code"""
-COMMAND_TYPE_COMPLETE_WORKFLOW_UPDATE: CommandType.ValueType  # 15
-"""Indicates that an update has completed and carries either the success or
-failure outcome of said update.
-"""
+COMMAND_TYPE_PROTOCOL_MESSAGE: CommandType.ValueType  # 14
 COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES: CommandType.ValueType  # 16
-COMMAND_TYPE_REJECT_WORKFLOW_UPDATE: CommandType.ValueType  # 17
 global___CommandType = CommandType
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/common_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/common_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/common_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/event_type_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n&temporal/api/enums/v1/event_type.proto\x12\x15temporal.api.enums.v1*\xf0\x10\n\tEventType\x12\x1a\n\x16\x45VENT_TYPE_UNSPECIFIED\x10\x00\x12)\n%EVENT_TYPE_WORKFLOW_EXECUTION_STARTED\x10\x01\x12+\n\'EVENT_TYPE_WORKFLOW_EXECUTION_COMPLETED\x10\x02\x12(\n$EVENT_TYPE_WORKFLOW_EXECUTION_FAILED\x10\x03\x12+\n\'EVENT_TYPE_WORKFLOW_EXECUTION_TIMED_OUT\x10\x04\x12&\n"EVENT_TYPE_WORKFLOW_TASK_SCHEDULED\x10\x05\x12$\n EVENT_TYPE_WORKFLOW_TASK_STARTED\x10\x06\x12&\n"EVENT_TYPE_WORKFLOW_TASK_COMPLETED\x10\x07\x12&\n"EVENT_TYPE_WORKFLOW_TASK_TIMED_OUT\x10\x08\x12#\n\x1f\x45VENT_TYPE_WORKFLOW_TASK_FAILED\x10\t\x12&\n"EVENT_TYPE_ACTIVITY_TASK_SCHEDULED\x10\n\x12$\n EVENT_TYPE_ACTIVITY_TASK_STARTED\x10\x0b\x12&\n"EVENT_TYPE_ACTIVITY_TASK_COMPLETED\x10\x0c\x12#\n\x1f\x45VENT_TYPE_ACTIVITY_TASK_FAILED\x10\r\x12&\n"EVENT_TYPE_ACTIVITY_TASK_TIMED_OUT\x10\x0e\x12-\n)EVENT_TYPE_ACTIVITY_TASK_CANCEL_REQUESTED\x10\x0f\x12%\n!EVENT_TYPE_ACTIVITY_TASK_CANCELED\x10\x10\x12\x1c\n\x18\x45VENT_TYPE_TIMER_STARTED\x10\x11\x12\x1a\n\x16\x45VENT_TYPE_TIMER_FIRED\x10\x12\x12\x1d\n\x19\x45VENT_TYPE_TIMER_CANCELED\x10\x13\x12\x32\n.EVENT_TYPE_WORKFLOW_EXECUTION_CANCEL_REQUESTED\x10\x14\x12*\n&EVENT_TYPE_WORKFLOW_EXECUTION_CANCELED\x10\x15\x12\x43\n?EVENT_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED\x10\x16\x12@\n<EVENT_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED\x10\x17\x12;\n7EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_CANCEL_REQUESTED\x10\x18\x12\x1e\n\x1a\x45VENT_TYPE_MARKER_RECORDED\x10\x19\x12*\n&EVENT_TYPE_WORKFLOW_EXECUTION_SIGNALED\x10\x1a\x12,\n(EVENT_TYPE_WORKFLOW_EXECUTION_TERMINATED\x10\x1b\x12\x32\n.EVENT_TYPE_WORKFLOW_EXECUTION_CONTINUED_AS_NEW\x10\x1c\x12\x37\n3EVENT_TYPE_START_CHILD_WORKFLOW_EXECUTION_INITIATED\x10\x1d\x12\x34\n0EVENT_TYPE_START_CHILD_WORKFLOW_EXECUTION_FAILED\x10\x1e\x12/\n+EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_STARTED\x10\x1f\x12\x31\n-EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_COMPLETED\x10 \x12.\n*EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_FAILED\x10!\x12\x30\n,EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_CANCELED\x10"\x12\x31\n-EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TIMED_OUT\x10#\x12\x32\n.EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TERMINATED\x10$\x12;\n7EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED\x10%\x12\x38\n4EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED\x10&\x12\x33\n/EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED\x10\'\x12\x30\n,EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES\x10(\x12\'\n#EVENT_TYPE_WORKFLOW_UPDATE_REJECTED\x10)\x12\'\n#EVENT_TYPE_WORKFLOW_UPDATE_ACCEPTED\x10*\x12(\n$EVENT_TYPE_WORKFLOW_UPDATE_COMPLETED\x10+\x12\x36\n2EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY\x10,\x12\x36\n2EVENT_TYPE_ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY\x10-\x12+\n\'EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED\x10.B\x86\x01\n\x18io.temporal.api.enums.v1B\x0e\x45ventTypeProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
+    b'\n&temporal/api/enums/v1/event_type.proto\x12\x15temporal.api.enums.v1*\x8e\x11\n\tEventType\x12\x1a\n\x16\x45VENT_TYPE_UNSPECIFIED\x10\x00\x12)\n%EVENT_TYPE_WORKFLOW_EXECUTION_STARTED\x10\x01\x12+\n\'EVENT_TYPE_WORKFLOW_EXECUTION_COMPLETED\x10\x02\x12(\n$EVENT_TYPE_WORKFLOW_EXECUTION_FAILED\x10\x03\x12+\n\'EVENT_TYPE_WORKFLOW_EXECUTION_TIMED_OUT\x10\x04\x12&\n"EVENT_TYPE_WORKFLOW_TASK_SCHEDULED\x10\x05\x12$\n EVENT_TYPE_WORKFLOW_TASK_STARTED\x10\x06\x12&\n"EVENT_TYPE_WORKFLOW_TASK_COMPLETED\x10\x07\x12&\n"EVENT_TYPE_WORKFLOW_TASK_TIMED_OUT\x10\x08\x12#\n\x1f\x45VENT_TYPE_WORKFLOW_TASK_FAILED\x10\t\x12&\n"EVENT_TYPE_ACTIVITY_TASK_SCHEDULED\x10\n\x12$\n EVENT_TYPE_ACTIVITY_TASK_STARTED\x10\x0b\x12&\n"EVENT_TYPE_ACTIVITY_TASK_COMPLETED\x10\x0c\x12#\n\x1f\x45VENT_TYPE_ACTIVITY_TASK_FAILED\x10\r\x12&\n"EVENT_TYPE_ACTIVITY_TASK_TIMED_OUT\x10\x0e\x12-\n)EVENT_TYPE_ACTIVITY_TASK_CANCEL_REQUESTED\x10\x0f\x12%\n!EVENT_TYPE_ACTIVITY_TASK_CANCELED\x10\x10\x12\x1c\n\x18\x45VENT_TYPE_TIMER_STARTED\x10\x11\x12\x1a\n\x16\x45VENT_TYPE_TIMER_FIRED\x10\x12\x12\x1d\n\x19\x45VENT_TYPE_TIMER_CANCELED\x10\x13\x12\x32\n.EVENT_TYPE_WORKFLOW_EXECUTION_CANCEL_REQUESTED\x10\x14\x12*\n&EVENT_TYPE_WORKFLOW_EXECUTION_CANCELED\x10\x15\x12\x43\n?EVENT_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED\x10\x16\x12@\n<EVENT_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED\x10\x17\x12;\n7EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_CANCEL_REQUESTED\x10\x18\x12\x1e\n\x1a\x45VENT_TYPE_MARKER_RECORDED\x10\x19\x12*\n&EVENT_TYPE_WORKFLOW_EXECUTION_SIGNALED\x10\x1a\x12,\n(EVENT_TYPE_WORKFLOW_EXECUTION_TERMINATED\x10\x1b\x12\x32\n.EVENT_TYPE_WORKFLOW_EXECUTION_CONTINUED_AS_NEW\x10\x1c\x12\x37\n3EVENT_TYPE_START_CHILD_WORKFLOW_EXECUTION_INITIATED\x10\x1d\x12\x34\n0EVENT_TYPE_START_CHILD_WORKFLOW_EXECUTION_FAILED\x10\x1e\x12/\n+EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_STARTED\x10\x1f\x12\x31\n-EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_COMPLETED\x10 \x12.\n*EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_FAILED\x10!\x12\x30\n,EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_CANCELED\x10"\x12\x31\n-EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TIMED_OUT\x10#\x12\x32\n.EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TERMINATED\x10$\x12;\n7EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED\x10%\x12\x38\n4EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED\x10&\x12\x33\n/EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED\x10\'\x12\x30\n,EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES\x10(\x12\x31\n-EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_ACCEPTED\x10)\x12\x31\n-EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_REJECTED\x10*\x12\x32\n.EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_COMPLETED\x10+\x12\x36\n2EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY\x10,\x12\x36\n2EVENT_TYPE_ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY\x10-\x12+\n\'EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED\x10.B\x86\x01\n\x18io.temporal.api.enums.v1B\x0e\x45ventTypeProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _EVENTTYPE = DESCRIPTOR.enum_types_by_name["EventType"]
 EventType = enum_type_wrapper.EnumTypeWrapper(_EVENTTYPE)
 EVENT_TYPE_UNSPECIFIED = 0
 EVENT_TYPE_WORKFLOW_EXECUTION_STARTED = 1
 EVENT_TYPE_WORKFLOW_EXECUTION_COMPLETED = 2
@@ -57,21 +57,21 @@
 EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_CANCELED = 34
 EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TIMED_OUT = 35
 EVENT_TYPE_CHILD_WORKFLOW_EXECUTION_TERMINATED = 36
 EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED = 37
 EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED = 38
 EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED = 39
 EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES = 40
-EVENT_TYPE_WORKFLOW_UPDATE_REJECTED = 41
-EVENT_TYPE_WORKFLOW_UPDATE_ACCEPTED = 42
-EVENT_TYPE_WORKFLOW_UPDATE_COMPLETED = 43
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_ACCEPTED = 41
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_REJECTED = 42
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_COMPLETED = 43
 EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY = 44
 EVENT_TYPE_ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY = 45
 EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED = 46
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\016EventTypeProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _EVENTTYPE._serialized_start = 66
-    _EVENTTYPE._serialized_end = 2226
+    _EVENTTYPE._serialized_end = 2256
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/event_type_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/event_type_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -178,20 +178,20 @@
     """Temporal Server cannot Signal the targeted Workflow
     Usually because the Workflow could not be found
     """
     EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED: _EventType.ValueType  # 39
     """Temporal Server has successfully Signaled the targeted Workflow"""
     EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES: _EventType.ValueType  # 40
     """Workflow search attributes should be updated and synchronized with the visibility store"""
-    EVENT_TYPE_WORKFLOW_UPDATE_REJECTED: _EventType.ValueType  # 41
-    """Workflow update request has been received"""
-    EVENT_TYPE_WORKFLOW_UPDATE_ACCEPTED: _EventType.ValueType  # 42
-    """Workflow update request has been accepted by user workflow code"""
-    EVENT_TYPE_WORKFLOW_UPDATE_COMPLETED: _EventType.ValueType  # 43
-    """Workflow update has been completed"""
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_ACCEPTED: _EventType.ValueType  # 41
+    """An update was accepted (i.e. validated)"""
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_REJECTED: _EventType.ValueType  # 42
+    """An update was rejected (i.e. failed validation)"""
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_COMPLETED: _EventType.ValueType  # 43
+    """An update completed"""
     EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY: _EventType.ValueType  # 44
     """Some property or properties of the workflow as a whole have changed by non-workflow code.
     The distinction of external vs. command-based modification is important so the SDK can
     maintain determinism when using the command-based approach.
     """
     EVENT_TYPE_ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY: _EventType.ValueType  # 45
     """Some property or properties of an already-scheduled activity have changed by non-workflow code.
@@ -337,20 +337,20 @@
 """Temporal Server cannot Signal the targeted Workflow
 Usually because the Workflow could not be found
 """
 EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED: EventType.ValueType  # 39
 """Temporal Server has successfully Signaled the targeted Workflow"""
 EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES: EventType.ValueType  # 40
 """Workflow search attributes should be updated and synchronized with the visibility store"""
-EVENT_TYPE_WORKFLOW_UPDATE_REJECTED: EventType.ValueType  # 41
-"""Workflow update request has been received"""
-EVENT_TYPE_WORKFLOW_UPDATE_ACCEPTED: EventType.ValueType  # 42
-"""Workflow update request has been accepted by user workflow code"""
-EVENT_TYPE_WORKFLOW_UPDATE_COMPLETED: EventType.ValueType  # 43
-"""Workflow update has been completed"""
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_ACCEPTED: EventType.ValueType  # 41
+"""An update was accepted (i.e. validated)"""
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_REJECTED: EventType.ValueType  # 42
+"""An update was rejected (i.e. failed validation)"""
+EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_COMPLETED: EventType.ValueType  # 43
+"""An update completed"""
 EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY: EventType.ValueType  # 44
 """Some property or properties of the workflow as a whole have changed by non-workflow code.
 The distinction of external vs. command-based modification is important so the SDK can
 maintain determinism when using the command-based approach.
 """
 EVENT_TYPE_ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY: EventType.ValueType  # 45
 """Some property or properties of an already-scheduled activity have changed by non-workflow code.
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/failed_cause_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n(temporal/api/enums/v1/failed_cause.proto\x12\x15temporal.api.enums.v1*\xe8\x0e\n\x17WorkflowTaskFailedCause\x12*\n&WORKFLOW_TASK_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12\x30\n,WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND\x10\x01\x12?\n;WORKFLOW_TASK_FAILED_CAUSE_BAD_SCHEDULE_ACTIVITY_ATTRIBUTES\x10\x02\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_ACTIVITY_ATTRIBUTES\x10\x03\x12\x39\n5WORKFLOW_TASK_FAILED_CAUSE_BAD_START_TIMER_ATTRIBUTES\x10\x04\x12:\n6WORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_TIMER_ATTRIBUTES\x10\x05\x12;\n7WORKFLOW_TASK_FAILED_CAUSE_BAD_RECORD_MARKER_ATTRIBUTES\x10\x06\x12I\nEWORKFLOW_TASK_FAILED_CAUSE_BAD_COMPLETE_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x07\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_FAIL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x08\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\t\x12X\nTWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\n\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_BAD_CONTINUE_AS_NEW_ATTRIBUTES\x10\x0b\x12\x37\n3WORKFLOW_TASK_FAILED_CAUSE_START_TIMER_DUPLICATE_ID\x10\x0c\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_RESET_STICKY_TASK_QUEUE\x10\r\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_WORKFLOW_WORKER_UNHANDLED_FAILURE\x10\x0e\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x0f\x12\x43\n?WORKFLOW_TASK_FAILED_CAUSE_BAD_START_CHILD_EXECUTION_ATTRIBUTES\x10\x10\x12\x32\n.WORKFLOW_TASK_FAILED_CAUSE_FORCE_CLOSE_COMMAND\x10\x11\x12\x35\n1WORKFLOW_TASK_FAILED_CAUSE_FAILOVER_CLOSE_COMMAND\x10\x12\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_INPUT_SIZE\x10\x13\x12-\n)WORKFLOW_TASK_FAILED_CAUSE_RESET_WORKFLOW\x10\x14\x12)\n%WORKFLOW_TASK_FAILED_CAUSE_BAD_BINARY\x10\x15\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_SCHEDULE_ACTIVITY_DUPLICATE_ID\x10\x16\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES\x10\x17\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_NON_DETERMINISTIC_ERROR\x10\x18\x12H\nDWORKFLOW_TASK_FAILED_CAUSE_BAD_MODIFY_WORKFLOW_PROPERTIES_ATTRIBUTES\x10\x19\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_PENDING_CHILD_WORKFLOWS_LIMIT_EXCEEDED\x10\x1a\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED\x10\x1b\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED\x10\x1c\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED\x10\x1d*\xf3\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01\x12\x43\n?START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\x91\x02\n*CancelExternalWorkflowExecutionFailedCause\x12?\n;CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\x91\x02\n*SignalExternalWorkflowExecutionFailedCause\x12?\n;SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\xf9\x01\n\x16ResourceExhaustedCause\x12(\n$RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED\x10\x00\x12&\n"RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT\x10\x01\x12-\n)RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT\x10\x02\x12.\n*RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED\x10\x03\x12.\n*RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT\x10\x04\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x46\x61iledCauseProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
+    b'\n(temporal/api/enums/v1/failed_cause.proto\x12\x15temporal.api.enums.v1*\xdf\x0f\n\x17WorkflowTaskFailedCause\x12*\n&WORKFLOW_TASK_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12\x30\n,WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND\x10\x01\x12?\n;WORKFLOW_TASK_FAILED_CAUSE_BAD_SCHEDULE_ACTIVITY_ATTRIBUTES\x10\x02\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_ACTIVITY_ATTRIBUTES\x10\x03\x12\x39\n5WORKFLOW_TASK_FAILED_CAUSE_BAD_START_TIMER_ATTRIBUTES\x10\x04\x12:\n6WORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_TIMER_ATTRIBUTES\x10\x05\x12;\n7WORKFLOW_TASK_FAILED_CAUSE_BAD_RECORD_MARKER_ATTRIBUTES\x10\x06\x12I\nEWORKFLOW_TASK_FAILED_CAUSE_BAD_COMPLETE_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x07\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_BAD_FAIL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x08\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_CANCEL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\t\x12X\nTWORKFLOW_TASK_FAILED_CAUSE_BAD_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\n\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_BAD_CONTINUE_AS_NEW_ATTRIBUTES\x10\x0b\x12\x37\n3WORKFLOW_TASK_FAILED_CAUSE_START_TIMER_DUPLICATE_ID\x10\x0c\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_RESET_STICKY_TASK_QUEUE\x10\r\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_WORKFLOW_WORKER_UNHANDLED_FAILURE\x10\x0e\x12G\nCWORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_WORKFLOW_EXECUTION_ATTRIBUTES\x10\x0f\x12\x43\n?WORKFLOW_TASK_FAILED_CAUSE_BAD_START_CHILD_EXECUTION_ATTRIBUTES\x10\x10\x12\x32\n.WORKFLOW_TASK_FAILED_CAUSE_FORCE_CLOSE_COMMAND\x10\x11\x12\x35\n1WORKFLOW_TASK_FAILED_CAUSE_FAILOVER_CLOSE_COMMAND\x10\x12\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SIGNAL_INPUT_SIZE\x10\x13\x12-\n)WORKFLOW_TASK_FAILED_CAUSE_RESET_WORKFLOW\x10\x14\x12)\n%WORKFLOW_TASK_FAILED_CAUSE_BAD_BINARY\x10\x15\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_SCHEDULE_ACTIVITY_DUPLICATE_ID\x10\x16\x12\x34\n0WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES\x10\x17\x12\x36\n2WORKFLOW_TASK_FAILED_CAUSE_NON_DETERMINISTIC_ERROR\x10\x18\x12H\nDWORKFLOW_TASK_FAILED_CAUSE_BAD_MODIFY_WORKFLOW_PROPERTIES_ATTRIBUTES\x10\x19\x12\x45\nAWORKFLOW_TASK_FAILED_CAUSE_PENDING_CHILD_WORKFLOWS_LIMIT_EXCEEDED\x10\x1a\x12@\n<WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED\x10\x1b\x12=\n9WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED\x10\x1c\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED\x10\x1d\x12\x44\n@WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE\x10\x1e\x12/\n+WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE\x10\x1f*\xf3\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01\x12\x43\n?START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\x91\x02\n*CancelExternalWorkflowExecutionFailedCause\x12?\n;CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCCANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02*\xe2\x02\n*SignalExternalWorkflowExecutionFailedCause\x12?\n;SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12Y\nUSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND\x10\x01\x12G\nCSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND\x10\x02\x12O\nKSIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED\x10\x03*\xf9\x01\n\x16ResourceExhaustedCause\x12(\n$RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED\x10\x00\x12&\n"RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT\x10\x01\x12-\n)RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT\x10\x02\x12.\n*RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED\x10\x03\x12.\n*RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT\x10\x04\x42\x88\x01\n\x18io.temporal.api.enums.v1B\x10\x46\x61iledCauseProtoP\x01Z!go.temporal.io/api/enums/v1;enums\xaa\x02\x17Temporalio.Api.Enums.V1\xea\x02\x1aTemporalio::Api::Enums::V1b\x06proto3'
 )
 
 _WORKFLOWTASKFAILEDCAUSE = DESCRIPTOR.enum_types_by_name["WorkflowTaskFailedCause"]
 WorkflowTaskFailedCause = enum_type_wrapper.EnumTypeWrapper(_WORKFLOWTASKFAILEDCAUSE)
 _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE = DESCRIPTOR.enum_types_by_name[
     "StartChildWorkflowExecutionFailedCause"
 ]
@@ -68,41 +68,44 @@
 WORKFLOW_TASK_FAILED_CAUSE_BAD_SEARCH_ATTRIBUTES = 23
 WORKFLOW_TASK_FAILED_CAUSE_NON_DETERMINISTIC_ERROR = 24
 WORKFLOW_TASK_FAILED_CAUSE_BAD_MODIFY_WORKFLOW_PROPERTIES_ATTRIBUTES = 25
 WORKFLOW_TASK_FAILED_CAUSE_PENDING_CHILD_WORKFLOWS_LIMIT_EXCEEDED = 26
 WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED = 27
 WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED = 28
 WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED = 29
+WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE = 30
+WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE = 31
 START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0
 START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS = 1
 START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2
 CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0
 CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND = (
     1
 )
 CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND = (
     1
 )
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2
+SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED = 3
 RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED = 0
 RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT = 1
 RESOURCE_EXHAUSTED_CAUSE_CONCURRENT_LIMIT = 2
 RESOURCE_EXHAUSTED_CAUSE_SYSTEM_OVERLOADED = 3
 RESOURCE_EXHAUSTED_CAUSE_PERSISTENCE_LIMIT = 4
 
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\030io.temporal.api.enums.v1B\020FailedCauseProtoP\001Z!go.temporal.io/api/enums/v1;enums\252\002\027Temporalio.Api.Enums.V1\352\002\032Temporalio::Api::Enums::V1"
     _WORKFLOWTASKFAILEDCAUSE._serialized_start = 68
-    _WORKFLOWTASKFAILEDCAUSE._serialized_end = 1964
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 1967
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2210
-    _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2213
-    _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2486
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2489
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2762
-    _RESOURCEEXHAUSTEDCAUSE._serialized_start = 2765
-    _RESOURCEEXHAUSTEDCAUSE._serialized_end = 3014
+    _WORKFLOWTASKFAILEDCAUSE._serialized_end = 2083
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2086
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2329
+    _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2332
+    _CANCELEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2605
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 2608
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 2962
+    _RESOURCEEXHAUSTEDCAUSE._serialized_start = 2965
+    _RESOURCEEXHAUSTEDCAUSE._serialized_end = 3214
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/failed_cause_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/failed_cause_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -100,14 +100,20 @@
     """A workflow has a buffer of signals that have not yet reached their destination. We return this
     error when sending a new signal would exceed the capacity of this buffer.
     """
     WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED: _WorkflowTaskFailedCause.ValueType  # 29
     """Similarly, we have a buffer of pending requests to cancel other workflows. We return this error
     when our capacity for pending cancel requests is already reached.
     """
+    WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE: _WorkflowTaskFailedCause.ValueType  # 30
+    """Workflow execution update message (update.Acceptance, update.Rejection, or update.Response)
+    has wrong format, or missing required fields.
+    """
+    WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE: _WorkflowTaskFailedCause.ValueType  # 31
+    """Similar to WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND, but for updates."""
 
 class WorkflowTaskFailedCause(
     _WorkflowTaskFailedCause, metaclass=_WorkflowTaskFailedCauseEnumTypeWrapper
 ):
     """Workflow tasks can fail for various reasons. Note that some of these reasons can only originate
     from the server, and some of them can only originate from the SDK/worker.
     """
@@ -165,14 +171,20 @@
 """A workflow has a buffer of signals that have not yet reached their destination. We return this
 error when sending a new signal would exceed the capacity of this buffer.
 """
 WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED: WorkflowTaskFailedCause.ValueType  # 29
 """Similarly, we have a buffer of pending requests to cancel other workflows. We return this error
 when our capacity for pending cancel requests is already reached.
 """
+WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE: WorkflowTaskFailedCause.ValueType  # 30
+"""Workflow execution update message (update.Acceptance, update.Rejection, or update.Response)
+has wrong format, or missing required fields.
+"""
+WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE: WorkflowTaskFailedCause.ValueType  # 31
+"""Similar to WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND, but for updates."""
 global___WorkflowTaskFailedCause = WorkflowTaskFailedCause
 
 class _StartChildWorkflowExecutionFailedCause:
     ValueType = typing.NewType("ValueType", builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 
 class _StartChildWorkflowExecutionFailedCauseEnumTypeWrapper(
@@ -233,23 +245,27 @@
     ],
     builtins.type,
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED: _SignalExternalWorkflowExecutionFailedCause.ValueType  # 0
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND: _SignalExternalWorkflowExecutionFailedCause.ValueType  # 1
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND: _SignalExternalWorkflowExecutionFailedCause.ValueType  # 2
+    SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED: _SignalExternalWorkflowExecutionFailedCause.ValueType  # 3
+    """Signal count limit is per workflow and controlled by server dynamic config "history.maximumSignalsPerExecution" """
 
 class SignalExternalWorkflowExecutionFailedCause(
     _SignalExternalWorkflowExecutionFailedCause,
     metaclass=_SignalExternalWorkflowExecutionFailedCauseEnumTypeWrapper,
 ): ...
 
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED: SignalExternalWorkflowExecutionFailedCause.ValueType  # 0
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND: SignalExternalWorkflowExecutionFailedCause.ValueType  # 1
 SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND: SignalExternalWorkflowExecutionFailedCause.ValueType  # 2
+SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED: SignalExternalWorkflowExecutionFailedCause.ValueType  # 3
+"""Signal count limit is per workflow and controlled by server dynamic config "history.maximumSignalsPerExecution" """
 global___SignalExternalWorkflowExecutionFailedCause = (
     SignalExternalWorkflowExecutionFailedCause
 )
 
 class _ResourceExhaustedCause:
     ValueType = typing.NewType("ValueType", builtins.int)
     V: typing_extensions.TypeAlias = ValueType
```

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/namespace_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/namespace_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/namespace_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/query_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/query_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/query_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/reset_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/reset_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/reset_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/schedule_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/schedule_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/schedule_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/task_queue_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/task_queue_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/task_queue_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/workflow_pb2.py` & `temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/enums/v1/workflow_pb2.pyi` & `temporalio-1.2.0/temporalio/api/enums/v1/workflow_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/errordetails/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/errordetails/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/errordetails/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/errordetails/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/errordetails/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/failure/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/failure/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/failure/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/failure/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/failure/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/filter/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/filter/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/filter/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/history/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/history/v1/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -33,24 +33,24 @@
     WorkflowExecutionCompletedEventAttributes,
     WorkflowExecutionContinuedAsNewEventAttributes,
     WorkflowExecutionFailedEventAttributes,
     WorkflowExecutionSignaledEventAttributes,
     WorkflowExecutionStartedEventAttributes,
     WorkflowExecutionTerminatedEventAttributes,
     WorkflowExecutionTimedOutEventAttributes,
+    WorkflowExecutionUpdateAcceptedEventAttributes,
+    WorkflowExecutionUpdateCompletedEventAttributes,
+    WorkflowExecutionUpdateRejectedEventAttributes,
     WorkflowPropertiesModifiedEventAttributes,
     WorkflowPropertiesModifiedExternallyEventAttributes,
     WorkflowTaskCompletedEventAttributes,
     WorkflowTaskFailedEventAttributes,
     WorkflowTaskScheduledEventAttributes,
     WorkflowTaskStartedEventAttributes,
     WorkflowTaskTimedOutEventAttributes,
-    WorkflowUpdateAcceptedEventAttributes,
-    WorkflowUpdateCompletedEventAttributes,
-    WorkflowUpdateRejectedEventAttributes,
 )
 
 __all__ = [
     "ActivityPropertiesModifiedExternallyEventAttributes",
     "ActivityTaskCancelRequestedEventAttributes",
     "ActivityTaskCanceledEventAttributes",
     "ActivityTaskCompletedEventAttributes",
@@ -84,18 +84,18 @@
     "WorkflowExecutionCompletedEventAttributes",
     "WorkflowExecutionContinuedAsNewEventAttributes",
     "WorkflowExecutionFailedEventAttributes",
     "WorkflowExecutionSignaledEventAttributes",
     "WorkflowExecutionStartedEventAttributes",
     "WorkflowExecutionTerminatedEventAttributes",
     "WorkflowExecutionTimedOutEventAttributes",
+    "WorkflowExecutionUpdateAcceptedEventAttributes",
+    "WorkflowExecutionUpdateCompletedEventAttributes",
+    "WorkflowExecutionUpdateRejectedEventAttributes",
     "WorkflowPropertiesModifiedEventAttributes",
     "WorkflowPropertiesModifiedExternallyEventAttributes",
     "WorkflowTaskCompletedEventAttributes",
     "WorkflowTaskFailedEventAttributes",
     "WorkflowTaskScheduledEventAttributes",
     "WorkflowTaskStartedEventAttributes",
     "WorkflowTaskTimedOutEventAttributes",
-    "WorkflowUpdateAcceptedEventAttributes",
-    "WorkflowUpdateCompletedEventAttributes",
-    "WorkflowUpdateRejectedEventAttributes",
 ]
```

### Comparing `temporalio-1.1.0/temporalio/api/history/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/history/v1/message_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -30,26 +30,29 @@
 )
 from temporalio.api.enums.v1 import (
     workflow_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_workflow__pb2,
 )
 from temporalio.api.failure.v1 import (
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
-from temporalio.api.interaction.v1 import (
-    message_pb2 as temporal_dot_api_dot_interaction_dot_v1_dot_message__pb2,
+from temporalio.api.sdk.v1 import (
+    task_complete_metadata_pb2 as temporal_dot_api_dot_sdk_dot_v1_dot_task__complete__metadata__pb2,
 )
 from temporalio.api.taskqueue.v1 import (
     message_pb2 as temporal_dot_api_dot_taskqueue_dot_v1_dot_message__pb2,
 )
+from temporalio.api.update.v1 import (
+    message_pb2 as temporal_dot_api_dot_update_dot_v1_dot_message__pb2,
+)
 from temporalio.api.workflow.v1 import (
     message_pb2 as temporal_dot_api_dot_workflow_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n%temporal/api/history/v1/message.proto\x12\x17temporal.api.history.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/event_type.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a)temporal/api/interaction/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto"\x90\x0b\n\'WorkflowExecutionStartedEventAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19parent_workflow_namespace\x18\x02 \x01(\t\x12$\n\x1cparent_workflow_namespace_id\x18\x1b \x01(\t\x12L\n\x19parent_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12!\n\x19parent_initiated_event_id\x18\x04 \x01(\x03\x12\x38\n\ntask_queue\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12"\n\x1a\x63ontinued_execution_run_id\x18\n \x01(\t\x12@\n\tinitiator\x18\x0b \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\x0c \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12!\n\x19original_execution_run_id\x18\x0e \x01(\t\x12\x10\n\x08identity\x18\x0f \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x10 \x01(\t\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x12 \x01(\x05\x12L\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcron_schedule\x18\x14 \x01(\t\x12\x44\n\x1b\x66irst_workflow_task_backoff\x18\x15 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12*\n\x04memo\x18\x16 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x17 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x45\n\x16prev_auto_reset_points\x18\x18 \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12.\n\x06header\x18\x19 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12&\n\x1eparent_initiated_event_version\x18\x1a \x01(\x03"\xa5\x01\n)WorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x03 \x01(\t"\xdb\x01\n&WorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x36\n\x0bretry_state\x18\x02 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x04 \x01(\t"\x80\x01\n(WorkflowExecutionTimedOutEventAttributes\x12\x36\n\x0bretry_state\x18\x01 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12\x1c\n\x14new_execution_run_id\x18\x02 \x01(\t"\xb8\x06\n.WorkflowExecutionContinuedAsNewEventAttributes\x12\x1c\n\x14new_execution_run_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12@\n\tinitiator\x18\t \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\n \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0b \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xb2\x01\n$WorkflowTaskScheduledEventAttributes\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12?\n\x16start_to_close_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x03 \x01(\x05"\xa3\x01\n"WorkflowTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x1f\n\x17suggest_continue_as_new\x18\x04 \x01(\x08\x12\x1a\n\x12history_size_bytes\x18\x05 \x01(\x03"\xcb\x01\n$WorkflowTaskCompletedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12\x42\n\x14worker_versioning_id\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId"\x95\x01\n#WorkflowTaskTimedOutEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x38\n\x0ctimeout_type\x18\x03 \x01(\x0e\x32".temporal.api.enums.v1.TimeoutType"\xbb\x02\n!WorkflowTaskFailedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12=\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x13\n\x0b\x62\x61se_run_id\x18\x06 \x01(\t\x12\x12\n\nnew_run_id\x18\x07 \x01(\t\x12\x1a\n\x12\x66ork_event_version\x18\x08 \x01(\x03\x12\x17\n\x0f\x62inary_checksum\x18\t \x01(\t"\x83\x05\n$ActivityTaskScheduledEventAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicyJ\x04\x08\x03\x10\x04"\xaf\x01\n"ActivityTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\x05\x12\x36\n\x0clast_failure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xa0\x01\n$ActivityTaskCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xd6\x01\n!ActivityTaskFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x36\n\x0bretry_state\x18\x05 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc6\x01\n#ActivityTaskTimedOutEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x36\n\x0bretry_state\x18\x04 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"r\n*ActivityTaskCancelRequestedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03"\xca\x01\n#ActivityTaskCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n latest_cancel_requested_event_id\x18\x02 \x01(\x03\x12\x1a\n\x12scheduled_event_id\x18\x03 \x01(\x03\x12\x18\n\x10started_event_id\x18\x04 \x01(\x03\x12\x10\n\x08identity\x18\x05 \x01(\t"\x99\x01\n\x1bTimerStartedEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03"G\n\x19TimerFiredEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03"\x86\x01\n\x1cTimerCanceledEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xc7\x01\n/WorkflowExecutionCancelRequestedEventAttributes\x12\r\n\x05\x63\x61use\x18\x01 \x01(\t\x12#\n\x1b\x65xternal_initiated_event_id\x18\x02 \x01(\x03\x12N\n\x1b\x65xternal_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x04 \x01(\t"\x87\x01\n(WorkflowExecutionCanceledEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xe9\x02\n\x1dMarkerRecordedEventAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.history.v1.MarkerRecordedEventAttributes.DetailsEntry\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xb2\x01\n(WorkflowExecutionSignaledEventAttributes\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\x81\x01\n*WorkflowExecutionTerminatedEventAttributes\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t"\x98\x02\n>RequestCancelExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xd6\x02\n;RequestCancelExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.CancelExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xc5\x01\n7ExternalWorkflowExecutionCancelRequestedEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x04 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xf7\x02\n7SignalExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\t \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x07 \x01(\x08\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xcf\x02\n4SignalExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.SignalExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xcf\x01\n0ExternalWorkflowExecutionSignaledEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x05 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t"\x9e\x01\n-UpsertWorkflowSearchAttributesEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x43\n\x11search_attributes\x18\x02 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\x8a\x01\n)WorkflowPropertiesModifiedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x33\n\rupserted_memo\x18\x02 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xa4\x07\n3StartChildWorkflowExecutionInitiatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x12 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12.\n\x06header\x18\x0f \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x10 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x11 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xd2\x02\n0StartChildWorkflowExecutionFailedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12L\n\x05\x63\x61use\x18\x04 \x01(\x0e\x32=.temporal.api.enums.v1.StartChildWorkflowExecutionFailedCause\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x06 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03"\xa7\x02\n,ChildWorkflowExecutionStartedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x02 \x01(\x03\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xc5\x02\n.ChildWorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xfb\x02\n+ChildWorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03\x12\x36\n\x0bretry_state\x18\x07 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc5\x02\n-ChildWorkflowExecutionCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xca\x02\n-ChildWorkflowExecutionTimedOutEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x36\n\x0bretry_state\x18\x06 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\x94\x02\n/ChildWorkflowExecutionTerminatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03"\x8b\x01\n%WorkflowUpdateAcceptedEventAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x31\n\x05input\x18\x02 \x01(\x0b\x32".temporal.api.interaction.v1.Input"\x8e\x01\n&WorkflowUpdateCompletedEventAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x33\n\x06output\x18\x02 \x01(\x0b\x32#.temporal.api.interaction.v1.Output"\x8b\x01\n%WorkflowUpdateRejectedEventAttributes\x12/\n\x04meta\x18\x01 \x01(\x0b\x32!.temporal.api.interaction.v1.Meta\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xd2\x02\n3WorkflowPropertiesModifiedExternallyEventAttributes\x12\x16\n\x0enew_task_queue\x18\x01 \x01(\t\x12\x42\n\x19new_workflow_task_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x41\n\x18new_workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x1enew_workflow_execution_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x33\n\rupserted_memo\x18\x05 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\x90\x01\n3ActivityPropertiesModifiedExternallyEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12=\n\x10new_retry_policy\x18\x02 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\xa9/\n\x0cHistoryEvent\x12\x10\n\x08\x65vent_id\x18\x01 \x01(\x03\x12\x34\n\nevent_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nevent_type\x18\x03 \x01(\x0e\x32 .temporal.api.enums.v1.EventType\x12\x0f\n\x07version\x18\x04 \x01(\x03\x12\x0f\n\x07task_id\x18\x05 \x01(\x03\x12\x1a\n\x11worker_may_ignore\x18\xac\x02 \x01(\x08\x12w\n+workflow_execution_started_event_attributes\x18\x06 \x01(\x0b\x32@.temporal.api.history.v1.WorkflowExecutionStartedEventAttributesH\x00\x12{\n-workflow_execution_completed_event_attributes\x18\x07 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowExecutionCompletedEventAttributesH\x00\x12u\n*workflow_execution_failed_event_attributes\x18\x08 \x01(\x0b\x32?.temporal.api.history.v1.WorkflowExecutionFailedEventAttributesH\x00\x12z\n-workflow_execution_timed_out_event_attributes\x18\t \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionTimedOutEventAttributesH\x00\x12q\n(workflow_task_scheduled_event_attributes\x18\n \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskScheduledEventAttributesH\x00\x12m\n&workflow_task_started_event_attributes\x18\x0b \x01(\x0b\x32;.temporal.api.history.v1.WorkflowTaskStartedEventAttributesH\x00\x12q\n(workflow_task_completed_event_attributes\x18\x0c \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskCompletedEventAttributesH\x00\x12p\n(workflow_task_timed_out_event_attributes\x18\r \x01(\x0b\x32<.temporal.api.history.v1.WorkflowTaskTimedOutEventAttributesH\x00\x12k\n%workflow_task_failed_event_attributes\x18\x0e \x01(\x0b\x32:.temporal.api.history.v1.WorkflowTaskFailedEventAttributesH\x00\x12q\n(activity_task_scheduled_event_attributes\x18\x0f \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskScheduledEventAttributesH\x00\x12m\n&activity_task_started_event_attributes\x18\x10 \x01(\x0b\x32;.temporal.api.history.v1.ActivityTaskStartedEventAttributesH\x00\x12q\n(activity_task_completed_event_attributes\x18\x11 \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskCompletedEventAttributesH\x00\x12k\n%activity_task_failed_event_attributes\x18\x12 \x01(\x0b\x32:.temporal.api.history.v1.ActivityTaskFailedEventAttributesH\x00\x12p\n(activity_task_timed_out_event_attributes\x18\x13 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskTimedOutEventAttributesH\x00\x12^\n\x1etimer_started_event_attributes\x18\x14 \x01(\x0b\x32\x34.temporal.api.history.v1.TimerStartedEventAttributesH\x00\x12Z\n\x1ctimer_fired_event_attributes\x18\x15 \x01(\x0b\x32\x32.temporal.api.history.v1.TimerFiredEventAttributesH\x00\x12~\n/activity_task_cancel_requested_event_attributes\x18\x16 \x01(\x0b\x32\x43.temporal.api.history.v1.ActivityTaskCancelRequestedEventAttributesH\x00\x12o\n\'activity_task_canceled_event_attributes\x18\x17 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskCanceledEventAttributesH\x00\x12`\n\x1ftimer_canceled_event_attributes\x18\x18 \x01(\x0b\x32\x35.temporal.api.history.v1.TimerCanceledEventAttributesH\x00\x12\x62\n marker_recorded_event_attributes\x18\x19 \x01(\x0b\x32\x36.temporal.api.history.v1.MarkerRecordedEventAttributesH\x00\x12y\n,workflow_execution_signaled_event_attributes\x18\x1a \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionSignaledEventAttributesH\x00\x12}\n.workflow_execution_terminated_event_attributes\x18\x1b \x01(\x0b\x32\x43.temporal.api.history.v1.WorkflowExecutionTerminatedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_cancel_requested_event_attributes\x18\x1c \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionCancelRequestedEventAttributesH\x00\x12y\n,workflow_execution_canceled_event_attributes\x18\x1d \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionCanceledEventAttributesH\x00\x12\xa8\x01\nErequest_cancel_external_workflow_execution_initiated_event_attributes\x18\x1e \x01(\x0b\x32W.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\xa2\x01\nBrequest_cancel_external_workflow_execution_failed_event_attributes\x18\x1f \x01(\x0b\x32T.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x99\x01\n=external_workflow_execution_cancel_requested_event_attributes\x18  \x01(\x0b\x32P.temporal.api.history.v1.ExternalWorkflowExecutionCancelRequestedEventAttributesH\x00\x12\x87\x01\n4workflow_execution_continued_as_new_event_attributes\x18! \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionContinuedAsNewEventAttributesH\x00\x12\x91\x01\n9start_child_workflow_execution_initiated_event_attributes\x18" \x01(\x0b\x32L.temporal.api.history.v1.StartChildWorkflowExecutionInitiatedEventAttributesH\x00\x12\x8b\x01\n6start_child_workflow_execution_failed_event_attributes\x18# \x01(\x0b\x32I.temporal.api.history.v1.StartChildWorkflowExecutionFailedEventAttributesH\x00\x12\x82\x01\n1child_workflow_execution_started_event_attributes\x18$ \x01(\x0b\x32\x45.temporal.api.history.v1.ChildWorkflowExecutionStartedEventAttributesH\x00\x12\x86\x01\n3child_workflow_execution_completed_event_attributes\x18% \x01(\x0b\x32G.temporal.api.history.v1.ChildWorkflowExecutionCompletedEventAttributesH\x00\x12\x80\x01\n0child_workflow_execution_failed_event_attributes\x18& \x01(\x0b\x32\x44.temporal.api.history.v1.ChildWorkflowExecutionFailedEventAttributesH\x00\x12\x84\x01\n2child_workflow_execution_canceled_event_attributes\x18\' \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionCanceledEventAttributesH\x00\x12\x85\x01\n3child_workflow_execution_timed_out_event_attributes\x18( \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionTimedOutEventAttributesH\x00\x12\x88\x01\n4child_workflow_execution_terminated_event_attributes\x18) \x01(\x0b\x32H.temporal.api.history.v1.ChildWorkflowExecutionTerminatedEventAttributesH\x00\x12\x99\x01\n=signal_external_workflow_execution_initiated_event_attributes\x18* \x01(\x0b\x32P.temporal.api.history.v1.SignalExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\x93\x01\n:signal_external_workflow_execution_failed_event_attributes\x18+ \x01(\x0b\x32M.temporal.api.history.v1.SignalExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x8a\x01\n5external_workflow_execution_signaled_event_attributes\x18, \x01(\x0b\x32I.temporal.api.history.v1.ExternalWorkflowExecutionSignaledEventAttributesH\x00\x12\x84\x01\n2upsert_workflow_search_attributes_event_attributes\x18- \x01(\x0b\x32\x46.temporal.api.history.v1.UpsertWorkflowSearchAttributesEventAttributesH\x00\x12s\n)workflow_update_rejected_event_attributes\x18. \x01(\x0b\x32>.temporal.api.history.v1.WorkflowUpdateRejectedEventAttributesH\x00\x12s\n)workflow_update_accepted_event_attributes\x18/ \x01(\x0b\x32>.temporal.api.history.v1.WorkflowUpdateAcceptedEventAttributesH\x00\x12u\n*workflow_update_completed_event_attributes\x18\x30 \x01(\x0b\x32?.temporal.api.history.v1.WorkflowUpdateCompletedEventAttributesH\x00\x12\x90\x01\n8workflow_properties_modified_externally_event_attributes\x18\x31 \x01(\x0b\x32L.temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributesH\x00\x12\x90\x01\n8activity_properties_modified_externally_event_attributes\x18\x32 \x01(\x0b\x32L.temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributesH\x00\x12{\n-workflow_properties_modified_event_attributes\x18\x33 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowPropertiesModifiedEventAttributesH\x00\x42\x0c\n\nattributes"@\n\x07History\x12\x35\n\x06\x65vents\x18\x01 \x03(\x0b\x32%.temporal.api.history.v1.HistoryEventB\x8e\x01\n\x1aio.temporal.api.history.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/history/v1;history\xaa\x02\x19Temporalio.Api.History.V1\xea\x02\x1cTemporalio::Api::History::V1b\x06proto3'
+    b'\n%temporal/api/history/v1/message.proto\x12\x17temporal.api.history.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/event_type.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto"\x90\x0b\n\'WorkflowExecutionStartedEventAttributes\x12;\n\rworkflow_type\x18\x01 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19parent_workflow_namespace\x18\x02 \x01(\t\x12$\n\x1cparent_workflow_namespace_id\x18\x1b \x01(\t\x12L\n\x19parent_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12!\n\x19parent_initiated_event_id\x18\x04 \x01(\x03\x12\x38\n\ntask_queue\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12"\n\x1a\x63ontinued_execution_run_id\x18\n \x01(\t\x12@\n\tinitiator\x18\x0b \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\x0c \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12!\n\x19original_execution_run_id\x18\x0e \x01(\t\x12\x10\n\x08identity\x18\x0f \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x10 \x01(\t\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x12 \x01(\x05\x12L\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x15\n\rcron_schedule\x18\x14 \x01(\t\x12\x44\n\x1b\x66irst_workflow_task_backoff\x18\x15 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12*\n\x04memo\x18\x16 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x17 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x45\n\x16prev_auto_reset_points\x18\x18 \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12.\n\x06header\x18\x19 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12&\n\x1eparent_initiated_event_version\x18\x1a \x01(\x03"\xa5\x01\n)WorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x03 \x01(\t"\xdb\x01\n&WorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x36\n\x0bretry_state\x18\x02 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x1c\n\x14new_execution_run_id\x18\x04 \x01(\t"\x80\x01\n(WorkflowExecutionTimedOutEventAttributes\x12\x36\n\x0bretry_state\x18\x01 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState\x12\x1c\n\x14new_execution_run_id\x18\x02 \x01(\t"\xb8\x06\n.WorkflowExecutionContinuedAsNewEventAttributes\x12\x1c\n\x14new_execution_run_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_run_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03\x12?\n\x16\x62\x61\x63koff_start_interval\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12@\n\tinitiator\x18\t \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12\x31\n\x07\x66\x61ilure\x18\n \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0b \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12.\n\x06header\x18\x0c \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\r \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0e \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xb2\x01\n$WorkflowTaskScheduledEventAttributes\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12?\n\x16start_to_close_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x03 \x01(\x05"\xa3\x01\n"WorkflowTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x1f\n\x17suggest_continue_as_new\x18\x04 \x01(\x08\x12\x1a\n\x12history_size_bytes\x18\x05 \x01(\x03"\xda\x02\n$WorkflowTaskCompletedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12\x42\n\x0eworker_version\x18\x05 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12H\n\x0csdk_metadata\x18\x06 \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata"\x95\x01\n#WorkflowTaskTimedOutEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12\x38\n\x0ctimeout_type\x18\x03 \x01(\x0e\x32".temporal.api.enums.v1.TimeoutType"\xbb\x02\n!WorkflowTaskFailedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12=\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x04 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x13\n\x0b\x62\x61se_run_id\x18\x06 \x01(\t\x12\x12\n\nnew_run_id\x18\x07 \x01(\t\x12\x1a\n\x12\x66ork_event_version\x18\x08 \x01(\x03\x12\x17\n\x0f\x62inary_checksum\x18\t \x01(\t"\x83\x05\n$ActivityTaskScheduledEventAttributes\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x06 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x42\n\x19schedule_to_close_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x42\n\x19schedule_to_start_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicyJ\x04\x08\x03\x10\x04"\xaf\x01\n"ActivityTaskStartedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x12\n\nrequest_id\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\x05\x12\x36\n\x0clast_failure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xa0\x01\n$ActivityTaskCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xd6\x01\n!ActivityTaskFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x36\n\x0bretry_state\x18\x05 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc6\x01\n#ActivityTaskTimedOutEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1a\n\x12scheduled_event_id\x18\x02 \x01(\x03\x12\x18\n\x10started_event_id\x18\x03 \x01(\x03\x12\x36\n\x0bretry_state\x18\x04 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"r\n*ActivityTaskCancelRequestedEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03"\xca\x01\n#ActivityTaskCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12(\n latest_cancel_requested_event_id\x18\x02 \x01(\x03\x12\x1a\n\x12scheduled_event_id\x18\x03 \x01(\x03\x12\x18\n\x10started_event_id\x18\x04 \x01(\x03\x12\x10\n\x08identity\x18\x05 \x01(\t"\x99\x01\n\x1bTimerStartedEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12>\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03"G\n\x19TimerFiredEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03"\x86\x01\n\x1cTimerCanceledEventAttributes\x12\x10\n\x08timer_id\x18\x01 \x01(\t\x12\x18\n\x10started_event_id\x18\x02 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12\x10\n\x08identity\x18\x04 \x01(\t"\xc7\x01\n/WorkflowExecutionCancelRequestedEventAttributes\x12\r\n\x05\x63\x61use\x18\x01 \x01(\t\x12#\n\x1b\x65xternal_initiated_event_id\x18\x02 \x01(\x03\x12N\n\x1b\x65xternal_workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x04 \x01(\t"\x87\x01\n(WorkflowExecutionCanceledEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"\xe9\x02\n\x1dMarkerRecordedEventAttributes\x12\x13\n\x0bmarker_name\x18\x01 \x01(\t\x12T\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x43.temporal.api.history.v1.MarkerRecordedEventAttributes.DetailsEntry\x12(\n workflow_task_completed_event_id\x18\x03 \x01(\x03\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x1aP\n\x0c\x44\x65tailsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12/\n\x05value\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads:\x02\x38\x01"\xd7\x01\n(WorkflowExecutionSignaledEventAttributes\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12/\n\x05input\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12.\n\x06header\x18\x04 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\x05 \x01(\x08"\x81\x01\n*WorkflowExecutionTerminatedEventAttributes\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t"\x98\x02\n>RequestCancelExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x05 \x01(\x08\x12\x0e\n\x06reason\x18\x06 \x01(\t"\xd6\x02\n;RequestCancelExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.CancelExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xc5\x01\n7ExternalWorkflowExecutionCancelRequestedEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x04 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xf7\x02\n7SignalExternalWorkflowExecutionInitiatedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\t \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t\x12\x1b\n\x13\x63hild_workflow_only\x18\x07 \x01(\x08\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xcf\x02\n4SignalExternalWorkflowExecutionFailedEventAttributes\x12P\n\x05\x63\x61use\x18\x01 \x01(\x0e\x32\x41.temporal.api.enums.v1.SignalExternalWorkflowExecutionFailedCause\x12(\n workflow_task_completed_event_id\x18\x02 \x01(\x03\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x63ontrol\x18\x06 \x01(\t"\xcf\x01\n0ExternalWorkflowExecutionSignaledEventAttributes\x12\x1a\n\x12initiated_event_id\x18\x01 \x01(\x03\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x05 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0f\n\x07\x63ontrol\x18\x04 \x01(\t"\x9e\x01\n-UpsertWorkflowSearchAttributesEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x43\n\x11search_attributes\x18\x02 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\x8a\x01\n)WorkflowPropertiesModifiedEventAttributes\x12(\n workflow_task_completed_event_id\x18\x01 \x01(\x03\x12\x33\n\rupserted_memo\x18\x02 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\xa4\x07\n3StartChildWorkflowExecutionInitiatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x12 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x45\n\x13parent_close_policy\x18\t \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy\x12\x0f\n\x07\x63ontrol\x18\n \x01(\t\x12(\n workflow_task_completed_event_id\x18\x0b \x01(\x03\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12.\n\x06header\x18\x0f \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12*\n\x04memo\x18\x10 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x11 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"\xd2\x02\n0StartChildWorkflowExecutionFailedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12L\n\x05\x63\x61use\x18\x04 \x01(\x0e\x32=.temporal.api.enums.v1.StartChildWorkflowExecutionFailedCause\x12\x0f\n\x07\x63ontrol\x18\x05 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x06 \x01(\x03\x12(\n workflow_task_completed_event_id\x18\x07 \x01(\x03"\xa7\x02\n,ChildWorkflowExecutionStartedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x1a\n\x12initiated_event_id\x18\x02 \x01(\x03\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12.\n\x06header\x18\x05 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"\xc5\x02\n.ChildWorkflowExecutionCompletedEventAttributes\x12\x30\n\x06result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xfb\x02\n+ChildWorkflowExecutionFailedEventAttributes\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x08 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03\x12\x36\n\x0bretry_state\x18\x07 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\xc5\x02\n-ChildWorkflowExecutionCanceledEventAttributes\x12\x31\n\x07\x64\x65tails\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x04 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x05 \x01(\x03\x12\x18\n\x10started_event_id\x18\x06 \x01(\x03"\xca\x02\n-ChildWorkflowExecutionTimedOutEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x07 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x36\n\x0bretry_state\x18\x06 \x01(\x0e\x32!.temporal.api.enums.v1.RetryState"\x94\x02\n/ChildWorkflowExecutionTerminatedEventAttributes\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x14\n\x0cnamespace_id\x18\x06 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x1a\n\x12initiated_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03"\xd2\x02\n3WorkflowPropertiesModifiedExternallyEventAttributes\x12\x16\n\x0enew_task_queue\x18\x01 \x01(\t\x12\x42\n\x19new_workflow_task_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x41\n\x18new_workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x1enew_workflow_execution_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x33\n\rupserted_memo\x18\x05 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo"\x90\x01\n3ActivityPropertiesModifiedExternallyEventAttributes\x12\x1a\n\x12scheduled_event_id\x18\x01 \x01(\x03\x12=\n\x10new_retry_policy\x18\x02 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\xdc\x01\n.WorkflowExecutionUpdateAcceptedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1b\x61\x63\x63\x65pted_request_message_id\x18\x02 \x01(\t\x12,\n$accepted_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10\x61\x63\x63\x65pted_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\x8f\x01\n/WorkflowExecutionUpdateCompletedEventAttributes\x12*\n\x04meta\x18\x01 \x01(\x0b\x32\x1c.temporal.api.update.v1.Meta\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\x8f\x02\n.WorkflowExecutionUpdateRejectedEventAttributes\x12\x1c\n\x14protocol_instance_id\x18\x01 \x01(\t\x12#\n\x1brejected_request_message_id\x18\x02 \x01(\t\x12,\n$rejected_request_sequencing_event_id\x18\x03 \x01(\x03\x12\x39\n\x10rejected_request\x18\x04 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xe5/\n\x0cHistoryEvent\x12\x10\n\x08\x65vent_id\x18\x01 \x01(\x03\x12\x34\n\nevent_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nevent_type\x18\x03 \x01(\x0e\x32 .temporal.api.enums.v1.EventType\x12\x0f\n\x07version\x18\x04 \x01(\x03\x12\x0f\n\x07task_id\x18\x05 \x01(\x03\x12\x1a\n\x11worker_may_ignore\x18\xac\x02 \x01(\x08\x12w\n+workflow_execution_started_event_attributes\x18\x06 \x01(\x0b\x32@.temporal.api.history.v1.WorkflowExecutionStartedEventAttributesH\x00\x12{\n-workflow_execution_completed_event_attributes\x18\x07 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowExecutionCompletedEventAttributesH\x00\x12u\n*workflow_execution_failed_event_attributes\x18\x08 \x01(\x0b\x32?.temporal.api.history.v1.WorkflowExecutionFailedEventAttributesH\x00\x12z\n-workflow_execution_timed_out_event_attributes\x18\t \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionTimedOutEventAttributesH\x00\x12q\n(workflow_task_scheduled_event_attributes\x18\n \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskScheduledEventAttributesH\x00\x12m\n&workflow_task_started_event_attributes\x18\x0b \x01(\x0b\x32;.temporal.api.history.v1.WorkflowTaskStartedEventAttributesH\x00\x12q\n(workflow_task_completed_event_attributes\x18\x0c \x01(\x0b\x32=.temporal.api.history.v1.WorkflowTaskCompletedEventAttributesH\x00\x12p\n(workflow_task_timed_out_event_attributes\x18\r \x01(\x0b\x32<.temporal.api.history.v1.WorkflowTaskTimedOutEventAttributesH\x00\x12k\n%workflow_task_failed_event_attributes\x18\x0e \x01(\x0b\x32:.temporal.api.history.v1.WorkflowTaskFailedEventAttributesH\x00\x12q\n(activity_task_scheduled_event_attributes\x18\x0f \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskScheduledEventAttributesH\x00\x12m\n&activity_task_started_event_attributes\x18\x10 \x01(\x0b\x32;.temporal.api.history.v1.ActivityTaskStartedEventAttributesH\x00\x12q\n(activity_task_completed_event_attributes\x18\x11 \x01(\x0b\x32=.temporal.api.history.v1.ActivityTaskCompletedEventAttributesH\x00\x12k\n%activity_task_failed_event_attributes\x18\x12 \x01(\x0b\x32:.temporal.api.history.v1.ActivityTaskFailedEventAttributesH\x00\x12p\n(activity_task_timed_out_event_attributes\x18\x13 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskTimedOutEventAttributesH\x00\x12^\n\x1etimer_started_event_attributes\x18\x14 \x01(\x0b\x32\x34.temporal.api.history.v1.TimerStartedEventAttributesH\x00\x12Z\n\x1ctimer_fired_event_attributes\x18\x15 \x01(\x0b\x32\x32.temporal.api.history.v1.TimerFiredEventAttributesH\x00\x12~\n/activity_task_cancel_requested_event_attributes\x18\x16 \x01(\x0b\x32\x43.temporal.api.history.v1.ActivityTaskCancelRequestedEventAttributesH\x00\x12o\n\'activity_task_canceled_event_attributes\x18\x17 \x01(\x0b\x32<.temporal.api.history.v1.ActivityTaskCanceledEventAttributesH\x00\x12`\n\x1ftimer_canceled_event_attributes\x18\x18 \x01(\x0b\x32\x35.temporal.api.history.v1.TimerCanceledEventAttributesH\x00\x12\x62\n marker_recorded_event_attributes\x18\x19 \x01(\x0b\x32\x36.temporal.api.history.v1.MarkerRecordedEventAttributesH\x00\x12y\n,workflow_execution_signaled_event_attributes\x18\x1a \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionSignaledEventAttributesH\x00\x12}\n.workflow_execution_terminated_event_attributes\x18\x1b \x01(\x0b\x32\x43.temporal.api.history.v1.WorkflowExecutionTerminatedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_cancel_requested_event_attributes\x18\x1c \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionCancelRequestedEventAttributesH\x00\x12y\n,workflow_execution_canceled_event_attributes\x18\x1d \x01(\x0b\x32\x41.temporal.api.history.v1.WorkflowExecutionCanceledEventAttributesH\x00\x12\xa8\x01\nErequest_cancel_external_workflow_execution_initiated_event_attributes\x18\x1e \x01(\x0b\x32W.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\xa2\x01\nBrequest_cancel_external_workflow_execution_failed_event_attributes\x18\x1f \x01(\x0b\x32T.temporal.api.history.v1.RequestCancelExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x99\x01\n=external_workflow_execution_cancel_requested_event_attributes\x18  \x01(\x0b\x32P.temporal.api.history.v1.ExternalWorkflowExecutionCancelRequestedEventAttributesH\x00\x12\x87\x01\n4workflow_execution_continued_as_new_event_attributes\x18! \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionContinuedAsNewEventAttributesH\x00\x12\x91\x01\n9start_child_workflow_execution_initiated_event_attributes\x18" \x01(\x0b\x32L.temporal.api.history.v1.StartChildWorkflowExecutionInitiatedEventAttributesH\x00\x12\x8b\x01\n6start_child_workflow_execution_failed_event_attributes\x18# \x01(\x0b\x32I.temporal.api.history.v1.StartChildWorkflowExecutionFailedEventAttributesH\x00\x12\x82\x01\n1child_workflow_execution_started_event_attributes\x18$ \x01(\x0b\x32\x45.temporal.api.history.v1.ChildWorkflowExecutionStartedEventAttributesH\x00\x12\x86\x01\n3child_workflow_execution_completed_event_attributes\x18% \x01(\x0b\x32G.temporal.api.history.v1.ChildWorkflowExecutionCompletedEventAttributesH\x00\x12\x80\x01\n0child_workflow_execution_failed_event_attributes\x18& \x01(\x0b\x32\x44.temporal.api.history.v1.ChildWorkflowExecutionFailedEventAttributesH\x00\x12\x84\x01\n2child_workflow_execution_canceled_event_attributes\x18\' \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionCanceledEventAttributesH\x00\x12\x85\x01\n3child_workflow_execution_timed_out_event_attributes\x18( \x01(\x0b\x32\x46.temporal.api.history.v1.ChildWorkflowExecutionTimedOutEventAttributesH\x00\x12\x88\x01\n4child_workflow_execution_terminated_event_attributes\x18) \x01(\x0b\x32H.temporal.api.history.v1.ChildWorkflowExecutionTerminatedEventAttributesH\x00\x12\x99\x01\n=signal_external_workflow_execution_initiated_event_attributes\x18* \x01(\x0b\x32P.temporal.api.history.v1.SignalExternalWorkflowExecutionInitiatedEventAttributesH\x00\x12\x93\x01\n:signal_external_workflow_execution_failed_event_attributes\x18+ \x01(\x0b\x32M.temporal.api.history.v1.SignalExternalWorkflowExecutionFailedEventAttributesH\x00\x12\x8a\x01\n5external_workflow_execution_signaled_event_attributes\x18, \x01(\x0b\x32I.temporal.api.history.v1.ExternalWorkflowExecutionSignaledEventAttributesH\x00\x12\x84\x01\n2upsert_workflow_search_attributes_event_attributes\x18- \x01(\x0b\x32\x46.temporal.api.history.v1.UpsertWorkflowSearchAttributesEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_accepted_event_attributes\x18. \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateAcceptedEventAttributesH\x00\x12\x86\x01\n3workflow_execution_update_rejected_event_attributes\x18/ \x01(\x0b\x32G.temporal.api.history.v1.WorkflowExecutionUpdateRejectedEventAttributesH\x00\x12\x88\x01\n4workflow_execution_update_completed_event_attributes\x18\x30 \x01(\x0b\x32H.temporal.api.history.v1.WorkflowExecutionUpdateCompletedEventAttributesH\x00\x12\x90\x01\n8workflow_properties_modified_externally_event_attributes\x18\x31 \x01(\x0b\x32L.temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributesH\x00\x12\x90\x01\n8activity_properties_modified_externally_event_attributes\x18\x32 \x01(\x0b\x32L.temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributesH\x00\x12{\n-workflow_properties_modified_event_attributes\x18\x33 \x01(\x0b\x32\x42.temporal.api.history.v1.WorkflowPropertiesModifiedEventAttributesH\x00\x42\x0c\n\nattributes"@\n\x07History\x12\x35\n\x06\x65vents\x18\x01 \x03(\x0b\x32%.temporal.api.history.v1.HistoryEventB\x8e\x01\n\x1aio.temporal.api.history.v1B\x0cMessageProtoP\x01Z%go.temporal.io/api/history/v1;history\xaa\x02\x19Temporalio.Api.History.V1\xea\x02\x1cTemporalio::Api::History::V1b\x06proto3'
 )
 
 
 _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "WorkflowExecutionStartedEventAttributes"
 ]
 _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
@@ -181,29 +184,29 @@
 ]
 _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ChildWorkflowExecutionTimedOutEventAttributes"
 ]
 _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ChildWorkflowExecutionTerminatedEventAttributes"
 ]
-_WORKFLOWUPDATEACCEPTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "WorkflowUpdateAcceptedEventAttributes"
-]
-_WORKFLOWUPDATECOMPLETEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "WorkflowUpdateCompletedEventAttributes"
-]
-_WORKFLOWUPDATEREJECTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
-    "WorkflowUpdateRejectedEventAttributes"
-]
 _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "WorkflowPropertiesModifiedExternallyEventAttributes"
 ]
 _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "ActivityPropertiesModifiedExternallyEventAttributes"
 ]
+_WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
+    "WorkflowExecutionUpdateAcceptedEventAttributes"
+]
+_WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
+    "WorkflowExecutionUpdateCompletedEventAttributes"
+]
+_WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES = DESCRIPTOR.message_types_by_name[
+    "WorkflowExecutionUpdateRejectedEventAttributes"
+]
 _HISTORYEVENT = DESCRIPTOR.message_types_by_name["HistoryEvent"]
 _HISTORY = DESCRIPTOR.message_types_by_name["History"]
 WorkflowExecutionStartedEventAttributes = _reflection.GeneratedProtocolMessageType(
     "WorkflowExecutionStartedEventAttributes",
     (_message.Message,),
     {
         "DESCRIPTOR": _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES,
@@ -659,68 +662,68 @@
         "DESCRIPTOR": _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.history.v1.ChildWorkflowExecutionTerminatedEventAttributes)
     },
 )
 _sym_db.RegisterMessage(ChildWorkflowExecutionTerminatedEventAttributes)
 
-WorkflowUpdateAcceptedEventAttributes = _reflection.GeneratedProtocolMessageType(
-    "WorkflowUpdateAcceptedEventAttributes",
+WorkflowPropertiesModifiedExternallyEventAttributes = _reflection.GeneratedProtocolMessageType(
+    "WorkflowPropertiesModifiedExternallyEventAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _WORKFLOWUPDATEACCEPTEDEVENTATTRIBUTES,
+        "DESCRIPTOR": _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowUpdateAcceptedEventAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributes)
     },
 )
-_sym_db.RegisterMessage(WorkflowUpdateAcceptedEventAttributes)
+_sym_db.RegisterMessage(WorkflowPropertiesModifiedExternallyEventAttributes)
 
-WorkflowUpdateCompletedEventAttributes = _reflection.GeneratedProtocolMessageType(
-    "WorkflowUpdateCompletedEventAttributes",
+ActivityPropertiesModifiedExternallyEventAttributes = _reflection.GeneratedProtocolMessageType(
+    "ActivityPropertiesModifiedExternallyEventAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _WORKFLOWUPDATECOMPLETEDEVENTATTRIBUTES,
+        "DESCRIPTOR": _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowUpdateCompletedEventAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributes)
     },
 )
-_sym_db.RegisterMessage(WorkflowUpdateCompletedEventAttributes)
+_sym_db.RegisterMessage(ActivityPropertiesModifiedExternallyEventAttributes)
 
-WorkflowUpdateRejectedEventAttributes = _reflection.GeneratedProtocolMessageType(
-    "WorkflowUpdateRejectedEventAttributes",
+WorkflowExecutionUpdateAcceptedEventAttributes = _reflection.GeneratedProtocolMessageType(
+    "WorkflowExecutionUpdateAcceptedEventAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _WORKFLOWUPDATEREJECTEDEVENTATTRIBUTES,
+        "DESCRIPTOR": _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowUpdateRejectedEventAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowExecutionUpdateAcceptedEventAttributes)
     },
 )
-_sym_db.RegisterMessage(WorkflowUpdateRejectedEventAttributes)
+_sym_db.RegisterMessage(WorkflowExecutionUpdateAcceptedEventAttributes)
 
-WorkflowPropertiesModifiedExternallyEventAttributes = _reflection.GeneratedProtocolMessageType(
-    "WorkflowPropertiesModifiedExternallyEventAttributes",
+WorkflowExecutionUpdateCompletedEventAttributes = _reflection.GeneratedProtocolMessageType(
+    "WorkflowExecutionUpdateCompletedEventAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES,
+        "DESCRIPTOR": _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowPropertiesModifiedExternallyEventAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowExecutionUpdateCompletedEventAttributes)
     },
 )
-_sym_db.RegisterMessage(WorkflowPropertiesModifiedExternallyEventAttributes)
+_sym_db.RegisterMessage(WorkflowExecutionUpdateCompletedEventAttributes)
 
-ActivityPropertiesModifiedExternallyEventAttributes = _reflection.GeneratedProtocolMessageType(
-    "ActivityPropertiesModifiedExternallyEventAttributes",
+WorkflowExecutionUpdateRejectedEventAttributes = _reflection.GeneratedProtocolMessageType(
+    "WorkflowExecutionUpdateRejectedEventAttributes",
     (_message.Message,),
     {
-        "DESCRIPTOR": _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES,
+        "DESCRIPTOR": _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES,
         "__module__": "temporal.api.history.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.ActivityPropertiesModifiedExternallyEventAttributes)
+        # @@protoc_insertion_point(class_scope:temporal.api.history.v1.WorkflowExecutionUpdateRejectedEventAttributes)
     },
 )
-_sym_db.RegisterMessage(ActivityPropertiesModifiedExternallyEventAttributes)
+_sym_db.RegisterMessage(WorkflowExecutionUpdateRejectedEventAttributes)
 
 HistoryEvent = _reflection.GeneratedProtocolMessageType(
     "HistoryEvent",
     (_message.Message,),
     {
         "DESCRIPTOR": _HISTORYEVENT,
         "__module__": "temporal.api.history.v1.message_pb2"
@@ -861,112 +864,112 @@
         "new_workflow_execution_timeout"
     ]._options = None
     _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES.fields_by_name[
         "new_workflow_execution_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _HISTORYEVENT.fields_by_name["event_time"]._options = None
     _HISTORYEVENT.fields_by_name["event_time"]._serialized_options = b"\220\337\037\001"
-    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 488
-    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 1912
-    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 1915
-    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 2080
-    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 2083
-    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 2302
-    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 2305
-    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 2433
-    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_start = 2436
-    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_end = 3260
-    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 3263
-    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 3441
-    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_start = 3444
-    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_end = 3607
-    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 3610
-    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 3813
-    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 3816
-    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 3965
-    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_start = 3968
-    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_end = 4283
-    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 4286
-    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 4929
-    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_start = 4932
-    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_end = 5107
-    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 5110
-    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 5270
-    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_start = 5273
-    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_end = 5487
-    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 5490
-    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 5688
-    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 5690
-    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 5804
-    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_start = 5807
-    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_end = 6009
-    _TIMERSTARTEDEVENTATTRIBUTES._serialized_start = 6012
-    _TIMERSTARTEDEVENTATTRIBUTES._serialized_end = 6165
-    _TIMERFIREDEVENTATTRIBUTES._serialized_start = 6167
-    _TIMERFIREDEVENTATTRIBUTES._serialized_end = 6238
-    _TIMERCANCELEDEVENTATTRIBUTES._serialized_start = 6241
-    _TIMERCANCELEDEVENTATTRIBUTES._serialized_end = 6375
-    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 6378
-    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 6577
-    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 6580
-    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 6715
-    _MARKERRECORDEDEVENTATTRIBUTES._serialized_start = 6718
-    _MARKERRECORDEDEVENTATTRIBUTES._serialized_end = 7079
-    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_start = 6999
-    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_end = 7079
-    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 7082
-    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 7260
-    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 7263
-    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 7392
+    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 533
+    _WORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 1957
+    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 1960
+    _WORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 2125
+    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 2128
+    _WORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 2347
+    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 2350
+    _WORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 2478
+    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_start = 2481
+    _WORKFLOWEXECUTIONCONTINUEDASNEWEVENTATTRIBUTES._serialized_end = 3305
+    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 3308
+    _WORKFLOWTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 3486
+    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_start = 3489
+    _WORKFLOWTASKSTARTEDEVENTATTRIBUTES._serialized_end = 3652
+    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 3655
+    _WORKFLOWTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 4001
+    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 4004
+    _WORKFLOWTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 4153
+    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_start = 4156
+    _WORKFLOWTASKFAILEDEVENTATTRIBUTES._serialized_end = 4471
+    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_start = 4474
+    _ACTIVITYTASKSCHEDULEDEVENTATTRIBUTES._serialized_end = 5117
+    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_start = 5120
+    _ACTIVITYTASKSTARTEDEVENTATTRIBUTES._serialized_end = 5295
+    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_start = 5298
+    _ACTIVITYTASKCOMPLETEDEVENTATTRIBUTES._serialized_end = 5458
+    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_start = 5461
+    _ACTIVITYTASKFAILEDEVENTATTRIBUTES._serialized_end = 5675
+    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_start = 5678
+    _ACTIVITYTASKTIMEDOUTEVENTATTRIBUTES._serialized_end = 5876
+    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 5878
+    _ACTIVITYTASKCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 5992
+    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_start = 5995
+    _ACTIVITYTASKCANCELEDEVENTATTRIBUTES._serialized_end = 6197
+    _TIMERSTARTEDEVENTATTRIBUTES._serialized_start = 6200
+    _TIMERSTARTEDEVENTATTRIBUTES._serialized_end = 6353
+    _TIMERFIREDEVENTATTRIBUTES._serialized_start = 6355
+    _TIMERFIREDEVENTATTRIBUTES._serialized_end = 6426
+    _TIMERCANCELEDEVENTATTRIBUTES._serialized_start = 6429
+    _TIMERCANCELEDEVENTATTRIBUTES._serialized_end = 6563
+    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 6566
+    _WORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 6765
+    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 6768
+    _WORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 6903
+    _MARKERRECORDEDEVENTATTRIBUTES._serialized_start = 6906
+    _MARKERRECORDEDEVENTATTRIBUTES._serialized_end = 7267
+    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_start = 7187
+    _MARKERRECORDEDEVENTATTRIBUTES_DETAILSENTRY._serialized_end = 7267
+    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 7270
+    _WORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 7485
+    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 7488
+    _WORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 7617
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = (
-        7395
+        7620
     )
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = (
-        7675
+        7900
     )
     _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = (
-        7678
+        7903
     )
-    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 8020
-    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 8023
-    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 8220
-    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 8223
-    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 8598
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 8601
-    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 8936
-    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 8939
-    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 9146
-    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_start = 9149
-    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_end = 9307
-    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_start = 9310
-    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_end = 9448
-    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 9451
-    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 10383
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 10386
-    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 10724
-    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 10727
-    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 11022
-    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 11025
-    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 11350
-    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 11353
-    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 11732
-    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 11735
-    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 12060
-    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 12063
-    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 12393
-    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 12396
-    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 12672
-    _WORKFLOWUPDATEACCEPTEDEVENTATTRIBUTES._serialized_start = 12675
-    _WORKFLOWUPDATEACCEPTEDEVENTATTRIBUTES._serialized_end = 12814
-    _WORKFLOWUPDATECOMPLETEDEVENTATTRIBUTES._serialized_start = 12817
-    _WORKFLOWUPDATECOMPLETEDEVENTATTRIBUTES._serialized_end = 12959
-    _WORKFLOWUPDATEREJECTEDEVENTATTRIBUTES._serialized_start = 12962
-    _WORKFLOWUPDATEREJECTEDEVENTATTRIBUTES._serialized_end = 13101
-    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13104
-    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13442
-    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13445
-    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13589
-    _HISTORYEVENT._serialized_start = 13592
-    _HISTORYEVENT._serialized_end = 19649
-    _HISTORY._serialized_start = 19651
-    _HISTORY._serialized_end = 19715
+    _REQUESTCANCELEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 8245
+    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_start = 8248
+    _EXTERNALWORKFLOWEXECUTIONCANCELREQUESTEDEVENTATTRIBUTES._serialized_end = 8445
+    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 8448
+    _SIGNALEXTERNALWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 8823
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 8826
+    _SIGNALEXTERNALWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 9161
+    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_start = 9164
+    _EXTERNALWORKFLOWEXECUTIONSIGNALEDEVENTATTRIBUTES._serialized_end = 9371
+    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_start = 9374
+    _UPSERTWORKFLOWSEARCHATTRIBUTESEVENTATTRIBUTES._serialized_end = 9532
+    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_start = 9535
+    _WORKFLOWPROPERTIESMODIFIEDEVENTATTRIBUTES._serialized_end = 9673
+    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_start = 9676
+    _STARTCHILDWORKFLOWEXECUTIONINITIATEDEVENTATTRIBUTES._serialized_end = 10608
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 10611
+    _STARTCHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 10949
+    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_start = 10952
+    _CHILDWORKFLOWEXECUTIONSTARTEDEVENTATTRIBUTES._serialized_end = 11247
+    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_start = 11250
+    _CHILDWORKFLOWEXECUTIONCOMPLETEDEVENTATTRIBUTES._serialized_end = 11575
+    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_start = 11578
+    _CHILDWORKFLOWEXECUTIONFAILEDEVENTATTRIBUTES._serialized_end = 11957
+    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_start = 11960
+    _CHILDWORKFLOWEXECUTIONCANCELEDEVENTATTRIBUTES._serialized_end = 12285
+    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_start = 12288
+    _CHILDWORKFLOWEXECUTIONTIMEDOUTEVENTATTRIBUTES._serialized_end = 12618
+    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_start = 12621
+    _CHILDWORKFLOWEXECUTIONTERMINATEDEVENTATTRIBUTES._serialized_end = 12897
+    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 12900
+    _WORKFLOWPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13238
+    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_start = 13241
+    _ACTIVITYPROPERTIESMODIFIEDEXTERNALLYEVENTATTRIBUTES._serialized_end = 13385
+    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_start = 13388
+    _WORKFLOWEXECUTIONUPDATEACCEPTEDEVENTATTRIBUTES._serialized_end = 13608
+    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_start = 13611
+    _WORKFLOWEXECUTIONUPDATECOMPLETEDEVENTATTRIBUTES._serialized_end = 13754
+    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_start = 13757
+    _WORKFLOWEXECUTIONUPDATEREJECTEDEVENTATTRIBUTES._serialized_end = 14028
+    _HISTORYEVENT._serialized_start = 14031
+    _HISTORYEVENT._serialized_end = 20148
+    _HISTORY._serialized_start = 20150
+    _HISTORY._serialized_end = 20214
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/history/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/history/v1/message_pb2.pyi`

 * *Files 1% similar despite different names*

```diff
@@ -32,16 +32,17 @@
 import google.protobuf.timestamp_pb2
 import sys
 import temporalio.api.common.v1.message_pb2
 import temporalio.api.enums.v1.event_type_pb2
 import temporalio.api.enums.v1.failed_cause_pb2
 import temporalio.api.enums.v1.workflow_pb2
 import temporalio.api.failure.v1.message_pb2
-import temporalio.api.interaction.v1.message_pb2
+import temporalio.api.sdk.v1.task_complete_metadata_pb2
 import temporalio.api.taskqueue.v1.message_pb2
+import temporalio.api.update.v1.message_pb2
 import temporalio.api.workflow.v1.message_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
 
@@ -652,57 +653,85 @@
 class WorkflowTaskCompletedEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SCHEDULED_EVENT_ID_FIELD_NUMBER: builtins.int
     STARTED_EVENT_ID_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
-    WORKER_VERSIONING_ID_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_FIELD_NUMBER: builtins.int
+    SDK_METADATA_FIELD_NUMBER: builtins.int
+    METERING_METADATA_FIELD_NUMBER: builtins.int
     scheduled_event_id: builtins.int
     """The id of the `WORKFLOW_TASK_SCHEDULED` event this task corresponds to"""
     started_event_id: builtins.int
     """The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to"""
     identity: builtins.str
     """Identity of the worker who completed this task"""
     binary_checksum: builtins.str
     """Binary ID of the worker who completed this task"""
     @property
-    def worker_versioning_id(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """ID of the worker who picked up this workflow task, or missing if worker
-        is not using versioning.
+    def worker_version(self) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """Version info of the worker who processed this workflow task, or missing if worker is not
+        using versioning. If present, the `build_id` field within is also used as `binary_checksum`,
+        which may be omitted in that case (it may also be populated to preserve compatibility).
         """
+    @property
+    def sdk_metadata(
+        self,
+    ) -> temporalio.api.sdk.v1.task_complete_metadata_pb2.WorkflowTaskCompletedMetadata:
+        """Data the SDK wishes to record for itself, but server need not interpret, and does not
+        directly impact workflow state.
+        """
+    @property
+    def metering_metadata(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.MeteringMetadata:
+        """Local usage data sent during workflow task completion and recorded here for posterity"""
     def __init__(
         self,
         *,
         scheduled_event_id: builtins.int = ...,
         started_event_id: builtins.int = ...,
         identity: builtins.str = ...,
         binary_checksum: builtins.str = ...,
-        worker_versioning_id: temporalio.api.taskqueue.v1.message_pb2.VersionId
+        worker_version: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
+        sdk_metadata: temporalio.api.sdk.v1.task_complete_metadata_pb2.WorkflowTaskCompletedMetadata
+        | None = ...,
+        metering_metadata: temporalio.api.common.v1.message_pb2.MeteringMetadata
         | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "worker_versioning_id", b"worker_versioning_id"
+            "metering_metadata",
+            b"metering_metadata",
+            "sdk_metadata",
+            b"sdk_metadata",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "binary_checksum",
             b"binary_checksum",
             "identity",
             b"identity",
+            "metering_metadata",
+            b"metering_metadata",
             "scheduled_event_id",
             b"scheduled_event_id",
+            "sdk_metadata",
+            b"sdk_metadata",
             "started_event_id",
             b"started_event_id",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version",
+            b"worker_version",
         ],
     ) -> None: ...
 
 global___WorkflowTaskCompletedEventAttributes = WorkflowTaskCompletedEventAttributes
 
 class WorkflowTaskTimedOutEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1480,33 +1509,37 @@
 class WorkflowExecutionSignaledEventAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SIGNAL_NAME_FIELD_NUMBER: builtins.int
     INPUT_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
+    SKIP_GENERATE_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     signal_name: builtins.str
     """The name/type of the signal to fire"""
     @property
     def input(self) -> temporalio.api.common.v1.message_pb2.Payloads:
         """Will be deserialized and provided as argument(s) to the signal handler"""
     identity: builtins.str
     """id of the worker/client who sent this signal"""
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header:
         """Headers that were passed by the sender of the signal and copied by temporal
         server into the workflow task.
         """
+    skip_generate_workflow_task: builtins.bool
+    """Indicates the signal did not generate a new workflow task when received."""
     def __init__(
         self,
         *,
         signal_name: builtins.str = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         identity: builtins.str = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
+        skip_generate_workflow_task: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal["header", b"header", "input", b"input"],
     ) -> builtins.bool: ...
     def ClearField(
         self,
@@ -1515,14 +1548,16 @@
             b"header",
             "identity",
             b"identity",
             "input",
             b"input",
             "signal_name",
             b"signal_name",
+            "skip_generate_workflow_task",
+            b"skip_generate_workflow_task",
         ],
     ) -> None: ...
 
 global___WorkflowExecutionSignaledEventAttributes = (
     WorkflowExecutionSignaledEventAttributes
 )
 
@@ -2703,90 +2738,14 @@
         ],
     ) -> None: ...
 
 global___ChildWorkflowExecutionTerminatedEventAttributes = (
     ChildWorkflowExecutionTerminatedEventAttributes
 )
 
-class WorkflowUpdateAcceptedEventAttributes(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    META_FIELD_NUMBER: builtins.int
-    INPUT_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def input(self) -> temporalio.api.interaction.v1.message_pb2.Input: ...
-    def __init__(
-        self,
-        *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        input: temporalio.api.interaction.v1.message_pb2.Input | None = ...,
-    ) -> None: ...
-    def HasField(
-        self, field_name: typing_extensions.Literal["input", b"input", "meta", b"meta"]
-    ) -> builtins.bool: ...
-    def ClearField(
-        self, field_name: typing_extensions.Literal["input", b"input", "meta", b"meta"]
-    ) -> None: ...
-
-global___WorkflowUpdateAcceptedEventAttributes = WorkflowUpdateAcceptedEventAttributes
-
-class WorkflowUpdateCompletedEventAttributes(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    META_FIELD_NUMBER: builtins.int
-    OUTPUT_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def output(self) -> temporalio.api.interaction.v1.message_pb2.Output: ...
-    def __init__(
-        self,
-        *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        output: temporalio.api.interaction.v1.message_pb2.Output | None = ...,
-    ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal["meta", b"meta", "output", b"output"],
-    ) -> builtins.bool: ...
-    def ClearField(
-        self,
-        field_name: typing_extensions.Literal["meta", b"meta", "output", b"output"],
-    ) -> None: ...
-
-global___WorkflowUpdateCompletedEventAttributes = WorkflowUpdateCompletedEventAttributes
-
-class WorkflowUpdateRejectedEventAttributes(google.protobuf.message.Message):
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    META_FIELD_NUMBER: builtins.int
-    FAILURE_FIELD_NUMBER: builtins.int
-    @property
-    def meta(self) -> temporalio.api.interaction.v1.message_pb2.Meta: ...
-    @property
-    def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
-    def __init__(
-        self,
-        *,
-        meta: temporalio.api.interaction.v1.message_pb2.Meta | None = ...,
-        failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
-    ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal["failure", b"failure", "meta", b"meta"],
-    ) -> builtins.bool: ...
-    def ClearField(
-        self,
-        field_name: typing_extensions.Literal["failure", b"failure", "meta", b"meta"],
-    ) -> None: ...
-
-global___WorkflowUpdateRejectedEventAttributes = WorkflowUpdateRejectedEventAttributes
-
 class WorkflowPropertiesModifiedExternallyEventAttributes(
     google.protobuf.message.Message
 ):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NEW_TASK_QUEUE_FIELD_NUMBER: builtins.int
     NEW_WORKFLOW_TASK_TIMEOUT_FIELD_NUMBER: builtins.int
@@ -2889,14 +2848,155 @@
         ],
     ) -> None: ...
 
 global___ActivityPropertiesModifiedExternallyEventAttributes = (
     ActivityPropertiesModifiedExternallyEventAttributes
 )
 
+class WorkflowExecutionUpdateAcceptedEventAttributes(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    PROTOCOL_INSTANCE_ID_FIELD_NUMBER: builtins.int
+    ACCEPTED_REQUEST_MESSAGE_ID_FIELD_NUMBER: builtins.int
+    ACCEPTED_REQUEST_SEQUENCING_EVENT_ID_FIELD_NUMBER: builtins.int
+    ACCEPTED_REQUEST_FIELD_NUMBER: builtins.int
+    protocol_instance_id: builtins.str
+    """The instance ID of the update protocol that generated this event."""
+    accepted_request_message_id: builtins.str
+    """The message ID of the original request message that initiated this
+    update. Needed so that the worker can recreate and deliver that same
+    message as part of replay.
+    """
+    accepted_request_sequencing_event_id: builtins.int
+    """The event ID used to sequence the original request message."""
+    @property
+    def accepted_request(self) -> temporalio.api.update.v1.message_pb2.Request:
+        """The message payload of the original request message that initiated this
+        update.
+        """
+    def __init__(
+        self,
+        *,
+        protocol_instance_id: builtins.str = ...,
+        accepted_request_message_id: builtins.str = ...,
+        accepted_request_sequencing_event_id: builtins.int = ...,
+        accepted_request: temporalio.api.update.v1.message_pb2.Request | None = ...,
+    ) -> None: ...
+    def HasField(
+        self,
+        field_name: typing_extensions.Literal["accepted_request", b"accepted_request"],
+    ) -> builtins.bool: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "accepted_request",
+            b"accepted_request",
+            "accepted_request_message_id",
+            b"accepted_request_message_id",
+            "accepted_request_sequencing_event_id",
+            b"accepted_request_sequencing_event_id",
+            "protocol_instance_id",
+            b"protocol_instance_id",
+        ],
+    ) -> None: ...
+
+global___WorkflowExecutionUpdateAcceptedEventAttributes = (
+    WorkflowExecutionUpdateAcceptedEventAttributes
+)
+
+class WorkflowExecutionUpdateCompletedEventAttributes(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    META_FIELD_NUMBER: builtins.int
+    OUTCOME_FIELD_NUMBER: builtins.int
+    @property
+    def meta(self) -> temporalio.api.update.v1.message_pb2.Meta:
+        """The metadata about this update."""
+    @property
+    def outcome(self) -> temporalio.api.update.v1.message_pb2.Outcome:
+        """The outcome of executing the workflow update function."""
+    def __init__(
+        self,
+        *,
+        meta: temporalio.api.update.v1.message_pb2.Meta | None = ...,
+        outcome: temporalio.api.update.v1.message_pb2.Outcome | None = ...,
+    ) -> None: ...
+    def HasField(
+        self,
+        field_name: typing_extensions.Literal["meta", b"meta", "outcome", b"outcome"],
+    ) -> builtins.bool: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal["meta", b"meta", "outcome", b"outcome"],
+    ) -> None: ...
+
+global___WorkflowExecutionUpdateCompletedEventAttributes = (
+    WorkflowExecutionUpdateCompletedEventAttributes
+)
+
+class WorkflowExecutionUpdateRejectedEventAttributes(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    PROTOCOL_INSTANCE_ID_FIELD_NUMBER: builtins.int
+    REJECTED_REQUEST_MESSAGE_ID_FIELD_NUMBER: builtins.int
+    REJECTED_REQUEST_SEQUENCING_EVENT_ID_FIELD_NUMBER: builtins.int
+    REJECTED_REQUEST_FIELD_NUMBER: builtins.int
+    FAILURE_FIELD_NUMBER: builtins.int
+    protocol_instance_id: builtins.str
+    """The instance ID of the update protocol that generated this event."""
+    rejected_request_message_id: builtins.str
+    """The message ID of the original request message that initiated this
+    update. Needed so that the worker can recreate and deliver that same
+    message as part of replay.
+    """
+    rejected_request_sequencing_event_id: builtins.int
+    """The event ID used to sequence the original request message."""
+    @property
+    def rejected_request(self) -> temporalio.api.update.v1.message_pb2.Request:
+        """The message payload of the original request message that initiated this
+        update.
+        """
+    @property
+    def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
+        """The cause of rejection."""
+    def __init__(
+        self,
+        *,
+        protocol_instance_id: builtins.str = ...,
+        rejected_request_message_id: builtins.str = ...,
+        rejected_request_sequencing_event_id: builtins.int = ...,
+        rejected_request: temporalio.api.update.v1.message_pb2.Request | None = ...,
+        failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
+    ) -> None: ...
+    def HasField(
+        self,
+        field_name: typing_extensions.Literal[
+            "failure", b"failure", "rejected_request", b"rejected_request"
+        ],
+    ) -> builtins.bool: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "failure",
+            b"failure",
+            "protocol_instance_id",
+            b"protocol_instance_id",
+            "rejected_request",
+            b"rejected_request",
+            "rejected_request_message_id",
+            b"rejected_request_message_id",
+            "rejected_request_sequencing_event_id",
+            b"rejected_request_sequencing_event_id",
+        ],
+    ) -> None: ...
+
+global___WorkflowExecutionUpdateRejectedEventAttributes = (
+    WorkflowExecutionUpdateRejectedEventAttributes
+)
+
 class HistoryEvent(google.protobuf.message.Message):
     """History events are the method by which Temporal SDKs advance (or recreate) workflow state.
     See the `EventType` enum for more info about what each event is for.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -2942,17 +3042,17 @@
     CHILD_WORKFLOW_EXECUTION_CANCELED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     CHILD_WORKFLOW_EXECUTION_TIMED_OUT_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     CHILD_WORKFLOW_EXECUTION_TERMINATED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_INITIATED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     EXTERNAL_WORKFLOW_EXECUTION_SIGNALED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     UPSERT_WORKFLOW_SEARCH_ATTRIBUTES_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    WORKFLOW_UPDATE_REJECTED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    WORKFLOW_UPDATE_ACCEPTED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
-    WORKFLOW_UPDATE_COMPLETED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    WORKFLOW_EXECUTION_UPDATE_ACCEPTED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    WORKFLOW_EXECUTION_UPDATE_REJECTED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    WORKFLOW_EXECUTION_UPDATE_COMPLETED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     ACTIVITY_PROPERTIES_MODIFIED_EXTERNALLY_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     WORKFLOW_PROPERTIES_MODIFIED_EVENT_ATTRIBUTES_FIELD_NUMBER: builtins.int
     event_id: builtins.int
     """Monotonically increasing event number, starts at 1."""
     @property
     def event_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
@@ -3122,25 +3222,25 @@
         self,
     ) -> global___ExternalWorkflowExecutionSignaledEventAttributes: ...
     @property
     def upsert_workflow_search_attributes_event_attributes(
         self,
     ) -> global___UpsertWorkflowSearchAttributesEventAttributes: ...
     @property
-    def workflow_update_rejected_event_attributes(
+    def workflow_execution_update_accepted_event_attributes(
         self,
-    ) -> global___WorkflowUpdateRejectedEventAttributes: ...
+    ) -> global___WorkflowExecutionUpdateAcceptedEventAttributes: ...
     @property
-    def workflow_update_accepted_event_attributes(
+    def workflow_execution_update_rejected_event_attributes(
         self,
-    ) -> global___WorkflowUpdateAcceptedEventAttributes: ...
+    ) -> global___WorkflowExecutionUpdateRejectedEventAttributes: ...
     @property
-    def workflow_update_completed_event_attributes(
+    def workflow_execution_update_completed_event_attributes(
         self,
-    ) -> global___WorkflowUpdateCompletedEventAttributes: ...
+    ) -> global___WorkflowExecutionUpdateCompletedEventAttributes: ...
     @property
     def workflow_properties_modified_externally_event_attributes(
         self,
     ) -> global___WorkflowPropertiesModifiedExternallyEventAttributes: ...
     @property
     def activity_properties_modified_externally_event_attributes(
         self,
@@ -3233,19 +3333,19 @@
         | None = ...,
         signal_external_workflow_execution_failed_event_attributes: global___SignalExternalWorkflowExecutionFailedEventAttributes
         | None = ...,
         external_workflow_execution_signaled_event_attributes: global___ExternalWorkflowExecutionSignaledEventAttributes
         | None = ...,
         upsert_workflow_search_attributes_event_attributes: global___UpsertWorkflowSearchAttributesEventAttributes
         | None = ...,
-        workflow_update_rejected_event_attributes: global___WorkflowUpdateRejectedEventAttributes
+        workflow_execution_update_accepted_event_attributes: global___WorkflowExecutionUpdateAcceptedEventAttributes
         | None = ...,
-        workflow_update_accepted_event_attributes: global___WorkflowUpdateAcceptedEventAttributes
+        workflow_execution_update_rejected_event_attributes: global___WorkflowExecutionUpdateRejectedEventAttributes
         | None = ...,
-        workflow_update_completed_event_attributes: global___WorkflowUpdateCompletedEventAttributes
+        workflow_execution_update_completed_event_attributes: global___WorkflowExecutionUpdateCompletedEventAttributes
         | None = ...,
         workflow_properties_modified_externally_event_attributes: global___WorkflowPropertiesModifiedExternallyEventAttributes
         | None = ...,
         activity_properties_modified_externally_event_attributes: global___ActivityPropertiesModifiedExternallyEventAttributes
         | None = ...,
         workflow_properties_modified_event_attributes: global___WorkflowPropertiesModifiedEventAttributes
         | None = ...,
@@ -3325,34 +3425,34 @@
             b"workflow_execution_signaled_event_attributes",
             "workflow_execution_started_event_attributes",
             b"workflow_execution_started_event_attributes",
             "workflow_execution_terminated_event_attributes",
             b"workflow_execution_terminated_event_attributes",
             "workflow_execution_timed_out_event_attributes",
             b"workflow_execution_timed_out_event_attributes",
+            "workflow_execution_update_accepted_event_attributes",
+            b"workflow_execution_update_accepted_event_attributes",
+            "workflow_execution_update_completed_event_attributes",
+            b"workflow_execution_update_completed_event_attributes",
+            "workflow_execution_update_rejected_event_attributes",
+            b"workflow_execution_update_rejected_event_attributes",
             "workflow_properties_modified_event_attributes",
             b"workflow_properties_modified_event_attributes",
             "workflow_properties_modified_externally_event_attributes",
             b"workflow_properties_modified_externally_event_attributes",
             "workflow_task_completed_event_attributes",
             b"workflow_task_completed_event_attributes",
             "workflow_task_failed_event_attributes",
             b"workflow_task_failed_event_attributes",
             "workflow_task_scheduled_event_attributes",
             b"workflow_task_scheduled_event_attributes",
             "workflow_task_started_event_attributes",
             b"workflow_task_started_event_attributes",
             "workflow_task_timed_out_event_attributes",
             b"workflow_task_timed_out_event_attributes",
-            "workflow_update_accepted_event_attributes",
-            b"workflow_update_accepted_event_attributes",
-            "workflow_update_completed_event_attributes",
-            b"workflow_update_completed_event_attributes",
-            "workflow_update_rejected_event_attributes",
-            b"workflow_update_rejected_event_attributes",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "activity_properties_modified_externally_event_attributes",
             b"activity_properties_modified_externally_event_attributes",
@@ -3436,34 +3536,34 @@
             b"workflow_execution_signaled_event_attributes",
             "workflow_execution_started_event_attributes",
             b"workflow_execution_started_event_attributes",
             "workflow_execution_terminated_event_attributes",
             b"workflow_execution_terminated_event_attributes",
             "workflow_execution_timed_out_event_attributes",
             b"workflow_execution_timed_out_event_attributes",
+            "workflow_execution_update_accepted_event_attributes",
+            b"workflow_execution_update_accepted_event_attributes",
+            "workflow_execution_update_completed_event_attributes",
+            b"workflow_execution_update_completed_event_attributes",
+            "workflow_execution_update_rejected_event_attributes",
+            b"workflow_execution_update_rejected_event_attributes",
             "workflow_properties_modified_event_attributes",
             b"workflow_properties_modified_event_attributes",
             "workflow_properties_modified_externally_event_attributes",
             b"workflow_properties_modified_externally_event_attributes",
             "workflow_task_completed_event_attributes",
             b"workflow_task_completed_event_attributes",
             "workflow_task_failed_event_attributes",
             b"workflow_task_failed_event_attributes",
             "workflow_task_scheduled_event_attributes",
             b"workflow_task_scheduled_event_attributes",
             "workflow_task_started_event_attributes",
             b"workflow_task_started_event_attributes",
             "workflow_task_timed_out_event_attributes",
             b"workflow_task_timed_out_event_attributes",
-            "workflow_update_accepted_event_attributes",
-            b"workflow_update_accepted_event_attributes",
-            "workflow_update_completed_event_attributes",
-            b"workflow_update_completed_event_attributes",
-            "workflow_update_rejected_event_attributes",
-            b"workflow_update_rejected_event_attributes",
         ],
     ) -> None: ...
     def WhichOneof(
         self, oneof_group: typing_extensions.Literal["attributes", b"attributes"]
     ) -> (
         typing_extensions.Literal[
             "workflow_execution_started_event_attributes",
@@ -3502,17 +3602,17 @@
             "child_workflow_execution_canceled_event_attributes",
             "child_workflow_execution_timed_out_event_attributes",
             "child_workflow_execution_terminated_event_attributes",
             "signal_external_workflow_execution_initiated_event_attributes",
             "signal_external_workflow_execution_failed_event_attributes",
             "external_workflow_execution_signaled_event_attributes",
             "upsert_workflow_search_attributes_event_attributes",
-            "workflow_update_rejected_event_attributes",
-            "workflow_update_accepted_event_attributes",
-            "workflow_update_completed_event_attributes",
+            "workflow_execution_update_accepted_event_attributes",
+            "workflow_execution_update_rejected_event_attributes",
+            "workflow_execution_update_completed_event_attributes",
             "workflow_properties_modified_externally_event_attributes",
             "activity_properties_modified_externally_event_attributes",
             "workflow_properties_modified_event_attributes",
         ]
         | None
     ): ...
```

### Comparing `temporalio-1.1.0/temporalio/api/interaction/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/interaction/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/interaction/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/namespace/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.py`

 * *Files 4% similar despite different names*

```diff
@@ -20,21 +20,24 @@
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     namespace_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_namespace__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n\'temporal/api/namespace/v1/message.proto\x12\x19temporal.api.namespace.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a%temporal/api/enums/v1/namespace.proto"\x94\x02\n\rNamespaceInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x34\n\x05state\x18\x02 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t\x12\x13\n\x0bowner_email\x18\x04 \x01(\t\x12@\n\x04\x64\x61ta\x18\x05 \x03(\x0b\x32\x32.temporal.api.namespace.v1.NamespaceInfo.DataEntry\x12\n\n\x02id\x18\x06 \x01(\t\x12\x1a\n\x12supports_schedules\x18\x64 \x01(\x08\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\xe8\x02\n\x0fNamespaceConfig\x12I\n workflow_execution_retention_ttl\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12<\n\x0c\x62\x61\x64_binaries\x18\x02 \x01(\x0b\x32&.temporal.api.namespace.v1.BadBinaries\x12\x44\n\x16history_archival_state\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x04 \x01(\t\x12G\n\x19visibility_archival_state\x18\x05 \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\x06 \x01(\t"\xb0\x01\n\x0b\x42\x61\x64\x42inaries\x12\x46\n\x08\x62inaries\x18\x01 \x03(\x0b\x32\x34.temporal.api.namespace.v1.BadBinaries.BinariesEntry\x1aY\n\rBinariesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x37\n\x05value\x18\x02 \x01(\x0b\x32(.temporal.api.namespace.v1.BadBinaryInfo:\x02\x38\x01"h\n\rBadBinaryInfo\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\x35\n\x0b\x63reate_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"\xea\x01\n\x13UpdateNamespaceInfo\x12\x13\n\x0b\x64\x65scription\x18\x01 \x01(\t\x12\x13\n\x0bowner_email\x18\x02 \x01(\t\x12\x46\n\x04\x64\x61ta\x18\x03 \x03(\x0b\x32\x38.temporal.api.namespace.v1.UpdateNamespaceInfo.DataEntry\x12\x34\n\x05state\x18\x04 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"*\n\x0fNamespaceFilter\x12\x17\n\x0finclude_deleted\x18\x01 \x01(\x08\x42\x98\x01\n\x1cio.temporal.api.namespace.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/namespace/v1;namespace\xaa\x02\x1bTemporalio.Api.Namespace.V1\xea\x02\x1eTemporalio::Api::Namespace::V1b\x06proto3'
+    b'\n\'temporal/api/namespace/v1/message.proto\x12\x19temporal.api.namespace.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a%temporal/api/enums/v1/namespace.proto"\x94\x02\n\rNamespaceInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x34\n\x05state\x18\x02 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t\x12\x13\n\x0bowner_email\x18\x04 \x01(\t\x12@\n\x04\x64\x61ta\x18\x05 \x03(\x0b\x32\x32.temporal.api.namespace.v1.NamespaceInfo.DataEntry\x12\n\n\x02id\x18\x06 \x01(\t\x12\x1a\n\x12supports_schedules\x18\x64 \x01(\x08\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\xa4\x04\n\x0fNamespaceConfig\x12I\n workflow_execution_retention_ttl\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12<\n\x0c\x62\x61\x64_binaries\x18\x02 \x01(\x0b\x32&.temporal.api.namespace.v1.BadBinaries\x12\x44\n\x16history_archival_state\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x04 \x01(\t\x12G\n\x19visibility_archival_state\x18\x05 \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\x06 \x01(\t\x12u\n\x1f\x63ustom_search_attribute_aliases\x18\x07 \x03(\x0b\x32L.temporal.api.namespace.v1.NamespaceConfig.CustomSearchAttributeAliasesEntry\x1a\x43\n!CustomSearchAttributeAliasesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\xb0\x01\n\x0b\x42\x61\x64\x42inaries\x12\x46\n\x08\x62inaries\x18\x01 \x03(\x0b\x32\x34.temporal.api.namespace.v1.BadBinaries.BinariesEntry\x1aY\n\rBinariesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x37\n\x05value\x18\x02 \x01(\x0b\x32(.temporal.api.namespace.v1.BadBinaryInfo:\x02\x38\x01"h\n\rBadBinaryInfo\x12\x0e\n\x06reason\x18\x01 \x01(\t\x12\x10\n\x08operator\x18\x02 \x01(\t\x12\x35\n\x0b\x63reate_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"\xea\x01\n\x13UpdateNamespaceInfo\x12\x13\n\x0b\x64\x65scription\x18\x01 \x01(\t\x12\x13\n\x0bowner_email\x18\x02 \x01(\t\x12\x46\n\x04\x64\x61ta\x18\x03 \x03(\x0b\x32\x38.temporal.api.namespace.v1.UpdateNamespaceInfo.DataEntry\x12\x34\n\x05state\x18\x04 \x01(\x0e\x32%.temporal.api.enums.v1.NamespaceState\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"*\n\x0fNamespaceFilter\x12\x17\n\x0finclude_deleted\x18\x01 \x01(\x08\x42\x98\x01\n\x1cio.temporal.api.namespace.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/namespace/v1;namespace\xaa\x02\x1bTemporalio.Api.Namespace.V1\xea\x02\x1eTemporalio::Api::Namespace::V1b\x06proto3'
 )
 
 
 _NAMESPACEINFO = DESCRIPTOR.message_types_by_name["NamespaceInfo"]
 _NAMESPACEINFO_DATAENTRY = _NAMESPACEINFO.nested_types_by_name["DataEntry"]
 _NAMESPACECONFIG = DESCRIPTOR.message_types_by_name["NamespaceConfig"]
+_NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY = (
+    _NAMESPACECONFIG.nested_types_by_name["CustomSearchAttributeAliasesEntry"]
+)
 _BADBINARIES = DESCRIPTOR.message_types_by_name["BadBinaries"]
 _BADBINARIES_BINARIESENTRY = _BADBINARIES.nested_types_by_name["BinariesEntry"]
 _BADBINARYINFO = DESCRIPTOR.message_types_by_name["BadBinaryInfo"]
 _UPDATENAMESPACEINFO = DESCRIPTOR.message_types_by_name["UpdateNamespaceInfo"]
 _UPDATENAMESPACEINFO_DATAENTRY = _UPDATENAMESPACEINFO.nested_types_by_name["DataEntry"]
 _NAMESPACEFILTER = DESCRIPTOR.message_types_by_name["NamespaceFilter"]
 NamespaceInfo = _reflection.GeneratedProtocolMessageType(
@@ -58,20 +61,30 @@
 _sym_db.RegisterMessage(NamespaceInfo)
 _sym_db.RegisterMessage(NamespaceInfo.DataEntry)
 
 NamespaceConfig = _reflection.GeneratedProtocolMessageType(
     "NamespaceConfig",
     (_message.Message,),
     {
+        "CustomSearchAttributeAliasesEntry": _reflection.GeneratedProtocolMessageType(
+            "CustomSearchAttributeAliasesEntry",
+            (_message.Message,),
+            {
+                "DESCRIPTOR": _NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY,
+                "__module__": "temporal.api.namespace.v1.message_pb2"
+                # @@protoc_insertion_point(class_scope:temporal.api.namespace.v1.NamespaceConfig.CustomSearchAttributeAliasesEntry)
+            },
+        ),
         "DESCRIPTOR": _NAMESPACECONFIG,
         "__module__": "temporal.api.namespace.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.namespace.v1.NamespaceConfig)
     },
 )
 _sym_db.RegisterMessage(NamespaceConfig)
+_sym_db.RegisterMessage(NamespaceConfig.CustomSearchAttributeAliasesEntry)
 
 BadBinaries = _reflection.GeneratedProtocolMessageType(
     "BadBinaries",
     (_message.Message,),
     {
         "BinariesEntry": _reflection.GeneratedProtocolMessageType(
             "BinariesEntry",
@@ -134,14 +147,16 @@
 _sym_db.RegisterMessage(NamespaceFilter)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\034io.temporal.api.namespace.v1B\014MessageProtoP\001Z)go.temporal.io/api/namespace/v1;namespace\252\002\033Temporalio.Api.Namespace.V1\352\002\036Temporalio::Api::Namespace::V1"
     _NAMESPACEINFO_DATAENTRY._options = None
     _NAMESPACEINFO_DATAENTRY._serialized_options = b"8\001"
+    _NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY._options = None
+    _NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY._serialized_options = b"8\001"
     _NAMESPACECONFIG.fields_by_name["workflow_execution_retention_ttl"]._options = None
     _NAMESPACECONFIG.fields_by_name[
         "workflow_execution_retention_ttl"
     ]._serialized_options = b"\230\337\037\001"
     _BADBINARIES_BINARIESENTRY._options = None
     _BADBINARIES_BINARIESENTRY._serialized_options = b"8\001"
     _BADBINARYINFO.fields_by_name["create_time"]._options = None
@@ -151,21 +166,23 @@
     _UPDATENAMESPACEINFO_DATAENTRY._options = None
     _UPDATENAMESPACEINFO_DATAENTRY._serialized_options = b"8\001"
     _NAMESPACEINFO._serialized_start = 210
     _NAMESPACEINFO._serialized_end = 486
     _NAMESPACEINFO_DATAENTRY._serialized_start = 443
     _NAMESPACEINFO_DATAENTRY._serialized_end = 486
     _NAMESPACECONFIG._serialized_start = 489
-    _NAMESPACECONFIG._serialized_end = 849
-    _BADBINARIES._serialized_start = 852
-    _BADBINARIES._serialized_end = 1028
-    _BADBINARIES_BINARIESENTRY._serialized_start = 939
-    _BADBINARIES_BINARIESENTRY._serialized_end = 1028
-    _BADBINARYINFO._serialized_start = 1030
-    _BADBINARYINFO._serialized_end = 1134
-    _UPDATENAMESPACEINFO._serialized_start = 1137
-    _UPDATENAMESPACEINFO._serialized_end = 1371
+    _NAMESPACECONFIG._serialized_end = 1037
+    _NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY._serialized_start = 970
+    _NAMESPACECONFIG_CUSTOMSEARCHATTRIBUTEALIASESENTRY._serialized_end = 1037
+    _BADBINARIES._serialized_start = 1040
+    _BADBINARIES._serialized_end = 1216
+    _BADBINARIES_BINARIESENTRY._serialized_start = 1127
+    _BADBINARIES_BINARIESENTRY._serialized_end = 1216
+    _BADBINARYINFO._serialized_start = 1218
+    _BADBINARYINFO._serialized_end = 1322
+    _UPDATENAMESPACEINFO._serialized_start = 1325
+    _UPDATENAMESPACEINFO._serialized_end = 1559
     _UPDATENAMESPACEINFO_DATAENTRY._serialized_start = 443
     _UPDATENAMESPACEINFO_DATAENTRY._serialized_end = 486
-    _NAMESPACEFILTER._serialized_start = 1373
-    _NAMESPACEFILTER._serialized_end = 1415
+    _NAMESPACEFILTER._serialized_start = 1561
+    _NAMESPACEFILTER._serialized_end = 1603
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/namespace/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/namespace/v1/message_pb2.pyi`

 * *Files 10% similar despite different names*

```diff
@@ -114,42 +114,70 @@
     ) -> None: ...
 
 global___NamespaceInfo = NamespaceInfo
 
 class NamespaceConfig(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
+    class CustomSearchAttributeAliasesEntry(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        KEY_FIELD_NUMBER: builtins.int
+        VALUE_FIELD_NUMBER: builtins.int
+        key: builtins.str
+        value: builtins.str
+        def __init__(
+            self,
+            *,
+            key: builtins.str = ...,
+            value: builtins.str = ...,
+        ) -> None: ...
+        def ClearField(
+            self,
+            field_name: typing_extensions.Literal["key", b"key", "value", b"value"],
+        ) -> None: ...
+
     WORKFLOW_EXECUTION_RETENTION_TTL_FIELD_NUMBER: builtins.int
     BAD_BINARIES_FIELD_NUMBER: builtins.int
     HISTORY_ARCHIVAL_STATE_FIELD_NUMBER: builtins.int
     HISTORY_ARCHIVAL_URI_FIELD_NUMBER: builtins.int
     VISIBILITY_ARCHIVAL_STATE_FIELD_NUMBER: builtins.int
     VISIBILITY_ARCHIVAL_URI_FIELD_NUMBER: builtins.int
+    CUSTOM_SEARCH_ATTRIBUTE_ALIASES_FIELD_NUMBER: builtins.int
     @property
     def workflow_execution_retention_ttl(
         self,
     ) -> google.protobuf.duration_pb2.Duration: ...
     @property
     def bad_binaries(self) -> global___BadBinaries: ...
     history_archival_state: temporalio.api.enums.v1.namespace_pb2.ArchivalState.ValueType
     """If unspecified (ARCHIVAL_STATE_UNSPECIFIED) then default server configuration is used."""
     history_archival_uri: builtins.str
     visibility_archival_state: temporalio.api.enums.v1.namespace_pb2.ArchivalState.ValueType
     """If unspecified (ARCHIVAL_STATE_UNSPECIFIED) then default server configuration is used."""
     visibility_archival_uri: builtins.str
+    @property
+    def custom_search_attribute_aliases(
+        self,
+    ) -> google.protobuf.internal.containers.ScalarMap[builtins.str, builtins.str]:
+        """Map from field name to alias."""
     def __init__(
         self,
         *,
         workflow_execution_retention_ttl: google.protobuf.duration_pb2.Duration
         | None = ...,
         bad_binaries: global___BadBinaries | None = ...,
         history_archival_state: temporalio.api.enums.v1.namespace_pb2.ArchivalState.ValueType = ...,
         history_archival_uri: builtins.str = ...,
         visibility_archival_state: temporalio.api.enums.v1.namespace_pb2.ArchivalState.ValueType = ...,
         visibility_archival_uri: builtins.str = ...,
+        custom_search_attribute_aliases: collections.abc.Mapping[
+            builtins.str, builtins.str
+        ]
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "bad_binaries",
             b"bad_binaries",
             "workflow_execution_retention_ttl",
@@ -157,14 +185,16 @@
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "bad_binaries",
             b"bad_binaries",
+            "custom_search_attribute_aliases",
+            b"custom_search_attribute_aliases",
             "history_archival_state",
             b"history_archival_state",
             "history_archival_uri",
             b"history_archival_uri",
             "visibility_archival_state",
             b"visibility_archival_state",
             "visibility_archival_uri",
```

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2.py` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 
 
 from temporalio.api.enums.v1 import (
     common_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n6temporal/api/operatorservice/v1/request_response.proto\x12\x1ftemporal.api.operatorservice.v1\x1a"temporal/api/enums/v1/common.proto"\xec\x01\n\x1a\x41\x64\x64SearchAttributesRequest\x12l\n\x11search_attributes\x18\x01 \x03(\x0b\x32Q.temporal.api.operatorservice.v1.AddSearchAttributesRequest.SearchAttributesEntry\x1a`\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\x1d\n\x1b\x41\x64\x64SearchAttributesResponse":\n\x1dRemoveSearchAttributesRequest\x12\x19\n\x11search_attributes\x18\x01 \x03(\t" \n\x1eRemoveSearchAttributesResponse"\x1d\n\x1bListSearchAttributesRequest"\xe2\x04\n\x1cListSearchAttributesResponse\x12n\n\x11\x63ustom_attributes\x18\x01 \x03(\x0b\x32S.temporal.api.operatorservice.v1.ListSearchAttributesResponse.CustomAttributesEntry\x12n\n\x11system_attributes\x18\x02 \x03(\x0b\x32S.temporal.api.operatorservice.v1.ListSearchAttributesResponse.SystemAttributesEntry\x12h\n\x0estorage_schema\x18\x03 \x03(\x0b\x32P.temporal.api.operatorservice.v1.ListSearchAttributesResponse.StorageSchemaEntry\x1a`\n\x15\x43ustomAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01\x1a`\n\x15SystemAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01\x1a\x34\n\x12StorageSchemaEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"+\n\x16\x44\x65leteNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t"4\n\x17\x44\x65leteNamespaceResponse\x12\x19\n\x11\x64\x65leted_namespace\x18\x01 \x01(\t"e\n\x1f\x41\x64\x64OrUpdateRemoteClusterRequest\x12\x18\n\x10\x66rontend_address\x18\x01 \x01(\t\x12(\n enable_remote_cluster_connection\x18\x02 \x01(\x08""\n AddOrUpdateRemoteClusterResponse"2\n\x1aRemoveRemoteClusterRequest\x12\x14\n\x0c\x63luster_name\x18\x01 \x01(\t"\x1d\n\x1bRemoveRemoteClusterResponse"A\n\x13ListClustersRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"s\n\x14ListClustersResponse\x12\x42\n\x08\x63lusters\x18\x01 \x03(\x0b\x32\x30.temporal.api.operatorservice.v1.ClusterMetadata\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"\xaa\x01\n\x0f\x43lusterMetadata\x12\x14\n\x0c\x63luster_name\x18\x01 \x01(\t\x12\x12\n\ncluster_id\x18\x02 \x01(\t\x12\x0f\n\x07\x61\x64\x64ress\x18\x03 \x01(\t\x12 \n\x18initial_failover_version\x18\x04 \x01(\x03\x12\x1b\n\x13history_shard_count\x18\x05 \x01(\x05\x12\x1d\n\x15is_connection_enabled\x18\x06 \x01(\x08\x42\xbe\x01\n"io.temporal.api.operatorservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/operatorservice/v1;operatorservice\xaa\x02!Temporalio.Api.OperatorService.V1\xea\x02$Temporalio::Api::OperatorService::V1b\x06proto3'
+    b'\n6temporal/api/operatorservice/v1/request_response.proto\x12\x1ftemporal.api.operatorservice.v1\x1a"temporal/api/enums/v1/common.proto"\xff\x01\n\x1a\x41\x64\x64SearchAttributesRequest\x12l\n\x11search_attributes\x18\x01 \x03(\x0b\x32Q.temporal.api.operatorservice.v1.AddSearchAttributesRequest.SearchAttributesEntry\x12\x11\n\tnamespace\x18\x02 \x01(\t\x1a`\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\x1d\n\x1b\x41\x64\x64SearchAttributesResponse"M\n\x1dRemoveSearchAttributesRequest\x12\x19\n\x11search_attributes\x18\x01 \x03(\t\x12\x11\n\tnamespace\x18\x02 \x01(\t" \n\x1eRemoveSearchAttributesResponse"0\n\x1bListSearchAttributesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t"\xe2\x04\n\x1cListSearchAttributesResponse\x12n\n\x11\x63ustom_attributes\x18\x01 \x03(\x0b\x32S.temporal.api.operatorservice.v1.ListSearchAttributesResponse.CustomAttributesEntry\x12n\n\x11system_attributes\x18\x02 \x03(\x0b\x32S.temporal.api.operatorservice.v1.ListSearchAttributesResponse.SystemAttributesEntry\x12h\n\x0estorage_schema\x18\x03 \x03(\x0b\x32P.temporal.api.operatorservice.v1.ListSearchAttributesResponse.StorageSchemaEntry\x1a`\n\x15\x43ustomAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01\x1a`\n\x15SystemAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01\x1a\x34\n\x12StorageSchemaEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"+\n\x16\x44\x65leteNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t"4\n\x17\x44\x65leteNamespaceResponse\x12\x19\n\x11\x64\x65leted_namespace\x18\x01 \x01(\t"e\n\x1f\x41\x64\x64OrUpdateRemoteClusterRequest\x12\x18\n\x10\x66rontend_address\x18\x01 \x01(\t\x12(\n enable_remote_cluster_connection\x18\x02 \x01(\x08""\n AddOrUpdateRemoteClusterResponse"2\n\x1aRemoveRemoteClusterRequest\x12\x14\n\x0c\x63luster_name\x18\x01 \x01(\t"\x1d\n\x1bRemoveRemoteClusterResponse"A\n\x13ListClustersRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"s\n\x14ListClustersResponse\x12\x42\n\x08\x63lusters\x18\x01 \x03(\x0b\x32\x30.temporal.api.operatorservice.v1.ClusterMetadata\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"\xaa\x01\n\x0f\x43lusterMetadata\x12\x14\n\x0c\x63luster_name\x18\x01 \x01(\t\x12\x12\n\ncluster_id\x18\x02 \x01(\t\x12\x0f\n\x07\x61\x64\x64ress\x18\x03 \x01(\t\x12 \n\x18initial_failover_version\x18\x04 \x01(\x03\x12\x1b\n\x13history_shard_count\x18\x05 \x01(\x05\x12\x1d\n\x15is_connection_enabled\x18\x06 \x01(\x08\x42\xbe\x01\n"io.temporal.api.operatorservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/operatorservice/v1;operatorservice\xaa\x02!Temporalio.Api.OperatorService.V1\xea\x02$Temporalio::Api::OperatorService::V1b\x06proto3'
 )
 
 
 _ADDSEARCHATTRIBUTESREQUEST = DESCRIPTOR.message_types_by_name[
     "AddSearchAttributesRequest"
 ]
 _ADDSEARCHATTRIBUTESREQUEST_SEARCHATTRIBUTESENTRY = (
@@ -282,45 +282,45 @@
     _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._options = None
     _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._serialized_options = b"8\001"
     _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._options = None
     _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._serialized_options = b"8\001"
     _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._options = None
     _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._serialized_options = b"8\001"
     _ADDSEARCHATTRIBUTESREQUEST._serialized_start = 128
-    _ADDSEARCHATTRIBUTESREQUEST._serialized_end = 364
-    _ADDSEARCHATTRIBUTESREQUEST_SEARCHATTRIBUTESENTRY._serialized_start = 268
-    _ADDSEARCHATTRIBUTESREQUEST_SEARCHATTRIBUTESENTRY._serialized_end = 364
-    _ADDSEARCHATTRIBUTESRESPONSE._serialized_start = 366
-    _ADDSEARCHATTRIBUTESRESPONSE._serialized_end = 395
-    _REMOVESEARCHATTRIBUTESREQUEST._serialized_start = 397
-    _REMOVESEARCHATTRIBUTESREQUEST._serialized_end = 455
-    _REMOVESEARCHATTRIBUTESRESPONSE._serialized_start = 457
-    _REMOVESEARCHATTRIBUTESRESPONSE._serialized_end = 489
-    _LISTSEARCHATTRIBUTESREQUEST._serialized_start = 491
-    _LISTSEARCHATTRIBUTESREQUEST._serialized_end = 520
-    _LISTSEARCHATTRIBUTESRESPONSE._serialized_start = 523
-    _LISTSEARCHATTRIBUTESRESPONSE._serialized_end = 1133
-    _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._serialized_start = 885
-    _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._serialized_end = 981
-    _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._serialized_start = 983
-    _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._serialized_end = 1079
-    _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._serialized_start = 1081
-    _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._serialized_end = 1133
-    _DELETENAMESPACEREQUEST._serialized_start = 1135
-    _DELETENAMESPACEREQUEST._serialized_end = 1178
-    _DELETENAMESPACERESPONSE._serialized_start = 1180
-    _DELETENAMESPACERESPONSE._serialized_end = 1232
-    _ADDORUPDATEREMOTECLUSTERREQUEST._serialized_start = 1234
-    _ADDORUPDATEREMOTECLUSTERREQUEST._serialized_end = 1335
-    _ADDORUPDATEREMOTECLUSTERRESPONSE._serialized_start = 1337
-    _ADDORUPDATEREMOTECLUSTERRESPONSE._serialized_end = 1371
-    _REMOVEREMOTECLUSTERREQUEST._serialized_start = 1373
-    _REMOVEREMOTECLUSTERREQUEST._serialized_end = 1423
-    _REMOVEREMOTECLUSTERRESPONSE._serialized_start = 1425
-    _REMOVEREMOTECLUSTERRESPONSE._serialized_end = 1454
-    _LISTCLUSTERSREQUEST._serialized_start = 1456
-    _LISTCLUSTERSREQUEST._serialized_end = 1521
-    _LISTCLUSTERSRESPONSE._serialized_start = 1523
-    _LISTCLUSTERSRESPONSE._serialized_end = 1638
-    _CLUSTERMETADATA._serialized_start = 1641
-    _CLUSTERMETADATA._serialized_end = 1811
+    _ADDSEARCHATTRIBUTESREQUEST._serialized_end = 383
+    _ADDSEARCHATTRIBUTESREQUEST_SEARCHATTRIBUTESENTRY._serialized_start = 287
+    _ADDSEARCHATTRIBUTESREQUEST_SEARCHATTRIBUTESENTRY._serialized_end = 383
+    _ADDSEARCHATTRIBUTESRESPONSE._serialized_start = 385
+    _ADDSEARCHATTRIBUTESRESPONSE._serialized_end = 414
+    _REMOVESEARCHATTRIBUTESREQUEST._serialized_start = 416
+    _REMOVESEARCHATTRIBUTESREQUEST._serialized_end = 493
+    _REMOVESEARCHATTRIBUTESRESPONSE._serialized_start = 495
+    _REMOVESEARCHATTRIBUTESRESPONSE._serialized_end = 527
+    _LISTSEARCHATTRIBUTESREQUEST._serialized_start = 529
+    _LISTSEARCHATTRIBUTESREQUEST._serialized_end = 577
+    _LISTSEARCHATTRIBUTESRESPONSE._serialized_start = 580
+    _LISTSEARCHATTRIBUTESRESPONSE._serialized_end = 1190
+    _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._serialized_start = 942
+    _LISTSEARCHATTRIBUTESRESPONSE_CUSTOMATTRIBUTESENTRY._serialized_end = 1038
+    _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._serialized_start = 1040
+    _LISTSEARCHATTRIBUTESRESPONSE_SYSTEMATTRIBUTESENTRY._serialized_end = 1136
+    _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._serialized_start = 1138
+    _LISTSEARCHATTRIBUTESRESPONSE_STORAGESCHEMAENTRY._serialized_end = 1190
+    _DELETENAMESPACEREQUEST._serialized_start = 1192
+    _DELETENAMESPACEREQUEST._serialized_end = 1235
+    _DELETENAMESPACERESPONSE._serialized_start = 1237
+    _DELETENAMESPACERESPONSE._serialized_end = 1289
+    _ADDORUPDATEREMOTECLUSTERREQUEST._serialized_start = 1291
+    _ADDORUPDATEREMOTECLUSTERREQUEST._serialized_end = 1392
+    _ADDORUPDATEREMOTECLUSTERRESPONSE._serialized_start = 1394
+    _ADDORUPDATEREMOTECLUSTERRESPONSE._serialized_end = 1428
+    _REMOVEREMOTECLUSTERREQUEST._serialized_start = 1430
+    _REMOVEREMOTECLUSTERREQUEST._serialized_end = 1480
+    _REMOVEREMOTECLUSTERRESPONSE._serialized_start = 1482
+    _REMOVEREMOTECLUSTERRESPONSE._serialized_end = 1511
+    _LISTCLUSTERSREQUEST._serialized_start = 1513
+    _LISTCLUSTERSREQUEST._serialized_end = 1578
+    _LISTCLUSTERSRESPONSE._serialized_start = 1580
+    _LISTCLUSTERSRESPONSE._serialized_end = 1695
+    _CLUSTERMETADATA._serialized_start = 1698
+    _CLUSTERMETADATA._serialized_end = 1868
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2.pyi`

 * *Files 3% similar despite different names*

```diff
@@ -58,33 +58,36 @@
         ) -> None: ...
         def ClearField(
             self,
             field_name: typing_extensions.Literal["key", b"key", "value", b"value"],
         ) -> None: ...
 
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    NAMESPACE_FIELD_NUMBER: builtins.int
     @property
     def search_attributes(
         self,
     ) -> google.protobuf.internal.containers.ScalarMap[
         builtins.str, temporalio.api.enums.v1.common_pb2.IndexedValueType.ValueType
     ]:
         """Mapping between search attribute name and its IndexedValueType."""
+    namespace: builtins.str
     def __init__(
         self,
         *,
         search_attributes: collections.abc.Mapping[
             builtins.str, temporalio.api.enums.v1.common_pb2.IndexedValueType.ValueType
         ]
         | None = ...,
+        namespace: builtins.str = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "search_attributes", b"search_attributes"
+            "namespace", b"namespace", "search_attributes", b"search_attributes"
         ],
     ) -> None: ...
 
 global___AddSearchAttributesRequest = AddSearchAttributesRequest
 
 class AddSearchAttributesResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -95,28 +98,31 @@
 
 global___AddSearchAttributesResponse = AddSearchAttributesResponse
 
 class RemoveSearchAttributesRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
+    NAMESPACE_FIELD_NUMBER: builtins.int
     @property
     def search_attributes(
         self,
     ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
         """Search attribute names to delete."""
+    namespace: builtins.str
     def __init__(
         self,
         *,
         search_attributes: collections.abc.Iterable[builtins.str] | None = ...,
+        namespace: builtins.str = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "search_attributes", b"search_attributes"
+            "namespace", b"namespace", "search_attributes", b"search_attributes"
         ],
     ) -> None: ...
 
 global___RemoveSearchAttributesRequest = RemoveSearchAttributesRequest
 
 class RemoveSearchAttributesResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -126,16 +132,23 @@
     ) -> None: ...
 
 global___RemoveSearchAttributesResponse = RemoveSearchAttributesResponse
 
 class ListSearchAttributesRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
+    NAMESPACE_FIELD_NUMBER: builtins.int
+    namespace: builtins.str
     def __init__(
         self,
+        *,
+        namespace: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self, field_name: typing_extensions.Literal["namespace", b"namespace"]
     ) -> None: ...
 
 global___ListSearchAttributesRequest = ListSearchAttributesRequest
 
 class ListSearchAttributesResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
```

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2.py` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2.pyi` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/operatorservice/v1/service_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/query/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/query/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/query/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/query/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/replication/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/replication/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/replication/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/schedule/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/schedule/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/schedule/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/schedule/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/schedule/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/taskqueue/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.py`

 * *Files 6% similar despite different names*

```diff
@@ -13,39 +13,41 @@
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
 from google.protobuf import wrappers_pb2 as google_dot_protobuf_dot_wrappers__pb2
 
+from temporalio.api.common.v1 import (
+    message_pb2 as temporal_dot_api_dot_common_dot_v1_dot_message__pb2,
+)
 from temporalio.api.dependencies.gogoproto import (
     gogo_pb2 as dependencies_dot_gogoproto_dot_gogo__pb2,
 )
 from temporalio.api.enums.v1 import (
     task_queue_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_task__queue__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n\'temporal/api/taskqueue/v1/message.proto\x12\x19temporal.api.taskqueue.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/task_queue.proto"M\n\tTaskQueue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x32\n\x04kind\x18\x02 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueKind"O\n\x11TaskQueueMetadata\x12:\n\x14max_tasks_per_second\x18\x01 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue"\xac\x01\n\x0fTaskQueueStatus\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x01 \x01(\x03\x12\x12\n\nread_level\x18\x02 \x01(\x03\x12\x11\n\tack_level\x18\x03 \x01(\x03\x12\x17\n\x0frate_per_second\x18\x04 \x01(\x01\x12=\n\rtask_id_block\x18\x05 \x01(\x0b\x32&.temporal.api.taskqueue.v1.TaskIdBlock"/\n\x0bTaskIdBlock\x12\x10\n\x08start_id\x18\x01 \x01(\x03\x12\x0e\n\x06\x65nd_id\x18\x02 \x01(\x03"B\n\x1aTaskQueuePartitionMetadata\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x17\n\x0fowner_host_name\x18\x02 \x01(\t"\xb7\x01\n\nPollerInfo\x12:\n\x10last_access_time\x18\x01 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x17\n\x0frate_per_second\x18\x03 \x01(\x01\x12\x42\n\x14worker_versioning_id\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId"\xa0\x01\n\x19StickyExecutionAttributes\x12?\n\x11worker_task_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x42\n\x19schedule_to_start_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\xd6\x01\n\rVersionIdNode\x12\x35\n\x07version\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId\x12\x45\n\x13previous_compatible\x18\x02 \x01(\x0b\x32(.temporal.api.taskqueue.v1.VersionIdNode\x12G\n\x15previous_incompatible\x18\x03 \x01(\x0b\x32(.temporal.api.taskqueue.v1.VersionIdNode"$\n\tVersionId\x12\x17\n\x0fworker_build_id\x18\x01 \x01(\tB\x98\x01\n\x1cio.temporal.api.taskqueue.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/taskqueue/v1;taskqueue\xaa\x02\x1bTemporalio.Api.TaskQueue.V1\xea\x02\x1eTemporalio::Api::TaskQueue::V1b\x06proto3'
+    b'\n\'temporal/api/taskqueue/v1/message.proto\x12\x19temporal.api.taskqueue.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/wrappers.proto\x1a!dependencies/gogoproto/gogo.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto"M\n\tTaskQueue\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x32\n\x04kind\x18\x02 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueKind"O\n\x11TaskQueueMetadata\x12:\n\x14max_tasks_per_second\x18\x01 \x01(\x0b\x32\x1c.google.protobuf.DoubleValue"\xac\x01\n\x0fTaskQueueStatus\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x01 \x01(\x03\x12\x12\n\nread_level\x18\x02 \x01(\x03\x12\x11\n\tack_level\x18\x03 \x01(\x03\x12\x17\n\x0frate_per_second\x18\x04 \x01(\x01\x12=\n\rtask_id_block\x18\x05 \x01(\x0b\x32&.temporal.api.taskqueue.v1.TaskIdBlock"/\n\x0bTaskIdBlock\x12\x10\n\x08start_id\x18\x01 \x01(\x03\x12\x0e\n\x06\x65nd_id\x18\x02 \x01(\x03"B\n\x1aTaskQueuePartitionMetadata\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x17\n\x0fowner_host_name\x18\x02 \x01(\t"\xcb\x01\n\nPollerInfo\x12:\n\x10last_access_time\x18\x01 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x10\n\x08identity\x18\x02 \x01(\t\x12\x17\n\x0frate_per_second\x18\x03 \x01(\x01\x12V\n\x1bworker_version_capabilities\x18\x04 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xa0\x01\n\x19StickyExecutionAttributes\x12?\n\x11worker_task_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x42\n\x19schedule_to_start_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"A\n\x14\x43ompatibleVersionSet\x12\x16\n\x0eversion_set_id\x18\x01 \x01(\t\x12\x11\n\tbuild_ids\x18\x02 \x03(\tB\x98\x01\n\x1cio.temporal.api.taskqueue.v1B\x0cMessageProtoP\x01Z)go.temporal.io/api/taskqueue/v1;taskqueue\xaa\x02\x1bTemporalio.Api.TaskQueue.V1\xea\x02\x1eTemporalio::Api::TaskQueue::V1b\x06proto3'
 )
 
 
 _TASKQUEUE = DESCRIPTOR.message_types_by_name["TaskQueue"]
 _TASKQUEUEMETADATA = DESCRIPTOR.message_types_by_name["TaskQueueMetadata"]
 _TASKQUEUESTATUS = DESCRIPTOR.message_types_by_name["TaskQueueStatus"]
 _TASKIDBLOCK = DESCRIPTOR.message_types_by_name["TaskIdBlock"]
 _TASKQUEUEPARTITIONMETADATA = DESCRIPTOR.message_types_by_name[
     "TaskQueuePartitionMetadata"
 ]
 _POLLERINFO = DESCRIPTOR.message_types_by_name["PollerInfo"]
 _STICKYEXECUTIONATTRIBUTES = DESCRIPTOR.message_types_by_name[
     "StickyExecutionAttributes"
 ]
-_VERSIONIDNODE = DESCRIPTOR.message_types_by_name["VersionIdNode"]
-_VERSIONID = DESCRIPTOR.message_types_by_name["VersionId"]
+_COMPATIBLEVERSIONSET = DESCRIPTOR.message_types_by_name["CompatibleVersionSet"]
 TaskQueue = _reflection.GeneratedProtocolMessageType(
     "TaskQueue",
     (_message.Message,),
     {
         "DESCRIPTOR": _TASKQUEUE,
         "__module__": "temporal.api.taskqueue.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.TaskQueue)
@@ -115,61 +117,48 @@
         "DESCRIPTOR": _STICKYEXECUTIONATTRIBUTES,
         "__module__": "temporal.api.taskqueue.v1.message_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.StickyExecutionAttributes)
     },
 )
 _sym_db.RegisterMessage(StickyExecutionAttributes)
 
-VersionIdNode = _reflection.GeneratedProtocolMessageType(
-    "VersionIdNode",
-    (_message.Message,),
-    {
-        "DESCRIPTOR": _VERSIONIDNODE,
-        "__module__": "temporal.api.taskqueue.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.VersionIdNode)
-    },
-)
-_sym_db.RegisterMessage(VersionIdNode)
-
-VersionId = _reflection.GeneratedProtocolMessageType(
-    "VersionId",
+CompatibleVersionSet = _reflection.GeneratedProtocolMessageType(
+    "CompatibleVersionSet",
     (_message.Message,),
     {
-        "DESCRIPTOR": _VERSIONID,
+        "DESCRIPTOR": _COMPATIBLEVERSIONSET,
         "__module__": "temporal.api.taskqueue.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.VersionId)
+        # @@protoc_insertion_point(class_scope:temporal.api.taskqueue.v1.CompatibleVersionSet)
     },
 )
-_sym_db.RegisterMessage(VersionId)
+_sym_db.RegisterMessage(CompatibleVersionSet)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b"\n\034io.temporal.api.taskqueue.v1B\014MessageProtoP\001Z)go.temporal.io/api/taskqueue/v1;taskqueue\252\002\033Temporalio.Api.TaskQueue.V1\352\002\036Temporalio::Api::TaskQueue::V1"
     _POLLERINFO.fields_by_name["last_access_time"]._options = None
     _POLLERINFO.fields_by_name[
         "last_access_time"
     ]._serialized_options = b"\220\337\037\001"
     _STICKYEXECUTIONATTRIBUTES.fields_by_name[
         "schedule_to_start_timeout"
     ]._options = None
     _STICKYEXECUTIONATTRIBUTES.fields_by_name[
         "schedule_to_start_timeout"
     ]._serialized_options = b"\230\337\037\001"
-    _TASKQUEUE._serialized_start = 242
-    _TASKQUEUE._serialized_end = 319
-    _TASKQUEUEMETADATA._serialized_start = 321
-    _TASKQUEUEMETADATA._serialized_end = 400
-    _TASKQUEUESTATUS._serialized_start = 403
-    _TASKQUEUESTATUS._serialized_end = 575
-    _TASKIDBLOCK._serialized_start = 577
-    _TASKIDBLOCK._serialized_end = 624
-    _TASKQUEUEPARTITIONMETADATA._serialized_start = 626
-    _TASKQUEUEPARTITIONMETADATA._serialized_end = 692
-    _POLLERINFO._serialized_start = 695
-    _POLLERINFO._serialized_end = 878
-    _STICKYEXECUTIONATTRIBUTES._serialized_start = 881
-    _STICKYEXECUTIONATTRIBUTES._serialized_end = 1041
-    _VERSIONIDNODE._serialized_start = 1044
-    _VERSIONIDNODE._serialized_end = 1258
-    _VERSIONID._serialized_start = 1260
-    _VERSIONID._serialized_end = 1296
+    _TASKQUEUE._serialized_start = 280
+    _TASKQUEUE._serialized_end = 357
+    _TASKQUEUEMETADATA._serialized_start = 359
+    _TASKQUEUEMETADATA._serialized_end = 438
+    _TASKQUEUESTATUS._serialized_start = 441
+    _TASKQUEUESTATUS._serialized_end = 613
+    _TASKIDBLOCK._serialized_start = 615
+    _TASKIDBLOCK._serialized_end = 662
+    _TASKQUEUEPARTITIONMETADATA._serialized_start = 664
+    _TASKQUEUEPARTITIONMETADATA._serialized_end = 730
+    _POLLERINFO._serialized_start = 733
+    _POLLERINFO._serialized_end = 936
+    _STICKYEXECUTIONATTRIBUTES._serialized_start = 939
+    _STICKYEXECUTIONATTRIBUTES._serialized_end = 1099
+    _COMPATIBLEVERSIONSET._serialized_start = 1101
+    _COMPATIBLEVERSIONSET._serialized_end = 1166
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/taskqueue/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/taskqueue/v1/message_pb2.pyi`

 * *Files 10% similar despite different names*

```diff
@@ -20,20 +20,23 @@
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 THE SOFTWARE.
 """
 import builtins
+import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.duration_pb2
+import google.protobuf.internal.containers
 import google.protobuf.message
 import google.protobuf.timestamp_pb2
 import google.protobuf.wrappers_pb2
 import sys
+import temporalio.api.common.v1.message_pb2
 import temporalio.api.enums.v1.task_queue_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
 
@@ -180,53 +183,55 @@
 
 class PollerInfo(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     LAST_ACCESS_TIME_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     RATE_PER_SECOND_FIELD_NUMBER: builtins.int
-    WORKER_VERSIONING_ID_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_CAPABILITIES_FIELD_NUMBER: builtins.int
     @property
-    def last_access_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
-        """Unix Nano"""
+    def last_access_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     identity: builtins.str
     rate_per_second: builtins.float
     @property
-    def worker_versioning_id(self) -> global___VersionId:
-        """If a worker has specified an ID for use with the worker versioning feature while polling,
-        that id must appear here.
+    def worker_version_capabilities(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities:
+        """If a worker has opted into the worker versioning feature while polling, its capabilities will
+        appear here.
         """
     def __init__(
         self,
         *,
         last_access_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         identity: builtins.str = ...,
         rate_per_second: builtins.float = ...,
-        worker_versioning_id: global___VersionId | None = ...,
+        worker_version_capabilities: temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "last_access_time",
             b"last_access_time",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "identity",
             b"identity",
             "last_access_time",
             b"last_access_time",
             "rate_per_second",
             b"rate_per_second",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> None: ...
 
 global___PollerInfo = PollerInfo
 
 class StickyExecutionAttributes(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -263,80 +268,39 @@
             "worker_task_queue",
             b"worker_task_queue",
         ],
     ) -> None: ...
 
 global___StickyExecutionAttributes = StickyExecutionAttributes
 
-class VersionIdNode(google.protobuf.message.Message):
-    """Used by the worker versioning APIs, represents a node in the version graph for a particular
-    task queue
+class CompatibleVersionSet(google.protobuf.message.Message):
+    """Used by the worker versioning APIs, represents an ordering of one or more versions which are
+    considered to be compatible with each other. Currently the versions are always worker build ids.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    VERSION_FIELD_NUMBER: builtins.int
-    PREVIOUS_COMPATIBLE_FIELD_NUMBER: builtins.int
-    PREVIOUS_INCOMPATIBLE_FIELD_NUMBER: builtins.int
-    @property
-    def version(self) -> global___VersionId: ...
-    @property
-    def previous_compatible(self) -> global___VersionIdNode:
-        """A pointer to the previous version this version is considered to be compatible with"""
+    VERSION_SET_ID_FIELD_NUMBER: builtins.int
+    BUILD_IDS_FIELD_NUMBER: builtins.int
+    version_set_id: builtins.str
+    """A unique identifier for this version set. Users don't need to understand or care about this
+    value, but it has value for debugging purposes.
+    """
     @property
-    def previous_incompatible(self) -> global___VersionIdNode:
-        """A pointer to the last incompatible version (previous major version)"""
+    def build_ids(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.str]:
+        """All the compatible versions, ordered from oldest to newest"""
     def __init__(
         self,
         *,
-        version: global___VersionId | None = ...,
-        previous_compatible: global___VersionIdNode | None = ...,
-        previous_incompatible: global___VersionIdNode | None = ...,
+        version_set_id: builtins.str = ...,
+        build_ids: collections.abc.Iterable[builtins.str] | None = ...,
     ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal[
-            "previous_compatible",
-            b"previous_compatible",
-            "previous_incompatible",
-            b"previous_incompatible",
-            "version",
-            b"version",
-        ],
-    ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "previous_compatible",
-            b"previous_compatible",
-            "previous_incompatible",
-            b"previous_incompatible",
-            "version",
-            b"version",
+            "build_ids", b"build_ids", "version_set_id", b"version_set_id"
         ],
     ) -> None: ...
 
-global___VersionIdNode = VersionIdNode
-
-class VersionId(google.protobuf.message.Message):
-    """Used by the worker versioning APIs, represents a specific version of something
-    Currently, that's just a whole-worker id. In the future, if we support
-    WASM workflow bundle based versioning, for example, then the inside of this
-    message may become a oneof of different version types.
-    """
-
-    DESCRIPTOR: google.protobuf.descriptor.Descriptor
-
-    WORKER_BUILD_ID_FIELD_NUMBER: builtins.int
-    worker_build_id: builtins.str
-    """An opaque whole-worker identifier"""
-    def __init__(
-        self,
-        *,
-        worker_build_id: builtins.str = ...,
-    ) -> None: ...
-    def ClearField(
-        self,
-        field_name: typing_extensions.Literal["worker_build_id", b"worker_build_id"],
-    ) -> None: ...
-
-global___VersionId = VersionId
+global___CompatibleVersionSet = CompatibleVersionSet
```

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/testservice/v1/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2.py` & `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2.pyi` & `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/testservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2.py` & `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2.pyi` & `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2_grpc.py` & `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/testservice/v1/service_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/update/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/protocol/v1/message_pb2.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,42 +1,40 @@
 # -*- coding: utf-8 -*-
 # Generated by the protocol buffer compiler.  DO NOT EDIT!
-# source: temporal/api/update/v1/message.proto
+# source: temporal/api/protocol/v1/message.proto
 """Generated protocol buffer code."""
 from google.protobuf import descriptor as _descriptor
 from google.protobuf import descriptor_pool as _descriptor_pool
 from google.protobuf import message as _message
 from google.protobuf import reflection as _reflection
 from google.protobuf import symbol_database as _symbol_database
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
-from temporalio.api.common.v1 import (
-    message_pb2 as temporal_dot_api_dot_common_dot_v1_dot_message__pb2,
-)
+from google.protobuf import any_pb2 as google_dot_protobuf_dot_any__pb2
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n$temporal/api/update/v1/message.proto\x12\x16temporal.api.update.v1\x1a$temporal/api/common/v1/message.proto"~\n\x0eWorkflowUpdate\x12.\n\x06header\x18\x01 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x0c\n\x04name\x18\x02 \x01(\t\x12.\n\x04\x61rgs\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.PayloadsB\x85\x01\n\x19io.temporal.api.update.v1B\x0cMessageProtoP\x01Z#go.temporal.io/api/update/v1;update\xaa\x02\x16Temporal.Api.Update.V1\xea\x02\x19Temporal::Api::Update::V1b\x06proto3'
+    b'\n&temporal/api/protocol/v1/message.proto\x12\x18temporal.api.protocol.v1\x1a\x19google/protobuf/any.proto"\x95\x01\n\x07Message\x12\n\n\x02id\x18\x01 \x01(\t\x12\x1c\n\x14protocol_instance_id\x18\x02 \x01(\t\x12\x12\n\x08\x65vent_id\x18\x03 \x01(\x03H\x00\x12\x17\n\rcommand_index\x18\x04 \x01(\x03H\x00\x12"\n\x04\x62ody\x18\x05 \x01(\x0b\x32\x14.google.protobuf.AnyB\x0f\n\rsequencing_idB\x93\x01\n\x1bio.temporal.api.protocol.v1B\x0cMessageProtoP\x01Z\'go.temporal.io/api/protocol/v1;protocol\xaa\x02\x1aTemporalio.Api.Protocol.V1\xea\x02\x1dTemporalio::Api::Protocol::V1b\x06proto3'
 )
 
 
-_WORKFLOWUPDATE = DESCRIPTOR.message_types_by_name["WorkflowUpdate"]
-WorkflowUpdate = _reflection.GeneratedProtocolMessageType(
-    "WorkflowUpdate",
+_MESSAGE = DESCRIPTOR.message_types_by_name["Message"]
+Message = _reflection.GeneratedProtocolMessageType(
+    "Message",
     (_message.Message,),
     {
-        "DESCRIPTOR": _WORKFLOWUPDATE,
-        "__module__": "temporal.api.update.v1.message_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.update.v1.WorkflowUpdate)
+        "DESCRIPTOR": _MESSAGE,
+        "__module__": "temporal.api.protocol.v1.message_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.protocol.v1.Message)
     },
 )
-_sym_db.RegisterMessage(WorkflowUpdate)
+_sym_db.RegisterMessage(Message)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
-    DESCRIPTOR._serialized_options = b"\n\031io.temporal.api.update.v1B\014MessageProtoP\001Z#go.temporal.io/api/update/v1;update\252\002\026Temporal.Api.Update.V1\352\002\031Temporal::Api::Update::V1"
-    _WORKFLOWUPDATE._serialized_start = 102
-    _WORKFLOWUPDATE._serialized_end = 228
+    DESCRIPTOR._serialized_options = b"\n\033io.temporal.api.protocol.v1B\014MessageProtoP\001Z'go.temporal.io/api/protocol/v1;protocol\252\002\032Temporalio.Api.Protocol.V1\352\002\035Temporalio::Api::Protocol::V1"
+    _MESSAGE._serialized_start = 96
+    _MESSAGE._serialized_end = 245
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/version/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/version/v1/message_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/version/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/version/v1/message_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/workflow/v1/message_pb2.py` & `temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -29,15 +29,15 @@
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 from temporalio.api.taskqueue.v1 import (
     message_pb2 as temporal_dot_api_dot_taskqueue_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n&temporal/api/workflow/v1/message.proto\x12\x18temporal.api.workflow.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\xec\x05\n\x15WorkflowExecutionInfo\x12<\n\texecution\x18\x01 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x32\n\x04type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12>\n\x06status\x18\x05 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowExecutionStatus\x12\x16\n\x0ehistory_length\x18\x06 \x01(\x03\x12\x1b\n\x13parent_namespace_id\x18\x07 \x01(\t\x12\x43\n\x10parent_execution\x18\x08 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x38\n\x0e\x65xecution_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12*\n\x04memo\x18\n \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0b \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12@\n\x11\x61uto_reset_points\x18\x0c \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12\x12\n\ntask_queue\x18\r \x01(\t\x12\x1e\n\x16state_transition_count\x18\x0e \x01(\x03\x12\x1a\n\x12history_size_bytes\x18\x0f \x01(\x03"\x9f\x02\n\x17WorkflowExecutionConfig\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x43\n\x1aworkflow_execution_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x46\n\x1d\x64\x65\x66\x61ult_workflow_task_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\xd2\x04\n\x13PendingActivityInfo\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12:\n\x05state\x18\x03 \x01(\x0e\x32+.temporal.api.enums.v1.PendingActivityState\x12;\n\x11heartbeat_details\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x13last_heartbeat_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12;\n\x11last_started_time\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x07 \x01(\x05\x12\x18\n\x10maximum_attempts\x18\x08 \x01(\x05\x12\x38\n\x0escheduled_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x39\n\x0f\x65xpiration_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0clast_failure\x18\x0b \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1c\n\x14last_worker_identity\x18\x0c \x01(\t"\xb9\x01\n\x19PendingChildExecutionInfo\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t\x12\x1a\n\x12workflow_type_name\x18\x03 \x01(\t\x12\x14\n\x0cinitiated_id\x18\x04 \x01(\x03\x12\x45\n\x13parent_close_policy\x18\x05 \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy"\x9f\x02\n\x17PendingWorkflowTaskInfo\x12>\n\x05state\x18\x01 \x01(\x0e\x32/.temporal.api.enums.v1.PendingWorkflowTaskState\x12\x38\n\x0escheduled_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x41\n\x17original_scheduled_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x05 \x01(\x05"G\n\x0bResetPoints\x12\x38\n\x06points\x18\x01 \x03(\x0b\x32(.temporal.api.workflow.v1.ResetPointInfo"\xe5\x01\n\x0eResetPointInfo\x12\x17\n\x0f\x62inary_checksum\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t\x12(\n first_workflow_task_completed_id\x18\x03 \x01(\x03\x12\x35\n\x0b\x63reate_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x35\n\x0b\x65xpire_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x12\n\nresettable\x18\x06 \x01(\x08"\xde\x05\n\x18NewWorkflowExecutionInfo\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12N\n\x18workflow_id_reuse_policy\x18\x08 \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\n \x01(\t\x12*\n\x04memo\x18\x0b \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0c \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\r \x01(\x0b\x32\x1e.temporal.api.common.v1.HeaderB\x93\x01\n\x1bio.temporal.api.workflow.v1B\x0cMessageProtoP\x01Z\'go.temporal.io/api/workflow/v1;workflow\xaa\x02\x1aTemporalio.Api.Workflow.V1\xea\x02\x1dTemporalio::Api::Workflow::V1b\x06proto3'
+    b'\n&temporal/api/workflow/v1/message.proto\x12\x18temporal.api.workflow.v1\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto"\xc2\x06\n\x15WorkflowExecutionInfo\x12<\n\texecution\x18\x01 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x32\n\x04type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12>\n\x06status\x18\x05 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowExecutionStatus\x12\x16\n\x0ehistory_length\x18\x06 \x01(\x03\x12\x1b\n\x13parent_namespace_id\x18\x07 \x01(\t\x12\x43\n\x10parent_execution\x18\x08 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x38\n\x0e\x65xecution_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12*\n\x04memo\x18\n \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0b \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12@\n\x11\x61uto_reset_points\x18\x0c \x01(\x0b\x32%.temporal.api.workflow.v1.ResetPoints\x12\x12\n\ntask_queue\x18\r \x01(\t\x12\x1e\n\x16state_transition_count\x18\x0e \x01(\x03\x12\x1a\n\x12history_size_bytes\x18\x0f \x01(\x03\x12T\n most_recent_worker_version_stamp\x18\x10 \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp"\x9f\x02\n\x17WorkflowExecutionConfig\x12\x38\n\ntask_queue\x18\x01 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x43\n\x1aworkflow_execution_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x03 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x46\n\x1d\x64\x65\x66\x61ult_workflow_task_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\xd2\x04\n\x13PendingActivityInfo\x12\x13\n\x0b\x61\x63tivity_id\x18\x01 \x01(\t\x12;\n\ractivity_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12:\n\x05state\x18\x03 \x01(\x0e\x32+.temporal.api.enums.v1.PendingActivityState\x12;\n\x11heartbeat_details\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x13last_heartbeat_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12;\n\x11last_started_time\x18\x06 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x07 \x01(\x05\x12\x18\n\x10maximum_attempts\x18\x08 \x01(\x05\x12\x38\n\x0escheduled_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x39\n\x0f\x65xpiration_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0clast_failure\x18\x0b \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x1c\n\x14last_worker_identity\x18\x0c \x01(\t"\xb9\x01\n\x19PendingChildExecutionInfo\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t\x12\x1a\n\x12workflow_type_name\x18\x03 \x01(\t\x12\x14\n\x0cinitiated_id\x18\x04 \x01(\x03\x12\x45\n\x13parent_close_policy\x18\x05 \x01(\x0e\x32(.temporal.api.enums.v1.ParentClosePolicy"\x9f\x02\n\x17PendingWorkflowTaskInfo\x12>\n\x05state\x18\x01 \x01(\x0e\x32/.temporal.api.enums.v1.PendingWorkflowTaskState\x12\x38\n\x0escheduled_time\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x41\n\x17original_scheduled_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\x05 \x01(\x05"G\n\x0bResetPoints\x12\x38\n\x06points\x18\x01 \x03(\x0b\x32(.temporal.api.workflow.v1.ResetPointInfo"\xe5\x01\n\x0eResetPointInfo\x12\x17\n\x0f\x62inary_checksum\x18\x01 \x01(\t\x12\x0e\n\x06run_id\x18\x02 \x01(\t\x12(\n first_workflow_task_completed_id\x18\x03 \x01(\x03\x12\x35\n\x0b\x63reate_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x35\n\x0b\x65xpire_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x12\n\nresettable\x18\x06 \x01(\x08"\xde\x05\n\x18NewWorkflowExecutionInfo\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12;\n\rworkflow_type\x18\x02 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12N\n\x18workflow_id_reuse_policy\x18\x08 \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\n \x01(\t\x12*\n\x04memo\x18\x0b \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0c \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\r \x01(\x0b\x32\x1e.temporal.api.common.v1.HeaderB\x93\x01\n\x1bio.temporal.api.workflow.v1B\x0cMessageProtoP\x01Z\'go.temporal.io/api/workflow/v1;workflow\xaa\x02\x1aTemporalio.Api.Workflow.V1\xea\x02\x1dTemporalio::Api::Workflow::V1b\x06proto3'
 )
 
 
 _WORKFLOWEXECUTIONINFO = DESCRIPTOR.message_types_by_name["WorkflowExecutionInfo"]
 _WORKFLOWEXECUTIONCONFIG = DESCRIPTOR.message_types_by_name["WorkflowExecutionConfig"]
 _PENDINGACTIVITYINFO = DESCRIPTOR.message_types_by_name["PendingActivityInfo"]
 _PENDINGCHILDEXECUTIONINFO = DESCRIPTOR.message_types_by_name[
@@ -213,23 +213,23 @@
         "workflow_run_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _NEWWORKFLOWEXECUTIONINFO.fields_by_name["workflow_task_timeout"]._options = None
     _NEWWORKFLOWEXECUTIONINFO.fields_by_name[
         "workflow_task_timeout"
     ]._serialized_options = b"\230\337\037\001"
     _WORKFLOWEXECUTIONINFO._serialized_start = 325
-    _WORKFLOWEXECUTIONINFO._serialized_end = 1073
-    _WORKFLOWEXECUTIONCONFIG._serialized_start = 1076
-    _WORKFLOWEXECUTIONCONFIG._serialized_end = 1363
-    _PENDINGACTIVITYINFO._serialized_start = 1366
-    _PENDINGACTIVITYINFO._serialized_end = 1960
-    _PENDINGCHILDEXECUTIONINFO._serialized_start = 1963
-    _PENDINGCHILDEXECUTIONINFO._serialized_end = 2148
-    _PENDINGWORKFLOWTASKINFO._serialized_start = 2151
-    _PENDINGWORKFLOWTASKINFO._serialized_end = 2438
-    _RESETPOINTS._serialized_start = 2440
-    _RESETPOINTS._serialized_end = 2511
-    _RESETPOINTINFO._serialized_start = 2514
-    _RESETPOINTINFO._serialized_end = 2743
-    _NEWWORKFLOWEXECUTIONINFO._serialized_start = 2746
-    _NEWWORKFLOWEXECUTIONINFO._serialized_end = 3480
+    _WORKFLOWEXECUTIONINFO._serialized_end = 1159
+    _WORKFLOWEXECUTIONCONFIG._serialized_start = 1162
+    _WORKFLOWEXECUTIONCONFIG._serialized_end = 1449
+    _PENDINGACTIVITYINFO._serialized_start = 1452
+    _PENDINGACTIVITYINFO._serialized_end = 2046
+    _PENDINGCHILDEXECUTIONINFO._serialized_start = 2049
+    _PENDINGCHILDEXECUTIONINFO._serialized_end = 2234
+    _PENDINGWORKFLOWTASKINFO._serialized_start = 2237
+    _PENDINGWORKFLOWTASKINFO._serialized_end = 2524
+    _RESETPOINTS._serialized_start = 2526
+    _RESETPOINTS._serialized_end = 2597
+    _RESETPOINTINFO._serialized_start = 2600
+    _RESETPOINTINFO._serialized_end = 2829
+    _NEWWORKFLOWEXECUTIONINFO._serialized_start = 2832
+    _NEWWORKFLOWEXECUTIONINFO._serialized_end = 3566
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/workflow/v1/message_pb2.pyi` & `temporalio-1.2.0/temporalio/api/workflow/v1/message_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -57,14 +57,15 @@
     EXECUTION_TIME_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     AUTO_RESET_POINTS_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
     STATE_TRANSITION_COUNT_FIELD_NUMBER: builtins.int
     HISTORY_SIZE_BYTES_FIELD_NUMBER: builtins.int
+    MOST_RECENT_WORKER_VERSION_STAMP_FIELD_NUMBER: builtins.int
     @property
     def execution(self) -> temporalio.api.common.v1.message_pb2.WorkflowExecution: ...
     @property
     def type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp: ...
     @property
@@ -85,14 +86,19 @@
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
     @property
     def auto_reset_points(self) -> global___ResetPoints: ...
     task_queue: builtins.str
     state_transition_count: builtins.int
     history_size_bytes: builtins.int
+    @property
+    def most_recent_worker_version_stamp(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """If set, the most recent worker version stamp that appeared in a workflow task completion"""
     def __init__(
         self,
         *,
         execution: temporalio.api.common.v1.message_pb2.WorkflowExecution | None = ...,
         type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         start_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         close_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
@@ -105,28 +111,32 @@
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
         auto_reset_points: global___ResetPoints | None = ...,
         task_queue: builtins.str = ...,
         state_transition_count: builtins.int = ...,
         history_size_bytes: builtins.int = ...,
+        most_recent_worker_version_stamp: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "auto_reset_points",
             b"auto_reset_points",
             "close_time",
             b"close_time",
             "execution",
             b"execution",
             "execution_time",
             b"execution_time",
             "memo",
             b"memo",
+            "most_recent_worker_version_stamp",
+            b"most_recent_worker_version_stamp",
             "parent_execution",
             b"parent_execution",
             "search_attributes",
             b"search_attributes",
             "start_time",
             b"start_time",
             "type",
@@ -146,14 +156,16 @@
             b"execution_time",
             "history_length",
             b"history_length",
             "history_size_bytes",
             b"history_size_bytes",
             "memo",
             b"memo",
+            "most_recent_worker_version_stamp",
+            b"most_recent_worker_version_stamp",
             "parent_execution",
             b"parent_execution",
             "parent_namespace_id",
             b"parent_namespace_id",
             "search_attributes",
             b"search_attributes",
             "start_time",
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/__init__.py` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,16 +21,16 @@
     DescribeWorkflowExecutionResponse,
     GetClusterInfoRequest,
     GetClusterInfoResponse,
     GetSearchAttributesRequest,
     GetSearchAttributesResponse,
     GetSystemInfoRequest,
     GetSystemInfoResponse,
-    GetWorkerBuildIdOrderingRequest,
-    GetWorkerBuildIdOrderingResponse,
+    GetWorkerBuildIdCompatibilityRequest,
+    GetWorkerBuildIdCompatibilityResponse,
     GetWorkflowExecutionHistoryRequest,
     GetWorkflowExecutionHistoryResponse,
     GetWorkflowExecutionHistoryReverseRequest,
     GetWorkflowExecutionHistoryReverseResponse,
     ListArchivedWorkflowExecutionsRequest,
     ListArchivedWorkflowExecutionsResponse,
     ListBatchOperationsRequest,
@@ -49,14 +49,16 @@
     ListTaskQueuePartitionsResponse,
     ListWorkflowExecutionsRequest,
     ListWorkflowExecutionsResponse,
     PatchScheduleRequest,
     PatchScheduleResponse,
     PollActivityTaskQueueRequest,
     PollActivityTaskQueueResponse,
+    PollWorkflowExecutionUpdateRequest,
+    PollWorkflowExecutionUpdateResponse,
     PollWorkflowTaskQueueRequest,
     PollWorkflowTaskQueueResponse,
     QueryWorkflowRequest,
     QueryWorkflowResponse,
     RecordActivityTaskHeartbeatByIdRequest,
     RecordActivityTaskHeartbeatByIdResponse,
     RecordActivityTaskHeartbeatRequest,
@@ -101,18 +103,18 @@
     StopBatchOperationResponse,
     TerminateWorkflowExecutionRequest,
     TerminateWorkflowExecutionResponse,
     UpdateNamespaceRequest,
     UpdateNamespaceResponse,
     UpdateScheduleRequest,
     UpdateScheduleResponse,
-    UpdateWorkerBuildIdOrderingRequest,
-    UpdateWorkerBuildIdOrderingResponse,
-    UpdateWorkflowRequest,
-    UpdateWorkflowResponse,
+    UpdateWorkerBuildIdCompatibilityRequest,
+    UpdateWorkerBuildIdCompatibilityResponse,
+    UpdateWorkflowExecutionRequest,
+    UpdateWorkflowExecutionResponse,
 )
 
 __all__ = [
     "CountWorkflowExecutionsRequest",
     "CountWorkflowExecutionsResponse",
     "CreateScheduleRequest",
     "CreateScheduleResponse",
@@ -134,16 +136,16 @@
     "DescribeWorkflowExecutionResponse",
     "GetClusterInfoRequest",
     "GetClusterInfoResponse",
     "GetSearchAttributesRequest",
     "GetSearchAttributesResponse",
     "GetSystemInfoRequest",
     "GetSystemInfoResponse",
-    "GetWorkerBuildIdOrderingRequest",
-    "GetWorkerBuildIdOrderingResponse",
+    "GetWorkerBuildIdCompatibilityRequest",
+    "GetWorkerBuildIdCompatibilityResponse",
     "GetWorkflowExecutionHistoryRequest",
     "GetWorkflowExecutionHistoryResponse",
     "GetWorkflowExecutionHistoryReverseRequest",
     "GetWorkflowExecutionHistoryReverseResponse",
     "ListArchivedWorkflowExecutionsRequest",
     "ListArchivedWorkflowExecutionsResponse",
     "ListBatchOperationsRequest",
@@ -162,14 +164,16 @@
     "ListTaskQueuePartitionsResponse",
     "ListWorkflowExecutionsRequest",
     "ListWorkflowExecutionsResponse",
     "PatchScheduleRequest",
     "PatchScheduleResponse",
     "PollActivityTaskQueueRequest",
     "PollActivityTaskQueueResponse",
+    "PollWorkflowExecutionUpdateRequest",
+    "PollWorkflowExecutionUpdateResponse",
     "PollWorkflowTaskQueueRequest",
     "PollWorkflowTaskQueueResponse",
     "QueryWorkflowRequest",
     "QueryWorkflowResponse",
     "RecordActivityTaskHeartbeatByIdRequest",
     "RecordActivityTaskHeartbeatByIdResponse",
     "RecordActivityTaskHeartbeatRequest",
@@ -214,18 +218,18 @@
     "StopBatchOperationResponse",
     "TerminateWorkflowExecutionRequest",
     "TerminateWorkflowExecutionResponse",
     "UpdateNamespaceRequest",
     "UpdateNamespaceResponse",
     "UpdateScheduleRequest",
     "UpdateScheduleResponse",
-    "UpdateWorkerBuildIdOrderingRequest",
-    "UpdateWorkerBuildIdOrderingResponse",
-    "UpdateWorkflowRequest",
-    "UpdateWorkflowResponse",
+    "UpdateWorkerBuildIdCompatibilityRequest",
+    "UpdateWorkerBuildIdCompatibilityResponse",
+    "UpdateWorkflowExecutionRequest",
+    "UpdateWorkflowExecutionResponse",
 ]
 
 # gRPC is optional
 try:
     import grpc
 
     from .service_pb2_grpc import (
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2.py` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.py`

 * *Files 6% similar despite different names*

```diff
@@ -46,55 +46,58 @@
 from temporalio.api.enums.v1 import (
     reset_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_reset__pb2,
 )
 from temporalio.api.enums.v1 import (
     task_queue_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_task__queue__pb2,
 )
 from temporalio.api.enums.v1 import (
-    update_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_update__pb2,
-)
-from temporalio.api.enums.v1 import (
     workflow_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_workflow__pb2,
 )
 from temporalio.api.failure.v1 import (
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 from temporalio.api.filter.v1 import (
     message_pb2 as temporal_dot_api_dot_filter_dot_v1_dot_message__pb2,
 )
 from temporalio.api.history.v1 import (
     message_pb2 as temporal_dot_api_dot_history_dot_v1_dot_message__pb2,
 )
-from temporalio.api.interaction.v1 import (
-    message_pb2 as temporal_dot_api_dot_interaction_dot_v1_dot_message__pb2,
-)
 from temporalio.api.namespace.v1 import (
     message_pb2 as temporal_dot_api_dot_namespace_dot_v1_dot_message__pb2,
 )
+from temporalio.api.protocol.v1 import (
+    message_pb2 as temporal_dot_api_dot_protocol_dot_v1_dot_message__pb2,
+)
 from temporalio.api.query.v1 import (
     message_pb2 as temporal_dot_api_dot_query_dot_v1_dot_message__pb2,
 )
 from temporalio.api.replication.v1 import (
     message_pb2 as temporal_dot_api_dot_replication_dot_v1_dot_message__pb2,
 )
 from temporalio.api.schedule.v1 import (
     message_pb2 as temporal_dot_api_dot_schedule_dot_v1_dot_message__pb2,
 )
+from temporalio.api.sdk.v1 import (
+    task_complete_metadata_pb2 as temporal_dot_api_dot_sdk_dot_v1_dot_task__complete__metadata__pb2,
+)
 from temporalio.api.taskqueue.v1 import (
     message_pb2 as temporal_dot_api_dot_taskqueue_dot_v1_dot_message__pb2,
 )
+from temporalio.api.update.v1 import (
+    message_pb2 as temporal_dot_api_dot_update_dot_v1_dot_message__pb2,
+)
 from temporalio.api.version.v1 import (
     message_pb2 as temporal_dot_api_dot_version_dot_v1_dot_message__pb2,
 )
 from temporalio.api.workflow.v1 import (
     message_pb2 as temporal_dot_api_dot_workflow_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n6temporal/api/workflowservice/v1/request_response.proto\x12\x1ftemporal.api.workflowservice.v1\x1a+temporal/api/enums/v1/batch_operation.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/enums/v1/namespace.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a"temporal/api/enums/v1/common.proto\x1a!temporal/api/enums/v1/query.proto\x1a!temporal/api/enums/v1/reset.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a"temporal/api/enums/v1/update.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/history/v1/message.proto\x1a)temporal/api/interaction/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a%temporal/api/command/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/filter/v1/message.proto\x1a\'temporal/api/namespace/v1/message.proto\x1a#temporal/api/query/v1/message.proto\x1a)temporal/api/replication/v1/message.proto\x1a&temporal/api/schedule/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a%temporal/api/version/v1/message.proto\x1a#temporal/api/batch/v1/message.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto"\x8e\x05\n\x18RegisterNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12\x13\n\x0bowner_email\x18\x03 \x01(\t\x12L\n#workflow_execution_retention_period\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x08\x63lusters\x18\x05 \x03(\x0b\x32\x35.temporal.api.replication.v1.ClusterReplicationConfig\x12\x1b\n\x13\x61\x63tive_cluster_name\x18\x06 \x01(\t\x12Q\n\x04\x64\x61ta\x18\x07 \x03(\x0b\x32\x43.temporal.api.workflowservice.v1.RegisterNamespaceRequest.DataEntry\x12\x16\n\x0esecurity_token\x18\x08 \x01(\t\x12\x1b\n\x13is_global_namespace\x18\t \x01(\x08\x12\x44\n\x16history_archival_state\x18\n \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x0b \x01(\t\x12G\n\x19visibility_archival_state\x18\x0c \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\r \x01(\t\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x1b\n\x19RegisterNamespaceResponse"\x89\x01\n\x15ListNamespacesRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c\x12\x44\n\x10namespace_filter\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceFilter"\x81\x01\n\x16ListNamespacesResponse\x12N\n\nnamespaces\x18\x01 \x03(\x0b\x32:.temporal.api.workflowservice.v1.DescribeNamespaceResponse\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"9\n\x18\x44\x65scribeNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\t"\xec\x02\n\x19\x44\x65scribeNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08\x12\x45\n\x10\x66\x61ilover_history\x18\x06 \x03(\x0b\x32+.temporal.api.replication.v1.FailoverStatus"\xcf\x02\n\x16UpdateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x43\n\x0bupdate_info\x18\x02 \x01(\x0b\x32..temporal.api.namespace.v1.UpdateNamespaceInfo\x12:\n\x06\x63onfig\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x04 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x16\n\x0esecurity_token\x18\x05 \x01(\t\x12\x19\n\x11\x64\x65lete_bad_binary\x18\x06 \x01(\t\x12\x19\n\x11promote_namespace\x18\x07 \x01(\x08"\xa3\x02\n\x17UpdateNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08"F\n\x19\x44\x65precateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x16\n\x0esecurity_token\x18\x02 \x01(\t"\x1c\n\x1a\x44\x65precateNamespaceResponse"\x9c\x06\n\x1dStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12*\n\x04memo\x18\x0e \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0f \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x10 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"0\n\x1eStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xaa\x02\n"GetWorkflowExecutionHistoryRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c\x12\x16\n\x0ewait_new_event\x18\x05 \x01(\x08\x12P\n\x19history_event_filter_type\x18\x06 \x01(\x0e\x32-.temporal.api.enums.v1.HistoryEventFilterType\x12\x15\n\rskip_archival\x18\x07 \x01(\x08"\xba\x01\n#GetWorkflowExecutionHistoryResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x35\n\x0braw_history\x18\x02 \x03(\x0b\x32 .temporal.api.common.v1.DataBlob\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x10\n\x08\x61rchived\x18\x04 \x01(\x08"\xb0\x01\n)GetWorkflowExecutionHistoryReverseRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"x\n*GetWorkflowExecutionHistoryReverseResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"\xda\x01\n\x1cPollWorkflowTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12\x42\n\x14worker_versioning_id\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId"\xd4\x06\n\x1dPollWorkflowTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19previous_started_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x61ttempt\x18\x06 \x01(\x05\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x07 \x01(\x03\x12\x31\n\x07history\x18\x08 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\t \x01(\x0c\x12\x33\n\x05query\x18\n \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x1dworkflow_execution_task_queue\x18\x0b \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x38\n\x0escheduled_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\\\n\x07queries\x18\x0e \x03(\x0b\x32K.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse.QueriesEntry\x12=\n\x0cinteractions\x18\x0f \x03(\x0b\x32\'.temporal.api.interaction.v1.Invocation\x1aT\n\x0cQueriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery:\x02\x38\x01"\xda\x04\n#RespondWorkflowTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x32\n\x08\x63ommands\x18\x02 \x03(\x0b\x32 .temporal.api.command.v1.Command\x12\x10\n\x08identity\x18\x03 \x01(\t\x12O\n\x11sticky_attributes\x18\x04 \x01(\x0b\x32\x34.temporal.api.taskqueue.v1.StickyExecutionAttributes\x12 \n\x18return_new_workflow_task\x18\x05 \x01(\x08\x12&\n\x1e\x66orce_create_new_workflow_task\x18\x06 \x01(\x08\x12\x17\n\x0f\x62inary_checksum\x18\x07 \x01(\t\x12m\n\rquery_results\x18\x08 \x03(\x0b\x32V.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest.QueryResultsEntry\x12\x11\n\tnamespace\x18\t \x01(\t\x12\x42\n\x14worker_versioning_id\x18\n \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId\x1a_\n\x11QueryResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.temporal.api.query.v1.WorkflowQueryResult:\x02\x38\x01"\xf5\x01\n$RespondWorkflowTaskCompletedResponse\x12U\n\rworkflow_task\x18\x01 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse\x12V\n\x0e\x61\x63tivity_tasks\x18\x02 \x03(\x0b\x32>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse\x12\x1e\n\x16reset_history_event_id\x18\x03 \x01(\x03"\xe6\x01\n RespondWorkflowTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12=\n\x05\x63\x61use\x18\x02 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x05 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\t"#\n!RespondWorkflowTaskFailedResponse"\x8c\x02\n\x1cPollActivityTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x13task_queue_metadata\x18\x04 \x01(\x0b\x32,.temporal.api.taskqueue.v1.TaskQueueMetadata\x12\x42\n\x14worker_versioning_id\x18\x05 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId"\x8c\x07\n\x1dPollActivityTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x1a\n\x12workflow_namespace\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\ractivity_type\x18\x05 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x13\n\x0b\x61\x63tivity_id\x18\x06 \x01(\t\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x08 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12;\n\x11heartbeat_details\x18\t \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x38\n\x0escheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12H\n\x1e\x63urrent_attempt_scheduled_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\r \x01(\x05\x12\x42\n\x19schedule_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\x10 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\x90\x01\n"RecordActivityTaskHeartbeatRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"?\n#RecordActivityTaskHeartbeatResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\xba\x01\n&RecordActivityTaskHeartbeatByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"C\n\'RecordActivityTaskHeartbeatByIdResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\x90\x01\n#RespondActivityTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x06result\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"&\n$RespondActivityTaskCompletedResponse"\xba\x01\n\'RespondActivityTaskCompletedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x30\n\x06result\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"*\n(RespondActivityTaskCompletedByIdResponse"\xd0\x01\n RespondActivityTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"W\n!RespondActivityTaskFailedResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\xfa\x01\n$RespondActivityTaskFailedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x06 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x07 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n%RespondActivityTaskFailedByIdResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\x90\x01\n"RespondActivityTaskCanceledRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"%\n#RespondActivityTaskCanceledResponse"\xba\x01\n&RespondActivityTaskCanceledByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t")\n\'RespondActivityTaskCanceledByIdResponse"\xd7\x01\n%RequestCancelWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x12\n\nrequest_id\x18\x04 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t"(\n&RequestCancelWorkflowExecutionResponse"\xa7\x02\n\x1eSignalWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x07 \x01(\t\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header"!\n\x1fSignalWorkflowExecutionResponse"\x84\x07\n\'SignalWithStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x13\n\x0bsignal_name\x18\x0c \x01(\t\x12\x36\n\x0csignal_input\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x0e \x01(\t\x12\x39\n\x0cretry_policy\x18\x0f \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x10 \x01(\t\x12*\n\x04memo\x18\x11 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x12 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x13 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header":\n(SignalWithStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\x89\x02\n\x1dResetWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12%\n\x1dworkflow_task_finish_event_id\x18\x04 \x01(\x03\x12\x12\n\nrequest_id\x18\x05 \x01(\t\x12\x43\n\x12reset_reapply_type\x18\x06 \x01(\x0e\x32\'.temporal.api.enums.v1.ResetReapplyType"0\n\x1eResetWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xf2\x01\n!TerminateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x06 \x01(\t"$\n"TerminateWorkflowExecutionResponse"z\n\x1e\x44\x65leteWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"!\n\x1f\x44\x65leteWorkflowExecutionResponse"\xc9\x02\n!ListOpenWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x42\t\n\x07\x66ilters"\x82\x01\n"ListOpenWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\x8a\x03\n#ListClosedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x12=\n\rstatus_filter\x18\x07 \x01(\x0b\x32$.temporal.api.filter.v1.StatusFilterH\x00\x42\t\n\x07\x66ilters"\x84\x01\n$ListClosedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dListWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eListWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"u\n%ListArchivedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"\x86\x01\n&ListArchivedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dScanWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eScanWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"B\n\x1e\x43ountWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t"0\n\x1f\x43ountWorkflowExecutionsResponse\x12\r\n\x05\x63ount\x18\x01 \x01(\x03"\x1c\n\x1aGetSearchAttributesRequest"\xc9\x01\n\x1bGetSearchAttributesResponse\x12T\n\x04keys\x18\x01 \x03(\x0b\x32\x46.temporal.api.workflowservice.v1.GetSearchAttributesResponse.KeysEntry\x1aT\n\tKeysEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\xde\x01\n RespondQueryTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12>\n\x0e\x63ompleted_type\x18\x02 \x01(\x0e\x32&.temporal.api.enums.v1.QueryResultType\x12\x36\n\x0cquery_result\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rerror_message\x18\x04 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\tJ\x04\x08\x05\x10\x06"#\n!RespondQueryTaskCompletedResponse"n\n\x1bResetStickyTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\x1e\n\x1cResetStickyTaskQueueResponse"\xe9\x01\n\x14QueryWorkflowRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x33\n\x05query\x18\x03 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x16query_reject_condition\x18\x04 \x01(\x0e\x32+.temporal.api.enums.v1.QueryRejectCondition"\x8d\x01\n\x15QueryWorkflowResponse\x12\x36\n\x0cquery_result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12<\n\x0equery_rejected\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.QueryRejected"s\n DescribeWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xae\x03\n!DescribeWorkflowExecutionResponse\x12K\n\x10\x65xecution_config\x18\x01 \x01(\x0b\x32\x31.temporal.api.workflow.v1.WorkflowExecutionConfig\x12P\n\x17workflow_execution_info\x18\x02 \x01(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12I\n\x12pending_activities\x18\x03 \x03(\x0b\x32-.temporal.api.workflow.v1.PendingActivityInfo\x12M\n\x10pending_children\x18\x04 \x03(\x0b\x32\x33.temporal.api.workflow.v1.PendingChildExecutionInfo\x12P\n\x15pending_workflow_task\x18\x05 \x01(\x0b\x32\x31.temporal.api.workflow.v1.PendingWorkflowTaskInfo"\xc9\x01\n\x18\x44\x65scribeTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12=\n\x0ftask_queue_type\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueType\x12!\n\x19include_task_queue_status\x18\x04 \x01(\x08"\x9a\x01\n\x19\x44\x65scribeTaskQueueResponse\x12\x36\n\x07pollers\x18\x01 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x12\x45\n\x11task_queue_status\x18\x02 \x01(\x0b\x32*.temporal.api.taskqueue.v1.TaskQueueStatus"\x17\n\x15GetClusterInfoRequest"\x8b\x03\n\x16GetClusterInfoResponse\x12h\n\x11supported_clients\x18\x01 \x03(\x0b\x32M.temporal.api.workflowservice.v1.GetClusterInfoResponse.SupportedClientsEntry\x12\x16\n\x0eserver_version\x18\x02 \x01(\t\x12\x12\n\ncluster_id\x18\x03 \x01(\t\x12:\n\x0cversion_info\x18\x04 \x01(\x0b\x32$.temporal.api.version.v1.VersionInfo\x12\x14\n\x0c\x63luster_name\x18\x05 \x01(\t\x12\x1b\n\x13history_shard_count\x18\x06 \x01(\x05\x12\x19\n\x11persistence_store\x18\x07 \x01(\t\x12\x18\n\x10visibility_store\x18\x08 \x01(\t\x1a\x37\n\x15SupportedClientsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x16\n\x14GetSystemInfoRequest"\x88\x03\n\x15GetSystemInfoResponse\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12Y\n\x0c\x63\x61pabilities\x18\x02 \x01(\x0b\x32\x43.temporal.api.workflowservice.v1.GetSystemInfoResponse.Capabilities\x1a\xfb\x01\n\x0c\x43\x61pabilities\x12\x1f\n\x17signal_and_query_header\x18\x01 \x01(\x08\x12&\n\x1einternal_error_differentiation\x18\x02 \x01(\x08\x12*\n"activity_failure_include_heartbeat\x18\x03 \x01(\x08\x12\x1a\n\x12supports_schedules\x18\x04 \x01(\x08\x12"\n\x1a\x65ncoded_failure_attributes\x18\x05 \x01(\x08\x12!\n\x19\x62uild_id_based_versioning\x18\x06 \x01(\x08\x12\x13\n\x0bupsert_memo\x18\x07 \x01(\x08"m\n\x1eListTaskQueuePartitionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue"\xdf\x01\n\x1fListTaskQueuePartitionsResponse\x12]\n\x1e\x61\x63tivity_task_queue_partitions\x18\x01 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata\x12]\n\x1eworkflow_task_queue_partitions\x18\x02 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata"\xcc\x02\n\x15\x43reateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12>\n\rinitial_patch\x18\x04 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12*\n\x04memo\x18\x07 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x08 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"0\n\x16\x43reateScheduleResponse\x12\x16\n\x0e\x63onflict_token\x18\x01 \x01(\x0c"A\n\x17\x44\x65scribeScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t"\x8f\x02\n\x18\x44\x65scribeScheduleResponse\x12\x34\n\x08schedule\x18\x01 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x34\n\x04info\x18\x02 \x01(\x0b\x32&.temporal.api.schedule.v1.ScheduleInfo\x12*\n\x04memo\x18\x03 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x04 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x16\n\x0e\x63onflict_token\x18\x05 \x01(\x0c"\xb3\x01\n\x15UpdateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x16\n\x0e\x63onflict_token\x18\x04 \x01(\x0c\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t"\x18\n\x16UpdateScheduleResponse"\x9c\x01\n\x14PatchScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x36\n\x05patch\x18\x03 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x12\n\nrequest_id\x18\x05 \x01(\t"\x17\n\x15PatchScheduleResponse"\xb4\x01\n ListScheduleMatchingTimesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x32\n\x08\x65nd_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Y\n!ListScheduleMatchingTimesResponse\x12\x34\n\nstart_time\x18\x01 \x03(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Q\n\x15\x44\x65leteScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x10\n\x08identity\x18\x03 \x01(\t"\x18\n\x16\x44\x65leteScheduleResponse"]\n\x14ListSchedulesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"p\n\x15ListSchedulesResponse\x12>\n\tschedules\x18\x01 \x03(\x0b\x32+.temporal.api.schedule.v1.ScheduleListEntry\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xe0\x01\n"UpdateWorkerBuildIdOrderingRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x38\n\nversion_id\x18\x03 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId\x12\x41\n\x13previous_compatible\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.VersionId\x12\x16\n\x0e\x62\x65\x63ome_default\x18\x05 \x01(\x08"%\n#UpdateWorkerBuildIdOrderingResponse"[\n\x1fGetWorkerBuildIdOrderingRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x11\n\tmax_depth\x18\x03 \x01(\x05"\xaa\x01\n GetWorkerBuildIdOrderingResponse\x12\x41\n\x0f\x63urrent_default\x18\x01 \x01(\x0b\x32(.temporal.api.taskqueue.v1.VersionIdNode\x12\x43\n\x11\x63ompatible_leaves\x18\x02 \x03(\x0b\x32(.temporal.api.taskqueue.v1.VersionIdNode"\xbf\x02\n\x15UpdateWorkflowRequest\x12\x12\n\nrequest_id\x18\x01 \x01(\t\x12S\n\x13result_access_style\x18\x02 \x01(\x0e\x32\x36.temporal.api.enums.v1.WorkflowUpdateResultAccessStyle\x12\x11\n\tnamespace\x18\x03 \x01(\t\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1e\n\x16\x66irst_execution_run_id\x18\x05 \x01(\t\x12\x10\n\x08identity\x18\x06 \x01(\t\x12\x31\n\x05input\x18\x07 \x01(\x0b\x32".temporal.api.interaction.v1.Input"c\n\x16UpdateWorkflowResponse\x12\x14\n\x0cupdate_token\x18\x01 \x01(\x0c\x12\x33\n\x06output\x18\x02 \x01(\x0b\x32#.temporal.api.interaction.v1.Output"\xb4\x03\n\x1aStartBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x18\n\x10visibility_query\x18\x02 \x01(\t\x12\x0e\n\x06job_id\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12Q\n\x15termination_operation\x18\n \x01(\x0b\x32\x30.temporal.api.batch.v1.BatchOperationTerminationH\x00\x12G\n\x10signal_operation\x18\x0b \x01(\x0b\x32+.temporal.api.batch.v1.BatchOperationSignalH\x00\x12S\n\x16\x63\x61ncellation_operation\x18\x0c \x01(\x0b\x32\x31.temporal.api.batch.v1.BatchOperationCancellationH\x00\x12K\n\x12\x64\x65letion_operation\x18\r \x01(\x0b\x32-.temporal.api.batch.v1.BatchOperationDeletionH\x00\x42\x0b\n\toperation"\x1d\n\x1bStartBatchOperationResponse"`\n\x19StopBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x10\n\x08identity\x18\x04 \x01(\t"\x1c\n\x1aStopBatchOperationResponse"B\n\x1d\x44\x65scribeBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t"\x9e\x03\n\x1e\x44\x65scribeBatchOperationResponse\x12\x41\n\x0eoperation_type\x18\x01 \x01(\x0e\x32).temporal.api.enums.v1.BatchOperationType\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x39\n\x05state\x18\x03 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x1d\n\x15total_operation_count\x18\x06 \x01(\x03\x12 \n\x18\x63omplete_operation_count\x18\x07 \x01(\x03\x12\x1f\n\x17\x66\x61ilure_operation_count\x18\x08 \x01(\x03\x12\x10\n\x08identity\x18\t \x01(\t\x12\x0e\n\x06reason\x18\n \x01(\t"[\n\x1aListBatchOperationsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"y\n\x1bListBatchOperationsResponse\x12\x41\n\x0eoperation_info\x18\x01 \x03(\x0b\x32).temporal.api.batch.v1.BatchOperationInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c\x42\xbe\x01\n"io.temporal.api.workflowservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
+    b'\n6temporal/api/workflowservice/v1/request_response.proto\x12\x1ftemporal.api.workflowservice.v1\x1a+temporal/api/enums/v1/batch_operation.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/enums/v1/namespace.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a"temporal/api/enums/v1/common.proto\x1a!temporal/api/enums/v1/query.proto\x1a!temporal/api/enums/v1/reset.proto\x1a&temporal/api/enums/v1/task_queue.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/history/v1/message.proto\x1a&temporal/api/workflow/v1/message.proto\x1a%temporal/api/command/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/filter/v1/message.proto\x1a&temporal/api/protocol/v1/message.proto\x1a\'temporal/api/namespace/v1/message.proto\x1a#temporal/api/query/v1/message.proto\x1a)temporal/api/replication/v1/message.proto\x1a&temporal/api/schedule/v1/message.proto\x1a\'temporal/api/taskqueue/v1/message.proto\x1a$temporal/api/update/v1/message.proto\x1a%temporal/api/version/v1/message.proto\x1a#temporal/api/batch/v1/message.proto\x1a\x30temporal/api/sdk/v1/task_complete_metadata.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a!dependencies/gogoproto/gogo.proto"\x8e\x05\n\x18RegisterNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x12\x13\n\x0bowner_email\x18\x03 \x01(\t\x12L\n#workflow_execution_retention_period\x18\x04 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12G\n\x08\x63lusters\x18\x05 \x03(\x0b\x32\x35.temporal.api.replication.v1.ClusterReplicationConfig\x12\x1b\n\x13\x61\x63tive_cluster_name\x18\x06 \x01(\t\x12Q\n\x04\x64\x61ta\x18\x07 \x03(\x0b\x32\x43.temporal.api.workflowservice.v1.RegisterNamespaceRequest.DataEntry\x12\x16\n\x0esecurity_token\x18\x08 \x01(\t\x12\x1b\n\x13is_global_namespace\x18\t \x01(\x08\x12\x44\n\x16history_archival_state\x18\n \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1c\n\x14history_archival_uri\x18\x0b \x01(\t\x12G\n\x19visibility_archival_state\x18\x0c \x01(\x0e\x32$.temporal.api.enums.v1.ArchivalState\x12\x1f\n\x17visibility_archival_uri\x18\r \x01(\t\x1a+\n\tDataEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x1b\n\x19RegisterNamespaceResponse"\x89\x01\n\x15ListNamespacesRequest\x12\x11\n\tpage_size\x18\x01 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c\x12\x44\n\x10namespace_filter\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceFilter"\x81\x01\n\x16ListNamespacesResponse\x12N\n\nnamespaces\x18\x01 \x03(\x0b\x32:.temporal.api.workflowservice.v1.DescribeNamespaceResponse\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"9\n\x18\x44\x65scribeNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\n\n\x02id\x18\x02 \x01(\t"\xec\x02\n\x19\x44\x65scribeNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08\x12\x45\n\x10\x66\x61ilover_history\x18\x06 \x03(\x0b\x32+.temporal.api.replication.v1.FailoverStatus"\xcf\x02\n\x16UpdateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x43\n\x0bupdate_info\x18\x02 \x01(\x0b\x32..temporal.api.namespace.v1.UpdateNamespaceInfo\x12:\n\x06\x63onfig\x18\x03 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x04 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x16\n\x0esecurity_token\x18\x05 \x01(\t\x12\x19\n\x11\x64\x65lete_bad_binary\x18\x06 \x01(\t\x12\x19\n\x11promote_namespace\x18\x07 \x01(\x08"\xa3\x02\n\x17UpdateNamespaceResponse\x12@\n\x0enamespace_info\x18\x01 \x01(\x0b\x32(.temporal.api.namespace.v1.NamespaceInfo\x12:\n\x06\x63onfig\x18\x02 \x01(\x0b\x32*.temporal.api.namespace.v1.NamespaceConfig\x12S\n\x12replication_config\x18\x03 \x01(\x0b\x32\x37.temporal.api.replication.v1.NamespaceReplicationConfig\x12\x18\n\x10\x66\x61ilover_version\x18\x04 \x01(\x03\x12\x1b\n\x13is_global_namespace\x18\x05 \x01(\x08"F\n\x19\x44\x65precateNamespaceRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x16\n\x0esecurity_token\x18\x02 \x01(\t"\x1c\n\x1a\x44\x65precateNamespaceResponse"\xfb\x07\n\x1dStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\r \x01(\t\x12*\n\x04memo\x18\x0e \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x0f \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x10 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12\x1f\n\x17request_eager_execution\x18\x11 \x01(\x08\x12;\n\x11\x63ontinued_failure\x18\x12 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x13 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01"\x8d\x01\n\x1eStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12[\n\x13\x65\x61ger_workflow_task\x18\x02 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\xaa\x02\n"GetWorkflowExecutionHistoryRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c\x12\x16\n\x0ewait_new_event\x18\x05 \x01(\x08\x12P\n\x19history_event_filter_type\x18\x06 \x01(\x0e\x32-.temporal.api.enums.v1.HistoryEventFilterType\x12\x15\n\rskip_archival\x18\x07 \x01(\x08"\xba\x01\n#GetWorkflowExecutionHistoryResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x35\n\x0braw_history\x18\x02 \x03(\x0b\x32 .temporal.api.common.v1.DataBlob\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x10\n\x08\x61rchived\x18\x04 \x01(\x08"\xb0\x01\n)GetWorkflowExecutionHistoryReverseRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x19\n\x11maximum_page_size\x18\x03 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x04 \x01(\x0c"x\n*GetWorkflowExecutionHistoryReverseResponse\x12\x31\n\x07history\x18\x01 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"\xee\x01\n\x1cPollWorkflowTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x04 \x01(\t\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\xca\x06\n\x1dPollWorkflowTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12!\n\x19previous_started_event_id\x18\x04 \x01(\x03\x12\x18\n\x10started_event_id\x18\x05 \x01(\x03\x12\x0f\n\x07\x61ttempt\x18\x06 \x01(\x05\x12\x1a\n\x12\x62\x61\x63klog_count_hint\x18\x07 \x01(\x03\x12\x31\n\x07history\x18\x08 \x01(\x0b\x32 .temporal.api.history.v1.History\x12\x17\n\x0fnext_page_token\x18\t \x01(\x0c\x12\x33\n\x05query\x18\n \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x1dworkflow_execution_task_queue\x18\x0b \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x38\n\x0escheduled_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\r \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\\\n\x07queries\x18\x0e \x03(\x0b\x32K.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse.QueriesEntry\x12\x33\n\x08messages\x18\x0f \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x1aT\n\x0cQueriesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x33\n\x05value\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery:\x02\x38\x01"\xa4\x06\n#RespondWorkflowTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x32\n\x08\x63ommands\x18\x02 \x03(\x0b\x32 .temporal.api.command.v1.Command\x12\x10\n\x08identity\x18\x03 \x01(\t\x12O\n\x11sticky_attributes\x18\x04 \x01(\x0b\x32\x34.temporal.api.taskqueue.v1.StickyExecutionAttributes\x12 \n\x18return_new_workflow_task\x18\x05 \x01(\x08\x12&\n\x1e\x66orce_create_new_workflow_task\x18\x06 \x01(\x08\x12\x17\n\x0f\x62inary_checksum\x18\x07 \x01(\t\x12m\n\rquery_results\x18\x08 \x03(\x0b\x32V.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest.QueryResultsEntry\x12\x11\n\tnamespace\x18\t \x01(\t\x12H\n\x14worker_version_stamp\x18\n \x01(\x0b\x32*.temporal.api.common.v1.WorkerVersionStamp\x12\x33\n\x08messages\x18\x0b \x03(\x0b\x32!.temporal.api.protocol.v1.Message\x12H\n\x0csdk_metadata\x18\x0c \x01(\x0b\x32\x32.temporal.api.sdk.v1.WorkflowTaskCompletedMetadata\x12\x43\n\x11metering_metadata\x18\r \x01(\x0b\x32(.temporal.api.common.v1.MeteringMetadata\x1a_\n\x11QueryResultsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x39\n\x05value\x18\x02 \x01(\x0b\x32*.temporal.api.query.v1.WorkflowQueryResult:\x02\x38\x01"\xf5\x01\n$RespondWorkflowTaskCompletedResponse\x12U\n\rworkflow_task\x18\x01 \x01(\x0b\x32>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse\x12V\n\x0e\x61\x63tivity_tasks\x18\x02 \x03(\x0b\x32>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse\x12\x1e\n\x16reset_history_event_id\x18\x03 \x01(\x03"\x9b\x02\n RespondWorkflowTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12=\n\x05\x63\x61use\x18\x02 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCause\x12\x31\n\x07\x66\x61ilure\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x17\n\x0f\x62inary_checksum\x18\x05 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\t\x12\x33\n\x08messages\x18\x07 \x03(\x0b\x32!.temporal.api.protocol.v1.Message"#\n!RespondWorkflowTaskFailedResponse"\xa0\x02\n\x1cPollActivityTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x13task_queue_metadata\x18\x04 \x01(\x0b\x32,.temporal.api.taskqueue.v1.TaskQueueMetadata\x12V\n\x1bworker_version_capabilities\x18\x05 \x01(\x0b\x32\x31.temporal.api.common.v1.WorkerVersionCapabilities"\x8c\x07\n\x1dPollActivityTaskQueueResponse\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x1a\n\x12workflow_namespace\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x45\n\x12workflow_execution\x18\x04 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12;\n\ractivity_type\x18\x05 \x01(\x0b\x32$.temporal.api.common.v1.ActivityType\x12\x13\n\x0b\x61\x63tivity_id\x18\x06 \x01(\t\x12.\n\x06header\x18\x07 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12/\n\x05input\x18\x08 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12;\n\x11heartbeat_details\x18\t \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x38\n\x0escheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12H\n\x1e\x63urrent_attempt_scheduled_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x36\n\x0cstarted_time\x18\x0c \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x0f\n\x07\x61ttempt\x18\r \x01(\x05\x12\x42\n\x19schedule_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12?\n\x16start_to_close_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12:\n\x11heartbeat_timeout\x18\x10 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x39\n\x0cretry_policy\x18\x11 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy"\x90\x01\n"RecordActivityTaskHeartbeatRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"?\n#RecordActivityTaskHeartbeatResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\xba\x01\n&RecordActivityTaskHeartbeatByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"C\n\'RecordActivityTaskHeartbeatByIdResponse\x12\x18\n\x10\x63\x61ncel_requested\x18\x01 \x01(\x08"\x90\x01\n#RespondActivityTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x06result\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"&\n$RespondActivityTaskCompletedResponse"\xba\x01\n\'RespondActivityTaskCompletedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x30\n\x06result\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t"*\n(RespondActivityTaskCompletedByIdResponse"\xd0\x01\n RespondActivityTaskFailedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"W\n!RespondActivityTaskFailedResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\xfa\x01\n$RespondActivityTaskFailedByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x66\x61ilure\x18\x05 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x10\n\x08identity\x18\x06 \x01(\t\x12@\n\x16last_heartbeat_details\x18\x07 \x01(\x0b\x32 .temporal.api.common.v1.Payloads"[\n%RespondActivityTaskFailedByIdResponse\x12\x32\n\x08\x66\x61ilures\x18\x01 \x03(\x0b\x32 .temporal.api.failure.v1.Failure"\x90\x01\n"RespondActivityTaskCanceledRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x31\n\x07\x64\x65tails\x18\x02 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x11\n\tnamespace\x18\x04 \x01(\t"%\n#RespondActivityTaskCanceledResponse"\xba\x01\n&RespondActivityTaskCanceledByIdRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\t\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x06 \x01(\t")\n\'RespondActivityTaskCanceledByIdResponse"\xd7\x01\n%RequestCancelWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x12\n\nrequest_id\x18\x04 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x05 \x01(\t\x12\x0e\n\x06reason\x18\x06 \x01(\t"(\n&RequestCancelWorkflowExecutionResponse"\xcc\x02\n\x1eSignalWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0bsignal_name\x18\x03 \x01(\t\x12/\n\x05input\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12\x0f\n\x07\x63ontrol\x18\x07 \x01(\t\x12.\n\x06header\x18\x08 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12#\n\x1bskip_generate_workflow_task\x18\t \x01(\x08"!\n\x1fSignalWorkflowExecutionResponse"\xe8\x07\n\'SignalWithStartWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12;\n\rworkflow_type\x18\x03 \x01(\x0b\x32$.temporal.api.common.v1.WorkflowType\x12\x38\n\ntask_queue\x18\x04 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12/\n\x05input\x18\x05 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x43\n\x1aworkflow_execution_timeout\x18\x06 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12=\n\x14workflow_run_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12>\n\x15workflow_task_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12\x10\n\x08identity\x18\t \x01(\t\x12\x12\n\nrequest_id\x18\n \x01(\t\x12N\n\x18workflow_id_reuse_policy\x18\x0b \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x13\n\x0bsignal_name\x18\x0c \x01(\t\x12\x36\n\x0csignal_input\x18\r \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x0f\n\x07\x63ontrol\x18\x0e \x01(\t\x12\x39\n\x0cretry_policy\x18\x0f \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x10 \x01(\t\x12*\n\x04memo\x18\x11 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x12 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\x06header\x18\x13 \x01(\x0b\x32\x1e.temporal.api.common.v1.Header\x12=\n\x14workflow_start_delay\x18\x14 \x01(\x0b\x32\x19.google.protobuf.DurationB\x04\x98\xdf\x1f\x01\x12#\n\x1bskip_generate_workflow_task\x18\x15 \x01(\x08":\n(SignalWithStartWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\x89\x02\n\x1dResetWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12%\n\x1dworkflow_task_finish_event_id\x18\x04 \x01(\x03\x12\x12\n\nrequest_id\x18\x05 \x01(\t\x12\x43\n\x12reset_reapply_type\x18\x06 \x01(\x0e\x32\'.temporal.api.enums.v1.ResetReapplyType"0\n\x1eResetWorkflowExecutionResponse\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xf2\x01\n!TerminateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x31\n\x07\x64\x65tails\x18\x04 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x1e\n\x16\x66irst_execution_run_id\x18\x06 \x01(\t"$\n"TerminateWorkflowExecutionResponse"z\n\x1e\x44\x65leteWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"!\n\x1f\x44\x65leteWorkflowExecutionResponse"\xc9\x02\n!ListOpenWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x42\t\n\x07\x66ilters"\x82\x01\n"ListOpenWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\x8a\x03\n#ListClosedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\x42\n\x11start_time_filter\x18\x04 \x01(\x0b\x32\'.temporal.api.filter.v1.StartTimeFilter\x12K\n\x10\x65xecution_filter\x18\x05 \x01(\x0b\x32/.temporal.api.filter.v1.WorkflowExecutionFilterH\x00\x12\x41\n\x0btype_filter\x18\x06 \x01(\x0b\x32*.temporal.api.filter.v1.WorkflowTypeFilterH\x00\x12=\n\rstatus_filter\x18\x07 \x01(\x0b\x32$.temporal.api.filter.v1.StatusFilterH\x00\x42\t\n\x07\x66ilters"\x84\x01\n$ListClosedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dListWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eListWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"u\n%ListArchivedWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"\x86\x01\n&ListArchivedWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"m\n\x1dScanWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c\x12\r\n\x05query\x18\x04 \x01(\t"~\n\x1eScanWorkflowExecutionsResponse\x12\x43\n\nexecutions\x18\x01 \x03(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"B\n\x1e\x43ountWorkflowExecutionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\r\n\x05query\x18\x02 \x01(\t"0\n\x1f\x43ountWorkflowExecutionsResponse\x12\r\n\x05\x63ount\x18\x01 \x01(\x03"\x1c\n\x1aGetSearchAttributesRequest"\xc9\x01\n\x1bGetSearchAttributesResponse\x12T\n\x04keys\x18\x01 \x03(\x0b\x32\x46.temporal.api.workflowservice.v1.GetSearchAttributesResponse.KeysEntry\x1aT\n\tKeysEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\x36\n\x05value\x18\x02 \x01(\x0e\x32\'.temporal.api.enums.v1.IndexedValueType:\x02\x38\x01"\xde\x01\n RespondQueryTaskCompletedRequest\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12>\n\x0e\x63ompleted_type\x18\x02 \x01(\x0e\x32&.temporal.api.enums.v1.QueryResultType\x12\x36\n\x0cquery_result\x18\x03 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x15\n\rerror_message\x18\x04 \x01(\t\x12\x11\n\tnamespace\x18\x06 \x01(\tJ\x04\x08\x05\x10\x06"#\n!RespondQueryTaskCompletedResponse"n\n\x1bResetStickyTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\x1e\n\x1cResetStickyTaskQueueResponse"\xe9\x01\n\x14QueryWorkflowRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x33\n\x05query\x18\x03 \x01(\x0b\x32$.temporal.api.query.v1.WorkflowQuery\x12K\n\x16query_reject_condition\x18\x04 \x01(\x0e\x32+.temporal.api.enums.v1.QueryRejectCondition"\x8d\x01\n\x15QueryWorkflowResponse\x12\x36\n\x0cquery_result\x18\x01 \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12<\n\x0equery_rejected\x18\x02 \x01(\x0b\x32$.temporal.api.query.v1.QueryRejected"s\n DescribeWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12<\n\texecution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution"\xae\x03\n!DescribeWorkflowExecutionResponse\x12K\n\x10\x65xecution_config\x18\x01 \x01(\x0b\x32\x31.temporal.api.workflow.v1.WorkflowExecutionConfig\x12P\n\x17workflow_execution_info\x18\x02 \x01(\x0b\x32/.temporal.api.workflow.v1.WorkflowExecutionInfo\x12I\n\x12pending_activities\x18\x03 \x03(\x0b\x32-.temporal.api.workflow.v1.PendingActivityInfo\x12M\n\x10pending_children\x18\x04 \x03(\x0b\x32\x33.temporal.api.workflow.v1.PendingChildExecutionInfo\x12P\n\x15pending_workflow_task\x18\x05 \x01(\x0b\x32\x31.temporal.api.workflow.v1.PendingWorkflowTaskInfo"\xc9\x01\n\x18\x44\x65scribeTaskQueueRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue\x12=\n\x0ftask_queue_type\x18\x03 \x01(\x0e\x32$.temporal.api.enums.v1.TaskQueueType\x12!\n\x19include_task_queue_status\x18\x04 \x01(\x08"\x9a\x01\n\x19\x44\x65scribeTaskQueueResponse\x12\x36\n\x07pollers\x18\x01 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x12\x45\n\x11task_queue_status\x18\x02 \x01(\x0b\x32*.temporal.api.taskqueue.v1.TaskQueueStatus"\x17\n\x15GetClusterInfoRequest"\x8b\x03\n\x16GetClusterInfoResponse\x12h\n\x11supported_clients\x18\x01 \x03(\x0b\x32M.temporal.api.workflowservice.v1.GetClusterInfoResponse.SupportedClientsEntry\x12\x16\n\x0eserver_version\x18\x02 \x01(\t\x12\x12\n\ncluster_id\x18\x03 \x01(\t\x12:\n\x0cversion_info\x18\x04 \x01(\x0b\x32$.temporal.api.version.v1.VersionInfo\x12\x14\n\x0c\x63luster_name\x18\x05 \x01(\t\x12\x1b\n\x13history_shard_count\x18\x06 \x01(\x05\x12\x19\n\x11persistence_store\x18\x07 \x01(\t\x12\x18\n\x10visibility_store\x18\x08 \x01(\t\x1a\x37\n\x15SupportedClientsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t:\x02\x38\x01"\x16\n\x14GetSystemInfoRequest"\xbc\x03\n\x15GetSystemInfoResponse\x12\x16\n\x0eserver_version\x18\x01 \x01(\t\x12Y\n\x0c\x63\x61pabilities\x18\x02 \x01(\x0b\x32\x43.temporal.api.workflowservice.v1.GetSystemInfoResponse.Capabilities\x1a\xaf\x02\n\x0c\x43\x61pabilities\x12\x1f\n\x17signal_and_query_header\x18\x01 \x01(\x08\x12&\n\x1einternal_error_differentiation\x18\x02 \x01(\x08\x12*\n"activity_failure_include_heartbeat\x18\x03 \x01(\x08\x12\x1a\n\x12supports_schedules\x18\x04 \x01(\x08\x12"\n\x1a\x65ncoded_failure_attributes\x18\x05 \x01(\x08\x12!\n\x19\x62uild_id_based_versioning\x18\x06 \x01(\x08\x12\x13\n\x0bupsert_memo\x18\x07 \x01(\x08\x12\x1c\n\x14\x65\x61ger_workflow_start\x18\x08 \x01(\x08\x12\x14\n\x0csdk_metadata\x18\t \x01(\x08"m\n\x1eListTaskQueuePartitionsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x38\n\ntask_queue\x18\x02 \x01(\x0b\x32$.temporal.api.taskqueue.v1.TaskQueue"\xdf\x01\n\x1fListTaskQueuePartitionsResponse\x12]\n\x1e\x61\x63tivity_task_queue_partitions\x18\x01 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata\x12]\n\x1eworkflow_task_queue_partitions\x18\x02 \x03(\x0b\x32\x35.temporal.api.taskqueue.v1.TaskQueuePartitionMetadata"\xcc\x02\n\x15\x43reateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12>\n\rinitial_patch\x18\x04 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t\x12*\n\x04memo\x18\x07 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x08 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes"0\n\x16\x43reateScheduleResponse\x12\x16\n\x0e\x63onflict_token\x18\x01 \x01(\x0c"A\n\x17\x44\x65scribeScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t"\x8f\x02\n\x18\x44\x65scribeScheduleResponse\x12\x34\n\x08schedule\x18\x01 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x34\n\x04info\x18\x02 \x01(\x0b\x32&.temporal.api.schedule.v1.ScheduleInfo\x12*\n\x04memo\x18\x03 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x04 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12\x16\n\x0e\x63onflict_token\x18\x05 \x01(\x0c"\xb3\x01\n\x15UpdateScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\x08schedule\x18\x03 \x01(\x0b\x32".temporal.api.schedule.v1.Schedule\x12\x16\n\x0e\x63onflict_token\x18\x04 \x01(\x0c\x12\x10\n\x08identity\x18\x05 \x01(\t\x12\x12\n\nrequest_id\x18\x06 \x01(\t"\x18\n\x16UpdateScheduleResponse"\x9c\x01\n\x14PatchScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x36\n\x05patch\x18\x03 \x01(\x0b\x32\'.temporal.api.schedule.v1.SchedulePatch\x12\x10\n\x08identity\x18\x04 \x01(\t\x12\x12\n\nrequest_id\x18\x05 \x01(\t"\x17\n\x15PatchScheduleResponse"\xb4\x01\n ListScheduleMatchingTimesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x34\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x32\n\x08\x65nd_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Y\n!ListScheduleMatchingTimesResponse\x12\x34\n\nstart_time\x18\x01 \x03(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01"Q\n\x15\x44\x65leteScheduleRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bschedule_id\x18\x02 \x01(\t\x12\x10\n\x08identity\x18\x03 \x01(\t"\x18\n\x16\x44\x65leteScheduleResponse"]\n\x14ListSchedulesRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x19\n\x11maximum_page_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"p\n\x15ListSchedulesResponse\x12>\n\tschedules\x18\x01 \x03(\x0b\x32+.temporal.api.schedule.v1.ScheduleListEntry\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xd1\x03\n\'UpdateWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12-\n#add_new_build_id_in_new_default_set\x18\x03 \x01(\tH\x00\x12\x87\x01\n\x1b\x61\x64\x64_new_compatible_build_id\x18\x04 \x01(\x0b\x32`.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersionH\x00\x12!\n\x17promote_set_by_build_id\x18\x05 \x01(\tH\x00\x12%\n\x1bpromote_build_id_within_set\x18\x06 \x01(\tH\x00\x1ao\n\x17\x41\x64\x64NewCompatibleVersion\x12\x14\n\x0cnew_build_id\x18\x01 \x01(\t\x12$\n\x1c\x65xisting_compatible_build_id\x18\x02 \x01(\t\x12\x18\n\x10make_set_default\x18\x03 \x01(\x08\x42\x0b\n\toperation"B\n(UpdateWorkerBuildIdCompatibilityResponse\x12\x16\n\x0eversion_set_id\x18\x01 \x01(\t"\xac\x01\n$GetWorkerBuildIdCompatibilityRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x10\n\x08max_sets\x18\x03 \x01(\x05\x12%\n\x1dinclude_retirement_candidates\x18\x04 \x01(\x08\x12$\n\x1cinclude_poller_compatibility\x18\x05 \x01(\x08"\xf8\x04\n%GetWorkerBuildIdCompatibilityResponse\x12K\n\x12major_version_sets\x18\x01 \x03(\x0b\x32/.temporal.api.taskqueue.v1.CompatibleVersionSet\x12y\n\x15retirement_candidates\x18\x02 \x03(\x0b\x32Z.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.RetirementCandidate\x12\x89\x01\n\x1b\x61\x63tive_versions_and_pollers\x18\x03 \x03(\x0b\x32\x64.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers\x1a\x83\x01\n\x13RetirementCandidate\x12\x10\n\x08\x62uild_id\x18\x01 \x01(\t\x12"\n\x1a\x61ll_workflows_are_archived\x18\x02 \x01(\x08\x12\x36\n\x07pollers\x18\x03 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo\x1au\n\x1dVersionsWithCompatiblePollers\x12\x1c\n\x14most_recent_build_id\x18\x01 \x01(\t\x12\x36\n\x07pollers\x18\x02 \x03(\x0b\x32%.temporal.api.taskqueue.v1.PollerInfo"\x85\x02\n\x1eUpdateWorkflowExecutionRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x45\n\x12workflow_execution\x18\x02 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x1e\n\x16\x66irst_execution_run_id\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy\x12\x30\n\x07request\x18\x05 \x01(\x0b\x32\x1f.temporal.api.update.v1.Request"\x8a\x01\n\x1fUpdateWorkflowExecutionResponse\x12\x35\n\nupdate_ref\x18\x01 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x30\n\x07outcome\x18\x02 \x01(\x0b\x32\x1f.temporal.api.update.v1.Outcome"\xf3\x03\n\x1aStartBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x18\n\x10visibility_query\x18\x02 \x01(\t\x12\x0e\n\x06job_id\x18\x03 \x01(\t\x12\x0e\n\x06reason\x18\x04 \x01(\t\x12=\n\nexecutions\x18\x05 \x03(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12Q\n\x15termination_operation\x18\n \x01(\x0b\x32\x30.temporal.api.batch.v1.BatchOperationTerminationH\x00\x12G\n\x10signal_operation\x18\x0b \x01(\x0b\x32+.temporal.api.batch.v1.BatchOperationSignalH\x00\x12S\n\x16\x63\x61ncellation_operation\x18\x0c \x01(\x0b\x32\x31.temporal.api.batch.v1.BatchOperationCancellationH\x00\x12K\n\x12\x64\x65letion_operation\x18\r \x01(\x0b\x32-.temporal.api.batch.v1.BatchOperationDeletionH\x00\x42\x0b\n\toperation"\x1d\n\x1bStartBatchOperationResponse"`\n\x19StopBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x0e\n\x06reason\x18\x03 \x01(\t\x12\x10\n\x08identity\x18\x04 \x01(\t"\x1c\n\x1aStopBatchOperationResponse"B\n\x1d\x44\x65scribeBatchOperationRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x0e\n\x06job_id\x18\x02 \x01(\t"\x9e\x03\n\x1e\x44\x65scribeBatchOperationResponse\x12\x41\n\x0eoperation_type\x18\x01 \x01(\x0e\x32).temporal.api.enums.v1.BatchOperationType\x12\x0e\n\x06job_id\x18\x02 \x01(\t\x12\x39\n\x05state\x18\x03 \x01(\x0e\x32*.temporal.api.enums.v1.BatchOperationState\x12\x34\n\nstart_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x34\n\nclose_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.TimestampB\x04\x90\xdf\x1f\x01\x12\x1d\n\x15total_operation_count\x18\x06 \x01(\x03\x12 \n\x18\x63omplete_operation_count\x18\x07 \x01(\x03\x12\x1f\n\x17\x66\x61ilure_operation_count\x18\x08 \x01(\x03\x12\x10\n\x08identity\x18\t \x01(\t\x12\x0e\n\x06reason\x18\n \x01(\t"[\n\x1aListBatchOperationsRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x11\n\tpage_size\x18\x02 \x01(\x05\x12\x17\n\x0fnext_page_token\x18\x03 \x01(\x0c"y\n\x1bListBatchOperationsResponse\x12\x41\n\x0eoperation_info\x18\x01 \x03(\x0b\x32).temporal.api.batch.v1.BatchOperationInfo\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\x0c"\xb9\x01\n"PollWorkflowExecutionUpdateRequest\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x35\n\nupdate_ref\x18\x02 \x01(\x0b\x32!.temporal.api.update.v1.UpdateRef\x12\x10\n\x08identity\x18\x03 \x01(\t\x12\x37\n\x0bwait_policy\x18\x04 \x01(\x0b\x32".temporal.api.update.v1.WaitPolicy"W\n#PollWorkflowExecutionUpdateResponse\x12\x30\n\x07outcome\x18\x01 \x01(\x0b\x32\x1f.temporal.api.update.v1.OutcomeB\xbe\x01\n"io.temporal.api.workflowservice.v1B\x14RequestResponseProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
 )
 
 
 _REGISTERNAMESPACEREQUEST = DESCRIPTOR.message_types_by_name["RegisterNamespaceRequest"]
 _REGISTERNAMESPACEREQUEST_DATAENTRY = _REGISTERNAMESPACEREQUEST.nested_types_by_name[
     "DataEntry"
 ]
@@ -346,28 +349,45 @@
 _LISTSCHEDULEMATCHINGTIMESRESPONSE = DESCRIPTOR.message_types_by_name[
     "ListScheduleMatchingTimesResponse"
 ]
 _DELETESCHEDULEREQUEST = DESCRIPTOR.message_types_by_name["DeleteScheduleRequest"]
 _DELETESCHEDULERESPONSE = DESCRIPTOR.message_types_by_name["DeleteScheduleResponse"]
 _LISTSCHEDULESREQUEST = DESCRIPTOR.message_types_by_name["ListSchedulesRequest"]
 _LISTSCHEDULESRESPONSE = DESCRIPTOR.message_types_by_name["ListSchedulesResponse"]
-_UPDATEWORKERBUILDIDORDERINGREQUEST = DESCRIPTOR.message_types_by_name[
-    "UpdateWorkerBuildIdOrderingRequest"
+_UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST = DESCRIPTOR.message_types_by_name[
+    "UpdateWorkerBuildIdCompatibilityRequest"
+]
+_UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION = (
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST.nested_types_by_name[
+        "AddNewCompatibleVersion"
+    ]
+)
+_UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE = DESCRIPTOR.message_types_by_name[
+    "UpdateWorkerBuildIdCompatibilityResponse"
+]
+_GETWORKERBUILDIDCOMPATIBILITYREQUEST = DESCRIPTOR.message_types_by_name[
+    "GetWorkerBuildIdCompatibilityRequest"
 ]
-_UPDATEWORKERBUILDIDORDERINGRESPONSE = DESCRIPTOR.message_types_by_name[
-    "UpdateWorkerBuildIdOrderingResponse"
+_GETWORKERBUILDIDCOMPATIBILITYRESPONSE = DESCRIPTOR.message_types_by_name[
+    "GetWorkerBuildIdCompatibilityResponse"
 ]
-_GETWORKERBUILDIDORDERINGREQUEST = DESCRIPTOR.message_types_by_name[
-    "GetWorkerBuildIdOrderingRequest"
+_GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE = (
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE.nested_types_by_name["RetirementCandidate"]
+)
+_GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS = (
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE.nested_types_by_name[
+        "VersionsWithCompatiblePollers"
+    ]
+)
+_UPDATEWORKFLOWEXECUTIONREQUEST = DESCRIPTOR.message_types_by_name[
+    "UpdateWorkflowExecutionRequest"
 ]
-_GETWORKERBUILDIDORDERINGRESPONSE = DESCRIPTOR.message_types_by_name[
-    "GetWorkerBuildIdOrderingResponse"
+_UPDATEWORKFLOWEXECUTIONRESPONSE = DESCRIPTOR.message_types_by_name[
+    "UpdateWorkflowExecutionResponse"
 ]
-_UPDATEWORKFLOWREQUEST = DESCRIPTOR.message_types_by_name["UpdateWorkflowRequest"]
-_UPDATEWORKFLOWRESPONSE = DESCRIPTOR.message_types_by_name["UpdateWorkflowResponse"]
 _STARTBATCHOPERATIONREQUEST = DESCRIPTOR.message_types_by_name[
     "StartBatchOperationRequest"
 ]
 _STARTBATCHOPERATIONRESPONSE = DESCRIPTOR.message_types_by_name[
     "StartBatchOperationResponse"
 ]
 _STOPBATCHOPERATIONREQUEST = DESCRIPTOR.message_types_by_name[
@@ -384,14 +404,20 @@
 ]
 _LISTBATCHOPERATIONSREQUEST = DESCRIPTOR.message_types_by_name[
     "ListBatchOperationsRequest"
 ]
 _LISTBATCHOPERATIONSRESPONSE = DESCRIPTOR.message_types_by_name[
     "ListBatchOperationsResponse"
 ]
+_POLLWORKFLOWEXECUTIONUPDATEREQUEST = DESCRIPTOR.message_types_by_name[
+    "PollWorkflowExecutionUpdateRequest"
+]
+_POLLWORKFLOWEXECUTIONUPDATERESPONSE = DESCRIPTOR.message_types_by_name[
+    "PollWorkflowExecutionUpdateResponse"
+]
 RegisterNamespaceRequest = _reflection.GeneratedProtocolMessageType(
     "RegisterNamespaceRequest",
     (_message.Message,),
     {
         "DataEntry": _reflection.GeneratedProtocolMessageType(
             "DataEntry",
             (_message.Message,),
@@ -1500,79 +1526,111 @@
         "DESCRIPTOR": _LISTSCHEDULESRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.ListSchedulesResponse)
     },
 )
 _sym_db.RegisterMessage(ListSchedulesResponse)
 
-UpdateWorkerBuildIdOrderingRequest = _reflection.GeneratedProtocolMessageType(
-    "UpdateWorkerBuildIdOrderingRequest",
+UpdateWorkerBuildIdCompatibilityRequest = _reflection.GeneratedProtocolMessageType(
+    "UpdateWorkerBuildIdCompatibilityRequest",
     (_message.Message,),
     {
-        "DESCRIPTOR": _UPDATEWORKERBUILDIDORDERINGREQUEST,
+        "AddNewCompatibleVersion": _reflection.GeneratedProtocolMessageType(
+            "AddNewCompatibleVersion",
+            (_message.Message,),
+            {
+                "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION,
+                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion)
+            },
+        ),
+        "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdOrderingRequest)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest)
     },
 )
-_sym_db.RegisterMessage(UpdateWorkerBuildIdOrderingRequest)
+_sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityRequest)
+_sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion)
 
-UpdateWorkerBuildIdOrderingResponse = _reflection.GeneratedProtocolMessageType(
-    "UpdateWorkerBuildIdOrderingResponse",
+UpdateWorkerBuildIdCompatibilityResponse = _reflection.GeneratedProtocolMessageType(
+    "UpdateWorkerBuildIdCompatibilityResponse",
     (_message.Message,),
     {
-        "DESCRIPTOR": _UPDATEWORKERBUILDIDORDERINGRESPONSE,
+        "DESCRIPTOR": _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdOrderingResponse)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityResponse)
     },
 )
-_sym_db.RegisterMessage(UpdateWorkerBuildIdOrderingResponse)
+_sym_db.RegisterMessage(UpdateWorkerBuildIdCompatibilityResponse)
 
-GetWorkerBuildIdOrderingRequest = _reflection.GeneratedProtocolMessageType(
-    "GetWorkerBuildIdOrderingRequest",
+GetWorkerBuildIdCompatibilityRequest = _reflection.GeneratedProtocolMessageType(
+    "GetWorkerBuildIdCompatibilityRequest",
     (_message.Message,),
     {
-        "DESCRIPTOR": _GETWORKERBUILDIDORDERINGREQUEST,
+        "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdOrderingRequest)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityRequest)
     },
 )
-_sym_db.RegisterMessage(GetWorkerBuildIdOrderingRequest)
+_sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityRequest)
 
-GetWorkerBuildIdOrderingResponse = _reflection.GeneratedProtocolMessageType(
-    "GetWorkerBuildIdOrderingResponse",
+GetWorkerBuildIdCompatibilityResponse = _reflection.GeneratedProtocolMessageType(
+    "GetWorkerBuildIdCompatibilityResponse",
     (_message.Message,),
     {
-        "DESCRIPTOR": _GETWORKERBUILDIDORDERINGRESPONSE,
+        "RetirementCandidate": _reflection.GeneratedProtocolMessageType(
+            "RetirementCandidate",
+            (_message.Message,),
+            {
+                "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE,
+                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.RetirementCandidate)
+            },
+        ),
+        "VersionsWithCompatiblePollers": _reflection.GeneratedProtocolMessageType(
+            "VersionsWithCompatiblePollers",
+            (_message.Message,),
+            {
+                "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS,
+                "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+                # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers)
+            },
+        ),
+        "DESCRIPTOR": _GETWORKERBUILDIDCOMPATIBILITYRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdOrderingResponse)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse)
     },
 )
-_sym_db.RegisterMessage(GetWorkerBuildIdOrderingResponse)
+_sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityResponse)
+_sym_db.RegisterMessage(GetWorkerBuildIdCompatibilityResponse.RetirementCandidate)
+_sym_db.RegisterMessage(
+    GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
+)
 
-UpdateWorkflowRequest = _reflection.GeneratedProtocolMessageType(
-    "UpdateWorkflowRequest",
+UpdateWorkflowExecutionRequest = _reflection.GeneratedProtocolMessageType(
+    "UpdateWorkflowExecutionRequest",
     (_message.Message,),
     {
-        "DESCRIPTOR": _UPDATEWORKFLOWREQUEST,
+        "DESCRIPTOR": _UPDATEWORKFLOWEXECUTIONREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkflowRequest)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkflowExecutionRequest)
     },
 )
-_sym_db.RegisterMessage(UpdateWorkflowRequest)
+_sym_db.RegisterMessage(UpdateWorkflowExecutionRequest)
 
-UpdateWorkflowResponse = _reflection.GeneratedProtocolMessageType(
-    "UpdateWorkflowResponse",
+UpdateWorkflowExecutionResponse = _reflection.GeneratedProtocolMessageType(
+    "UpdateWorkflowExecutionResponse",
     (_message.Message,),
     {
-        "DESCRIPTOR": _UPDATEWORKFLOWRESPONSE,
+        "DESCRIPTOR": _UPDATEWORKFLOWEXECUTIONRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
-        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkflowResponse)
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.UpdateWorkflowExecutionResponse)
     },
 )
-_sym_db.RegisterMessage(UpdateWorkflowResponse)
+_sym_db.RegisterMessage(UpdateWorkflowExecutionResponse)
 
 StartBatchOperationRequest = _reflection.GeneratedProtocolMessageType(
     "StartBatchOperationRequest",
     (_message.Message,),
     {
         "DESCRIPTOR": _STARTBATCHOPERATIONREQUEST,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
@@ -1654,14 +1712,36 @@
         "DESCRIPTOR": _LISTBATCHOPERATIONSRESPONSE,
         "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
         # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.ListBatchOperationsResponse)
     },
 )
 _sym_db.RegisterMessage(ListBatchOperationsResponse)
 
+PollWorkflowExecutionUpdateRequest = _reflection.GeneratedProtocolMessageType(
+    "PollWorkflowExecutionUpdateRequest",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _POLLWORKFLOWEXECUTIONUPDATEREQUEST,
+        "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateRequest)
+    },
+)
+_sym_db.RegisterMessage(PollWorkflowExecutionUpdateRequest)
+
+PollWorkflowExecutionUpdateResponse = _reflection.GeneratedProtocolMessageType(
+    "PollWorkflowExecutionUpdateResponse",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _POLLWORKFLOWEXECUTIONUPDATERESPONSE,
+        "__module__": "temporal.api.workflowservice.v1.request_response_pb2"
+        # @@protoc_insertion_point(class_scope:temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateResponse)
+    },
+)
+_sym_db.RegisterMessage(PollWorkflowExecutionUpdateResponse)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b'\n"io.temporal.api.workflowservice.v1B\024RequestResponseProtoP\001Z5go.temporal.io/api/workflowservice/v1;workflowservice\252\002!Temporalio.Api.WorkflowService.V1\352\002$Temporalio::Api::WorkflowService::V1'
     _REGISTERNAMESPACEREQUEST_DATAENTRY._options = None
     _REGISTERNAMESPACEREQUEST_DATAENTRY._serialized_options = b"8\001"
     _REGISTERNAMESPACEREQUEST.fields_by_name[
         "workflow_execution_retention_period"
@@ -1683,14 +1763,20 @@
     ]._serialized_options = b"\230\337\037\001"
     _STARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
         "workflow_task_timeout"
     ]._options = None
     _STARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
         "workflow_task_timeout"
     ]._serialized_options = b"\230\337\037\001"
+    _STARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
+        "workflow_start_delay"
+    ]._options = None
+    _STARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
+        "workflow_start_delay"
+    ]._serialized_options = b"\230\337\037\001"
     _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._options = None
     _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._serialized_options = b"8\001"
     _POLLWORKFLOWTASKQUEUERESPONSE.fields_by_name["scheduled_time"]._options = None
     _POLLWORKFLOWTASKQUEUERESPONSE.fields_by_name[
         "scheduled_time"
     ]._serialized_options = b"\220\337\037\001"
     _POLLWORKFLOWTASKQUEUERESPONSE.fields_by_name["started_time"]._options = None
@@ -1745,14 +1831,20 @@
     ]._serialized_options = b"\230\337\037\001"
     _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
         "workflow_task_timeout"
     ]._options = None
     _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
         "workflow_task_timeout"
     ]._serialized_options = b"\230\337\037\001"
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
+        "workflow_start_delay"
+    ]._options = None
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST.fields_by_name[
+        "workflow_start_delay"
+    ]._serialized_options = b"\230\337\037\001"
     _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._options = None
     _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_options = b"8\001"
     _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._options = None
     _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_options = b"8\001"
     _LISTSCHEDULEMATCHINGTIMESREQUEST.fields_by_name["start_time"]._options = None
     _LISTSCHEDULEMATCHINGTIMESREQUEST.fields_by_name[
         "start_time"
@@ -1769,240 +1861,258 @@
     _DESCRIBEBATCHOPERATIONRESPONSE.fields_by_name[
         "start_time"
     ]._serialized_options = b"\220\337\037\001"
     _DESCRIBEBATCHOPERATIONRESPONSE.fields_by_name["close_time"]._options = None
     _DESCRIBEBATCHOPERATIONRESPONSE.fields_by_name[
         "close_time"
     ]._serialized_options = b"\220\337\037\001"
-    _REGISTERNAMESPACEREQUEST._serialized_start = 1092
-    _REGISTERNAMESPACEREQUEST._serialized_end = 1746
-    _REGISTERNAMESPACEREQUEST_DATAENTRY._serialized_start = 1703
-    _REGISTERNAMESPACEREQUEST_DATAENTRY._serialized_end = 1746
-    _REGISTERNAMESPACERESPONSE._serialized_start = 1748
-    _REGISTERNAMESPACERESPONSE._serialized_end = 1775
-    _LISTNAMESPACESREQUEST._serialized_start = 1778
-    _LISTNAMESPACESREQUEST._serialized_end = 1915
-    _LISTNAMESPACESRESPONSE._serialized_start = 1918
-    _LISTNAMESPACESRESPONSE._serialized_end = 2047
-    _DESCRIBENAMESPACEREQUEST._serialized_start = 2049
-    _DESCRIBENAMESPACEREQUEST._serialized_end = 2106
-    _DESCRIBENAMESPACERESPONSE._serialized_start = 2109
-    _DESCRIBENAMESPACERESPONSE._serialized_end = 2473
-    _UPDATENAMESPACEREQUEST._serialized_start = 2476
-    _UPDATENAMESPACEREQUEST._serialized_end = 2811
-    _UPDATENAMESPACERESPONSE._serialized_start = 2814
-    _UPDATENAMESPACERESPONSE._serialized_end = 3105
-    _DEPRECATENAMESPACEREQUEST._serialized_start = 3107
-    _DEPRECATENAMESPACEREQUEST._serialized_end = 3177
-    _DEPRECATENAMESPACERESPONSE._serialized_start = 3179
-    _DEPRECATENAMESPACERESPONSE._serialized_end = 3207
-    _STARTWORKFLOWEXECUTIONREQUEST._serialized_start = 3210
-    _STARTWORKFLOWEXECUTIONREQUEST._serialized_end = 4006
-    _STARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 4008
-    _STARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 4056
-    _GETWORKFLOWEXECUTIONHISTORYREQUEST._serialized_start = 4059
-    _GETWORKFLOWEXECUTIONHISTORYREQUEST._serialized_end = 4357
-    _GETWORKFLOWEXECUTIONHISTORYRESPONSE._serialized_start = 4360
-    _GETWORKFLOWEXECUTIONHISTORYRESPONSE._serialized_end = 4546
-    _GETWORKFLOWEXECUTIONHISTORYREVERSEREQUEST._serialized_start = 4549
-    _GETWORKFLOWEXECUTIONHISTORYREVERSEREQUEST._serialized_end = 4725
-    _GETWORKFLOWEXECUTIONHISTORYREVERSERESPONSE._serialized_start = 4727
-    _GETWORKFLOWEXECUTIONHISTORYREVERSERESPONSE._serialized_end = 4847
-    _POLLWORKFLOWTASKQUEUEREQUEST._serialized_start = 4850
-    _POLLWORKFLOWTASKQUEUEREQUEST._serialized_end = 5068
-    _POLLWORKFLOWTASKQUEUERESPONSE._serialized_start = 5071
-    _POLLWORKFLOWTASKQUEUERESPONSE._serialized_end = 5923
-    _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._serialized_start = 5839
-    _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._serialized_end = 5923
-    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_start = 5926
-    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_end = 6528
-    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_start = 6433
-    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_end = 6528
-    _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_start = 6531
-    _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_end = 6776
-    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_start = 6779
-    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_end = 7009
-    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_start = 7011
-    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_end = 7046
-    _POLLACTIVITYTASKQUEUEREQUEST._serialized_start = 7049
-    _POLLACTIVITYTASKQUEUEREQUEST._serialized_end = 7317
-    _POLLACTIVITYTASKQUEUERESPONSE._serialized_start = 7320
-    _POLLACTIVITYTASKQUEUERESPONSE._serialized_end = 8228
-    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_start = 8231
-    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_end = 8375
-    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_start = 8377
-    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_end = 8440
-    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_start = 8443
-    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_end = 8629
-    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_start = 8631
-    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_end = 8698
-    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_start = 8701
-    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_end = 8845
-    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_start = 8847
-    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_end = 8885
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_start = 8888
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_end = 9074
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_start = 9076
-    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_end = 9118
-    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_start = 9121
-    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_end = 9329
-    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_start = 9331
-    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_end = 9418
-    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_start = 9421
-    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_end = 9671
-    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_start = 9673
-    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_end = 9764
-    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_start = 9767
-    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_end = 9911
-    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_start = 9913
-    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_end = 9950
-    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_start = 9953
-    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_end = 10139
-    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_start = 10141
-    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_end = 10182
-    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_start = 10185
-    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_end = 10400
-    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_start = 10402
-    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_end = 10442
-    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_start = 10445
-    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_end = 10740
-    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_start = 10742
-    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_end = 10775
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_start = 10778
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_end = 11678
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 11680
-    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 11738
-    _RESETWORKFLOWEXECUTIONREQUEST._serialized_start = 11741
-    _RESETWORKFLOWEXECUTIONREQUEST._serialized_end = 12006
-    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_start = 12008
-    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_end = 12056
-    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_start = 12059
-    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_end = 12301
-    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 12303
-    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 12339
-    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_start = 12341
-    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_end = 12463
-    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_start = 12465
-    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_end = 12498
-    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_start = 12501
-    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_end = 12830
-    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_start = 12833
-    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_end = 12963
-    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 12966
-    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 13360
-    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13363
-    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 13495
-    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_start = 13497
-    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_end = 13606
-    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13608
-    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 13734
-    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 13736
-    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 13853
-    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13856
-    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 13990
-    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_start = 13992
-    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_end = 14101
-    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14103
-    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14229
-    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_start = 14231
-    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_end = 14297
-    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14299
-    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14347
-    _GETSEARCHATTRIBUTESREQUEST._serialized_start = 14349
-    _GETSEARCHATTRIBUTESREQUEST._serialized_end = 14377
-    _GETSEARCHATTRIBUTESRESPONSE._serialized_start = 14380
-    _GETSEARCHATTRIBUTESRESPONSE._serialized_end = 14581
-    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_start = 14497
-    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_end = 14581
-    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_start = 14584
-    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_end = 14806
-    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_start = 14808
-    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_end = 14843
-    _RESETSTICKYTASKQUEUEREQUEST._serialized_start = 14845
-    _RESETSTICKYTASKQUEUEREQUEST._serialized_end = 14955
-    _RESETSTICKYTASKQUEUERESPONSE._serialized_start = 14957
-    _RESETSTICKYTASKQUEUERESPONSE._serialized_end = 14987
-    _QUERYWORKFLOWREQUEST._serialized_start = 14990
-    _QUERYWORKFLOWREQUEST._serialized_end = 15223
-    _QUERYWORKFLOWRESPONSE._serialized_start = 15226
-    _QUERYWORKFLOWRESPONSE._serialized_end = 15367
-    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_start = 15369
-    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_end = 15484
-    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_start = 15487
-    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_end = 15917
-    _DESCRIBETASKQUEUEREQUEST._serialized_start = 15920
-    _DESCRIBETASKQUEUEREQUEST._serialized_end = 16121
-    _DESCRIBETASKQUEUERESPONSE._serialized_start = 16124
-    _DESCRIBETASKQUEUERESPONSE._serialized_end = 16278
-    _GETCLUSTERINFOREQUEST._serialized_start = 16280
-    _GETCLUSTERINFOREQUEST._serialized_end = 16303
-    _GETCLUSTERINFORESPONSE._serialized_start = 16306
-    _GETCLUSTERINFORESPONSE._serialized_end = 16701
-    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_start = 16646
-    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_end = 16701
-    _GETSYSTEMINFOREQUEST._serialized_start = 16703
-    _GETSYSTEMINFOREQUEST._serialized_end = 16725
-    _GETSYSTEMINFORESPONSE._serialized_start = 16728
-    _GETSYSTEMINFORESPONSE._serialized_end = 17120
-    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_start = 16869
-    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_end = 17120
-    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_start = 17122
-    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_end = 17231
-    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_start = 17234
-    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_end = 17457
-    _CREATESCHEDULEREQUEST._serialized_start = 17460
-    _CREATESCHEDULEREQUEST._serialized_end = 17792
-    _CREATESCHEDULERESPONSE._serialized_start = 17794
-    _CREATESCHEDULERESPONSE._serialized_end = 17842
-    _DESCRIBESCHEDULEREQUEST._serialized_start = 17844
-    _DESCRIBESCHEDULEREQUEST._serialized_end = 17909
-    _DESCRIBESCHEDULERESPONSE._serialized_start = 17912
-    _DESCRIBESCHEDULERESPONSE._serialized_end = 18183
-    _UPDATESCHEDULEREQUEST._serialized_start = 18186
-    _UPDATESCHEDULEREQUEST._serialized_end = 18365
-    _UPDATESCHEDULERESPONSE._serialized_start = 18367
-    _UPDATESCHEDULERESPONSE._serialized_end = 18391
-    _PATCHSCHEDULEREQUEST._serialized_start = 18394
-    _PATCHSCHEDULEREQUEST._serialized_end = 18550
-    _PATCHSCHEDULERESPONSE._serialized_start = 18552
-    _PATCHSCHEDULERESPONSE._serialized_end = 18575
-    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_start = 18578
-    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_end = 18758
-    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_start = 18760
-    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_end = 18849
-    _DELETESCHEDULEREQUEST._serialized_start = 18851
-    _DELETESCHEDULEREQUEST._serialized_end = 18932
-    _DELETESCHEDULERESPONSE._serialized_start = 18934
-    _DELETESCHEDULERESPONSE._serialized_end = 18958
-    _LISTSCHEDULESREQUEST._serialized_start = 18960
-    _LISTSCHEDULESREQUEST._serialized_end = 19053
-    _LISTSCHEDULESRESPONSE._serialized_start = 19055
-    _LISTSCHEDULESRESPONSE._serialized_end = 19167
-    _UPDATEWORKERBUILDIDORDERINGREQUEST._serialized_start = 19170
-    _UPDATEWORKERBUILDIDORDERINGREQUEST._serialized_end = 19394
-    _UPDATEWORKERBUILDIDORDERINGRESPONSE._serialized_start = 19396
-    _UPDATEWORKERBUILDIDORDERINGRESPONSE._serialized_end = 19433
-    _GETWORKERBUILDIDORDERINGREQUEST._serialized_start = 19435
-    _GETWORKERBUILDIDORDERINGREQUEST._serialized_end = 19526
-    _GETWORKERBUILDIDORDERINGRESPONSE._serialized_start = 19529
-    _GETWORKERBUILDIDORDERINGRESPONSE._serialized_end = 19699
-    _UPDATEWORKFLOWREQUEST._serialized_start = 19702
-    _UPDATEWORKFLOWREQUEST._serialized_end = 20021
-    _UPDATEWORKFLOWRESPONSE._serialized_start = 20023
-    _UPDATEWORKFLOWRESPONSE._serialized_end = 20122
-    _STARTBATCHOPERATIONREQUEST._serialized_start = 20125
-    _STARTBATCHOPERATIONREQUEST._serialized_end = 20561
-    _STARTBATCHOPERATIONRESPONSE._serialized_start = 20563
-    _STARTBATCHOPERATIONRESPONSE._serialized_end = 20592
-    _STOPBATCHOPERATIONREQUEST._serialized_start = 20594
-    _STOPBATCHOPERATIONREQUEST._serialized_end = 20690
-    _STOPBATCHOPERATIONRESPONSE._serialized_start = 20692
-    _STOPBATCHOPERATIONRESPONSE._serialized_end = 20720
-    _DESCRIBEBATCHOPERATIONREQUEST._serialized_start = 20722
-    _DESCRIBEBATCHOPERATIONREQUEST._serialized_end = 20788
-    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_start = 20791
-    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_end = 21205
-    _LISTBATCHOPERATIONSREQUEST._serialized_start = 21207
-    _LISTBATCHOPERATIONSREQUEST._serialized_end = 21298
-    _LISTBATCHOPERATIONSRESPONSE._serialized_start = 21300
-    _LISTBATCHOPERATIONSRESPONSE._serialized_end = 21421
+    _REGISTERNAMESPACEREQUEST._serialized_start = 1141
+    _REGISTERNAMESPACEREQUEST._serialized_end = 1795
+    _REGISTERNAMESPACEREQUEST_DATAENTRY._serialized_start = 1752
+    _REGISTERNAMESPACEREQUEST_DATAENTRY._serialized_end = 1795
+    _REGISTERNAMESPACERESPONSE._serialized_start = 1797
+    _REGISTERNAMESPACERESPONSE._serialized_end = 1824
+    _LISTNAMESPACESREQUEST._serialized_start = 1827
+    _LISTNAMESPACESREQUEST._serialized_end = 1964
+    _LISTNAMESPACESRESPONSE._serialized_start = 1967
+    _LISTNAMESPACESRESPONSE._serialized_end = 2096
+    _DESCRIBENAMESPACEREQUEST._serialized_start = 2098
+    _DESCRIBENAMESPACEREQUEST._serialized_end = 2155
+    _DESCRIBENAMESPACERESPONSE._serialized_start = 2158
+    _DESCRIBENAMESPACERESPONSE._serialized_end = 2522
+    _UPDATENAMESPACEREQUEST._serialized_start = 2525
+    _UPDATENAMESPACEREQUEST._serialized_end = 2860
+    _UPDATENAMESPACERESPONSE._serialized_start = 2863
+    _UPDATENAMESPACERESPONSE._serialized_end = 3154
+    _DEPRECATENAMESPACEREQUEST._serialized_start = 3156
+    _DEPRECATENAMESPACEREQUEST._serialized_end = 3226
+    _DEPRECATENAMESPACERESPONSE._serialized_start = 3228
+    _DEPRECATENAMESPACERESPONSE._serialized_end = 3256
+    _STARTWORKFLOWEXECUTIONREQUEST._serialized_start = 3259
+    _STARTWORKFLOWEXECUTIONREQUEST._serialized_end = 4278
+    _STARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 4281
+    _STARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 4422
+    _GETWORKFLOWEXECUTIONHISTORYREQUEST._serialized_start = 4425
+    _GETWORKFLOWEXECUTIONHISTORYREQUEST._serialized_end = 4723
+    _GETWORKFLOWEXECUTIONHISTORYRESPONSE._serialized_start = 4726
+    _GETWORKFLOWEXECUTIONHISTORYRESPONSE._serialized_end = 4912
+    _GETWORKFLOWEXECUTIONHISTORYREVERSEREQUEST._serialized_start = 4915
+    _GETWORKFLOWEXECUTIONHISTORYREVERSEREQUEST._serialized_end = 5091
+    _GETWORKFLOWEXECUTIONHISTORYREVERSERESPONSE._serialized_start = 5093
+    _GETWORKFLOWEXECUTIONHISTORYREVERSERESPONSE._serialized_end = 5213
+    _POLLWORKFLOWTASKQUEUEREQUEST._serialized_start = 5216
+    _POLLWORKFLOWTASKQUEUEREQUEST._serialized_end = 5454
+    _POLLWORKFLOWTASKQUEUERESPONSE._serialized_start = 5457
+    _POLLWORKFLOWTASKQUEUERESPONSE._serialized_end = 6299
+    _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._serialized_start = 6215
+    _POLLWORKFLOWTASKQUEUERESPONSE_QUERIESENTRY._serialized_end = 6299
+    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_start = 6302
+    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST._serialized_end = 7106
+    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_start = 7011
+    _RESPONDWORKFLOWTASKCOMPLETEDREQUEST_QUERYRESULTSENTRY._serialized_end = 7106
+    _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_start = 7109
+    _RESPONDWORKFLOWTASKCOMPLETEDRESPONSE._serialized_end = 7354
+    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_start = 7357
+    _RESPONDWORKFLOWTASKFAILEDREQUEST._serialized_end = 7640
+    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_start = 7642
+    _RESPONDWORKFLOWTASKFAILEDRESPONSE._serialized_end = 7677
+    _POLLACTIVITYTASKQUEUEREQUEST._serialized_start = 7680
+    _POLLACTIVITYTASKQUEUEREQUEST._serialized_end = 7968
+    _POLLACTIVITYTASKQUEUERESPONSE._serialized_start = 7971
+    _POLLACTIVITYTASKQUEUERESPONSE._serialized_end = 8879
+    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_start = 8882
+    _RECORDACTIVITYTASKHEARTBEATREQUEST._serialized_end = 9026
+    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_start = 9028
+    _RECORDACTIVITYTASKHEARTBEATRESPONSE._serialized_end = 9091
+    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_start = 9094
+    _RECORDACTIVITYTASKHEARTBEATBYIDREQUEST._serialized_end = 9280
+    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_start = 9282
+    _RECORDACTIVITYTASKHEARTBEATBYIDRESPONSE._serialized_end = 9349
+    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_start = 9352
+    _RESPONDACTIVITYTASKCOMPLETEDREQUEST._serialized_end = 9496
+    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_start = 9498
+    _RESPONDACTIVITYTASKCOMPLETEDRESPONSE._serialized_end = 9536
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_start = 9539
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDREQUEST._serialized_end = 9725
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_start = 9727
+    _RESPONDACTIVITYTASKCOMPLETEDBYIDRESPONSE._serialized_end = 9769
+    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_start = 9772
+    _RESPONDACTIVITYTASKFAILEDREQUEST._serialized_end = 9980
+    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_start = 9982
+    _RESPONDACTIVITYTASKFAILEDRESPONSE._serialized_end = 10069
+    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_start = 10072
+    _RESPONDACTIVITYTASKFAILEDBYIDREQUEST._serialized_end = 10322
+    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_start = 10324
+    _RESPONDACTIVITYTASKFAILEDBYIDRESPONSE._serialized_end = 10415
+    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_start = 10418
+    _RESPONDACTIVITYTASKCANCELEDREQUEST._serialized_end = 10562
+    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_start = 10564
+    _RESPONDACTIVITYTASKCANCELEDRESPONSE._serialized_end = 10601
+    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_start = 10604
+    _RESPONDACTIVITYTASKCANCELEDBYIDREQUEST._serialized_end = 10790
+    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_start = 10792
+    _RESPONDACTIVITYTASKCANCELEDBYIDRESPONSE._serialized_end = 10833
+    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_start = 10836
+    _REQUESTCANCELWORKFLOWEXECUTIONREQUEST._serialized_end = 11051
+    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_start = 11053
+    _REQUESTCANCELWORKFLOWEXECUTIONRESPONSE._serialized_end = 11093
+    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_start = 11096
+    _SIGNALWORKFLOWEXECUTIONREQUEST._serialized_end = 11428
+    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_start = 11430
+    _SIGNALWORKFLOWEXECUTIONRESPONSE._serialized_end = 11463
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_start = 11466
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONREQUEST._serialized_end = 12466
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_start = 12468
+    _SIGNALWITHSTARTWORKFLOWEXECUTIONRESPONSE._serialized_end = 12526
+    _RESETWORKFLOWEXECUTIONREQUEST._serialized_start = 12529
+    _RESETWORKFLOWEXECUTIONREQUEST._serialized_end = 12794
+    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_start = 12796
+    _RESETWORKFLOWEXECUTIONRESPONSE._serialized_end = 12844
+    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_start = 12847
+    _TERMINATEWORKFLOWEXECUTIONREQUEST._serialized_end = 13089
+    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13091
+    _TERMINATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13127
+    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_start = 13129
+    _DELETEWORKFLOWEXECUTIONREQUEST._serialized_end = 13251
+    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_start = 13253
+    _DELETEWORKFLOWEXECUTIONRESPONSE._serialized_end = 13286
+    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_start = 13289
+    _LISTOPENWORKFLOWEXECUTIONSREQUEST._serialized_end = 13618
+    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_start = 13621
+    _LISTOPENWORKFLOWEXECUTIONSRESPONSE._serialized_end = 13751
+    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 13754
+    _LISTCLOSEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14148
+    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14151
+    _LISTCLOSEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14283
+    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_start = 14285
+    _LISTWORKFLOWEXECUTIONSREQUEST._serialized_end = 14394
+    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14396
+    _LISTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14522
+    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_start = 14524
+    _LISTARCHIVEDWORKFLOWEXECUTIONSREQUEST._serialized_end = 14641
+    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14644
+    _LISTARCHIVEDWORKFLOWEXECUTIONSRESPONSE._serialized_end = 14778
+    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_start = 14780
+    _SCANWORKFLOWEXECUTIONSREQUEST._serialized_end = 14889
+    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_start = 14891
+    _SCANWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15017
+    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_start = 15019
+    _COUNTWORKFLOWEXECUTIONSREQUEST._serialized_end = 15085
+    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_start = 15087
+    _COUNTWORKFLOWEXECUTIONSRESPONSE._serialized_end = 15135
+    _GETSEARCHATTRIBUTESREQUEST._serialized_start = 15137
+    _GETSEARCHATTRIBUTESREQUEST._serialized_end = 15165
+    _GETSEARCHATTRIBUTESRESPONSE._serialized_start = 15168
+    _GETSEARCHATTRIBUTESRESPONSE._serialized_end = 15369
+    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_start = 15285
+    _GETSEARCHATTRIBUTESRESPONSE_KEYSENTRY._serialized_end = 15369
+    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_start = 15372
+    _RESPONDQUERYTASKCOMPLETEDREQUEST._serialized_end = 15594
+    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_start = 15596
+    _RESPONDQUERYTASKCOMPLETEDRESPONSE._serialized_end = 15631
+    _RESETSTICKYTASKQUEUEREQUEST._serialized_start = 15633
+    _RESETSTICKYTASKQUEUEREQUEST._serialized_end = 15743
+    _RESETSTICKYTASKQUEUERESPONSE._serialized_start = 15745
+    _RESETSTICKYTASKQUEUERESPONSE._serialized_end = 15775
+    _QUERYWORKFLOWREQUEST._serialized_start = 15778
+    _QUERYWORKFLOWREQUEST._serialized_end = 16011
+    _QUERYWORKFLOWRESPONSE._serialized_start = 16014
+    _QUERYWORKFLOWRESPONSE._serialized_end = 16155
+    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_start = 16157
+    _DESCRIBEWORKFLOWEXECUTIONREQUEST._serialized_end = 16272
+    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_start = 16275
+    _DESCRIBEWORKFLOWEXECUTIONRESPONSE._serialized_end = 16705
+    _DESCRIBETASKQUEUEREQUEST._serialized_start = 16708
+    _DESCRIBETASKQUEUEREQUEST._serialized_end = 16909
+    _DESCRIBETASKQUEUERESPONSE._serialized_start = 16912
+    _DESCRIBETASKQUEUERESPONSE._serialized_end = 17066
+    _GETCLUSTERINFOREQUEST._serialized_start = 17068
+    _GETCLUSTERINFOREQUEST._serialized_end = 17091
+    _GETCLUSTERINFORESPONSE._serialized_start = 17094
+    _GETCLUSTERINFORESPONSE._serialized_end = 17489
+    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_start = 17434
+    _GETCLUSTERINFORESPONSE_SUPPORTEDCLIENTSENTRY._serialized_end = 17489
+    _GETSYSTEMINFOREQUEST._serialized_start = 17491
+    _GETSYSTEMINFOREQUEST._serialized_end = 17513
+    _GETSYSTEMINFORESPONSE._serialized_start = 17516
+    _GETSYSTEMINFORESPONSE._serialized_end = 17960
+    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_start = 17657
+    _GETSYSTEMINFORESPONSE_CAPABILITIES._serialized_end = 17960
+    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_start = 17962
+    _LISTTASKQUEUEPARTITIONSREQUEST._serialized_end = 18071
+    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_start = 18074
+    _LISTTASKQUEUEPARTITIONSRESPONSE._serialized_end = 18297
+    _CREATESCHEDULEREQUEST._serialized_start = 18300
+    _CREATESCHEDULEREQUEST._serialized_end = 18632
+    _CREATESCHEDULERESPONSE._serialized_start = 18634
+    _CREATESCHEDULERESPONSE._serialized_end = 18682
+    _DESCRIBESCHEDULEREQUEST._serialized_start = 18684
+    _DESCRIBESCHEDULEREQUEST._serialized_end = 18749
+    _DESCRIBESCHEDULERESPONSE._serialized_start = 18752
+    _DESCRIBESCHEDULERESPONSE._serialized_end = 19023
+    _UPDATESCHEDULEREQUEST._serialized_start = 19026
+    _UPDATESCHEDULEREQUEST._serialized_end = 19205
+    _UPDATESCHEDULERESPONSE._serialized_start = 19207
+    _UPDATESCHEDULERESPONSE._serialized_end = 19231
+    _PATCHSCHEDULEREQUEST._serialized_start = 19234
+    _PATCHSCHEDULEREQUEST._serialized_end = 19390
+    _PATCHSCHEDULERESPONSE._serialized_start = 19392
+    _PATCHSCHEDULERESPONSE._serialized_end = 19415
+    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_start = 19418
+    _LISTSCHEDULEMATCHINGTIMESREQUEST._serialized_end = 19598
+    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_start = 19600
+    _LISTSCHEDULEMATCHINGTIMESRESPONSE._serialized_end = 19689
+    _DELETESCHEDULEREQUEST._serialized_start = 19691
+    _DELETESCHEDULEREQUEST._serialized_end = 19772
+    _DELETESCHEDULERESPONSE._serialized_start = 19774
+    _DELETESCHEDULERESPONSE._serialized_end = 19798
+    _LISTSCHEDULESREQUEST._serialized_start = 19800
+    _LISTSCHEDULESREQUEST._serialized_end = 19893
+    _LISTSCHEDULESRESPONSE._serialized_start = 19895
+    _LISTSCHEDULESRESPONSE._serialized_end = 20007
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20010
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 20475
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION._serialized_start = (
+        20351
+    )
+    _UPDATEWORKERBUILDIDCOMPATIBILITYREQUEST_ADDNEWCOMPATIBLEVERSION._serialized_end = (
+        20462
+    )
+    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 20477
+    _UPDATEWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 20543
+    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_start = 20546
+    _GETWORKERBUILDIDCOMPATIBILITYREQUEST._serialized_end = 20718
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_start = 20721
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE._serialized_end = 21353
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE._serialized_start = 21103
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_RETIREMENTCANDIDATE._serialized_end = 21234
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS._serialized_start = (
+        21236
+    )
+    _GETWORKERBUILDIDCOMPATIBILITYRESPONSE_VERSIONSWITHCOMPATIBLEPOLLERS._serialized_end = (
+        21353
+    )
+    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_start = 21356
+    _UPDATEWORKFLOWEXECUTIONREQUEST._serialized_end = 21617
+    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_start = 21620
+    _UPDATEWORKFLOWEXECUTIONRESPONSE._serialized_end = 21758
+    _STARTBATCHOPERATIONREQUEST._serialized_start = 21761
+    _STARTBATCHOPERATIONREQUEST._serialized_end = 22260
+    _STARTBATCHOPERATIONRESPONSE._serialized_start = 22262
+    _STARTBATCHOPERATIONRESPONSE._serialized_end = 22291
+    _STOPBATCHOPERATIONREQUEST._serialized_start = 22293
+    _STOPBATCHOPERATIONREQUEST._serialized_end = 22389
+    _STOPBATCHOPERATIONRESPONSE._serialized_start = 22391
+    _STOPBATCHOPERATIONRESPONSE._serialized_end = 22419
+    _DESCRIBEBATCHOPERATIONREQUEST._serialized_start = 22421
+    _DESCRIBEBATCHOPERATIONREQUEST._serialized_end = 22487
+    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_start = 22490
+    _DESCRIBEBATCHOPERATIONRESPONSE._serialized_end = 22904
+    _LISTBATCHOPERATIONSREQUEST._serialized_start = 22906
+    _LISTBATCHOPERATIONSREQUEST._serialized_end = 22997
+    _LISTBATCHOPERATIONSRESPONSE._serialized_start = 22999
+    _LISTBATCHOPERATIONSRESPONSE._serialized_end = 23120
+    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_start = 23123
+    _POLLWORKFLOWEXECUTIONUPDATEREQUEST._serialized_end = 23308
+    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_start = 23310
+    _POLLWORKFLOWEXECUTIONUPDATERESPONSE._serialized_end = 23397
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -37,25 +37,26 @@
 import temporalio.api.enums.v1.batch_operation_pb2
 import temporalio.api.enums.v1.common_pb2
 import temporalio.api.enums.v1.failed_cause_pb2
 import temporalio.api.enums.v1.namespace_pb2
 import temporalio.api.enums.v1.query_pb2
 import temporalio.api.enums.v1.reset_pb2
 import temporalio.api.enums.v1.task_queue_pb2
-import temporalio.api.enums.v1.update_pb2
 import temporalio.api.enums.v1.workflow_pb2
 import temporalio.api.failure.v1.message_pb2
 import temporalio.api.filter.v1.message_pb2
 import temporalio.api.history.v1.message_pb2
-import temporalio.api.interaction.v1.message_pb2
 import temporalio.api.namespace.v1.message_pb2
+import temporalio.api.protocol.v1.message_pb2
 import temporalio.api.query.v1.message_pb2
 import temporalio.api.replication.v1.message_pb2
 import temporalio.api.schedule.v1.message_pb2
+import temporalio.api.sdk.v1.task_complete_metadata_pb2
 import temporalio.api.taskqueue.v1.message_pb2
+import temporalio.api.update.v1.message_pb2
 import temporalio.api.version.v1.message_pb2
 import temporalio.api.workflow.v1.message_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
@@ -543,14 +544,18 @@
     REQUEST_ID_FIELD_NUMBER: builtins.int
     WORKFLOW_ID_REUSE_POLICY_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
+    REQUEST_EAGER_EXECUTION_FIELD_NUMBER: builtins.int
+    CONTINUED_FAILURE_FIELD_NUMBER: builtins.int
+    LAST_COMPLETION_RESULT_FIELD_NUMBER: builtins.int
+    WORKFLOW_START_DELAY_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     workflow_id: builtins.str
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     @property
@@ -580,14 +585,37 @@
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
+    request_eager_execution: builtins.bool
+    """Request to get the first workflow task inline in the response bypassing matching service and worker polling.
+    If set to `true` the caller is expected to have a worker available and capable of processing the task.
+    The returned task will be marked as started and is expected to be completed by the specified
+    `workflow_task_timeout`.
+    """
+    @property
+    def continued_failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
+        """These values will be available as ContinuedFailure and LastCompletionResult in the
+        WorkflowExecutionStarted event and through SDKs. The are currently only used by the
+        server itself (for the schedules feature) and are not intended to be exposed in
+        StartWorkflowExecution.
+        """
+    @property
+    def last_completion_result(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.Payloads: ...
+    @property
+    def workflow_start_delay(self) -> google.protobuf.duration_pb2.Duration:
+        """Time to wait before dispatching the first workflow task. Cannot be used with `cron_schedule`.
+        If the workflow gets a signal before the delay, a workflow task will be dispatched and the rest
+        of the delay will be ignored.
+        """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
@@ -600,55 +628,72 @@
         workflow_id_reuse_policy: temporalio.api.enums.v1.workflow_pb2.WorkflowIdReusePolicy.ValueType = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         cron_schedule: builtins.str = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
+        request_eager_execution: builtins.bool = ...,
+        continued_failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
+        last_completion_result: temporalio.api.common.v1.message_pb2.Payloads
+        | None = ...,
+        workflow_start_delay: google.protobuf.duration_pb2.Duration | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
+            "continued_failure",
+            b"continued_failure",
             "header",
             b"header",
             "input",
             b"input",
+            "last_completion_result",
+            b"last_completion_result",
             "memo",
             b"memo",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
             b"task_queue",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_run_timeout",
             b"workflow_run_timeout",
+            "workflow_start_delay",
+            b"workflow_start_delay",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
+            "continued_failure",
+            b"continued_failure",
             "cron_schedule",
             b"cron_schedule",
             "header",
             b"header",
             "identity",
             b"identity",
             "input",
             b"input",
+            "last_completion_result",
+            b"last_completion_result",
             "memo",
             b"memo",
             "namespace",
             b"namespace",
+            "request_eager_execution",
+            b"request_eager_execution",
             "request_id",
             b"request_id",
             "retry_policy",
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "task_queue",
@@ -657,35 +702,54 @@
             b"workflow_execution_timeout",
             "workflow_id",
             b"workflow_id",
             "workflow_id_reuse_policy",
             b"workflow_id_reuse_policy",
             "workflow_run_timeout",
             b"workflow_run_timeout",
+            "workflow_start_delay",
+            b"workflow_start_delay",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
     ) -> None: ...
 
 global___StartWorkflowExecutionRequest = StartWorkflowExecutionRequest
 
 class StartWorkflowExecutionResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_ID_FIELD_NUMBER: builtins.int
+    EAGER_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     run_id: builtins.str
+    @property
+    def eager_workflow_task(self) -> global___PollWorkflowTaskQueueResponse:
+        """When `request_eager_execution` is set on the `StartWorkflowExecutionRequest`, the server - if supported - will
+        return the first workflow task to be eagerly executed.
+        The caller is expected to have a worker available to process the task.
+        """
     def __init__(
         self,
         *,
         run_id: builtins.str = ...,
+        eager_workflow_task: global___PollWorkflowTaskQueueResponse | None = ...,
     ) -> None: ...
+    def HasField(
+        self,
+        field_name: typing_extensions.Literal[
+            "eager_workflow_task", b"eager_workflow_task"
+        ],
+    ) -> builtins.bool: ...
     def ClearField(
-        self, field_name: typing_extensions.Literal["run_id", b"run_id"]
+        self,
+        field_name: typing_extensions.Literal[
+            "eager_workflow_task", b"eager_workflow_task", "run_id", b"run_id"
+        ],
     ) -> None: ...
 
 global___StartWorkflowExecutionResponse = StartWorkflowExecutionResponse
 
 class GetWorkflowExecutionHistoryRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
@@ -873,61 +937,66 @@
 class PollWorkflowTaskQueueRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
-    WORKER_VERSIONING_ID_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_CAPABILITIES_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     identity: builtins.str
     """The identity of the worker/client who is polling this task queue"""
     binary_checksum: builtins.str
     """Each worker process should provide an ID unique to the specific set of code it is running
     "checksum" in this field name isn't very accurate, it should be though of as an id.
     """
     @property
-    def worker_versioning_id(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """If set, the worker is opting in to build-id based versioning and wishes to only
-        receive tasks that are considered compatible with the version provided.
-        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdOrdering` API.
-        When `worker_versioning_id` has a `worker_build_id`, and `binary_checksum` is not
+    def worker_version_capabilities(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities:
+        """If set, the worker is opting in to versioning and wishes to only
+        receive tasks that are considered compatible with the version capabilities provided.
+        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
+        When this field has a `worker_build_id`, and `binary_checksum` is not
         set, that value should also be considered as the `binary_checksum`.
         """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         identity: builtins.str = ...,
         binary_checksum: builtins.str = ...,
-        worker_versioning_id: temporalio.api.taskqueue.v1.message_pb2.VersionId
+        worker_version_capabilities: temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities
         | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "task_queue", b"task_queue", "worker_versioning_id", b"worker_versioning_id"
+            "task_queue",
+            b"task_queue",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "binary_checksum",
             b"binary_checksum",
             "identity",
             b"identity",
             "namespace",
             b"namespace",
             "task_queue",
             b"task_queue",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> None: ...
 
 global___PollWorkflowTaskQueueRequest = PollWorkflowTaskQueueRequest
 
 class PollWorkflowTaskQueueResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -964,15 +1033,15 @@
     HISTORY_FIELD_NUMBER: builtins.int
     NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
     QUERY_FIELD_NUMBER: builtins.int
     WORKFLOW_EXECUTION_TASK_QUEUE_FIELD_NUMBER: builtins.int
     SCHEDULED_TIME_FIELD_NUMBER: builtins.int
     STARTED_TIME_FIELD_NUMBER: builtins.int
     QUERIES_FIELD_NUMBER: builtins.int
-    INTERACTIONS_FIELD_NUMBER: builtins.int
+    MESSAGES_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """A unique identifier for this task"""
     @property
     def workflow_execution(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkflowExecution: ...
     @property
@@ -1027,19 +1096,20 @@
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.query.v1.message_pb2.WorkflowQuery
     ]:
         """Queries that should be executed after applying the history in this task. Responses should be
         attached to `RespondWorkflowTaskCompletedRequest::query_results`
         """
     @property
-    def interactions(
+    def messages(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-        temporalio.api.interaction.v1.message_pb2.Invocation
-    ]: ...
+        temporalio.api.protocol.v1.message_pb2.Message
+    ]:
+        """Protocol messages piggybacking on a WFT as a transport"""
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         workflow_execution: temporalio.api.common.v1.message_pb2.WorkflowExecution
         | None = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
@@ -1054,16 +1124,16 @@
         | None = ...,
         scheduled_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         started_time: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         queries: collections.abc.Mapping[
             builtins.str, temporalio.api.query.v1.message_pb2.WorkflowQuery
         ]
         | None = ...,
-        interactions: collections.abc.Iterable[
-            temporalio.api.interaction.v1.message_pb2.Invocation
+        messages: collections.abc.Iterable[
+            temporalio.api.protocol.v1.message_pb2.Message
         ]
         | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "history",
@@ -1087,16 +1157,16 @@
         field_name: typing_extensions.Literal[
             "attempt",
             b"attempt",
             "backlog_count_hint",
             b"backlog_count_hint",
             "history",
             b"history",
-            "interactions",
-            b"interactions",
+            "messages",
+            b"messages",
             "next_page_token",
             b"next_page_token",
             "previous_started_event_id",
             b"previous_started_event_id",
             "queries",
             b"queries",
             "query",
@@ -1150,15 +1220,18 @@
     IDENTITY_FIELD_NUMBER: builtins.int
     STICKY_ATTRIBUTES_FIELD_NUMBER: builtins.int
     RETURN_NEW_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     FORCE_CREATE_NEW_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
     QUERY_RESULTS_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
-    WORKER_VERSIONING_ID_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_STAMP_FIELD_NUMBER: builtins.int
+    MESSAGES_FIELD_NUMBER: builtins.int
+    SDK_METADATA_FIELD_NUMBER: builtins.int
+    METERING_METADATA_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollWorkflowTaskQueueResponse`"""
     @property
     def commands(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.command.v1.message_pb2.Command
@@ -1190,20 +1263,42 @@
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.query.v1.message_pb2.WorkflowQueryResult
     ]:
         """Responses to the `queries` field in the task being responded to"""
     namespace: builtins.str
     @property
-    def worker_versioning_id(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """If using versioning, worker should send the same id here that it used to
-        poll for the workflow task.
-        When `worker_versioning_id` has a `worker_build_id`, and `binary_checksum` is not
-        set, that value should also be considered as the `binary_checksum`.
+    def worker_version_stamp(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionStamp:
+        """If using versioning, the worker uses this field to indicate what version(s) it used to
+        process the task. When this field has a `worker_build_id`, and `binary_checksum` is not set,
+        that value should also be considered as the `binary_checksum`. Leaving this field empty when
+        replying to a task has had this field previously populated in history in an error, and such
+        a completion will be rejected.
         """
+    @property
+    def messages(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        temporalio.api.protocol.v1.message_pb2.Message
+    ]:
+        """Protocol messages piggybacking on a WFT as a transport"""
+    @property
+    def sdk_metadata(
+        self,
+    ) -> temporalio.api.sdk.v1.task_complete_metadata_pb2.WorkflowTaskCompletedMetadata:
+        """Data the SDK wishes to record for itself, but server need not interpret, and does not
+        directly impact workflow state.
+        """
+    @property
+    def metering_metadata(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.MeteringMetadata:
+        """Local usage data collected for metering"""
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         commands: collections.abc.Iterable[
             temporalio.api.command.v1.message_pb2.Command
         ]
@@ -1215,49 +1310,67 @@
         force_create_new_workflow_task: builtins.bool = ...,
         binary_checksum: builtins.str = ...,
         query_results: collections.abc.Mapping[
             builtins.str, temporalio.api.query.v1.message_pb2.WorkflowQueryResult
         ]
         | None = ...,
         namespace: builtins.str = ...,
-        worker_versioning_id: temporalio.api.taskqueue.v1.message_pb2.VersionId
+        worker_version_stamp: temporalio.api.common.v1.message_pb2.WorkerVersionStamp
+        | None = ...,
+        messages: collections.abc.Iterable[
+            temporalio.api.protocol.v1.message_pb2.Message
+        ]
+        | None = ...,
+        sdk_metadata: temporalio.api.sdk.v1.task_complete_metadata_pb2.WorkflowTaskCompletedMetadata
+        | None = ...,
+        metering_metadata: temporalio.api.common.v1.message_pb2.MeteringMetadata
         | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
+            "metering_metadata",
+            b"metering_metadata",
+            "sdk_metadata",
+            b"sdk_metadata",
             "sticky_attributes",
             b"sticky_attributes",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_stamp",
+            b"worker_version_stamp",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "binary_checksum",
             b"binary_checksum",
             "commands",
             b"commands",
             "force_create_new_workflow_task",
             b"force_create_new_workflow_task",
             "identity",
             b"identity",
+            "messages",
+            b"messages",
+            "metering_metadata",
+            b"metering_metadata",
             "namespace",
             b"namespace",
             "query_results",
             b"query_results",
             "return_new_workflow_task",
             b"return_new_workflow_task",
+            "sdk_metadata",
+            b"sdk_metadata",
             "sticky_attributes",
             b"sticky_attributes",
             "task_token",
             b"task_token",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_stamp",
+            b"worker_version_stamp",
         ],
     ) -> None: ...
 
 global___RespondWorkflowTaskCompletedRequest = RespondWorkflowTaskCompletedRequest
 
 class RespondWorkflowTaskCompletedResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -1306,37 +1419,49 @@
 
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     CAUSE_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     BINARY_CHECKSUM_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
+    MESSAGES_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
     """The task token as received in `PollWorkflowTaskQueueResponse`"""
     cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType
     """Why did the task fail? It's important to note that many of the variants in this enum cannot
     apply to worker responses. See the type's doc for more.
     """
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
         """Failure details"""
     identity: builtins.str
     """The identity of the worker/client"""
     binary_checksum: builtins.str
     """Worker process' unique binary id"""
     namespace: builtins.str
+    @property
+    def messages(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        temporalio.api.protocol.v1.message_pb2.Message
+    ]:
+        """Protocol messages piggybacking on a WFT as a transport"""
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
         identity: builtins.str = ...,
         binary_checksum: builtins.str = ...,
         namespace: builtins.str = ...,
+        messages: collections.abc.Iterable[
+            temporalio.api.protocol.v1.message_pb2.Message
+        ]
+        | None = ...,
     ) -> None: ...
     def HasField(
         self, field_name: typing_extensions.Literal["failure", b"failure"]
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
@@ -1344,14 +1469,16 @@
             b"binary_checksum",
             "cause",
             b"cause",
             "failure",
             b"failure",
             "identity",
             b"identity",
+            "messages",
+            b"messages",
             "namespace",
             b"namespace",
             "task_token",
             b"task_token",
         ],
     ) -> None: ...
 
@@ -1369,65 +1496,67 @@
 class PollActivityTaskQueueRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     TASK_QUEUE_METADATA_FIELD_NUMBER: builtins.int
-    WORKER_VERSIONING_ID_FIELD_NUMBER: builtins.int
+    WORKER_VERSION_CAPABILITIES_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue: ...
     identity: builtins.str
     """The identity of the worker/client"""
     @property
     def task_queue_metadata(
         self,
     ) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueueMetadata: ...
     @property
-    def worker_versioning_id(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """If set, the worker is opting in to build-id based versioning and wishes to only
-        receive tasks that are considered compatible with the version provided.
-        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdOrdering` API.
+    def worker_version_capabilities(
+        self,
+    ) -> temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities:
+        """If set, the worker is opting in to versioning and wishes to only
+        receive tasks that are considered compatible with the capabilities provided.
+        Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
         """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
         identity: builtins.str = ...,
         task_queue_metadata: temporalio.api.taskqueue.v1.message_pb2.TaskQueueMetadata
         | None = ...,
-        worker_versioning_id: temporalio.api.taskqueue.v1.message_pb2.VersionId
+        worker_version_capabilities: temporalio.api.common.v1.message_pb2.WorkerVersionCapabilities
         | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "task_queue",
             b"task_queue",
             "task_queue_metadata",
             b"task_queue_metadata",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "identity",
             b"identity",
             "namespace",
             b"namespace",
             "task_queue",
             b"task_queue",
             "task_queue_metadata",
             b"task_queue_metadata",
-            "worker_versioning_id",
-            b"worker_versioning_id",
+            "worker_version_capabilities",
+            b"worker_version_capabilities",
         ],
     ) -> None: ...
 
 global___PollActivityTaskQueueRequest = PollActivityTaskQueueRequest
 
 class PollActivityTaskQueueResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -2237,14 +2366,15 @@
     WORKFLOW_EXECUTION_FIELD_NUMBER: builtins.int
     SIGNAL_NAME_FIELD_NUMBER: builtins.int
     INPUT_FIELD_NUMBER: builtins.int
     IDENTITY_FIELD_NUMBER: builtins.int
     REQUEST_ID_FIELD_NUMBER: builtins.int
     CONTROL_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
+    SKIP_GENERATE_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     @property
     def workflow_execution(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkflowExecution: ...
     signal_name: builtins.str
     """The workflow author-defined name of the signal to send to the workflow"""
@@ -2258,26 +2388,29 @@
     control: builtins.str
     """Deprecated"""
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header:
         """Headers that are passed with the signal to the processing workflow.
         These can include things like auth or tracing tokens.
         """
+    skip_generate_workflow_task: builtins.bool
+    """Indicates that a new workflow task should not be generated when this signal is received."""
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         workflow_execution: temporalio.api.common.v1.message_pb2.WorkflowExecution
         | None = ...,
         signal_name: builtins.str = ...,
         input: temporalio.api.common.v1.message_pb2.Payloads | None = ...,
         identity: builtins.str = ...,
         request_id: builtins.str = ...,
         control: builtins.str = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
+        skip_generate_workflow_task: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "header",
             b"header",
             "input",
@@ -2299,14 +2432,16 @@
             b"input",
             "namespace",
             b"namespace",
             "request_id",
             b"request_id",
             "signal_name",
             b"signal_name",
+            "skip_generate_workflow_task",
+            b"skip_generate_workflow_task",
             "workflow_execution",
             b"workflow_execution",
         ],
     ) -> None: ...
 
 global___SignalWorkflowExecutionRequest = SignalWorkflowExecutionRequest
 
@@ -2337,14 +2472,16 @@
     SIGNAL_INPUT_FIELD_NUMBER: builtins.int
     CONTROL_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     HEADER_FIELD_NUMBER: builtins.int
+    WORKFLOW_START_DELAY_FIELD_NUMBER: builtins.int
+    SKIP_GENERATE_WORKFLOW_TASK_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     workflow_id: builtins.str
     @property
     def workflow_type(self) -> temporalio.api.common.v1.message_pb2.WorkflowType: ...
     @property
     def task_queue(self) -> temporalio.api.taskqueue.v1.message_pb2.TaskQueue:
         """The task queue to start this workflow on, if it will be started"""
@@ -2381,14 +2518,25 @@
     def memo(self) -> temporalio.api.common.v1.message_pb2.Memo: ...
     @property
     def search_attributes(
         self,
     ) -> temporalio.api.common.v1.message_pb2.SearchAttributes: ...
     @property
     def header(self) -> temporalio.api.common.v1.message_pb2.Header: ...
+    @property
+    def workflow_start_delay(self) -> google.protobuf.duration_pb2.Duration:
+        """Time to wait before dispatching the first workflow task. Cannot be used with `cron_schedule`.
+        Note that the signal will be delivered with the first workflow task. If the workflow gets
+        another SignalWithStartWorkflow before the delay and `skip_generate_workflow_task` is false
+        or not set, a workflow task will be dispatched immediately and the rest of the delay period
+        will be ignored, even if that request also had a delay. Signal via SignalWorkflowExecution
+        will not unblock the workflow.
+        """
+    skip_generate_workflow_task: builtins.bool
+    """Indicates that a new workflow task should not be generated when this signal is received."""
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: temporalio.api.common.v1.message_pb2.WorkflowType | None = ...,
         task_queue: temporalio.api.taskqueue.v1.message_pb2.TaskQueue | None = ...,
@@ -2404,14 +2552,16 @@
         control: builtins.str = ...,
         retry_policy: temporalio.api.common.v1.message_pb2.RetryPolicy | None = ...,
         cron_schedule: builtins.str = ...,
         memo: temporalio.api.common.v1.message_pb2.Memo | None = ...,
         search_attributes: temporalio.api.common.v1.message_pb2.SearchAttributes
         | None = ...,
         header: temporalio.api.common.v1.message_pb2.Header | None = ...,
+        workflow_start_delay: google.protobuf.duration_pb2.Duration | None = ...,
+        skip_generate_workflow_task: builtins.bool = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
             "header",
             b"header",
             "input",
@@ -2426,14 +2576,16 @@
             b"signal_input",
             "task_queue",
             b"task_queue",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_run_timeout",
             b"workflow_run_timeout",
+            "workflow_start_delay",
+            b"workflow_start_delay",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
     ) -> builtins.bool: ...
     def ClearField(
@@ -2459,24 +2611,28 @@
             b"retry_policy",
             "search_attributes",
             b"search_attributes",
             "signal_input",
             b"signal_input",
             "signal_name",
             b"signal_name",
+            "skip_generate_workflow_task",
+            b"skip_generate_workflow_task",
             "task_queue",
             b"task_queue",
             "workflow_execution_timeout",
             b"workflow_execution_timeout",
             "workflow_id",
             b"workflow_id",
             "workflow_id_reuse_policy",
             b"workflow_id_reuse_policy",
             "workflow_run_timeout",
             b"workflow_run_timeout",
+            "workflow_start_delay",
+            b"workflow_start_delay",
             "workflow_task_timeout",
             b"workflow_task_timeout",
             "workflow_type",
             b"workflow_type",
         ],
     ) -> None: ...
 
@@ -3665,14 +3821,16 @@
         SIGNAL_AND_QUERY_HEADER_FIELD_NUMBER: builtins.int
         INTERNAL_ERROR_DIFFERENTIATION_FIELD_NUMBER: builtins.int
         ACTIVITY_FAILURE_INCLUDE_HEARTBEAT_FIELD_NUMBER: builtins.int
         SUPPORTS_SCHEDULES_FIELD_NUMBER: builtins.int
         ENCODED_FAILURE_ATTRIBUTES_FIELD_NUMBER: builtins.int
         BUILD_ID_BASED_VERSIONING_FIELD_NUMBER: builtins.int
         UPSERT_MEMO_FIELD_NUMBER: builtins.int
+        EAGER_WORKFLOW_START_FIELD_NUMBER: builtins.int
+        SDK_METADATA_FIELD_NUMBER: builtins.int
         signal_and_query_header: builtins.bool
         """True if signal and query headers are supported."""
         internal_error_differentiation: builtins.bool
         """True if internal errors are differentiated from other types of errors for purposes of
         retrying non-internal errors.
 
         When unset/false, clients retry all failures. When true, clients should only retry
@@ -3687,36 +3845,48 @@
         build_id_based_versioning: builtins.bool
         """True if server supports dispatching Workflow and Activity tasks based on a worker's build_id
         (see:
         https://github.com/temporalio/proposals/blob/a123af3b559f43db16ea6dd31870bfb754c4dc5e/versioning/worker-versions.md)
         """
         upsert_memo: builtins.bool
         """True if server supports upserting workflow memo"""
+        eager_workflow_start: builtins.bool
+        """True if server supports eager workflow task dispatching for the StartWorkflowExecution API"""
+        sdk_metadata: builtins.bool
+        """True if the server knows about the sdk metadata field on WFT completions and will record
+        it in history
+        """
         def __init__(
             self,
             *,
             signal_and_query_header: builtins.bool = ...,
             internal_error_differentiation: builtins.bool = ...,
             activity_failure_include_heartbeat: builtins.bool = ...,
             supports_schedules: builtins.bool = ...,
             encoded_failure_attributes: builtins.bool = ...,
             build_id_based_versioning: builtins.bool = ...,
             upsert_memo: builtins.bool = ...,
+            eager_workflow_start: builtins.bool = ...,
+            sdk_metadata: builtins.bool = ...,
         ) -> None: ...
         def ClearField(
             self,
             field_name: typing_extensions.Literal[
                 "activity_failure_include_heartbeat",
                 b"activity_failure_include_heartbeat",
                 "build_id_based_versioning",
                 b"build_id_based_versioning",
+                "eager_workflow_start",
+                b"eager_workflow_start",
                 "encoded_failure_attributes",
                 b"encoded_failure_attributes",
                 "internal_error_differentiation",
                 b"internal_error_differentiation",
+                "sdk_metadata",
+                b"sdk_metadata",
                 "signal_and_query_header",
                 b"signal_and_query_header",
                 "supports_schedules",
                 b"supports_schedules",
                 "upsert_memo",
                 b"upsert_memo",
             ],
@@ -4327,196 +4497,384 @@
         field_name: typing_extensions.Literal[
             "next_page_token", b"next_page_token", "schedules", b"schedules"
         ],
     ) -> None: ...
 
 global___ListSchedulesResponse = ListSchedulesResponse
 
-class UpdateWorkerBuildIdOrderingRequest(google.protobuf.message.Message):
+class UpdateWorkerBuildIdCompatibilityRequest(google.protobuf.message.Message):
     """(-- api-linter: core::0134::request-mask-required=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrderingRequest doesn't follow Google API format --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibilityRequest doesn't follow Google API format --)
     (-- api-linter: core::0134::request-resource-required=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrderingRequest RPC doesn't follow Google API format. --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibilityRequest RPC doesn't follow Google API format. --)
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
+    class AddNewCompatibleVersion(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        NEW_BUILD_ID_FIELD_NUMBER: builtins.int
+        EXISTING_COMPATIBLE_BUILD_ID_FIELD_NUMBER: builtins.int
+        MAKE_SET_DEFAULT_FIELD_NUMBER: builtins.int
+        new_build_id: builtins.str
+        """A new id to be added to an existing compatible set."""
+        existing_compatible_build_id: builtins.str
+        """A build id which must already exist in the version sets known by the task queue. The new
+        id will be stored in the set containing this id, marking it as compatible with
+        the versions within.
+        """
+        make_set_default: builtins.bool
+        """When set, establishes the compatible set being targeted as the overall default for the
+        queue. If a different set was the current default, the targeted set will replace it as
+        the new default.
+        """
+        def __init__(
+            self,
+            *,
+            new_build_id: builtins.str = ...,
+            existing_compatible_build_id: builtins.str = ...,
+            make_set_default: builtins.bool = ...,
+        ) -> None: ...
+        def ClearField(
+            self,
+            field_name: typing_extensions.Literal[
+                "existing_compatible_build_id",
+                b"existing_compatible_build_id",
+                "make_set_default",
+                b"make_set_default",
+                "new_build_id",
+                b"new_build_id",
+            ],
+        ) -> None: ...
+
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
-    VERSION_ID_FIELD_NUMBER: builtins.int
-    PREVIOUS_COMPATIBLE_FIELD_NUMBER: builtins.int
-    BECOME_DEFAULT_FIELD_NUMBER: builtins.int
+    ADD_NEW_BUILD_ID_IN_NEW_DEFAULT_SET_FIELD_NUMBER: builtins.int
+    ADD_NEW_COMPATIBLE_BUILD_ID_FIELD_NUMBER: builtins.int
+    PROMOTE_SET_BY_BUILD_ID_FIELD_NUMBER: builtins.int
+    PROMOTE_BUILD_ID_WITHIN_SET_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     task_queue: builtins.str
-    """Must be set, the task queue to apply changes to. Because all workers on
-    a given task queue must have the same set of workflow & activity
-    implementations, there is no reason to specify a task queue type here.
+    """Must be set, the task queue to apply changes to. Because all workers on a given task queue
+    must have the same set of workflow & activity implementations, there is no reason to specify
+    a task queue type here.
+    """
+    add_new_build_id_in_new_default_set: builtins.str
+    """A new build id. This operation will create a new set which will be the new overall
+    default version for the queue, with this id as its only member. This new set is
+    incompatible with all previous sets/versions.
+
+    (-- api-linter: core::0140::prepositions=disabled
+        aip.dev/not-precedent: In makes perfect sense here. --)
     """
     @property
-    def version_id(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """The version id we are targeting."""
-    @property
-    def previous_compatible(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionId:
-        """When set, indicates that the `version_id` in this message is compatible
-        with the one specified in this field. Because compatability should form
-        a DAG, any build id can only be the "next compatible" version for one
-        other ID of a certain type at a time, and any setting which would create a cycle is invalid.
-        """
-    become_default: builtins.bool
-    """When set, establishes the specified `version_id` as the default of it's type
-    for the queue. Workers matching it will begin processing new workflow executions.
-    The existing default will be marked as a previous incompatible version
-    to this one, assuming it is not also in `is_compatible_with`.
+    def add_new_compatible_build_id(
+        self,
+    ) -> global___UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion:
+        """Adds a new id to an existing compatible set, see sub-message definition for more."""
+    promote_set_by_build_id: builtins.str
+    """Promote an existing set to be the current default (if it isn't already) by targeting
+    an existing build id within it. This field's value is the extant build id.
+
+    (-- api-linter: core::0140::prepositions=disabled
+        aip.dev/not-precedent: Names are hard. --)
+    """
+    promote_build_id_within_set: builtins.str
+    """Promote an existing build id within some set to be the current default for that set.
+
+    (-- api-linter: core::0140::prepositions=disabled
+        aip.dev/not-precedent: Within makes perfect sense here. --)
     """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: builtins.str = ...,
-        version_id: temporalio.api.taskqueue.v1.message_pb2.VersionId | None = ...,
-        previous_compatible: temporalio.api.taskqueue.v1.message_pb2.VersionId
+        add_new_build_id_in_new_default_set: builtins.str = ...,
+        add_new_compatible_build_id: global___UpdateWorkerBuildIdCompatibilityRequest.AddNewCompatibleVersion
         | None = ...,
-        become_default: builtins.bool = ...,
+        promote_set_by_build_id: builtins.str = ...,
+        promote_build_id_within_set: builtins.str = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "previous_compatible", b"previous_compatible", "version_id", b"version_id"
+            "add_new_build_id_in_new_default_set",
+            b"add_new_build_id_in_new_default_set",
+            "add_new_compatible_build_id",
+            b"add_new_compatible_build_id",
+            "operation",
+            b"operation",
+            "promote_build_id_within_set",
+            b"promote_build_id_within_set",
+            "promote_set_by_build_id",
+            b"promote_set_by_build_id",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "become_default",
-            b"become_default",
+            "add_new_build_id_in_new_default_set",
+            b"add_new_build_id_in_new_default_set",
+            "add_new_compatible_build_id",
+            b"add_new_compatible_build_id",
             "namespace",
             b"namespace",
-            "previous_compatible",
-            b"previous_compatible",
+            "operation",
+            b"operation",
+            "promote_build_id_within_set",
+            b"promote_build_id_within_set",
+            "promote_set_by_build_id",
+            b"promote_set_by_build_id",
             "task_queue",
             b"task_queue",
-            "version_id",
-            b"version_id",
         ],
     ) -> None: ...
+    def WhichOneof(
+        self, oneof_group: typing_extensions.Literal["operation", b"operation"]
+    ) -> (
+        typing_extensions.Literal[
+            "add_new_build_id_in_new_default_set",
+            "add_new_compatible_build_id",
+            "promote_set_by_build_id",
+            "promote_build_id_within_set",
+        ]
+        | None
+    ): ...
 
-global___UpdateWorkerBuildIdOrderingRequest = UpdateWorkerBuildIdOrderingRequest
+global___UpdateWorkerBuildIdCompatibilityRequest = (
+    UpdateWorkerBuildIdCompatibilityRequest
+)
 
-class UpdateWorkerBuildIdOrderingResponse(google.protobuf.message.Message):
+class UpdateWorkerBuildIdCompatibilityResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
+    VERSION_SET_ID_FIELD_NUMBER: builtins.int
+    version_set_id: builtins.str
+    """The id of the compatible set that the updated version was added to, or exists in. Users don't
+    need to understand or care about this value, but it has value for debugging purposes.
+    """
     def __init__(
         self,
+        *,
+        version_set_id: builtins.str = ...,
+    ) -> None: ...
+    def ClearField(
+        self, field_name: typing_extensions.Literal["version_set_id", b"version_set_id"]
     ) -> None: ...
 
-global___UpdateWorkerBuildIdOrderingResponse = UpdateWorkerBuildIdOrderingResponse
+global___UpdateWorkerBuildIdCompatibilityResponse = (
+    UpdateWorkerBuildIdCompatibilityResponse
+)
 
-class GetWorkerBuildIdOrderingRequest(google.protobuf.message.Message):
+class GetWorkerBuildIdCompatibilityRequest(google.protobuf.message.Message):
     """(-- api-linter: core::0134::request-resource-required=disabled
-    aip.dev/not-precedent: GetWorkerBuildIdOrderingRequest RPC doesn't follow Google API format. --)
+    aip.dev/not-precedent: GetWorkerBuildIdCompatibilityRequest RPC doesn't follow Google API format. --)
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMESPACE_FIELD_NUMBER: builtins.int
     TASK_QUEUE_FIELD_NUMBER: builtins.int
-    MAX_DEPTH_FIELD_NUMBER: builtins.int
+    MAX_SETS_FIELD_NUMBER: builtins.int
+    INCLUDE_RETIREMENT_CANDIDATES_FIELD_NUMBER: builtins.int
+    INCLUDE_POLLER_COMPATIBILITY_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     task_queue: builtins.str
-    """Must be set, the task queue to interrogate about worker id ordering"""
-    max_depth: builtins.int
-    """Limits how deep the returned DAG will go. 1 will return only the
-    default build id. A default/0 value will return the entire graph.
+    """Must be set, the task queue to interrogate about worker id compatibility."""
+    max_sets: builtins.int
+    """Limits how many compatible sets will be returned. Specify 1 to only return the current
+    default major version set. 0 returns all sets.
+    """
+    include_retirement_candidates: builtins.bool
+    """If set, the response will include information about worker versions which are ready to be
+    retired.
+    """
+    include_poller_compatibility: builtins.bool
+    """If set, the response will include information about which versions have open workflows, and
+    whether or not there are currently polling workers who are compatible with those versions.
     """
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         task_queue: builtins.str = ...,
-        max_depth: builtins.int = ...,
+        max_sets: builtins.int = ...,
+        include_retirement_candidates: builtins.bool = ...,
+        include_poller_compatibility: builtins.bool = ...,
     ) -> None: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "max_depth",
-            b"max_depth",
+            "include_poller_compatibility",
+            b"include_poller_compatibility",
+            "include_retirement_candidates",
+            b"include_retirement_candidates",
+            "max_sets",
+            b"max_sets",
             "namespace",
             b"namespace",
             "task_queue",
             b"task_queue",
         ],
     ) -> None: ...
 
-global___GetWorkerBuildIdOrderingRequest = GetWorkerBuildIdOrderingRequest
+global___GetWorkerBuildIdCompatibilityRequest = GetWorkerBuildIdCompatibilityRequest
 
-class GetWorkerBuildIdOrderingResponse(google.protobuf.message.Message):
+class GetWorkerBuildIdCompatibilityResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    CURRENT_DEFAULT_FIELD_NUMBER: builtins.int
-    COMPATIBLE_LEAVES_FIELD_NUMBER: builtins.int
+    class RetirementCandidate(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        BUILD_ID_FIELD_NUMBER: builtins.int
+        ALL_WORKFLOWS_ARE_ARCHIVED_FIELD_NUMBER: builtins.int
+        POLLERS_FIELD_NUMBER: builtins.int
+        build_id: builtins.str
+        """The worker build id which is ready for retirement"""
+        all_workflows_are_archived: builtins.bool
+        """If true, there are no open *or* closed workflows, meaning there is no reason at all
+        to keep the worker alive, not even to service queries on closed workflows. If not true,
+        then there are no open workflows, but some closed ones.
+        """
+        @property
+        def pollers(
+            self,
+        ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+            temporalio.api.taskqueue.v1.message_pb2.PollerInfo
+        ]:
+            """Currently polling workers who match the build id ready for retirement"""
+        def __init__(
+            self,
+            *,
+            build_id: builtins.str = ...,
+            all_workflows_are_archived: builtins.bool = ...,
+            pollers: collections.abc.Iterable[
+                temporalio.api.taskqueue.v1.message_pb2.PollerInfo
+            ]
+            | None = ...,
+        ) -> None: ...
+        def ClearField(
+            self,
+            field_name: typing_extensions.Literal[
+                "all_workflows_are_archived",
+                b"all_workflows_are_archived",
+                "build_id",
+                b"build_id",
+                "pollers",
+                b"pollers",
+            ],
+        ) -> None: ...
+
+    class VersionsWithCompatiblePollers(google.protobuf.message.Message):
+        DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+        MOST_RECENT_BUILD_ID_FIELD_NUMBER: builtins.int
+        POLLERS_FIELD_NUMBER: builtins.int
+        most_recent_build_id: builtins.str
+        """The latest build id which completed a workflow task on some open workflow"""
+        @property
+        def pollers(
+            self,
+        ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+            temporalio.api.taskqueue.v1.message_pb2.PollerInfo
+        ]:
+            """Currently polling workers who are compatible with `most_recent_build_id`."""
+        def __init__(
+            self,
+            *,
+            most_recent_build_id: builtins.str = ...,
+            pollers: collections.abc.Iterable[
+                temporalio.api.taskqueue.v1.message_pb2.PollerInfo
+            ]
+            | None = ...,
+        ) -> None: ...
+        def ClearField(
+            self,
+            field_name: typing_extensions.Literal[
+                "most_recent_build_id", b"most_recent_build_id", "pollers", b"pollers"
+            ],
+        ) -> None: ...
+
+    MAJOR_VERSION_SETS_FIELD_NUMBER: builtins.int
+    RETIREMENT_CANDIDATES_FIELD_NUMBER: builtins.int
+    ACTIVE_VERSIONS_AND_POLLERS_FIELD_NUMBER: builtins.int
     @property
-    def current_default(self) -> temporalio.api.taskqueue.v1.message_pb2.VersionIdNode:
-        """The currently established default version"""
+    def major_version_sets(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        temporalio.api.taskqueue.v1.message_pb2.CompatibleVersionSet
+    ]:
+        """Major version sets, in order from oldest to newest. The last element of the list will always
+        be the current default major version. IE: New workflows will target the most recent version
+        in that version set.
+
+        There may be fewer sets returned than exist, if the request chose to limit this response.
+        """
+    @property
+    def retirement_candidates(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        global___GetWorkerBuildIdCompatibilityResponse.RetirementCandidate
+    ]:
+        """A list of workers who are still live and polling the task queue, but may no longer be needed
+        to make progress on open workflows.
+        """
     @property
-    def compatible_leaves(
+    def active_versions_and_pollers(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
-        temporalio.api.taskqueue.v1.message_pb2.VersionIdNode
+        global___GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
     ]:
-        """Other current latest-compatible versions who are not the overall default. These are the
-        versions that will be used when generating new tasks by following the graph from the
-        version of the last task out to a leaf.
+        """A list of versions and pollers who are capable of processing tasks at that version (if any)
+        for which there are currently open workflows.
         """
     def __init__(
         self,
         *,
-        current_default: temporalio.api.taskqueue.v1.message_pb2.VersionIdNode
+        major_version_sets: collections.abc.Iterable[
+            temporalio.api.taskqueue.v1.message_pb2.CompatibleVersionSet
+        ]
+        | None = ...,
+        retirement_candidates: collections.abc.Iterable[
+            global___GetWorkerBuildIdCompatibilityResponse.RetirementCandidate
+        ]
         | None = ...,
-        compatible_leaves: collections.abc.Iterable[
-            temporalio.api.taskqueue.v1.message_pb2.VersionIdNode
+        active_versions_and_pollers: collections.abc.Iterable[
+            global___GetWorkerBuildIdCompatibilityResponse.VersionsWithCompatiblePollers
         ]
         | None = ...,
     ) -> None: ...
-    def HasField(
-        self,
-        field_name: typing_extensions.Literal["current_default", b"current_default"],
-    ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "compatible_leaves",
-            b"compatible_leaves",
-            "current_default",
-            b"current_default",
+            "active_versions_and_pollers",
+            b"active_versions_and_pollers",
+            "major_version_sets",
+            b"major_version_sets",
+            "retirement_candidates",
+            b"retirement_candidates",
         ],
     ) -> None: ...
 
-global___GetWorkerBuildIdOrderingResponse = GetWorkerBuildIdOrderingResponse
+global___GetWorkerBuildIdCompatibilityResponse = GetWorkerBuildIdCompatibilityResponse
 
-class UpdateWorkflowRequest(google.protobuf.message.Message):
+class UpdateWorkflowExecutionRequest(google.protobuf.message.Message):
     """(-- api-linter: core::0134=disabled
     aip.dev/not-precedent: Update RPCs don't follow Google API format. --)
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    REQUEST_ID_FIELD_NUMBER: builtins.int
-    RESULT_ACCESS_STYLE_FIELD_NUMBER: builtins.int
     NAMESPACE_FIELD_NUMBER: builtins.int
     WORKFLOW_EXECUTION_FIELD_NUMBER: builtins.int
     FIRST_EXECUTION_RUN_ID_FIELD_NUMBER: builtins.int
-    IDENTITY_FIELD_NUMBER: builtins.int
-    INPUT_FIELD_NUMBER: builtins.int
-    request_id: builtins.str
-    """A unique ID for this logical request"""
-    result_access_style: temporalio.api.enums.v1.update_pb2.WorkflowUpdateResultAccessStyle.ValueType
-    """The manner in which the update result will be accessed.
-    This field requires a non-default value; the default value of the enum
-    will result in an error.
-    """
+    WAIT_POLICY_FIELD_NUMBER: builtins.int
+    REQUEST_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     """The namespace name of the target workflow"""
     @property
     def workflow_execution(
         self,
     ) -> temporalio.api.common.v1.message_pb2.WorkflowExecution:
         """The target workflow id and (optionally) a specific run thereof
@@ -4524,111 +4882,130 @@
             aip.dev/not-precedent: false positive triggered by the word "optional" --)
         """
     first_execution_run_id: builtins.str
     """If set, this call will error if the most recent (if no run id is set on
     `workflow_execution`), or specified (if it is) workflow execution is not
     part of the same execution chain as this id.
     """
-    identity: builtins.str
-    """A string identifying the agent that requested this interaction."""
     @property
-    def input(self) -> temporalio.api.interaction.v1.message_pb2.Input:
-        """The name under which the workflow update function is registered and the
-        arguments to pass to said function.
+    def wait_policy(self) -> temporalio.api.update.v1.message_pb2.WaitPolicy:
+        """Describes when this request should return - basically whether the
+        update is synchronous, asynchronous, or somewhere in between.
+        """
+    @property
+    def request(self) -> temporalio.api.update.v1.message_pb2.Request:
+        """The request information that will be delivered all the way down to the
+        workflow execution.
         """
     def __init__(
         self,
         *,
-        request_id: builtins.str = ...,
-        result_access_style: temporalio.api.enums.v1.update_pb2.WorkflowUpdateResultAccessStyle.ValueType = ...,
         namespace: builtins.str = ...,
         workflow_execution: temporalio.api.common.v1.message_pb2.WorkflowExecution
         | None = ...,
         first_execution_run_id: builtins.str = ...,
-        identity: builtins.str = ...,
-        input: temporalio.api.interaction.v1.message_pb2.Input | None = ...,
+        wait_policy: temporalio.api.update.v1.message_pb2.WaitPolicy | None = ...,
+        request: temporalio.api.update.v1.message_pb2.Request | None = ...,
     ) -> None: ...
     def HasField(
         self,
         field_name: typing_extensions.Literal[
-            "input", b"input", "workflow_execution", b"workflow_execution"
+            "request",
+            b"request",
+            "wait_policy",
+            b"wait_policy",
+            "workflow_execution",
+            b"workflow_execution",
         ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "first_execution_run_id",
             b"first_execution_run_id",
-            "identity",
-            b"identity",
-            "input",
-            b"input",
             "namespace",
             b"namespace",
-            "request_id",
-            b"request_id",
-            "result_access_style",
-            b"result_access_style",
+            "request",
+            b"request",
+            "wait_policy",
+            b"wait_policy",
             "workflow_execution",
             b"workflow_execution",
         ],
     ) -> None: ...
 
-global___UpdateWorkflowRequest = UpdateWorkflowRequest
+global___UpdateWorkflowExecutionRequest = UpdateWorkflowExecutionRequest
 
-class UpdateWorkflowResponse(google.protobuf.message.Message):
+class UpdateWorkflowExecutionResponse(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
-    UPDATE_TOKEN_FIELD_NUMBER: builtins.int
-    OUTPUT_FIELD_NUMBER: builtins.int
-    update_token: builtins.bytes
-    """An opaque token that can be used to retrieve the update result via
-    polling if it is not returned as part of the gRPC response
-    """
+    UPDATE_REF_FIELD_NUMBER: builtins.int
+    OUTCOME_FIELD_NUMBER: builtins.int
+    @property
+    def update_ref(self) -> temporalio.api.update.v1.message_pb2.UpdateRef:
+        """Enough information for subsequent poll calls if needed. Never null."""
     @property
-    def output(self) -> temporalio.api.interaction.v1.message_pb2.Output:
-        """The success or failure status of the update"""
+    def outcome(self) -> temporalio.api.update.v1.message_pb2.Outcome:
+        """The outcome of the update if and only if the workflow execution update
+        has completed. If this response is being returned before the update has
+        completed then this field will not be set.
+        """
     def __init__(
         self,
         *,
-        update_token: builtins.bytes = ...,
-        output: temporalio.api.interaction.v1.message_pb2.Output | None = ...,
+        update_ref: temporalio.api.update.v1.message_pb2.UpdateRef | None = ...,
+        outcome: temporalio.api.update.v1.message_pb2.Outcome | None = ...,
     ) -> None: ...
     def HasField(
-        self, field_name: typing_extensions.Literal["output", b"output"]
+        self,
+        field_name: typing_extensions.Literal[
+            "outcome", b"outcome", "update_ref", b"update_ref"
+        ],
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
-            "output", b"output", "update_token", b"update_token"
+            "outcome", b"outcome", "update_ref", b"update_ref"
         ],
     ) -> None: ...
 
-global___UpdateWorkflowResponse = UpdateWorkflowResponse
+global___UpdateWorkflowExecutionResponse = UpdateWorkflowExecutionResponse
 
 class StartBatchOperationRequest(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     NAMESPACE_FIELD_NUMBER: builtins.int
     VISIBILITY_QUERY_FIELD_NUMBER: builtins.int
     JOB_ID_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
+    EXECUTIONS_FIELD_NUMBER: builtins.int
     TERMINATION_OPERATION_FIELD_NUMBER: builtins.int
     SIGNAL_OPERATION_FIELD_NUMBER: builtins.int
     CANCELLATION_OPERATION_FIELD_NUMBER: builtins.int
     DELETION_OPERATION_FIELD_NUMBER: builtins.int
     namespace: builtins.str
     """Namespace that contains the batch operation"""
     visibility_query: builtins.str
-    """Visibility query defines the the group of workflow to do batch operation"""
+    """Visibility query defines the the group of workflow to apply the batch operation
+    This field and Executions are mutually exclusive
+    """
     job_id: builtins.str
     """Job ID defines the unique ID for the batch job"""
     reason: builtins.str
     """Reason to perform the batch operation"""
     @property
+    def executions(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
+        temporalio.api.common.v1.message_pb2.WorkflowExecution
+    ]:
+        """Executions to apply the batch operation
+        This field and VisibilityQuery are mutually exclusive
+        """
+    @property
     def termination_operation(
         self,
     ) -> temporalio.api.batch.v1.message_pb2.BatchOperationTermination: ...
     @property
     def signal_operation(
         self,
     ) -> temporalio.api.batch.v1.message_pb2.BatchOperationSignal: ...
@@ -4643,14 +5020,18 @@
     def __init__(
         self,
         *,
         namespace: builtins.str = ...,
         visibility_query: builtins.str = ...,
         job_id: builtins.str = ...,
         reason: builtins.str = ...,
+        executions: collections.abc.Iterable[
+            temporalio.api.common.v1.message_pb2.WorkflowExecution
+        ]
+        | None = ...,
         termination_operation: temporalio.api.batch.v1.message_pb2.BatchOperationTermination
         | None = ...,
         signal_operation: temporalio.api.batch.v1.message_pb2.BatchOperationSignal
         | None = ...,
         cancellation_operation: temporalio.api.batch.v1.message_pb2.BatchOperationCancellation
         | None = ...,
         deletion_operation: temporalio.api.batch.v1.message_pb2.BatchOperationDeletion
@@ -4674,14 +5055,16 @@
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
             "cancellation_operation",
             b"cancellation_operation",
             "deletion_operation",
             b"deletion_operation",
+            "executions",
+            b"executions",
             "job_id",
             b"job_id",
             "namespace",
             b"namespace",
             "operation",
             b"operation",
             "reason",
@@ -4931,7 +5314,84 @@
         self,
         field_name: typing_extensions.Literal[
             "next_page_token", b"next_page_token", "operation_info", b"operation_info"
         ],
     ) -> None: ...
 
 global___ListBatchOperationsResponse = ListBatchOperationsResponse
+
+class PollWorkflowExecutionUpdateRequest(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    NAMESPACE_FIELD_NUMBER: builtins.int
+    UPDATE_REF_FIELD_NUMBER: builtins.int
+    IDENTITY_FIELD_NUMBER: builtins.int
+    WAIT_POLICY_FIELD_NUMBER: builtins.int
+    namespace: builtins.str
+    """The namespace of the workflow execution to which the update was
+    originally issued.
+    """
+    @property
+    def update_ref(self) -> temporalio.api.update.v1.message_pb2.UpdateRef:
+        """The update reference returned in the initial
+        UpdateWorkflowExecutionResponse
+        """
+    identity: builtins.str
+    """The identity of the worker/client who is polling this update outcome"""
+    @property
+    def wait_policy(self) -> temporalio.api.update.v1.message_pb2.WaitPolicy:
+        """Describes when this poll request should return a response"""
+    def __init__(
+        self,
+        *,
+        namespace: builtins.str = ...,
+        update_ref: temporalio.api.update.v1.message_pb2.UpdateRef | None = ...,
+        identity: builtins.str = ...,
+        wait_policy: temporalio.api.update.v1.message_pb2.WaitPolicy | None = ...,
+    ) -> None: ...
+    def HasField(
+        self,
+        field_name: typing_extensions.Literal[
+            "update_ref", b"update_ref", "wait_policy", b"wait_policy"
+        ],
+    ) -> builtins.bool: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal[
+            "identity",
+            b"identity",
+            "namespace",
+            b"namespace",
+            "update_ref",
+            b"update_ref",
+            "wait_policy",
+            b"wait_policy",
+        ],
+    ) -> None: ...
+
+global___PollWorkflowExecutionUpdateRequest = PollWorkflowExecutionUpdateRequest
+
+class PollWorkflowExecutionUpdateResponse(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    OUTCOME_FIELD_NUMBER: builtins.int
+    @property
+    def outcome(self) -> temporalio.api.update.v1.message_pb2.Outcome:
+        """The outcome of the update if and only if the update has completed. If
+        this response is being returned before the update has completed (e.g. due
+        to the specification of a wait policy that only waits on
+        UPDATE_WORKFLOW_EXECUTION_LIFECYCLE_STAGE_ACCEPTED) then this field will
+        not be set.
+        """
+    def __init__(
+        self,
+        *,
+        outcome: temporalio.api.update.v1.message_pb2.Outcome | None = ...,
+    ) -> None: ...
+    def HasField(
+        self, field_name: typing_extensions.Literal["outcome", b"outcome"]
+    ) -> builtins.bool: ...
+    def ClearField(
+        self, field_name: typing_extensions.Literal["outcome", b"outcome"]
+    ) -> None: ...
+
+global___PollWorkflowExecutionUpdateResponse = PollWorkflowExecutionUpdateResponse
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/request_response_pb2_grpc.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2.py` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.py`

 * *Files 3% similar despite different names*

```diff
@@ -14,18 +14,18 @@
 
 
 from temporalio.api.workflowservice.v1 import (
     request_response_pb2 as temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n-temporal/api/workflowservice/v1/service.proto\x12\x1ftemporal.api.workflowservice.v1\x1a\x36temporal/api/workflowservice/v1/request_response.proto2\x98\x44\n\x0fWorkflowService\x12\x8c\x01\n\x11RegisterNamespace\x12\x39.temporal.api.workflowservice.v1.RegisterNamespaceRequest\x1a:.temporal.api.workflowservice.v1.RegisterNamespaceResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeNamespace\x12\x39.temporal.api.workflowservice.v1.DescribeNamespaceRequest\x1a:.temporal.api.workflowservice.v1.DescribeNamespaceResponse"\x00\x12\x83\x01\n\x0eListNamespaces\x12\x36.temporal.api.workflowservice.v1.ListNamespacesRequest\x1a\x37.temporal.api.workflowservice.v1.ListNamespacesResponse"\x00\x12\x86\x01\n\x0fUpdateNamespace\x12\x37.temporal.api.workflowservice.v1.UpdateNamespaceRequest\x1a\x38.temporal.api.workflowservice.v1.UpdateNamespaceResponse"\x00\x12\x8f\x01\n\x12\x44\x65precateNamespace\x12:.temporal.api.workflowservice.v1.DeprecateNamespaceRequest\x1a;.temporal.api.workflowservice.v1.DeprecateNamespaceResponse"\x00\x12\x9b\x01\n\x16StartWorkflowExecution\x12>.temporal.api.workflowservice.v1.StartWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.StartWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bGetWorkflowExecutionHistory\x12\x43.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryRequest\x1a\x44.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryResponse"\x00\x12\xbf\x01\n"GetWorkflowExecutionHistoryReverse\x12J.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseRequest\x1aK.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseResponse"\x00\x12\x98\x01\n\x15PollWorkflowTaskQueue\x12=.temporal.api.workflowservice.v1.PollWorkflowTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\x00\x12\xad\x01\n\x1cRespondWorkflowTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedResponse"\x00\x12\xa4\x01\n\x19RespondWorkflowTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedResponse"\x00\x12\x98\x01\n\x15PollActivityTaskQueue\x12=.temporal.api.workflowservice.v1.PollActivityTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse"\x00\x12\xaa\x01\n\x1bRecordActivityTaskHeartbeat\x12\x43.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatRequest\x1a\x44.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatResponse"\x00\x12\xb6\x01\n\x1fRecordActivityTaskHeartbeatById\x12G.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdRequest\x1aH.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdResponse"\x00\x12\xad\x01\n\x1cRespondActivityTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondActivityTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondActivityTaskCompletedResponse"\x00\x12\xb9\x01\n RespondActivityTaskCompletedById\x12H.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdRequest\x1aI.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdResponse"\x00\x12\xa4\x01\n\x19RespondActivityTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondActivityTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondActivityTaskFailedResponse"\x00\x12\xb0\x01\n\x1dRespondActivityTaskFailedById\x12\x45.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdRequest\x1a\x46.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdResponse"\x00\x12\xaa\x01\n\x1bRespondActivityTaskCanceled\x12\x43.temporal.api.workflowservice.v1.RespondActivityTaskCanceledRequest\x1a\x44.temporal.api.workflowservice.v1.RespondActivityTaskCanceledResponse"\x00\x12\xb6\x01\n\x1fRespondActivityTaskCanceledById\x12G.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdRequest\x1aH.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdResponse"\x00\x12\xb3\x01\n\x1eRequestCancelWorkflowExecution\x12\x46.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionRequest\x1aG.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17SignalWorkflowExecution\x12?.temporal.api.workflowservice.v1.SignalWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.SignalWorkflowExecutionResponse"\x00\x12\xb9\x01\n SignalWithStartWorkflowExecution\x12H.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionRequest\x1aI.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionResponse"\x00\x12\x9b\x01\n\x16ResetWorkflowExecution\x12>.temporal.api.workflowservice.v1.ResetWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.ResetWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aTerminateWorkflowExecution\x12\x42.temporal.api.workflowservice.v1.TerminateWorkflowExecutionRequest\x1a\x43.temporal.api.workflowservice.v1.TerminateWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17\x44\x65leteWorkflowExecution\x12?.temporal.api.workflowservice.v1.DeleteWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.DeleteWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aListOpenWorkflowExecutions\x12\x42.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsRequest\x1a\x43.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsResponse"\x00\x12\xad\x01\n\x1cListClosedWorkflowExecutions\x12\x44.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsRequest\x1a\x45.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ListWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ListWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ListWorkflowExecutionsResponse"\x00\x12\xb3\x01\n\x1eListArchivedWorkflowExecutions\x12\x46.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsRequest\x1aG.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ScanWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ScanWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ScanWorkflowExecutionsResponse"\x00\x12\x9e\x01\n\x17\x43ountWorkflowExecutions\x12?.temporal.api.workflowservice.v1.CountWorkflowExecutionsRequest\x1a@.temporal.api.workflowservice.v1.CountWorkflowExecutionsResponse"\x00\x12\x92\x01\n\x13GetSearchAttributes\x12;.temporal.api.workflowservice.v1.GetSearchAttributesRequest\x1a<.temporal.api.workflowservice.v1.GetSearchAttributesResponse"\x00\x12\xa4\x01\n\x19RespondQueryTaskCompleted\x12\x41.temporal.api.workflowservice.v1.RespondQueryTaskCompletedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondQueryTaskCompletedResponse"\x00\x12\x95\x01\n\x14ResetStickyTaskQueue\x12<.temporal.api.workflowservice.v1.ResetStickyTaskQueueRequest\x1a=.temporal.api.workflowservice.v1.ResetStickyTaskQueueResponse"\x00\x12\x80\x01\n\rQueryWorkflow\x12\x35.temporal.api.workflowservice.v1.QueryWorkflowRequest\x1a\x36.temporal.api.workflowservice.v1.QueryWorkflowResponse"\x00\x12\xa4\x01\n\x19\x44\x65scribeWorkflowExecution\x12\x41.temporal.api.workflowservice.v1.DescribeWorkflowExecutionRequest\x1a\x42.temporal.api.workflowservice.v1.DescribeWorkflowExecutionResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeTaskQueue\x12\x39.temporal.api.workflowservice.v1.DescribeTaskQueueRequest\x1a:.temporal.api.workflowservice.v1.DescribeTaskQueueResponse"\x00\x12\x83\x01\n\x0eGetClusterInfo\x12\x36.temporal.api.workflowservice.v1.GetClusterInfoRequest\x1a\x37.temporal.api.workflowservice.v1.GetClusterInfoResponse"\x00\x12\x80\x01\n\rGetSystemInfo\x12\x35.temporal.api.workflowservice.v1.GetSystemInfoRequest\x1a\x36.temporal.api.workflowservice.v1.GetSystemInfoResponse"\x00\x12\x9e\x01\n\x17ListTaskQueuePartitions\x12?.temporal.api.workflowservice.v1.ListTaskQueuePartitionsRequest\x1a@.temporal.api.workflowservice.v1.ListTaskQueuePartitionsResponse"\x00\x12\x83\x01\n\x0e\x43reateSchedule\x12\x36.temporal.api.workflowservice.v1.CreateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.CreateScheduleResponse"\x00\x12\x89\x01\n\x10\x44\x65scribeSchedule\x12\x38.temporal.api.workflowservice.v1.DescribeScheduleRequest\x1a\x39.temporal.api.workflowservice.v1.DescribeScheduleResponse"\x00\x12\x83\x01\n\x0eUpdateSchedule\x12\x36.temporal.api.workflowservice.v1.UpdateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.UpdateScheduleResponse"\x00\x12\x80\x01\n\rPatchSchedule\x12\x35.temporal.api.workflowservice.v1.PatchScheduleRequest\x1a\x36.temporal.api.workflowservice.v1.PatchScheduleResponse"\x00\x12\xa4\x01\n\x19ListScheduleMatchingTimes\x12\x41.temporal.api.workflowservice.v1.ListScheduleMatchingTimesRequest\x1a\x42.temporal.api.workflowservice.v1.ListScheduleMatchingTimesResponse"\x00\x12\x83\x01\n\x0e\x44\x65leteSchedule\x12\x36.temporal.api.workflowservice.v1.DeleteScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.DeleteScheduleResponse"\x00\x12\x80\x01\n\rListSchedules\x12\x35.temporal.api.workflowservice.v1.ListSchedulesRequest\x1a\x36.temporal.api.workflowservice.v1.ListSchedulesResponse"\x00\x12\xaa\x01\n\x1bUpdateWorkerBuildIdOrdering\x12\x43.temporal.api.workflowservice.v1.UpdateWorkerBuildIdOrderingRequest\x1a\x44.temporal.api.workflowservice.v1.UpdateWorkerBuildIdOrderingResponse"\x00\x12\xa1\x01\n\x18GetWorkerBuildIdOrdering\x12@.temporal.api.workflowservice.v1.GetWorkerBuildIdOrderingRequest\x1a\x41.temporal.api.workflowservice.v1.GetWorkerBuildIdOrderingResponse"\x00\x12\x83\x01\n\x0eUpdateWorkflow\x12\x36.temporal.api.workflowservice.v1.UpdateWorkflowRequest\x1a\x37.temporal.api.workflowservice.v1.UpdateWorkflowResponse"\x00\x12\x92\x01\n\x13StartBatchOperation\x12;.temporal.api.workflowservice.v1.StartBatchOperationRequest\x1a<.temporal.api.workflowservice.v1.StartBatchOperationResponse"\x00\x12\x8f\x01\n\x12StopBatchOperation\x12:.temporal.api.workflowservice.v1.StopBatchOperationRequest\x1a;.temporal.api.workflowservice.v1.StopBatchOperationResponse"\x00\x12\x9b\x01\n\x16\x44\x65scribeBatchOperation\x12>.temporal.api.workflowservice.v1.DescribeBatchOperationRequest\x1a?.temporal.api.workflowservice.v1.DescribeBatchOperationResponse"\x00\x12\x92\x01\n\x13ListBatchOperations\x12;.temporal.api.workflowservice.v1.ListBatchOperationsRequest\x1a<.temporal.api.workflowservice.v1.ListBatchOperationsResponse"\x00\x42\xb6\x01\n"io.temporal.api.workflowservice.v1B\x0cServiceProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
+    b'\n-temporal/api/workflowservice/v1/service.proto\x12\x1ftemporal.api.workflowservice.v1\x1a\x36temporal/api/workflowservice/v1/request_response.proto2\xfe\x45\n\x0fWorkflowService\x12\x8c\x01\n\x11RegisterNamespace\x12\x39.temporal.api.workflowservice.v1.RegisterNamespaceRequest\x1a:.temporal.api.workflowservice.v1.RegisterNamespaceResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeNamespace\x12\x39.temporal.api.workflowservice.v1.DescribeNamespaceRequest\x1a:.temporal.api.workflowservice.v1.DescribeNamespaceResponse"\x00\x12\x83\x01\n\x0eListNamespaces\x12\x36.temporal.api.workflowservice.v1.ListNamespacesRequest\x1a\x37.temporal.api.workflowservice.v1.ListNamespacesResponse"\x00\x12\x86\x01\n\x0fUpdateNamespace\x12\x37.temporal.api.workflowservice.v1.UpdateNamespaceRequest\x1a\x38.temporal.api.workflowservice.v1.UpdateNamespaceResponse"\x00\x12\x8f\x01\n\x12\x44\x65precateNamespace\x12:.temporal.api.workflowservice.v1.DeprecateNamespaceRequest\x1a;.temporal.api.workflowservice.v1.DeprecateNamespaceResponse"\x00\x12\x9b\x01\n\x16StartWorkflowExecution\x12>.temporal.api.workflowservice.v1.StartWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.StartWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bGetWorkflowExecutionHistory\x12\x43.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryRequest\x1a\x44.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryResponse"\x00\x12\xbf\x01\n"GetWorkflowExecutionHistoryReverse\x12J.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseRequest\x1aK.temporal.api.workflowservice.v1.GetWorkflowExecutionHistoryReverseResponse"\x00\x12\x98\x01\n\x15PollWorkflowTaskQueue\x12=.temporal.api.workflowservice.v1.PollWorkflowTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollWorkflowTaskQueueResponse"\x00\x12\xad\x01\n\x1cRespondWorkflowTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondWorkflowTaskCompletedResponse"\x00\x12\xa4\x01\n\x19RespondWorkflowTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondWorkflowTaskFailedResponse"\x00\x12\x98\x01\n\x15PollActivityTaskQueue\x12=.temporal.api.workflowservice.v1.PollActivityTaskQueueRequest\x1a>.temporal.api.workflowservice.v1.PollActivityTaskQueueResponse"\x00\x12\xaa\x01\n\x1bRecordActivityTaskHeartbeat\x12\x43.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatRequest\x1a\x44.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatResponse"\x00\x12\xb6\x01\n\x1fRecordActivityTaskHeartbeatById\x12G.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdRequest\x1aH.temporal.api.workflowservice.v1.RecordActivityTaskHeartbeatByIdResponse"\x00\x12\xad\x01\n\x1cRespondActivityTaskCompleted\x12\x44.temporal.api.workflowservice.v1.RespondActivityTaskCompletedRequest\x1a\x45.temporal.api.workflowservice.v1.RespondActivityTaskCompletedResponse"\x00\x12\xb9\x01\n RespondActivityTaskCompletedById\x12H.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdRequest\x1aI.temporal.api.workflowservice.v1.RespondActivityTaskCompletedByIdResponse"\x00\x12\xa4\x01\n\x19RespondActivityTaskFailed\x12\x41.temporal.api.workflowservice.v1.RespondActivityTaskFailedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondActivityTaskFailedResponse"\x00\x12\xb0\x01\n\x1dRespondActivityTaskFailedById\x12\x45.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdRequest\x1a\x46.temporal.api.workflowservice.v1.RespondActivityTaskFailedByIdResponse"\x00\x12\xaa\x01\n\x1bRespondActivityTaskCanceled\x12\x43.temporal.api.workflowservice.v1.RespondActivityTaskCanceledRequest\x1a\x44.temporal.api.workflowservice.v1.RespondActivityTaskCanceledResponse"\x00\x12\xb6\x01\n\x1fRespondActivityTaskCanceledById\x12G.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdRequest\x1aH.temporal.api.workflowservice.v1.RespondActivityTaskCanceledByIdResponse"\x00\x12\xb3\x01\n\x1eRequestCancelWorkflowExecution\x12\x46.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionRequest\x1aG.temporal.api.workflowservice.v1.RequestCancelWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17SignalWorkflowExecution\x12?.temporal.api.workflowservice.v1.SignalWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.SignalWorkflowExecutionResponse"\x00\x12\xb9\x01\n SignalWithStartWorkflowExecution\x12H.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionRequest\x1aI.temporal.api.workflowservice.v1.SignalWithStartWorkflowExecutionResponse"\x00\x12\x9b\x01\n\x16ResetWorkflowExecution\x12>.temporal.api.workflowservice.v1.ResetWorkflowExecutionRequest\x1a?.temporal.api.workflowservice.v1.ResetWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aTerminateWorkflowExecution\x12\x42.temporal.api.workflowservice.v1.TerminateWorkflowExecutionRequest\x1a\x43.temporal.api.workflowservice.v1.TerminateWorkflowExecutionResponse"\x00\x12\x9e\x01\n\x17\x44\x65leteWorkflowExecution\x12?.temporal.api.workflowservice.v1.DeleteWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.DeleteWorkflowExecutionResponse"\x00\x12\xa7\x01\n\x1aListOpenWorkflowExecutions\x12\x42.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsRequest\x1a\x43.temporal.api.workflowservice.v1.ListOpenWorkflowExecutionsResponse"\x00\x12\xad\x01\n\x1cListClosedWorkflowExecutions\x12\x44.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsRequest\x1a\x45.temporal.api.workflowservice.v1.ListClosedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ListWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ListWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ListWorkflowExecutionsResponse"\x00\x12\xb3\x01\n\x1eListArchivedWorkflowExecutions\x12\x46.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsRequest\x1aG.temporal.api.workflowservice.v1.ListArchivedWorkflowExecutionsResponse"\x00\x12\x9b\x01\n\x16ScanWorkflowExecutions\x12>.temporal.api.workflowservice.v1.ScanWorkflowExecutionsRequest\x1a?.temporal.api.workflowservice.v1.ScanWorkflowExecutionsResponse"\x00\x12\x9e\x01\n\x17\x43ountWorkflowExecutions\x12?.temporal.api.workflowservice.v1.CountWorkflowExecutionsRequest\x1a@.temporal.api.workflowservice.v1.CountWorkflowExecutionsResponse"\x00\x12\x92\x01\n\x13GetSearchAttributes\x12;.temporal.api.workflowservice.v1.GetSearchAttributesRequest\x1a<.temporal.api.workflowservice.v1.GetSearchAttributesResponse"\x00\x12\xa4\x01\n\x19RespondQueryTaskCompleted\x12\x41.temporal.api.workflowservice.v1.RespondQueryTaskCompletedRequest\x1a\x42.temporal.api.workflowservice.v1.RespondQueryTaskCompletedResponse"\x00\x12\x95\x01\n\x14ResetStickyTaskQueue\x12<.temporal.api.workflowservice.v1.ResetStickyTaskQueueRequest\x1a=.temporal.api.workflowservice.v1.ResetStickyTaskQueueResponse"\x00\x12\x80\x01\n\rQueryWorkflow\x12\x35.temporal.api.workflowservice.v1.QueryWorkflowRequest\x1a\x36.temporal.api.workflowservice.v1.QueryWorkflowResponse"\x00\x12\xa4\x01\n\x19\x44\x65scribeWorkflowExecution\x12\x41.temporal.api.workflowservice.v1.DescribeWorkflowExecutionRequest\x1a\x42.temporal.api.workflowservice.v1.DescribeWorkflowExecutionResponse"\x00\x12\x8c\x01\n\x11\x44\x65scribeTaskQueue\x12\x39.temporal.api.workflowservice.v1.DescribeTaskQueueRequest\x1a:.temporal.api.workflowservice.v1.DescribeTaskQueueResponse"\x00\x12\x83\x01\n\x0eGetClusterInfo\x12\x36.temporal.api.workflowservice.v1.GetClusterInfoRequest\x1a\x37.temporal.api.workflowservice.v1.GetClusterInfoResponse"\x00\x12\x80\x01\n\rGetSystemInfo\x12\x35.temporal.api.workflowservice.v1.GetSystemInfoRequest\x1a\x36.temporal.api.workflowservice.v1.GetSystemInfoResponse"\x00\x12\x9e\x01\n\x17ListTaskQueuePartitions\x12?.temporal.api.workflowservice.v1.ListTaskQueuePartitionsRequest\x1a@.temporal.api.workflowservice.v1.ListTaskQueuePartitionsResponse"\x00\x12\x83\x01\n\x0e\x43reateSchedule\x12\x36.temporal.api.workflowservice.v1.CreateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.CreateScheduleResponse"\x00\x12\x89\x01\n\x10\x44\x65scribeSchedule\x12\x38.temporal.api.workflowservice.v1.DescribeScheduleRequest\x1a\x39.temporal.api.workflowservice.v1.DescribeScheduleResponse"\x00\x12\x83\x01\n\x0eUpdateSchedule\x12\x36.temporal.api.workflowservice.v1.UpdateScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.UpdateScheduleResponse"\x00\x12\x80\x01\n\rPatchSchedule\x12\x35.temporal.api.workflowservice.v1.PatchScheduleRequest\x1a\x36.temporal.api.workflowservice.v1.PatchScheduleResponse"\x00\x12\xa4\x01\n\x19ListScheduleMatchingTimes\x12\x41.temporal.api.workflowservice.v1.ListScheduleMatchingTimesRequest\x1a\x42.temporal.api.workflowservice.v1.ListScheduleMatchingTimesResponse"\x00\x12\x83\x01\n\x0e\x44\x65leteSchedule\x12\x36.temporal.api.workflowservice.v1.DeleteScheduleRequest\x1a\x37.temporal.api.workflowservice.v1.DeleteScheduleResponse"\x00\x12\x80\x01\n\rListSchedules\x12\x35.temporal.api.workflowservice.v1.ListSchedulesRequest\x1a\x36.temporal.api.workflowservice.v1.ListSchedulesResponse"\x00\x12\xb9\x01\n UpdateWorkerBuildIdCompatibility\x12H.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityRequest\x1aI.temporal.api.workflowservice.v1.UpdateWorkerBuildIdCompatibilityResponse"\x00\x12\xb0\x01\n\x1dGetWorkerBuildIdCompatibility\x12\x45.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityRequest\x1a\x46.temporal.api.workflowservice.v1.GetWorkerBuildIdCompatibilityResponse"\x00\x12\x9e\x01\n\x17UpdateWorkflowExecution\x12?.temporal.api.workflowservice.v1.UpdateWorkflowExecutionRequest\x1a@.temporal.api.workflowservice.v1.UpdateWorkflowExecutionResponse"\x00\x12\xaa\x01\n\x1bPollWorkflowExecutionUpdate\x12\x43.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateRequest\x1a\x44.temporal.api.workflowservice.v1.PollWorkflowExecutionUpdateResponse"\x00\x12\x92\x01\n\x13StartBatchOperation\x12;.temporal.api.workflowservice.v1.StartBatchOperationRequest\x1a<.temporal.api.workflowservice.v1.StartBatchOperationResponse"\x00\x12\x8f\x01\n\x12StopBatchOperation\x12:.temporal.api.workflowservice.v1.StopBatchOperationRequest\x1a;.temporal.api.workflowservice.v1.StopBatchOperationResponse"\x00\x12\x9b\x01\n\x16\x44\x65scribeBatchOperation\x12>.temporal.api.workflowservice.v1.DescribeBatchOperationRequest\x1a?.temporal.api.workflowservice.v1.DescribeBatchOperationResponse"\x00\x12\x92\x01\n\x13ListBatchOperations\x12;.temporal.api.workflowservice.v1.ListBatchOperationsRequest\x1a<.temporal.api.workflowservice.v1.ListBatchOperationsResponse"\x00\x42\xb6\x01\n"io.temporal.api.workflowservice.v1B\x0cServiceProtoP\x01Z5go.temporal.io/api/workflowservice/v1;workflowservice\xaa\x02!Temporalio.Api.WorkflowService.V1\xea\x02$Temporalio::Api::WorkflowService::V1b\x06proto3'
 )
 
 
 _WORKFLOWSERVICE = DESCRIPTOR.services_by_name["WorkflowService"]
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
     DESCRIPTOR._serialized_options = b'\n"io.temporal.api.workflowservice.v1B\014ServiceProtoP\001Z5go.temporal.io/api/workflowservice/v1;workflowservice\252\002!Temporalio.Api.WorkflowService.V1\352\002$Temporalio::Api::WorkflowService::V1'
     _WORKFLOWSERVICE._serialized_start = 139
-    _WORKFLOWSERVICE._serialized_end = 8867
+    _WORKFLOWSERVICE._serialized_end = 9097
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2.pyi` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.py`

 * *Files 1% similar despite different names*

```diff
@@ -263,28 +263,33 @@
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.DeleteScheduleResponse.FromString,
         )
         self.ListSchedules = channel.unary_unary(
             "/temporal.api.workflowservice.v1.WorkflowService/ListSchedules",
             request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.ListSchedulesRequest.SerializeToString,
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.ListSchedulesResponse.FromString,
         )
-        self.UpdateWorkerBuildIdOrdering = channel.unary_unary(
-            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkerBuildIdOrdering",
-            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingRequest.SerializeToString,
-            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingResponse.FromString,
-        )
-        self.GetWorkerBuildIdOrdering = channel.unary_unary(
-            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerBuildIdOrdering",
-            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingRequest.SerializeToString,
-            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingResponse.FromString,
-        )
-        self.UpdateWorkflow = channel.unary_unary(
-            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkflow",
-            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowRequest.SerializeToString,
-            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowResponse.FromString,
+        self.UpdateWorkerBuildIdCompatibility = channel.unary_unary(
+            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkerBuildIdCompatibility",
+            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityRequest.SerializeToString,
+            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityResponse.FromString,
+        )
+        self.GetWorkerBuildIdCompatibility = channel.unary_unary(
+            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerBuildIdCompatibility",
+            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityRequest.SerializeToString,
+            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityResponse.FromString,
+        )
+        self.UpdateWorkflowExecution = channel.unary_unary(
+            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkflowExecution",
+            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionRequest.SerializeToString,
+            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionResponse.FromString,
+        )
+        self.PollWorkflowExecutionUpdate = channel.unary_unary(
+            "/temporal.api.workflowservice.v1.WorkflowService/PollWorkflowExecutionUpdate",
+            request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateRequest.SerializeToString,
+            response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateResponse.FromString,
         )
         self.StartBatchOperation = channel.unary_unary(
             "/temporal.api.workflowservice.v1.WorkflowService/StartBatchOperation",
             request_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.StartBatchOperationRequest.SerializeToString,
             response_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.StartBatchOperationResponse.FromString,
         )
         self.StopBatchOperation = channel.unary_unary(
@@ -774,37 +779,51 @@
 
     def ListSchedules(self, request, context):
         """List all schedules in a namespace."""
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
-    def UpdateWorkerBuildIdOrdering(self, request, context):
-        """Allows users to specify a graph of worker build id based versions on a
-        per task queue basis. Versions are ordered, and may be either compatible
-        with some extant version, or a new incompatible version.
+    def UpdateWorkerBuildIdCompatibility(self, request, context):
+        """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
+        are ordered, and may be either compatible with some extant version, or a new incompatible
+        version, forming sets of ids which are incompatible with each other, but whose contained
+        members are compatible with one another.
+
         (-- api-linter: core::0134::response-message-name=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         (-- api-linter: core::0134::method-signature=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         """
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
-    def GetWorkerBuildIdOrdering(self, request, context):
-        """Fetches the worker build id versioning graph for some task queue."""
+    def GetWorkerBuildIdCompatibility(self, request, context):
+        """Fetches the worker build id versioning sets for some task queue and related metadata."""
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
-    def UpdateWorkflow(self, request, context):
+    def UpdateWorkflowExecution(self, request, context):
         """Invokes the specified update function on user workflow code.
         (-- api-linter: core::0134=disabled
-        aip.dev/not-precedent: UpdateWorkflow doesn't follow Google API format --)
+        aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
+        """
+        context.set_code(grpc.StatusCode.UNIMPLEMENTED)
+        context.set_details("Method not implemented!")
+        raise NotImplementedError("Method not implemented!")
+
+    def PollWorkflowExecutionUpdate(self, request, context):
+        """Polls a workflow execution for the outcome of a workflow execution update
+        previously issued through the UpdateWorkflowExecution RPC. The effective
+        timeout on this call will be shorter of the the caller-supplied gRPC
+        timeout and the server's configured long-poll timeout.
+        (-- api-linter: core::0134=disabled
+        aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
         """
         context.set_code(grpc.StatusCode.UNIMPLEMENTED)
         context.set_details("Method not implemented!")
         raise NotImplementedError("Method not implemented!")
 
     def StartBatchOperation(self, request, context):
         """StartBatchOperation starts a new batch operation"""
@@ -1069,28 +1088,33 @@
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.DeleteScheduleResponse.SerializeToString,
         ),
         "ListSchedules": grpc.unary_unary_rpc_method_handler(
             servicer.ListSchedules,
             request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.ListSchedulesRequest.FromString,
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.ListSchedulesResponse.SerializeToString,
         ),
-        "UpdateWorkerBuildIdOrdering": grpc.unary_unary_rpc_method_handler(
-            servicer.UpdateWorkerBuildIdOrdering,
-            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingRequest.FromString,
-            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingResponse.SerializeToString,
-        ),
-        "GetWorkerBuildIdOrdering": grpc.unary_unary_rpc_method_handler(
-            servicer.GetWorkerBuildIdOrdering,
-            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingRequest.FromString,
-            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingResponse.SerializeToString,
-        ),
-        "UpdateWorkflow": grpc.unary_unary_rpc_method_handler(
-            servicer.UpdateWorkflow,
-            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowRequest.FromString,
-            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowResponse.SerializeToString,
+        "UpdateWorkerBuildIdCompatibility": grpc.unary_unary_rpc_method_handler(
+            servicer.UpdateWorkerBuildIdCompatibility,
+            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityRequest.FromString,
+            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityResponse.SerializeToString,
+        ),
+        "GetWorkerBuildIdCompatibility": grpc.unary_unary_rpc_method_handler(
+            servicer.GetWorkerBuildIdCompatibility,
+            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityRequest.FromString,
+            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityResponse.SerializeToString,
+        ),
+        "UpdateWorkflowExecution": grpc.unary_unary_rpc_method_handler(
+            servicer.UpdateWorkflowExecution,
+            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionRequest.FromString,
+            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionResponse.SerializeToString,
+        ),
+        "PollWorkflowExecutionUpdate": grpc.unary_unary_rpc_method_handler(
+            servicer.PollWorkflowExecutionUpdate,
+            request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateRequest.FromString,
+            response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateResponse.SerializeToString,
         ),
         "StartBatchOperation": grpc.unary_unary_rpc_method_handler(
             servicer.StartBatchOperation,
             request_deserializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.StartBatchOperationRequest.FromString,
             response_serializer=temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.StartBatchOperationResponse.SerializeToString,
         ),
         "StopBatchOperation": grpc.unary_unary_rpc_method_handler(
@@ -2519,90 +2543,119 @@
             compression,
             wait_for_ready,
             timeout,
             metadata,
         )
 
     @staticmethod
-    def UpdateWorkerBuildIdOrdering(
+    def UpdateWorkerBuildIdCompatibility(
+        request,
+        target,
+        options=(),
+        channel_credentials=None,
+        call_credentials=None,
+        insecure=False,
+        compression=None,
+        wait_for_ready=None,
+        timeout=None,
+        metadata=None,
+    ):
+        return grpc.experimental.unary_unary(
+            request,
+            target,
+            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkerBuildIdCompatibility",
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityRequest.SerializeToString,
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdCompatibilityResponse.FromString,
+            options,
+            channel_credentials,
+            insecure,
+            call_credentials,
+            compression,
+            wait_for_ready,
+            timeout,
+            metadata,
+        )
+
+    @staticmethod
+    def GetWorkerBuildIdCompatibility(
         request,
         target,
         options=(),
         channel_credentials=None,
         call_credentials=None,
         insecure=False,
         compression=None,
         wait_for_ready=None,
         timeout=None,
         metadata=None,
     ):
         return grpc.experimental.unary_unary(
             request,
             target,
-            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkerBuildIdOrdering",
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingRequest.SerializeToString,
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkerBuildIdOrderingResponse.FromString,
+            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerBuildIdCompatibility",
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityRequest.SerializeToString,
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdCompatibilityResponse.FromString,
             options,
             channel_credentials,
             insecure,
             call_credentials,
             compression,
             wait_for_ready,
             timeout,
             metadata,
         )
 
     @staticmethod
-    def GetWorkerBuildIdOrdering(
+    def UpdateWorkflowExecution(
         request,
         target,
         options=(),
         channel_credentials=None,
         call_credentials=None,
         insecure=False,
         compression=None,
         wait_for_ready=None,
         timeout=None,
         metadata=None,
     ):
         return grpc.experimental.unary_unary(
             request,
             target,
-            "/temporal.api.workflowservice.v1.WorkflowService/GetWorkerBuildIdOrdering",
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingRequest.SerializeToString,
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.GetWorkerBuildIdOrderingResponse.FromString,
+            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkflowExecution",
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionRequest.SerializeToString,
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowExecutionResponse.FromString,
             options,
             channel_credentials,
             insecure,
             call_credentials,
             compression,
             wait_for_ready,
             timeout,
             metadata,
         )
 
     @staticmethod
-    def UpdateWorkflow(
+    def PollWorkflowExecutionUpdate(
         request,
         target,
         options=(),
         channel_credentials=None,
         call_credentials=None,
         insecure=False,
         compression=None,
         wait_for_ready=None,
         timeout=None,
         metadata=None,
     ):
         return grpc.experimental.unary_unary(
             request,
             target,
-            "/temporal.api.workflowservice.v1.WorkflowService/UpdateWorkflow",
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowRequest.SerializeToString,
-            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.UpdateWorkflowResponse.FromString,
+            "/temporal.api.workflowservice.v1.WorkflowService/PollWorkflowExecutionUpdate",
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateRequest.SerializeToString,
+            temporal_dot_api_dot_workflowservice_dot_v1_dot_request__response__pb2.PollWorkflowExecutionUpdateResponse.FromString,
             options,
             channel_credentials,
             insecure,
             call_credentials,
             compression,
             wait_for_ready,
             timeout,
```

### Comparing `temporalio-1.1.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi` & `temporalio-1.2.0/temporalio/api/workflowservice/v1/service_pb2_grpc.pyi`

 * *Files 0% similar despite different names*

```diff
@@ -449,38 +449,51 @@
         aip.dev/not-precedent: DeleteSchedule doesn't follow Google API format --)
     """
     ListSchedules: grpc.UnaryUnaryMultiCallable[
         temporalio.api.workflowservice.v1.request_response_pb2.ListSchedulesRequest,
         temporalio.api.workflowservice.v1.request_response_pb2.ListSchedulesResponse,
     ]
     """List all schedules in a namespace."""
-    UpdateWorkerBuildIdOrdering: grpc.UnaryUnaryMultiCallable[
-        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdOrderingRequest,
-        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdOrderingResponse,
+    UpdateWorkerBuildIdCompatibility: grpc.UnaryUnaryMultiCallable[
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityRequest,
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityResponse,
     ]
-    """Allows users to specify a graph of worker build id based versions on a
-    per task queue basis. Versions are ordered, and may be either compatible
-    with some extant version, or a new incompatible version.
+    """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
+    are ordered, and may be either compatible with some extant version, or a new incompatible
+    version, forming sets of ids which are incompatible with each other, but whose contained
+    members are compatible with one another.
+
     (-- api-linter: core::0134::response-message-name=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     (-- api-linter: core::0134::method-signature=disabled
-        aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+        aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     """
-    GetWorkerBuildIdOrdering: grpc.UnaryUnaryMultiCallable[
-        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdOrderingRequest,
-        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdOrderingResponse,
+    GetWorkerBuildIdCompatibility: grpc.UnaryUnaryMultiCallable[
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityRequest,
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityResponse,
     ]
-    """Fetches the worker build id versioning graph for some task queue."""
-    UpdateWorkflow: grpc.UnaryUnaryMultiCallable[
-        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowRequest,
-        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowResponse,
+    """Fetches the worker build id versioning sets for some task queue and related metadata."""
+    UpdateWorkflowExecution: grpc.UnaryUnaryMultiCallable[
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionRequest,
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionResponse,
     ]
     """Invokes the specified update function on user workflow code.
     (-- api-linter: core::0134=disabled
-        aip.dev/not-precedent: UpdateWorkflow doesn't follow Google API format --)
+        aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
+    """
+    PollWorkflowExecutionUpdate: grpc.UnaryUnaryMultiCallable[
+        temporalio.api.workflowservice.v1.request_response_pb2.PollWorkflowExecutionUpdateRequest,
+        temporalio.api.workflowservice.v1.request_response_pb2.PollWorkflowExecutionUpdateResponse,
+    ]
+    """Polls a workflow execution for the outcome of a workflow execution update
+    previously issued through the UpdateWorkflowExecution RPC. The effective
+    timeout on this call will be shorter of the the caller-supplied gRPC
+    timeout and the server's configured long-poll timeout.
+    (-- api-linter: core::0134=disabled
+        aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
     """
     StartBatchOperation: grpc.UnaryUnaryMultiCallable[
         temporalio.api.workflowservice.v1.request_response_pb2.StartBatchOperationRequest,
         temporalio.api.workflowservice.v1.request_response_pb2.StartBatchOperationResponse,
     ]
     """StartBatchOperation starts a new batch operation"""
     StopBatchOperation: grpc.UnaryUnaryMultiCallable[
@@ -1093,47 +1106,66 @@
     def ListSchedules(
         self,
         request: temporalio.api.workflowservice.v1.request_response_pb2.ListSchedulesRequest,
         context: grpc.ServicerContext,
     ) -> temporalio.api.workflowservice.v1.request_response_pb2.ListSchedulesResponse:
         """List all schedules in a namespace."""
     @abc.abstractmethod
-    def UpdateWorkerBuildIdOrdering(
+    def UpdateWorkerBuildIdCompatibility(
         self,
-        request: temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdOrderingRequest,
+        request: temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityRequest,
         context: grpc.ServicerContext,
     ) -> (
-        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdOrderingResponse
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkerBuildIdCompatibilityResponse
     ):
-        """Allows users to specify a graph of worker build id based versions on a
-        per task queue basis. Versions are ordered, and may be either compatible
-        with some extant version, or a new incompatible version.
+        """Allows users to specify sets of worker build id versions on a per task queue basis. Versions
+        are ordered, and may be either compatible with some extant version, or a new incompatible
+        version, forming sets of ids which are incompatible with each other, but whose contained
+        members are compatible with one another.
+
         (-- api-linter: core::0134::response-message-name=disabled
-            aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+            aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         (-- api-linter: core::0134::method-signature=disabled
-            aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+            aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
         """
     @abc.abstractmethod
-    def GetWorkerBuildIdOrdering(
+    def GetWorkerBuildIdCompatibility(
         self,
-        request: temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdOrderingRequest,
+        request: temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityRequest,
         context: grpc.ServicerContext,
     ) -> (
-        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdOrderingResponse
+        temporalio.api.workflowservice.v1.request_response_pb2.GetWorkerBuildIdCompatibilityResponse
     ):
-        """Fetches the worker build id versioning graph for some task queue."""
+        """Fetches the worker build id versioning sets for some task queue and related metadata."""
     @abc.abstractmethod
-    def UpdateWorkflow(
+    def UpdateWorkflowExecution(
         self,
-        request: temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowRequest,
+        request: temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionRequest,
         context: grpc.ServicerContext,
-    ) -> temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowResponse:
+    ) -> (
+        temporalio.api.workflowservice.v1.request_response_pb2.UpdateWorkflowExecutionResponse
+    ):
         """Invokes the specified update function on user workflow code.
         (-- api-linter: core::0134=disabled
-            aip.dev/not-precedent: UpdateWorkflow doesn't follow Google API format --)
+            aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
+        """
+    @abc.abstractmethod
+    def PollWorkflowExecutionUpdate(
+        self,
+        request: temporalio.api.workflowservice.v1.request_response_pb2.PollWorkflowExecutionUpdateRequest,
+        context: grpc.ServicerContext,
+    ) -> (
+        temporalio.api.workflowservice.v1.request_response_pb2.PollWorkflowExecutionUpdateResponse
+    ):
+        """Polls a workflow execution for the outcome of a workflow execution update
+        previously issued through the UpdateWorkflowExecution RPC. The effective
+        timeout on this call will be shorter of the the caller-supplied gRPC
+        timeout and the server's configured long-poll timeout.
+        (-- api-linter: core::0134=disabled
+            aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
         """
     @abc.abstractmethod
     def StartBatchOperation(
         self,
         request: temporalio.api.workflowservice.v1.request_response_pb2.StartBatchOperationRequest,
         context: grpc.ServicerContext,
     ) -> (
```

### Comparing `temporalio-1.1.0/temporalio/bridge/Cargo.lock` & `temporalio-1.2.0/temporalio/bridge/Cargo.lock`

 * *Files 2% similar despite different names*

```diff
@@ -18,98 +18,88 @@
  "cipher",
  "cpufeatures",
  "opaque-debug",
 ]
 
 [[package]]
 name = "ahash"
-version = "0.7.6"
+version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "fcb51a0695d8f838b1ee009b3fbf66bda078cd64590202a864a8f3e8c4315c47"
+checksum = "2c99f64d1e06488f620f932677e24bc6e2897582980441ae90a671415bd7ec2f"
 dependencies = [
- "getrandom",
+ "cfg-if",
  "once_cell",
  "version_check",
 ]
 
 [[package]]
 name = "aho-corasick"
-version = "0.7.19"
+version = "0.7.20"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b4f55bd91a0978cbfd91c457a164bab8b4001c833b7f323132c0a4e1922dd44e"
+checksum = "cc936419f96fa211c1b9166887b38e5e40b19958e5b895be7c1f93adec7071ac"
 dependencies = [
  "memchr",
 ]
 
 [[package]]
 name = "anyhow"
-version = "1.0.65"
+version = "1.0.70"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "98161a4e3e2184da77bb14f02184cdd111e83bbbcc9979dfee3c44b9a85f5602"
+checksum = "7de8ce5e0f9f8d88245311066a578d72b7af3e7088f32783804676302df237e4"
 
 [[package]]
 name = "arc-swap"
-version = "1.5.1"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "983cd8b9d4b02a6dc6ffa557262eb5858a27a0038ffffe21a0f133eaa819a164"
-
-[[package]]
-name = "async-channel"
-version = "1.7.1"
+version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e14485364214912d3b19cc3435dde4df66065127f05fa0d75c712f36f12c2f28"
-dependencies = [
- "concurrent-queue",
- "event-listener",
- "futures-core",
-]
+checksum = "bddcadddf5e9015d310179a59bb28c4d4b9920ad0f11e8e14dbadf654890c9a6"
 
 [[package]]
 name = "async-stream"
-version = "0.3.3"
+version = "0.3.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "dad5c83079eae9969be7fadefe640a1c566901f05ff91ab221de4b6f68d9507e"
+checksum = "ad445822218ce64be7a341abfb0b1ea43b5c23aa83902542a4542e78309d8e5e"
 dependencies = [
  "async-stream-impl",
  "futures-core",
+ "pin-project-lite",
 ]
 
 [[package]]
 name = "async-stream-impl"
-version = "0.3.3"
+version = "0.3.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "10f203db73a71dfa2fb6dd22763990fa26f3d2625a6da2da900d23b87d26be27"
+checksum = "e4655ae1a7b0cdf149156f780c5bf3f1352bc53cbd9e0a361a7ef7b22947e965"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "async-trait"
-version = "0.1.57"
+version = "0.1.67"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "76464446b8bc32758d7e88ee1a804d9914cd9b1cb264c029899680b0be29826f"
+checksum = "86ea188f25f0255d8f92797797c97ebf5631fa88178beb1a46fdf5622c9a00e4"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 2.0.8",
 ]
 
 [[package]]
 name = "autocfg"
 version = "1.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d468802bab17cbc0cc575e9b053f41e72aa36bfa6b7f55e3529ffa43161b97fa"
 
 [[package]]
 name = "axum"
-version = "0.5.16"
+version = "0.6.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c9e3356844c4d6a6d6467b8da2cffb4a2820be256f50a3a386c9d152bab31043"
+checksum = "349f8ccfd9221ee7d1f3d4b33e1f8319b3a81ed8f61f2ea40b37b859794b4491"
 dependencies = [
  "async-trait",
  "axum-core",
  "bitflags",
  "bytes",
  "futures-util",
  "http",
@@ -117,35 +107,35 @@
  "hyper",
  "itoa",
  "matchit",
  "memchr",
  "mime",
  "percent-encoding",
  "pin-project-lite",
+ "rustversion",
  "serde",
  "sync_wrapper",
- "tokio",
  "tower",
- "tower-http",
  "tower-layer",
  "tower-service",
 ]
 
 [[package]]
 name = "axum-core"
-version = "0.2.8"
+version = "0.3.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d9f0c0a60006f2a293d82d571f635042a72edf927539b7685bd62d361963839b"
+checksum = "b2f958c80c248b34b9a877a643811be8dbca03ca5ba827f2b63baf3a81e5fc4e"
 dependencies = [
  "async-trait",
  "bytes",
  "futures-util",
  "http",
  "http-body",
  "mime",
+ "rustversion",
  "tower-layer",
  "tower-service",
 ]
 
 [[package]]
 name = "backoff"
 version = "0.4.0"
@@ -155,68 +145,68 @@
  "getrandom",
  "instant",
  "rand",
 ]
 
 [[package]]
 name = "base64"
-version = "0.13.0"
+version = "0.13.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "904dfeac50f3cdaba28fc6f57fdcddb75f49ed61346676a78c4ffe55877802fd"
+checksum = "9e1b586273c5702936fe7b7d6896644d8be71e6314cfe09d3167c95f712589e8"
 
 [[package]]
 name = "base64"
-version = "0.20.0"
+version = "0.21.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0ea22880d78093b0cbe17c89f64a7d457941e65759157ec6cb31a31d652b05e5"
+checksum = "a4a4ddaa51a5bc52a6948f74c06d20aaaddb71924eab79b8c97a8c556e942d6a"
 
 [[package]]
 name = "base64ct"
-version = "1.5.2"
+version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ea2b2456fd614d856680dcd9fcc660a51a820fa09daef2e49772b56a193c8474"
+checksum = "8c3c1a368f70d6cf7302d78f8f7093da241fb8e8807c05cc9e51a125895a6d5b"
 
 [[package]]
 name = "bitflags"
 version = "1.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"
 
 [[package]]
 name = "block-buffer"
-version = "0.10.3"
+version = "0.10.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "69cce20737498f97b993470a6e536b8523f0af7892a4f928cceb1ac5e52ebe7e"
+checksum = "3078c7629b62d3f0439517fa394996acacc5cbc91c5a20d8c658e77abd503a71"
 dependencies = [
  "generic-array",
 ]
 
 [[package]]
 name = "bumpalo"
-version = "3.11.0"
+version = "3.12.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c1ad822118d20d2c234f427000d5acc36eabe1e29a348c89b63dd60b13f28e5d"
+checksum = "0d261e256854913907f67ed06efbc3338dfe6179796deefc1ff763fc1aee5535"
 
 [[package]]
 name = "byteorder"
 version = "1.4.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "14c189c53d098945499cdfa7ecc63567cf3886b3332b312a5b4585d8d3a6a610"
 
 [[package]]
 name = "bytes"
-version = "1.2.1"
+version = "1.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ec8a7b6a70fde80372154c65702f00a0f56f3e1c36abbc6c440484be248856db"
+checksum = "89b2fd2a0dcf38d7971e2194b6b6eebab45ae01067456a7fd93d5547a61b70be"
 
 [[package]]
 name = "bzip2"
-version = "0.4.3"
+version = "0.4.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6afcd980b5f3a45017c57e57a2fcccbb351cc43a356ce117ef760ef8052b89b0"
+checksum = "bdb116a6ef3f6c3698828873ad02c3014b3c85cadb88496095628e3ef1e347f8"
 dependencies = [
  "bzip2-sys",
  "libc",
 ]
 
 [[package]]
 name = "bzip2-sys"
@@ -226,50 +216,46 @@
 dependencies = [
  "cc",
  "libc",
  "pkg-config",
 ]
 
 [[package]]
-name = "cache-padded"
-version = "1.2.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c1db59621ec70f09c5e9b597b220c7a2b43611f4710dc03ceb8748637775692c"
-
-[[package]]
 name = "cc"
-version = "1.0.73"
+version = "1.0.79"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2fff2a6927b3bb87f9595d67196a70493f627687a71d87a0d692242c33f58c11"
+checksum = "50d30906286121d95be3d479533b458f87493b30a4b5f79a607db8f5d11aa91f"
 dependencies = [
  "jobserver",
 ]
 
 [[package]]
 name = "cfg-if"
 version = "1.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "baf1de4339761588bc0619e3cbc0120ee582ebb74b53b4efbf79117bd2da40fd"
 
 [[package]]
-name = "cipher"
-version = "0.3.0"
+name = "chrono"
+version = "0.4.24"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7ee52072ec15386f770805afd189a01c8841be8696bed250fa2f13c4c0d6dfb7"
+checksum = "4e3c5919066adf22df73762e50cffcde3a758f2a848b113b586d1f86728b673b"
 dependencies = [
- "generic-array",
+ "num-integer",
+ "num-traits",
+ "serde",
 ]
 
 [[package]]
-name = "concurrent-queue"
-version = "1.2.4"
+name = "cipher"
+version = "0.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "af4780a44ab5696ea9e28294517f1fffb421a83a25af521333c838635509db9c"
+checksum = "7ee52072ec15386f770805afd189a01c8841be8696bed250fa2f13c4c0d6dfb7"
 dependencies = [
- "cache-padded",
+ "generic-array",
 ]
 
 [[package]]
 name = "constant_time_eq"
 version = "0.1.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "245097e9a4535ee1e3e3931fcfcd55a796a44c643e8596ff6566d68f09b87bbc"
@@ -326,61 +312,61 @@
  "crossbeam-epoch",
  "crossbeam-queue",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-channel"
-version = "0.5.6"
+version = "0.5.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c2dd04ddaf88237dc3b8d8f9a3c1004b506b54b3313403944054d23c0870c521"
+checksum = "cf2b3e8478797446514c91ef04bafcb59faba183e621ad488df88983cc14128c"
 dependencies = [
  "cfg-if",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-deque"
-version = "0.8.2"
+version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "715e8152b692bba2d374b53d4875445368fdf21a94751410af607a5ac677d1fc"
+checksum = "ce6fd6f855243022dcecf8702fef0c297d4338e226845fe067f6341ad9fa0cef"
 dependencies = [
  "cfg-if",
  "crossbeam-epoch",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-epoch"
-version = "0.9.11"
+version = "0.9.14"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f916dfc5d356b0ed9dae65f1db9fc9770aa2851d2662b988ccf4fe3516e86348"
+checksum = "46bd5f3f85273295a9d14aedfb86f6aadbff6d8f5295c4a9edb08e819dcf5695"
 dependencies = [
  "autocfg",
  "cfg-if",
  "crossbeam-utils",
- "memoffset 0.6.5",
+ "memoffset 0.8.0",
  "scopeguard",
 ]
 
 [[package]]
 name = "crossbeam-queue"
-version = "0.3.6"
+version = "0.3.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1cd42583b04998a5363558e5f9291ee5a5ff6b49944332103f251e7479a82aa7"
+checksum = "d1cfb3ea8a53f37c40dea2c7bedcbd88bdfae54f5e2175d6ecaff1c988353add"
 dependencies = [
  "cfg-if",
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "crossbeam-utils"
-version = "0.8.12"
+version = "0.8.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "edbafec5fa1f196ca66527c1b12c2ec4745ca14b50f1ad8f9f6f720b55d11fac"
+checksum = "3c063cd8cc95f5c377ed0d4b49a4b21f632396ff690e8470c29b3359b346984b"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "crypto-common"
 version = "0.1.6"
@@ -388,56 +374,66 @@
 checksum = "1bfb12502f3fc46cca1bb51ac28df9d618d813cdc3d2f25b9fe775a34af26bb3"
 dependencies = [
  "generic-array",
  "typenum",
 ]
 
 [[package]]
+name = "ctor"
+version = "0.1.26"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "6d2301688392eb071b0bf1a37be05c469d3cc4dbbd95df672fe28ab021e6a096"
+dependencies = [
+ "quote",
+ "syn 1.0.109",
+]
+
+[[package]]
 name = "darling"
-version = "0.14.1"
+version = "0.14.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4529658bdda7fd6769b8614be250cdcfc3aeb0ee72fe66f9e41e5e5eb73eac02"
+checksum = "7b750cb3417fd1b327431a470f388520309479ab0bf5e323505daf0290cd3850"
 dependencies = [
  "darling_core",
  "darling_macro",
 ]
 
 [[package]]
 name = "darling_core"
-version = "0.14.1"
+version = "0.14.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "649c91bc01e8b1eac09fb91e8dbc7d517684ca6be8ebc75bb9cafc894f9fdb6f"
+checksum = "109c1ca6e6b7f82cc233a97004ea8ed7ca123a9af07a8230878fcfda9b158bf0"
 dependencies = [
  "fnv",
  "ident_case",
  "proc-macro2",
  "quote",
  "strsim",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "darling_macro"
-version = "0.14.1"
+version = "0.14.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ddfc69c5bfcbd2fc09a0f38451d2daf0e372e367986a83906d1b0dbc88134fb5"
+checksum = "a4aab4dbc9f7611d8b55048a3a16d2d010c2c8334e46304b40ac1cc14bf3b48e"
 dependencies = [
  "darling_core",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "dashmap"
 version = "5.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "907076dfda823b0b36d2a1bb5f90c96660a5bbcd7729e10727f07858f22c4edc"
 dependencies = [
  "cfg-if",
- "hashbrown",
+ "hashbrown 0.12.3",
  "lock_api",
  "once_cell",
  "parking_lot_core",
 ]
 
 [[package]]
 name = "derive_builder"
@@ -453,128 +449,172 @@
 version = "0.12.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c11bdc11a0c47bc7d37d582b5285da6849c96681023680b906673c5707af7b0f"
 dependencies = [
  "darling",
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "derive_builder_macro"
 version = "0.12.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "ebcda35c7a396850a55ffeac740804b40ffec779b98fffbb1738f4033f0ee79e"
 dependencies = [
  "derive_builder_core",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "derive_more"
 version = "0.99.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4fb810d30a7c1953f91334de7244731fc3f3c10d7fe163338a35b9f640960321"
 dependencies = [
  "convert_case",
  "proc-macro2",
  "quote",
  "rustc_version",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "difflib"
 version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6184e33543162437515c2e2b48714794e37845ec9851711914eec9d308f6ebe8"
 
 [[package]]
 name = "digest"
-version = "0.10.5"
+version = "0.10.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "adfbc57365a37acbd2ebf2b64d7e69bb766e2fea813521ed536f5d0520dcf86c"
+checksum = "8168378f4e5023e7218c89c891c0fd8ecdb5e5e4f18cb78f38cf245dd021e76f"
 dependencies = [
  "block-buffer",
  "crypto-common",
  "subtle",
 ]
 
 [[package]]
 name = "downcast"
 version = "0.11.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "1435fa1053d8b2fbbe9be7e97eca7f33d37b28409959813daefc1446a14247f1"
 
 [[package]]
 name = "either"
-version = "1.8.0"
+version = "1.8.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "90e5c1c8368803113bf0c9584fc495a58b86dc8a29edbf8fe877d21d9507e797"
+checksum = "7fcaabb2fef8c910e7f4c7ce9f67a1283a1715879a7c230ca9d6d1ae31f16d91"
 
 [[package]]
 name = "encoding_rs"
-version = "0.8.31"
+version = "0.8.32"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9852635589dc9f9ea1b6fe9f05b50ef208c85c834a562f0c6abb1c475736ec2b"
+checksum = "071a31f4ee85403370b58aca746f01041ede6f0da2730960ad001edc2b71b394"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
+name = "enum-iterator"
+version = "1.4.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "706d9e7cf1c7664859d79cd524e4e53ea2b67ea03c98cc2870c5e539695d597e"
+dependencies = [
+ "enum-iterator-derive",
+]
+
+[[package]]
+name = "enum-iterator-derive"
+version = "1.2.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "355f93763ef7b0ae1c43c4d8eccc9d5848d84ad1a1d8ce61c421d1ac85a19d05"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 1.0.109",
+]
+
+[[package]]
 name = "enum_dispatch"
-version = "0.3.8"
+version = "0.3.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0eb359f1476bf611266ac1f5355bc14aeca37b299d0ebccc038ee7058891c9cb"
+checksum = "11f36e95862220b211a6e2aa5eca09b4fa391b13cd52ceb8035a24bf65a79de2"
 dependencies = [
  "once_cell",
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
+]
+
+[[package]]
+name = "erased-serde"
+version = "0.3.25"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "4f2b0c2380453a92ea8b6c8e5f64ecaafccddde8ceab55ff7a8ac1029f894569"
+dependencies = [
+ "serde",
 ]
 
 [[package]]
-name = "event-listener"
-version = "2.5.3"
+name = "errno"
+version = "0.2.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0206175f82b8d6bf6652ff7d71a1e27fd2e4efde587fd368662814d6ec1d9ce0"
+checksum = "f639046355ee4f37944e44f60642c6f3a7efa3cf6b78c78a0d989a8ce6c396a1"
+dependencies = [
+ "errno-dragonfly",
+ "libc",
+ "winapi",
+]
+
+[[package]]
+name = "errno-dragonfly"
+version = "0.1.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "aa68f1b12764fab894d2755d2518754e71b4fd80ecfb822714a1206c2aab39bf"
+dependencies = [
+ "cc",
+ "libc",
+]
 
 [[package]]
 name = "fastrand"
-version = "1.8.0"
+version = "1.9.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a7a407cfaa3385c4ae6b23e84623d48c2798d06e3e6a1878f7f59f17b3f86499"
+checksum = "e51093e27b0797c359783294ca4f0a911c270184cb10f85783b118614a1501be"
 dependencies = [
  "instant",
 ]
 
 [[package]]
 name = "filetime"
-version = "0.2.17"
+version = "0.2.20"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e94a7bbaa59354bc20dd75b67f23e2797b4490e9d6928203fb105c79e448c86c"
+checksum = "8a3de6e8d11b22ff9edc6d916f890800597d60f8b2da1caf2955c274638d6412"
 dependencies = [
  "cfg-if",
  "libc",
  "redox_syscall",
- "windows-sys",
+ "windows-sys 0.45.0",
 ]
 
 [[package]]
 name = "fixedbitset"
 version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "0ce7134b9999ecaf8bcd65542e436736ef32ddca1b3e06094cb6ec5755203b80"
 
 [[package]]
 name = "flate2"
-version = "1.0.24"
+version = "1.0.25"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "f82b0f4c27ad9f8bfd1f3208d882da2b09c301bc1c828fd3a00d0216d2fbbff6"
+checksum = "a8a2db397cb1c8772f31494cb8917e48cd1e64f0fa7efac59fbd741a0a8ce841"
 dependencies = [
  "crc32fast",
  "miniz_oxide",
 ]
 
 [[package]]
 name = "float-cmp"
@@ -598,75 +638,75 @@
 checksum = "a9c384f161156f5260c24a097c56119f9be8c798586aecc13afbcbe7b7e26bf8"
 dependencies = [
  "percent-encoding",
 ]
 
 [[package]]
 name = "fragile"
-version = "1.2.1"
+version = "2.0.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "85dcb89d2b10c5f6133de2efd8c11959ce9dbb46a2f7a4cab208c4eeda6ce1ab"
+checksum = "6c2141d6d6c8512188a7891b4b01590a45f6dac67afb4f255c4124dbb86d4eaa"
 
 [[package]]
 name = "futures"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7f21eda599937fba36daeb58a22e8f5cee2d14c4a17b5b7739c7c8e5e3b8230c"
+checksum = "531ac96c6ff5fd7c62263c5e3c67a603af4fcaee2e1a0ae5565ba3a11e69e549"
 dependencies = [
  "futures-channel",
  "futures-core",
  "futures-executor",
  "futures-io",
  "futures-sink",
  "futures-task",
  "futures-util",
 ]
 
 [[package]]
 name = "futures-channel"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "30bdd20c28fadd505d0fd6712cdfcb0d4b5648baf45faef7f852afb2399bb050"
+checksum = "164713a5a0dcc3e7b4b1ed7d3b433cabc18025386f9339346e8daf15963cf7ac"
 dependencies = [
  "futures-core",
  "futures-sink",
 ]
 
 [[package]]
 name = "futures-core"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4e5aa3de05362c3fb88de6531e6296e85cde7739cccad4b9dfeeb7f6ebce56bf"
+checksum = "86d7a0c1aa76363dac491de0ee99faf6941128376f1cf96f07db7603b7de69dd"
 
 [[package]]
 name = "futures-executor"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9ff63c23854bee61b6e9cd331d523909f238fc7636290b96826e9cfa5faa00ab"
+checksum = "1997dd9df74cdac935c76252744c1ed5794fac083242ea4fe77ef3ed60ba0f83"
 dependencies = [
  "futures-core",
  "futures-task",
  "futures-util",
 ]
 
 [[package]]
 name = "futures-io"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bbf4d2a7a308fd4578637c0b17c7e1c7ba127b8f6ba00b29f717e9655d85eb68"
+checksum = "89d422fa3cbe3b40dca574ab087abb5bc98258ea57eea3fd6f1fa7162c778b91"
 
 [[package]]
 name = "futures-macro"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "42cd15d1c7456c04dbdf7e88bcd69760d74f3a798d6444e16974b505b0e62f17"
+checksum = "3eb14ed937631bd8b8b8977f2c198443447a8355b6e3ca599f38c975e5a963b6"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "futures-retry"
 version = "0.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "fde5a672a61f96552aa5ed9fd9c81c3fbdae4be9b1e205d6eaf17c83705adc0f"
@@ -674,35 +714,35 @@
  "futures",
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "futures-sink"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "21b20ba5a92e727ba30e72834706623d94ac93a725410b6a6b6fbc1b07f7ba56"
+checksum = "ec93083a4aecafb2a80a885c9de1f0ccae9dbd32c2bb54b0c3a65690e0b8d2f2"
 
 [[package]]
 name = "futures-task"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a6508c467c73851293f390476d4491cf4d227dbabcd4170f3bb6044959b294f1"
+checksum = "fd65540d33b37b16542a0438c12e6aeead10d4ac5d05bd3f805b8f35ab592879"
 
 [[package]]
 name = "futures-timer"
 version = "3.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e64b03909df88034c26dc1547e8970b91f98bdb65165d6a4e9110d94263dbb2c"
 
 [[package]]
 name = "futures-util"
-version = "0.3.24"
+version = "0.3.27"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "44fb6cb1be61cc1d2e43b262516aafcf63b241cffdb1d3fa115f91d9c7b09c90"
+checksum = "3ef6b17e481503ec85211fed8f39d1970f128935ca1f814cd32ac4a6842e84ab"
 dependencies = [
  "futures-channel",
  "futures-core",
  "futures-io",
  "futures-macro",
  "futures-sink",
  "futures-task",
@@ -720,28 +760,39 @@
 dependencies = [
  "typenum",
  "version_check",
 ]
 
 [[package]]
 name = "getrandom"
-version = "0.2.7"
+version = "0.2.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4eb1a864a501629691edf6c15a593b7a51eebaa1e8468e9ddc623de7c9b58ec6"
+checksum = "c05aeb6a22b8f62540c194aac980f2115af067bfe15a0734d7277a768d396b31"
 dependencies = [
  "cfg-if",
  "libc",
  "wasi 0.11.0+wasi-snapshot-preview1",
 ]
 
 [[package]]
+name = "ghost"
+version = "0.1.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "e77ac7b51b8e6313251737fcef4b1c01a2ea102bde68415b62c0ee9268fec357"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 2.0.8",
+]
+
+[[package]]
 name = "governor"
-version = "0.5.0"
+version = "0.5.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "de1b4626e87b9eb1d603ed23067ba1e29ec1d0b35325a2b96c3fe1cf20871f56"
+checksum = "c390a940a5d157878dd057c78680a33ce3415bcd05b4799509ea44210914b4d5"
 dependencies = [
  "cfg-if",
  "dashmap",
  "futures",
  "futures-timer",
  "no-std-compat",
  "nonzero_ext",
@@ -749,17 +800,17 @@
  "quanta",
  "rand",
  "smallvec",
 ]
 
 [[package]]
 name = "h2"
-version = "0.3.14"
+version = "0.3.16"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5ca32592cf21ac7ccab1825cd87f6c9b3d9022c44d086172ed0966bec8af30be"
+checksum = "5be7b54589b581f624f566bf5d8eb2bab1db736c51528720b6bd36b96b55924d"
 dependencies = [
  "bytes",
  "fnv",
  "futures-core",
  "futures-sink",
  "futures-util",
  "http",
@@ -771,47 +822,59 @@
 ]
 
 [[package]]
 name = "hashbrown"
 version = "0.12.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8a9ee70c43aaf417c914396645a0fa852624801b24ebb7ae78fe8272889ac888"
+
+[[package]]
+name = "hashbrown"
+version = "0.13.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "43a3c133739dddd0d2990f9a4bdf8eb4b21ef50e4851ca85ab661199821d510e"
 dependencies = [
  "ahash",
 ]
 
 [[package]]
 name = "heck"
-version = "0.4.0"
+version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2540771e65fc8cb83cd6e8a237f70c319bd5c29f78ed1084ba5d50eeac86f7f9"
+checksum = "95505c38b4572b2d910cecb0281560f54b440a19336cbbcb27bf6ce6adc6f5a8"
 
 [[package]]
 name = "hermit-abi"
-version = "0.1.19"
+version = "0.2.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "62b467343b94ba476dcb2500d242dadbb39557df889310ac77c5d99100aaac33"
+checksum = "ee512640fe35acbfb4bb779db6f0d80704c2cacfa2e39b601ef3e3f47d1ae4c7"
 dependencies = [
  "libc",
 ]
 
 [[package]]
+name = "hermit-abi"
+version = "0.3.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "fed44880c466736ef9a5c5b5facefb5ed0785676d0c02d612db14e54f0d84286"
+
+[[package]]
 name = "hmac"
 version = "0.12.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6c49c37c09c17a53d937dfbb742eb3a961d65a994e6bcdcf37e7399d0cc8ab5e"
 dependencies = [
  "digest",
 ]
 
 [[package]]
 name = "http"
-version = "0.2.8"
+version = "0.2.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "75f43d41e26995c17e71ee126451dd3941010b0514a81a9d11f3b341debc2399"
+checksum = "bd6effc99afb63425aff9b05836f029929e345a6148a14b7ecd5ab67af944482"
 dependencies = [
  "bytes",
  "fnv",
  "itoa",
 ]
 
 [[package]]
@@ -822,36 +885,30 @@
 dependencies = [
  "bytes",
  "http",
  "pin-project-lite",
 ]
 
 [[package]]
-name = "http-range-header"
-version = "0.3.0"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0bfe8eed0a9285ef776bb792479ea3834e8b94e13d615c2f66d03dd50a435a29"
-
-[[package]]
 name = "httparse"
 version = "1.8.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d897f394bad6a705d5f4104762e116a75639e470d80901eed05a860a95cb1904"
 
 [[package]]
 name = "httpdate"
 version = "1.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c4a1e36c821dbe04574f602848a19f742f4fb3c98d40449f11bcad18d6b17421"
 
 [[package]]
 name = "hyper"
-version = "0.14.20"
+version = "0.14.25"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "02c929dc5c39e335a03c405292728118860721b10190d98c2a0f0efd5baafbac"
+checksum = "cc5e554ff619822309ffd57d8734d77cd5ce6238bc956f037ea06c58238c9899"
 dependencies = [
  "bytes",
  "futures-channel",
  "futures-core",
  "futures-util",
  "h2",
  "http",
@@ -865,17 +922,17 @@
  "tower-service",
  "tracing",
  "want",
 ]
 
 [[package]]
 name = "hyper-rustls"
-version = "0.23.0"
+version = "0.23.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d87c48c02e0dc5e3b849a2041db3029fd066650f8f717c07bf8ed78ccb895cac"
+checksum = "1788965e61b367cd03a62950836d5cd41560c3577d90e40e0819373194d1661c"
 dependencies = [
  "http",
  "hyper",
  "rustls",
  "tokio",
  "tokio-rustls",
 ]
@@ -906,87 +963,114 @@
 dependencies = [
  "unicode-bidi",
  "unicode-normalization",
 ]
 
 [[package]]
 name = "indexmap"
-version = "1.9.1"
+version = "1.9.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "10a35a97730320ffe8e2d410b5d3b69279b98d2c14bdb8b70ea89ecf7888d41e"
+checksum = "1885e79c1fc4b10f0e172c475f458b7f7b93061064d98c3293e98c5ba0c8b399"
 dependencies = [
  "autocfg",
- "hashbrown",
+ "hashbrown 0.12.3",
 ]
 
 [[package]]
 name = "indoc"
-version = "1.0.7"
+version = "1.0.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "adab1eaa3408fb7f0c777a73e7465fd5656136fc93b670eb6df3c88c2c1344e3"
+checksum = "bfa799dd5ed20a7e349f3b4639aa80d74549c81716d9ec4f994c9b5815598306"
 
 [[package]]
 name = "instant"
 version = "0.1.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7a5bbe824c507c5da5956355e86a746d82e0e1464f65d862cc5e71da70e94b2c"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
+name = "inventory"
+version = "0.3.4"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "498ae1c9c329c7972b917506239b557a60386839192f1cf0ca034f345b65db99"
+dependencies = [
+ "ctor",
+ "ghost",
+]
+
+[[package]]
+name = "io-lifetimes"
+version = "1.0.9"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "09270fd4fa1111bc614ed2246c7ef56239a3063d5be0d1ec3b589c505d400aeb"
+dependencies = [
+ "hermit-abi 0.3.1",
+ "libc",
+ "windows-sys 0.45.0",
+]
+
+[[package]]
 name = "ipnet"
-version = "2.5.0"
+version = "2.7.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "879d54834c8c76457ef4293a689b2a8c59b076067ad77b15efafbb05f92a592b"
+checksum = "30e22bd8629359895450b59ea7a776c850561b96a3b1d31321c1949d9e6c9146"
 
 [[package]]
 name = "itertools"
 version = "0.10.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b0fd2260e829bddf4cb6ea802289de2f86d6a7a690192fbe91b3f46e0f2c8473"
 dependencies = [
  "either",
 ]
 
 [[package]]
 name = "itoa"
-version = "1.0.4"
+version = "1.0.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4217ad341ebadf8d8e724e264f13e593e0648f5b3e94b3896a5df283be015ecc"
+checksum = "453ad9f582a441959e5f0d088b02ce04cfe8d51a8eaf077f12ac6d3e94164ca6"
 
 [[package]]
 name = "jobserver"
-version = "0.1.25"
+version = "0.1.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "068b1ee6743e4d11fb9c6a1e6064b3693a1b600e7f5f5988047d98b3dc9fb90b"
+checksum = "936cfd212a0155903bcbc060e316fb6cc7cbf2e1907329391ebadc1fe0ce77c2"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "js-sys"
-version = "0.3.60"
+version = "0.3.61"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "49409df3e3bf0856b916e2ceaca09ee28e6871cf7d9ce97a692cacfdb2a25a47"
+checksum = "445dde2150c55e483f3d8416706b97ec8e8237c307e5b7b4b8dd15e6af2a0730"
 dependencies = [
  "wasm-bindgen",
 ]
 
 [[package]]
 name = "lazy_static"
 version = "1.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e2abad23fbc42b3700f2f279844dc832adb2b2eb069b2df918f455c4e18cc646"
 
 [[package]]
 name = "libc"
-version = "0.2.138"
+version = "0.2.140"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "db6d7e329c562c5dfab7a46a2afabc8b987ab9a4834c9d1ca04dc54c1546cef8"
+checksum = "99227334921fae1a979cf0bfdfcc6b3e5ce376ef57e16fb6fb3ea2ed6095f80c"
+
+[[package]]
+name = "linux-raw-sys"
+version = "0.1.4"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "f051f77a7c8e6957c0696eac88f26b0117e54f52d3fc682ab19397a8812846a4"
 
 [[package]]
 name = "lock_api"
 version = "0.4.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "435011366fe56583b16cf956f9df0095b405b82d76425bc8981c0e22e60ec4df"
 dependencies = [
@@ -1001,19 +1085,19 @@
 checksum = "abb12e687cfb44aa40f41fc3978ef76448f9b6038cad6aef4259d3c095a2382e"
 dependencies = [
  "cfg-if",
 ]
 
 [[package]]
 name = "lru"
-version = "0.8.1"
+version = "0.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "b6e8aaa3f231bb4bd57b84b2d5dc3ae7f350265df8aa96492e0bc394a1571909"
+checksum = "03f1160296536f10c833a82dca22267d5486734230d47bf00bf435885814ba1e"
 dependencies = [
- "hashbrown",
+ "hashbrown 0.13.2",
 ]
 
 [[package]]
 name = "mach"
 version = "0.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b823e83b2affd8f40a9ee8c29dbc56404c1e34cd2710921f2801e2cf29527afa"
@@ -1028,35 +1112,26 @@
 checksum = "8263075bb86c5a1b1427b5ae862e8889656f126e9f77c484496e8b47cf5c5558"
 dependencies = [
  "regex-automata",
 ]
 
 [[package]]
 name = "matchit"
-version = "0.5.0"
+version = "0.7.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "73cbba799671b762df5a175adf59ce145165747bb891505c43d09aefbbf38beb"
+checksum = "b87248edafb776e59e6ee64a79086f65890d3510f2c656c000bf2a7e8a0aea40"
 
 [[package]]
 name = "memchr"
 version = "2.5.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "2dffe52ecf27772e601905b7522cb4ef790d2cc203488bbd0e2fe85fcb74566d"
 
 [[package]]
 name = "memoffset"
-version = "0.6.5"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5aa361d4faea93603064a027415f07bd8e1d5c88c9fbf68bf56a285428fd79ce"
-dependencies = [
- "autocfg",
-]
-
-[[package]]
-name = "memoffset"
 version = "0.7.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5de893c32cde5f383baa4c04c5d6dbdd735cfd4a794b0debdb2bb1b421da5ff4"
 dependencies = [
  "autocfg",
 ]
 
@@ -1067,77 +1142,77 @@
 checksum = "d61c719bcfbcf5d62b3a09efa6088de8c54bc0bfcd3ea7ae39fcc186108b8de1"
 dependencies = [
  "autocfg",
 ]
 
 [[package]]
 name = "mime"
-version = "0.3.16"
+version = "0.3.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2a60c7ce501c71e03a9c9c0d35b861413ae925bd979cc7a4e30d060069aaac8d"
+checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"
 
 [[package]]
 name = "miniz_oxide"
-version = "0.5.4"
+version = "0.6.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "96590ba8f175222643a85693f33d26e9c8a015f599c216509b1a6894af675d34"
+checksum = "b275950c28b37e794e8c55d88aeb5e139d0ce23fdbbeda68f8d7174abdf9e8fa"
 dependencies = [
  "adler",
 ]
 
 [[package]]
 name = "mio"
-version = "0.8.4"
+version = "0.8.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "57ee1c23c7c63b0c9250c339ffdc69255f110b298b901b9f6c82547b7b87caaf"
+checksum = "5b9d9a46eff5b4ff64b45a9e316a6d1e0bc719ef429cbec4dc630684212bfdf9"
 dependencies = [
  "libc",
  "log",
  "wasi 0.11.0+wasi-snapshot-preview1",
- "windows-sys",
+ "windows-sys 0.45.0",
 ]
 
 [[package]]
 name = "mockall"
-version = "0.11.2"
+version = "0.11.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e2be9a9090bc1cac2930688fa9478092a64c6a92ddc6ae0692d46b37d9cab709"
+checksum = "50e4a1c770583dac7ab5e2f6c139153b783a53a1bbee9729613f193e59828326"
 dependencies = [
  "cfg-if",
  "downcast",
  "fragile",
  "lazy_static",
  "mockall_derive",
  "predicates",
  "predicates-tree",
 ]
 
 [[package]]
 name = "mockall_derive"
-version = "0.11.2"
+version = "0.11.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "86d702a0530a0141cf4ed147cf5ec7be6f2c187d4e37fcbefc39cf34116bfe8f"
+checksum = "832663583d5fa284ca8810bf7015e46c9fff9622d3cf34bd1eea5003fec06dd0"
 dependencies = [
  "cfg-if",
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "multimap"
 version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e5ce46fe64a9d73be07dcbe690a38ce1b293be448fd8ce1e6c1b8062c9f72c6a"
 
 [[package]]
 name = "nix"
-version = "0.26.1"
+version = "0.26.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "46a58d1d356c6597d08cde02c2f09d785b09e28711837b1ed667dc652c08a694"
+checksum = "bfdda3d196821d6af13126e40375cdf7da646a96114af134d5f417a9a1dc8e1a"
 dependencies = [
  "bitflags",
  "cfg-if",
  "libc",
  "memoffset 0.7.1",
  "pin-utils",
  "static_assertions",
@@ -1168,46 +1243,47 @@
 checksum = "77a8165726e8236064dbb45459242600304b42a5ea24ee2948e18e023bf7ba84"
 dependencies = [
  "overload",
  "winapi",
 ]
 
 [[package]]
-name = "num-traits"
-version = "0.2.15"
+name = "num-integer"
+version = "0.1.45"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "578ede34cf02f8924ab9447f50c28075b4d3e5b269972345e7e0372b38c6cdcd"
+checksum = "225d3389fb3509a24c93f5c29eb6bde2586b98d9f016636dff58d7c6f7569cd9"
 dependencies = [
  "autocfg",
+ "num-traits",
 ]
 
 [[package]]
-name = "num_cpus"
-version = "1.13.1"
+name = "num-traits"
+version = "0.2.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "19e64526ebdee182341572e50e9ad03965aa510cd94427a4549448f285e957a1"
+checksum = "578ede34cf02f8924ab9447f50c28075b4d3e5b269972345e7e0372b38c6cdcd"
 dependencies = [
- "hermit-abi",
- "libc",
+ "autocfg",
 ]
 
 [[package]]
-name = "num_threads"
-version = "0.1.6"
+name = "num_cpus"
+version = "1.15.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2819ce041d2ee131036f4fc9d6ae7ae125a3a40e97ba64d04fe799ad9dabbb44"
+checksum = "0fac9e2da13b5eb447a6ce3d392f23a29d8694bff781bf03a16cd9ac8697593b"
 dependencies = [
+ "hermit-abi 0.2.6",
  "libc",
 ]
 
 [[package]]
 name = "once_cell"
-version = "1.16.0"
+version = "1.17.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "86f0b0d4bf799edbc74508c1e8bf170ff5f41238e5f8225603ca7caaae2b7860"
+checksum = "b7e5500299e16ebb147ae15a00a942af264cf3688f47923b8fc2cd5858f23ad3"
 
 [[package]]
 name = "opaque-debug"
 version = "0.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "624a8340c38c1b80fd549087862da4ba43e08858af025b236e509b6649fc13d5"
 
@@ -1322,23 +1398,23 @@
 dependencies = [
  "lock_api",
  "parking_lot_core",
 ]
 
 [[package]]
 name = "parking_lot_core"
-version = "0.9.3"
+version = "0.9.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "09a279cbf25cb0757810394fbc1e359949b59e348145c643a939a525692e6929"
+checksum = "9069cbb9f99e3a5083476ccb29ceb1de18b9118cafa53e90c9551235de2b9521"
 dependencies = [
  "cfg-if",
  "libc",
  "redox_syscall",
  "smallvec",
- "windows-sys",
+ "windows-sys 0.45.0",
 ]
 
 [[package]]
 name = "password-hash"
 version = "0.4.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7676374caaee8a325c9e7a2ae557f216c5563a171d6997b0ef8a65af35147700"
@@ -1364,17 +1440,17 @@
 name = "percent-encoding"
 version = "2.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "478c572c3d73181ff3c2539045f6eb99e5491218eae919370993b890cdbdd98e"
 
 [[package]]
 name = "petgraph"
-version = "0.6.2"
+version = "0.6.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e6d5014253a1331579ce62aa67443b4a658c5e7dd03d4bc6d302b94474888143"
+checksum = "4dd7d28ee937e54fe3080c91faa1c3a46c06de6252988a7f4592ba2310ef22a4"
 dependencies = [
  "fixedbitset",
  "indexmap",
 ]
 
 [[package]]
 name = "pin-project"
@@ -1389,15 +1465,15 @@
 name = "pin-project-internal"
 version = "1.0.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "069bdb1e05adc7a8990dce9cc75370895fbe4e3d58b9b73bf1aee56359344a55"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "pin-project-lite"
 version = "0.2.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "e0a7ae3ac2f1173085d398531c705756c94a4c56843785df85a60c1a0afac116"
@@ -1406,142 +1482,189 @@
 name = "pin-utils"
 version = "0.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "8b870d8c151b6f2fb93e84a13146138f05d02ed11c7e7c54f8826aaaf7c9f184"
 
 [[package]]
 name = "pkg-config"
-version = "0.3.25"
+version = "0.3.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1df8c4ec4b0627e53bdf214615ad287367e482558cf84b109250b37464dc03ae"
+checksum = "6ac9a59f73473f1b8d852421e59e64809f025994837ef743615c6d0c5b305160"
 
 [[package]]
 name = "ppv-lite86"
-version = "0.2.16"
+version = "0.2.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "eb9f9e6e233e5c4a35559a617bf40a4ec447db2e84c20b55a6f83167b7e57872"
+checksum = "5b40af805b3121feab8a3c29f04d8ad262fa8e0561883e7653e024ae4479e6de"
 
 [[package]]
 name = "predicates"
-version = "2.1.1"
+version = "2.1.5"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a5aab5be6e4732b473071984b3164dbbfb7a3674d30ea5ff44410b6bcd960c3c"
+checksum = "59230a63c37f3e18569bdb90e4a89cbf5bf8b06fea0b84e65ea10cc4df47addd"
 dependencies = [
  "difflib",
  "float-cmp",
  "itertools",
  "normalize-line-endings",
  "predicates-core",
  "regex",
 ]
 
 [[package]]
 name = "predicates-core"
-version = "1.0.3"
+version = "1.0.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "da1c2388b1513e1b605fcec39a95e0a9e8ef088f71443ef37099fa9ae6673fcb"
+checksum = "b794032607612e7abeb4db69adb4e33590fa6cf1149e95fd7cb00e634b92f174"
 
 [[package]]
 name = "predicates-tree"
-version = "1.0.5"
+version = "1.0.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4d86de6de25020a36c6d3643a86d9a6a9f552107c0559c60ea03551b5e16c032"
+checksum = "368ba315fb8c5052ab692e68a0eefec6ec57b23a36959c14496f0b0df2c0cecf"
 dependencies = [
  "predicates-core",
  "termtree",
 ]
 
 [[package]]
 name = "prettyplease"
-version = "0.1.20"
+version = "0.1.25"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "83fead41e178796ef8274dc612a7d8ce4c7e10ca35cd2c5b5ad24cac63aeb6c0"
+checksum = "6c8646e95016a7a6c4adea95bafa8a16baab64b583356217f2c85db4a39d9a86"
 dependencies = [
  "proc-macro2",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "proc-macro2"
-version = "1.0.46"
+version = "1.0.53"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "94e2ef8dbfc347b10c094890f778ee2e36ca9bb4262e86dc99cd217e35f3470b"
+checksum = "ba466839c78239c09faf015484e5cc04860f88242cff4d03eb038f04b4699b73"
 dependencies = [
  "unicode-ident",
 ]
 
 [[package]]
 name = "prometheus"
-version = "0.13.2"
+version = "0.13.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "45c8babc29389186697fe5a2a4859d697825496b83db5d0b65271cdc0488e88c"
+checksum = "449811d15fbdf5ceb5c1144416066429cf82316e2ec8ce0c1f6f8a02e7bbcf8c"
 dependencies = [
  "cfg-if",
  "fnv",
  "lazy_static",
  "memchr",
  "parking_lot",
  "protobuf",
  "thiserror",
 ]
 
 [[package]]
 name = "prost"
-version = "0.11.0"
+version = "0.11.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "399c3c31cdec40583bb68f0b18403400d01ec4289c383aa047560439952c4dd7"
+checksum = "e48e50df39172a3e7eb17e14642445da64996989bc212b583015435d39a58537"
 dependencies = [
  "bytes",
  "prost-derive",
 ]
 
 [[package]]
 name = "prost-build"
-version = "0.11.1"
+version = "0.11.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7f835c582e6bd972ba8347313300219fed5bfa52caf175298d860b61ff6069bb"
+checksum = "2c828f93f5ca4826f97fedcbd3f9a536c16b12cff3dbbb4a007f932bbad95b12"
 dependencies = [
  "bytes",
  "heck",
  "itertools",
  "lazy_static",
  "log",
  "multimap",
  "petgraph",
+ "prettyplease",
  "prost",
  "prost-types",
  "regex",
+ "syn 1.0.109",
  "tempfile",
  "which",
 ]
 
 [[package]]
 name = "prost-derive"
-version = "0.11.0"
+version = "0.11.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "7345d5f0e08c0536d7ac7229952590239e77abf0a0100a1b1d890add6ea96364"
+checksum = "4ea9b0f8cbe5e15a8a042d030bd96668db28ecb567ec37d691971ff5731d2b1b"
 dependencies = [
  "anyhow",
  "itertools",
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "prost-types"
-version = "0.11.1"
+version = "0.11.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4dfaa718ad76a44b3415e6c4d53b17c8f99160dcb3a99b10470fce8ad43f6e3e"
+checksum = "379119666929a1afd7a043aa6cf96fa67a6dce9af60c88095a4686dbce4c9c88"
 dependencies = [
- "bytes",
  "prost",
 ]
 
 [[package]]
+name = "prost-wkt"
+version = "0.4.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "9f82196110c6376d25bf155f6d3a55835151d4f8ad470f203d46ee04c040d2fb"
+dependencies = [
+ "chrono",
+ "inventory",
+ "prost",
+ "serde",
+ "serde_derive",
+ "serde_json",
+ "typetag",
+]
+
+[[package]]
+name = "prost-wkt-build"
+version = "0.4.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8958d27269aec14c99c134ebb2796ab4287478bde21453d76aa43d1683265759"
+dependencies = [
+ "heck",
+ "prost",
+ "prost-build",
+ "prost-types",
+ "quote",
+]
+
+[[package]]
+name = "prost-wkt-types"
+version = "0.4.1"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "0c174ca3ca389b401547913b2a92aa9c08d849499138f962a771aedc9d77b2ce"
+dependencies = [
+ "chrono",
+ "prost",
+ "prost-build",
+ "prost-types",
+ "prost-wkt",
+ "prost-wkt-build",
+ "regex",
+ "serde",
+ "serde_derive",
+ "serde_json",
+]
+
+[[package]]
 name = "protobuf"
 version = "2.28.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "106dd99e98437432fed6519dedecfade6a06a73bb7b2a1e019fdd2bee5778d94"
 
 [[package]]
 name = "pyo3"
@@ -1598,26 +1721,26 @@
 version = "0.18.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "bd44cf207476c6a9760c4653559be4f206efafb924d3e4cbf2721475fc0d6cc5"
 dependencies = [
  "proc-macro2",
  "pyo3-macros-backend",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "pyo3-macros-backend"
 version = "0.18.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "dc1f43d8e30460f36350d18631ccf85ded64c059829208fe680904c65bcd0a4c"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "quanta"
 version = "0.9.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "20afe714292d5e879d8b12740aa223c6a88f118af41870e8b6196e39a02238a8"
@@ -1630,17 +1753,17 @@
  "wasi 0.10.2+wasi-snapshot-preview1",
  "web-sys",
  "winapi",
 ]
 
 [[package]]
 name = "quote"
-version = "1.0.21"
+version = "1.0.26"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bbe448f377a7d6961e30f5955f9b8d106c3f5e449d493ee1b125c1d43c2b5179"
+checksum = "4424af4bf778aae2051a77b60283332f386554255d722233d09fbfc7e30da2fc"
 dependencies = [
  "proc-macro2",
 ]
 
 [[package]]
 name = "rand"
 version = "0.8.5"
@@ -1669,17 +1792,17 @@
 checksum = "ec0be4795e2f6a28069bec0b5ff3e2ac9bafc99e6a9a7dc3547996c5c816922c"
 dependencies = [
  "getrandom",
 ]
 
 [[package]]
 name = "raw-cpuid"
-version = "10.6.0"
+version = "10.7.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a6823ea29436221176fe662da99998ad3b4db2c7f31e7b6f5fe43adccd6320bb"
+checksum = "6c297679cb867470fa8c9f67dbba74a78d78e3e98d7cf2b08d6d71540f797332"
 dependencies = [
  "bitflags",
 ]
 
 [[package]]
 name = "redox_syscall"
 version = "0.2.16"
@@ -1687,17 +1810,17 @@
 checksum = "fb5a58c1855b4b6819d59012155603f0b22ad30cad752600aadfcb695265519a"
 dependencies = [
  "bitflags",
 ]
 
 [[package]]
 name = "regex"
-version = "1.6.0"
+version = "1.7.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4c4eb3267174b8c6c2f654116623910a0fef09c4753f8dd83db29c48a0df988b"
+checksum = "cce168fea28d3e05f158bda4576cf0c844d5045bc2cc3620fa0292ed5bb5814c"
 dependencies = [
  "aho-corasick",
  "memchr",
  "regex-syntax",
 ]
 
 [[package]]
@@ -1707,34 +1830,25 @@
 checksum = "6c230d73fb8d8c1b9c0b3135c5142a8acee3a0558fb8db5cf1cb65f8d7862132"
 dependencies = [
  "regex-syntax",
 ]
 
 [[package]]
 name = "regex-syntax"
-version = "0.6.27"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a3f87b73ce11b1619a3c6332f45341e0047173771e8b8b73f87bfeefb7b56244"
-
-[[package]]
-name = "remove_dir_all"
-version = "0.5.3"
+version = "0.6.29"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3acd125665422973a33ac9d3dd2df85edad0f4ae9b00dafb1a05e43a9f5ef8e7"
-dependencies = [
- "winapi",
-]
+checksum = "f162c6dd7b008981e4d40210aca20b4bd0f9b60ca9271061b07f78537722f2e1"
 
 [[package]]
 name = "reqwest"
-version = "0.11.12"
+version = "0.11.15"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "431949c384f4e2ae07605ccaa56d1d9d2ecdb5cadd4f9577ccfab29f2e5149fc"
+checksum = "0ba30cc2c0cd02af1222ed216ba659cdb2f879dfe3181852fe7c50b1d0005949"
 dependencies = [
- "base64 0.13.0",
+ "base64 0.21.0",
  "bytes",
  "encoding_rs",
  "futures-core",
  "futures-util",
  "h2",
  "http",
  "http-body",
@@ -1755,14 +1869,15 @@
  "tokio",
  "tokio-rustls",
  "tokio-util",
  "tower-service",
  "url",
  "wasm-bindgen",
  "wasm-bindgen-futures",
+ "wasm-streams",
  "web-sys",
  "webpki-roots",
  "winreg",
 ]
 
 [[package]]
 name = "ring"
@@ -1777,17 +1892,17 @@
  "untrusted",
  "web-sys",
  "winapi",
 ]
 
 [[package]]
 name = "ringbuf"
-version = "0.3.1"
+version = "0.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "89e68dd9c1d8f7bb0c664e1556b1521809bc6fa62d92bb3b813adf8611caa0eb"
+checksum = "93ca10b9c9e53ac855a2d6953bce34cef6edbac32c4b13047a4d59d67299420a"
 dependencies = [
  "crossbeam-utils",
 ]
 
 [[package]]
 name = "rustc_version"
 version = "0.4.0"
@@ -1809,26 +1924,40 @@
 name = "rustfsm_procmacro"
 version = "0.1.0"
 dependencies = [
  "derive_more",
  "proc-macro2",
  "quote",
  "rustfsm_trait",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "rustfsm_trait"
 version = "0.1.0"
 
 [[package]]
+name = "rustix"
+version = "0.36.11"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "db4165c9963ab29e422d6c26fbc1d37f15bace6b2810221f9d925023480fcf0e"
+dependencies = [
+ "bitflags",
+ "errno",
+ "io-lifetimes",
+ "libc",
+ "linux-raw-sys",
+ "windows-sys 0.45.0",
+]
+
+[[package]]
 name = "rustls"
-version = "0.20.6"
+version = "0.20.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5aab8ee6c7097ed6057f43c187a62418d0c05a4bd5f18b3571db50ee0f9ce033"
+checksum = "fff78fc74d175294f4e83b28343315ffcfb114b156f0185e9741cb5570f50e2f"
 dependencies = [
  "log",
  "ring",
  "sct",
  "webpki",
 ]
 
@@ -1842,35 +1971,40 @@
  "rustls-pemfile",
  "schannel",
  "security-framework",
 ]
 
 [[package]]
 name = "rustls-pemfile"
-version = "1.0.1"
+version = "1.0.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0864aeff53f8c05aa08d86e5ef839d3dfcf07aeba2db32f12db0ef716e87bd55"
+checksum = "d194b56d58803a43635bdc398cd17e383d6f71f9182b9a192c127ca42494a59b"
 dependencies = [
- "base64 0.13.0",
+ "base64 0.21.0",
 ]
 
 [[package]]
+name = "rustversion"
+version = "1.0.12"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "4f3208ce4d8448b3f3e7d168a73f5e0c43a61e32930de3bceeccedb388b6bf06"
+
+[[package]]
 name = "ryu"
-version = "1.0.11"
+version = "1.0.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4501abdff3ae82a1c1b477a17252eb69cee9e66eb915c1abaa4f44d873df9f09"
+checksum = "f91339c0467de62360649f8d3e185ca8de4224ff281f66000de5eb2a77a79041"
 
 [[package]]
 name = "schannel"
-version = "0.1.20"
+version = "0.1.21"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "88d6731146462ea25d9244b2ed5fd1d716d25c52e4d54aa4fb0f3c4e9854dbe2"
+checksum = "713cfb06c7059f3588fb8044c0fad1d09e3c01d225e25b9220dbfdcf16dbb1b3"
 dependencies = [
- "lazy_static",
- "windows-sys",
+ "windows-sys 0.42.0",
 ]
 
 [[package]]
 name = "scopeguard"
 version = "1.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "d29ab0c6d3fc0ee92fe66e2d99f700eab17a8d57d1c1d3b748380fb20baa78cd"
@@ -1883,66 +2017,66 @@
 dependencies = [
  "ring",
  "untrusted",
 ]
 
 [[package]]
 name = "security-framework"
-version = "2.7.0"
+version = "2.8.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "2bc1bb97804af6631813c55739f771071e0f2ed33ee20b68c86ec505d906356c"
+checksum = "a332be01508d814fed64bf28f798a146d73792121129962fdf335bb3c49a4254"
 dependencies = [
  "bitflags",
  "core-foundation",
  "core-foundation-sys",
  "libc",
  "security-framework-sys",
 ]
 
 [[package]]
 name = "security-framework-sys"
-version = "2.6.1"
+version = "2.8.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0160a13a177a45bfb43ce71c01580998474f556ad854dcbca936dd2841a5c556"
+checksum = "31c9bb296072e961fcbd8853511dd39c2d8be2deb1e17c6860b1d30732b323b4"
 dependencies = [
  "core-foundation-sys",
  "libc",
 ]
 
 [[package]]
 name = "semver"
-version = "1.0.14"
+version = "1.0.17"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e25dfac463d778e353db5be2449d1cce89bd6fd23c9f1ea21310ce6e5a1b29c4"
+checksum = "bebd363326d05ec3e2f532ab7660680f3b02130d780c299bca73469d521bc0ed"
 
 [[package]]
 name = "serde"
-version = "1.0.145"
+version = "1.0.158"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "728eb6351430bccb993660dfffc5a72f91ccc1295abaa8ce19b27ebe4f75568b"
+checksum = "771d4d9c4163ee138805e12c710dd365e4f44be8be0503cb1bb9eb989425d9c9"
 dependencies = [
  "serde_derive",
 ]
 
 [[package]]
 name = "serde_derive"
-version = "1.0.145"
+version = "1.0.158"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "81fa1584d3d1bcacd84c277a0dfe21f5b0f6accf4a23d04d4c6d61f1af522b4c"
+checksum = "e801c1712f48475582b7696ac71e0ca34ebb30e09338425384269d9717c62cad"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 2.0.8",
 ]
 
 [[package]]
 name = "serde_json"
-version = "1.0.86"
+version = "1.0.94"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "41feea4228a6f1cd09ec7a3593a682276702cd67b5273544757dae23c096f074"
+checksum = "1c533a59c9d8a93a09c6ab31f0fd5e5f4dd1b8fc9434804029839884765d04ea"
 dependencies = [
  "itoa",
  "ryu",
  "serde",
 ]
 
 [[package]]
@@ -1986,32 +2120,32 @@
 checksum = "900fba806f70c630b0a382d0d825e17a0f19fcd059a2ade1ff237bcddf446b31"
 dependencies = [
  "lazy_static",
 ]
 
 [[package]]
 name = "signal-hook-registry"
-version = "1.4.0"
+version = "1.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e51e73328dc4ac0c7ccbda3a494dfa03df1de2f46018127f60c693f2648455b0"
+checksum = "d8229b473baa5980ac72ef434c4415e70c4b5e71b423043adb4ba059f89c99a1"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "siphasher"
 version = "0.3.10"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "7bd3e3206899af3f8b12af284fafc038cc1dc2b41d1b89dd17297221c5d225de"
 
 [[package]]
 name = "slab"
-version = "0.4.7"
+version = "0.4.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4614a76b2a8be0058caa9dbbaf66d988527d86d003c11a94fbd335d7661edcef"
+checksum = "6528351c9bc8ab22353f9d776db39a20288e8d6c37ef8cfe3317cf875eecfc2d"
 dependencies = [
  "autocfg",
 ]
 
 [[package]]
 name = "slotmap"
 version = "1.0.6"
@@ -2025,17 +2159,17 @@
 name = "smallvec"
 version = "1.10.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a507befe795404456341dfab10cef66ead4c041f62b8b11bbb92bffe5d0953e0"
 
 [[package]]
 name = "socket2"
-version = "0.4.7"
+version = "0.4.9"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "02e2d2db9033d13a1567121ddd7a095ee144db4e1ca1b1bda3419bc0da294ebd"
+checksum = "64a4a911eed85daf18834cfaa86a79b7d266ff93ff5ba14005426219480ed662"
 dependencies = [
  "libc",
  "winapi",
 ]
 
 [[package]]
 name = "spin"
@@ -2059,58 +2193,68 @@
 name = "subtle"
 version = "2.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "6bdef32e8150c2a081110b42772ffe7d7c9032b606bc226c8260fd97e0976601"
 
 [[package]]
 name = "syn"
-version = "1.0.102"
+version = "1.0.109"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "72b64191b275b66ffe2469e8af2c1cfe3bafa67b529ead792a6d0160888b4237"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "unicode-ident",
+]
+
+[[package]]
+name = "syn"
+version = "2.0.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3fcd952facd492f9be3ef0d0b7032a6e442ee9b361d4acc2b1d0c4aaa5f613a1"
+checksum = "bcc02725fd69ab9f26eab07fad303e2497fad6fb9eba4f96c4d1687bdf704ad9"
 dependencies = [
  "proc-macro2",
  "quote",
  "unicode-ident",
 ]
 
 [[package]]
 name = "sync_wrapper"
-version = "0.1.1"
+version = "0.1.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "20518fe4a4c9acf048008599e464deb21beeae3d3578418951a189c235a7a9a8"
+checksum = "2047c6ded9c721764247e62cd3b03c09ffc529b2ba5b10ec482ae507a4a70160"
 
 [[package]]
 name = "tar"
 version = "0.4.38"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4b55807c0344e1e6c04d7c965f5289c39a8d94ae23ed5c0b57aabac549f871c6"
 dependencies = [
  "filetime",
  "libc",
  "xattr",
 ]
 
 [[package]]
 name = "target-lexicon"
-version = "0.12.4"
+version = "0.12.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c02424087780c9b71cc96799eaeddff35af2bc513278cda5c99fc1f5d026d3c1"
+checksum = "8ae9980cab1db3fceee2f6c6f643d5d8de2997c58ee8d25fb0cc8a9e9e7348e5"
 
 [[package]]
 name = "tempfile"
-version = "3.3.0"
+version = "3.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5cdb1ef4eaeeaddc8fbd371e5017057064af0911902ef36b39801f67cc6d79e4"
+checksum = "af18f7ae1acd354b992402e9ec5864359d693cd8a79dcbef59f76891701c1e95"
 dependencies = [
  "cfg-if",
  "fastrand",
- "libc",
  "redox_syscall",
- "remove_dir_all",
- "winapi",
+ "rustix",
+ "windows-sys 0.42.0",
 ]
 
 [[package]]
 name = "temporal-client"
 version = "0.1.0"
 dependencies = [
  "anyhow",
@@ -2159,43 +2303,42 @@
 
 [[package]]
 name = "temporal-sdk-core"
 version = "0.1.0"
 dependencies = [
  "anyhow",
  "arc-swap",
- "async-channel",
  "async-trait",
- "base64 0.20.0",
+ "base64 0.21.0",
  "crossbeam",
  "dashmap",
  "derive_builder",
  "derive_more",
+ "enum-iterator",
  "enum_dispatch",
  "flate2",
  "futures",
  "futures-util",
  "governor",
  "http",
  "hyper",
  "itertools",
  "lazy_static",
- "log",
  "lru",
  "mockall",
  "nix",
  "once_cell",
  "opentelemetry",
  "opentelemetry-otlp",
  "opentelemetry-prometheus",
  "parking_lot",
  "pin-project",
  "prometheus",
  "prost",
- "prost-types",
+ "prost-wkt-types",
  "rand",
  "reqwest",
  "ringbuf",
  "rustfsm",
  "serde",
  "serde_json",
  "siphasher",
@@ -2221,150 +2364,152 @@
 
 [[package]]
 name = "temporal-sdk-core-api"
 version = "0.1.0"
 dependencies = [
  "async-trait",
  "derive_builder",
- "opentelemetry",
  "prost-types",
+ "serde",
  "serde_json",
  "temporal-client",
  "temporal-sdk-core-protos",
  "thiserror",
+ "tokio",
  "tonic",
  "tracing-core",
  "url",
 ]
 
 [[package]]
 name = "temporal-sdk-core-protos"
 version = "0.1.0"
 dependencies = [
  "anyhow",
- "base64 0.20.0",
+ "base64 0.21.0",
  "derive_more",
  "prost",
- "prost-types",
+ "prost-wkt",
+ "prost-wkt-build",
+ "prost-wkt-types",
  "rand",
  "serde",
  "serde_json",
  "thiserror",
  "tonic",
  "tonic-build",
  "uuid",
 ]
 
 [[package]]
 name = "termtree"
-version = "0.2.4"
+version = "0.4.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "507e9898683b6c43a9aa55b64259b721b52ba226e0f3779137e50ad114a4c90b"
+checksum = "3369f5ac52d5eb6ab48c6b4ffdc8efbcad6b89c765749064ba298f2c68a16a76"
 
 [[package]]
 name = "thiserror"
-version = "1.0.37"
+version = "1.0.40"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "10deb33631e3c9018b9baf9dcbbc4f737320d2b576bac10f6aefa048fa407e3e"
+checksum = "978c9a314bd8dc99be594bc3c175faaa9794be04a5a5e153caba6915336cebac"
 dependencies = [
  "thiserror-impl",
 ]
 
 [[package]]
 name = "thiserror-impl"
-version = "1.0.37"
+version = "1.0.40"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "982d17546b47146b28f7c22e3d08465f6b8903d0ea13c1660d9d84a6e7adcdbb"
+checksum = "f9456a42c5b0d803c8cd86e73dd7cc9edd429499f37a3550d286d5e86720569f"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 2.0.8",
 ]
 
 [[package]]
 name = "thread_local"
-version = "1.1.4"
+version = "1.1.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "5516c27b78311c50bf42c071425c560ac799b11c30b31f87e3081965fe5e0180"
+checksum = "3fdd6f064ccff2d6567adcb3873ca630700f00b5ad3f060c25b5dcfd9a4ce152"
 dependencies = [
+ "cfg-if",
  "once_cell",
 ]
 
 [[package]]
 name = "time"
-version = "0.3.15"
+version = "0.3.20"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d634a985c4d4238ec39cacaed2e7ae552fbd3c476b552c1deac3021b7d7eaf0c"
+checksum = "cd0cbfecb4d19b5ea75bb31ad904eb5b9fa13f21079c3b92017ebdf4999a5890"
 dependencies = [
- "itoa",
- "libc",
- "num_threads",
- "time-macros",
+ "serde",
+ "time-core",
 ]
 
 [[package]]
-name = "time-macros"
-version = "0.2.4"
+name = "time-core"
+version = "0.1.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "42657b1a6f4d817cda8e7a0ace261fe0cc946cf3a80314390b22cc61ae080792"
+checksum = "2e153e1f1acaef8acc537e68b44906d2db6436e2b35ac2c6b42640fff91f00fd"
 
 [[package]]
 name = "tinyvec"
 version = "1.6.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "87cc5ceb3875bb20c2890005a4e226a4651264a5c75edb2421b52861a0a0cb50"
 dependencies = [
  "tinyvec_macros",
 ]
 
 [[package]]
 name = "tinyvec_macros"
-version = "0.1.0"
+version = "0.1.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "cda74da7e1a664f795bb1f8a87ec406fb89a02522cf6e50620d016add6dbbf5c"
+checksum = "1f3ccbac311fea05f86f61904b462b55fb3df8837a366dfc601a0161d0532f20"
 
 [[package]]
 name = "tokio"
-version = "1.21.2"
+version = "1.26.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "a9e03c497dc955702ba729190dc4aac6f2a0ce97f913e5b1b5912fc5039d9099"
+checksum = "03201d01c3c27a29c8a5cee5b55a93ddae1ccf6f08f65365c2c918f8c1b76f64"
 dependencies = [
  "autocfg",
  "bytes",
  "libc",
  "memchr",
  "mio",
  "num_cpus",
  "parking_lot",
  "pin-project-lite",
  "signal-hook-registry",
  "socket2",
  "tokio-macros",
- "winapi",
+ "windows-sys 0.45.0",
 ]
 
 [[package]]
 name = "tokio-io-timeout"
 version = "1.2.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "30b74022ada614a1b4834de765f9bb43877f910cc8ce4be40e89042c9223a8bf"
 dependencies = [
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "tokio-macros"
-version = "1.8.0"
+version = "1.8.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9724f9a975fb987ef7a3cd9be0350edcbe130698af5b8f7a631e23d42d052484"
+checksum = "d266c00fde287f55d3f1c3e96c500c362a2b8c695076ec180f27918820bc6df8"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "tokio-rustls"
 version = "0.23.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c43ee83903113e03984cb9e5cebe6c04a5116269e900e3ddba8f068a62adda59"
@@ -2372,47 +2517,47 @@
  "rustls",
  "tokio",
  "webpki",
 ]
 
 [[package]]
 name = "tokio-stream"
-version = "0.1.11"
+version = "0.1.12"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "d660770404473ccd7bc9f8b28494a811bc18542b915c0855c51e8f419d5223ce"
+checksum = "8fb52b74f05dbf495a8fba459fdc331812b96aa086d9eb78101fa0d4569c3313"
 dependencies = [
  "futures-core",
  "pin-project-lite",
  "tokio",
 ]
 
 [[package]]
 name = "tokio-util"
-version = "0.7.4"
+version = "0.7.7"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "0bb2e075f03b3d66d8d8785356224ba688d2906a371015e225beeb65ca92c740"
+checksum = "5427d89453009325de0d8f342c9490009f76e999cb7672d77e46267448f7e6b2"
 dependencies = [
  "bytes",
  "futures-core",
  "futures-sink",
  "pin-project-lite",
  "tokio",
  "tracing",
 ]
 
 [[package]]
 name = "tonic"
-version = "0.8.2"
+version = "0.8.3"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "55b9af819e54b8f33d453655bef9b9acc171568fb49523078d0cc4e7484200ec"
+checksum = "8f219fad3b929bef19b1f86fbc0358d35daed8f2cac972037ac0dc10bbb8d5fb"
 dependencies = [
  "async-stream",
  "async-trait",
  "axum",
- "base64 0.13.0",
+ "base64 0.13.1",
  "bytes",
  "futures-core",
  "futures-util",
  "h2",
  "http",
  "http-body",
  "hyper",
@@ -2432,23 +2577,23 @@
  "tower-service",
  "tracing",
  "tracing-futures",
 ]
 
 [[package]]
 name = "tonic-build"
-version = "0.8.2"
+version = "0.8.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "48c6fd7c2581e36d63388a9e04c350c21beb7a8b059580b2e93993c526899ddc"
+checksum = "5bf5e9b9c0f7e0a7c027dcfaba7b2c60816c7049171f679d99ee2ff65d0de8c4"
 dependencies = [
  "prettyplease",
  "proc-macro2",
  "prost-build",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "tower"
 version = "0.4.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "b8fa9be0de6cf49e536ce1851f987bd21a43b771b09473c3549a6c853db37c1c"
@@ -2464,33 +2609,14 @@
  "tokio-util",
  "tower-layer",
  "tower-service",
  "tracing",
 ]
 
 [[package]]
-name = "tower-http"
-version = "0.3.4"
-source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "3c530c8675c1dbf98facee631536fa116b5fb6382d7dd6dc1b118d970eafe3ba"
-dependencies = [
- "bitflags",
- "bytes",
- "futures-core",
- "futures-util",
- "http",
- "http-body",
- "http-range-header",
- "pin-project-lite",
- "tower",
- "tower-layer",
- "tower-service",
-]
-
-[[package]]
 name = "tower-layer"
 version = "0.3.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "c20c8dbed6283a09604c3e69b4b7eeb54e298b8a600d4d5ecb5ad39de609f1d0"
 
 [[package]]
 name = "tower-service"
@@ -2515,15 +2641,15 @@
 name = "tracing-attributes"
 version = "0.1.23"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "4017f8f45139870ca7e672686113917c71c7a6e02d4924eda67186083c03081a"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
 ]
 
 [[package]]
 name = "tracing-core"
 version = "0.1.30"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "24eb03ba0eab1fd845050058ce5e616558e8f8d8fca633e6b163fe25c797213a"
@@ -2584,50 +2710,74 @@
  "tracing",
  "tracing-core",
  "tracing-log",
 ]
 
 [[package]]
 name = "try-lock"
-version = "0.2.3"
+version = "0.2.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "59547bce71d9c38b83d9c0e92b6066c4253371f15005def0c30d9657f50c7642"
+checksum = "3528ecfd12c466c6f163363caf2d02a71161dd5e1cc6ae7b34207ea2d42d81ed"
 
 [[package]]
 name = "typenum"
-version = "1.15.0"
+version = "1.16.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "dcf81ac59edc17cc8697ff311e8f5ef2d99fcbd9817b34cec66f90b6c3dfd987"
+checksum = "497961ef93d974e23eb6f433eb5fe1b7930b659f06d12dec6fc44a8f554c0bba"
+
+[[package]]
+name = "typetag"
+version = "0.2.7"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "edc3ebbaab23e6cc369cb48246769d031f5bd85f1b28141f32982e3c0c7b33cf"
+dependencies = [
+ "erased-serde",
+ "inventory",
+ "once_cell",
+ "serde",
+ "typetag-impl",
+]
+
+[[package]]
+name = "typetag-impl"
+version = "0.2.7"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "bb01b60fcc3f5e17babb1a9956263f3ccd2cadc3e52908400231441683283c1d"
+dependencies = [
+ "proc-macro2",
+ "quote",
+ "syn 2.0.8",
+]
 
 [[package]]
 name = "unicode-bidi"
-version = "0.3.8"
+version = "0.3.13"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "099b7128301d285f79ddd55b9a83d5e6b9e97c92e0ea0daebee7263e932de992"
+checksum = "92888ba5573ff080736b3648696b70cafad7d250551175acbaa4e0385b3e1460"
 
 [[package]]
 name = "unicode-ident"
-version = "1.0.5"
+version = "1.0.8"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "6ceab39d59e4c9499d4e5a8ee0e2735b891bb7308ac83dfb4e80cad195c9f6f3"
+checksum = "e5464a87b239f13a63a501f2701565754bae92d243d4bb7eb12f6d57d2269bf4"
 
 [[package]]
 name = "unicode-normalization"
 version = "0.1.22"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "5c5713f0fc4b5db668a2ac63cdb7bb4469d8c9fed047b1d0292cc7b0ce2ba921"
 dependencies = [
  "tinyvec",
 ]
 
 [[package]]
 name = "unindent"
-version = "0.1.10"
+version = "0.1.11"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "58ee9362deb4a96cef4d437d1ad49cffc9b9e92d202b6995674e928ce684f112"
+checksum = "e1766d682d402817b5ac4490b3c3002d91dfa0d22812f341609f97b08757359c"
 
 [[package]]
 name = "untrusted"
 version = "0.7.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "a156c684c91ea7d62626509bce3cb4e1d9ed5c4d978f7b4352658f96a4c26b4a"
 
@@ -2640,17 +2790,17 @@
  "form_urlencoded",
  "idna",
  "percent-encoding",
 ]
 
 [[package]]
 name = "uuid"
-version = "1.2.1"
+version = "1.3.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "feb41e78f93363bb2df8b0e86a2ca30eed7806ea16ea0c790d757cf93f79be83"
+checksum = "1674845326ee10d37ca60470760d4288a6f80f304007d92e5c53bab78c9cfd79"
 dependencies = [
  "getrandom",
 ]
 
 [[package]]
 name = "valuable"
 version = "0.1.0"
@@ -2683,83 +2833,96 @@
 name = "wasi"
 version = "0.11.0+wasi-snapshot-preview1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "9c8d87e72b64a3b4db28d11ce29237c246188f4f51057d65a7eab63b7987e423"
 
 [[package]]
 name = "wasm-bindgen"
-version = "0.2.83"
+version = "0.2.84"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "eaf9f5aceeec8be17c128b2e93e031fb8a4d469bb9c4ae2d7dc1888b26887268"
+checksum = "31f8dcbc21f30d9b8f2ea926ecb58f6b91192c17e9d33594b3df58b2007ca53b"
 dependencies = [
  "cfg-if",
  "wasm-bindgen-macro",
 ]
 
 [[package]]
 name = "wasm-bindgen-backend"
-version = "0.2.83"
+version = "0.2.84"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4c8ffb332579b0557b52d268b91feab8df3615f265d5270fec2a8c95b17c1142"
+checksum = "95ce90fd5bcc06af55a641a86428ee4229e44e07033963a2290a8e241607ccb9"
 dependencies = [
  "bumpalo",
  "log",
  "once_cell",
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-futures"
-version = "0.4.33"
+version = "0.4.34"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "23639446165ca5a5de86ae1d8896b737ae80319560fbaa4c2887b7da6e7ebd7d"
+checksum = "f219e0d211ba40266969f6dbdd90636da12f75bee4fc9d6c23d1260dadb51454"
 dependencies = [
  "cfg-if",
  "js-sys",
  "wasm-bindgen",
  "web-sys",
 ]
 
 [[package]]
 name = "wasm-bindgen-macro"
-version = "0.2.83"
+version = "0.2.84"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "052be0f94026e6cbc75cdefc9bae13fd6052cdcaf532fa6c45e7ae33a1e6c810"
+checksum = "4c21f77c0bedc37fd5dc21f897894a5ca01e7bb159884559461862ae90c0b4c5"
 dependencies = [
  "quote",
  "wasm-bindgen-macro-support",
 ]
 
 [[package]]
 name = "wasm-bindgen-macro-support"
-version = "0.2.83"
+version = "0.2.84"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "07bc0c051dc5f23e307b13285f9d75df86bfdf816c5721e573dec1f9b8aa193c"
+checksum = "2aff81306fcac3c7515ad4e177f521b5c9a15f2b08f4e32d823066102f35a5f6"
 dependencies = [
  "proc-macro2",
  "quote",
- "syn",
+ "syn 1.0.109",
  "wasm-bindgen-backend",
  "wasm-bindgen-shared",
 ]
 
 [[package]]
 name = "wasm-bindgen-shared"
-version = "0.2.83"
+version = "0.2.84"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1c38c045535d93ec4f0b4defec448e4291638ee608530863b1e2ba115d4fff7f"
+checksum = "0046fef7e28c3804e5e38bfa31ea2a0f73905319b677e57ebe37e49358989b5d"
+
+[[package]]
+name = "wasm-streams"
+version = "0.2.3"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "6bbae3363c08332cadccd13b67db371814cd214c2524020932f0804b8cf7c078"
+dependencies = [
+ "futures-util",
+ "js-sys",
+ "wasm-bindgen",
+ "wasm-bindgen-futures",
+ "web-sys",
+]
 
 [[package]]
 name = "web-sys"
-version = "0.3.60"
+version = "0.3.61"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "bcda906d8be16e728fd5adc5b729afad4e444e106ab28cd1c7256e54fa61510f"
+checksum = "e33b99f4b23ba3eec1a53ac264e35a755f00e966e0065077d6027c0f575b0b97"
 dependencies = [
  "js-sys",
  "wasm-bindgen",
 ]
 
 [[package]]
 name = "webpki"
@@ -2769,26 +2932,26 @@
 dependencies = [
  "ring",
  "untrusted",
 ]
 
 [[package]]
 name = "webpki-roots"
-version = "0.22.5"
+version = "0.22.6"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "368bfe657969fb01238bb756d351dcade285e0f6fcbd36dcb23359a5169975be"
+checksum = "b6c71e40d7d2c34a5106301fb632274ca37242cd0c9d3e64dbece371a40a2d87"
 dependencies = [
  "webpki",
 ]
 
 [[package]]
 name = "which"
-version = "4.3.0"
+version = "4.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "1c831fbbee9e129a8cf93e7747a82da9d95ba8e16621cae60ec2cdc849bacb7b"
+checksum = "2441c784c52b289a054b7201fc93253e288f094e2f4be9058343127c4226a269"
 dependencies = [
  "either",
  "libc",
  "once_cell",
 ]
 
 [[package]]
@@ -2811,54 +2974,92 @@
 name = "winapi-x86_64-pc-windows-gnu"
 version = "0.4.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"
 
 [[package]]
 name = "windows-sys"
-version = "0.36.1"
+version = "0.42.0"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "5a3e1820f08b8513f676f7ab6c1f99ff312fb97b553d30ff4dd86f9f15728aa7"
+dependencies = [
+ "windows_aarch64_gnullvm",
+ "windows_aarch64_msvc",
+ "windows_i686_gnu",
+ "windows_i686_msvc",
+ "windows_x86_64_gnu",
+ "windows_x86_64_gnullvm",
+ "windows_x86_64_msvc",
+]
+
+[[package]]
+name = "windows-sys"
+version = "0.45.0"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "ea04155a16a59f9eab786fe12a4a450e75cdb175f9e0d80da1e17db09f55b8d2"
+checksum = "75283be5efb2831d37ea142365f009c02ec203cd29a3ebecbc093d52315b66d0"
 dependencies = [
+ "windows-targets",
+]
+
+[[package]]
+name = "windows-targets"
+version = "0.42.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8e5180c00cd44c9b1c88adb3693291f1cd93605ded80c250a75d472756b4d071"
+dependencies = [
+ "windows_aarch64_gnullvm",
  "windows_aarch64_msvc",
  "windows_i686_gnu",
  "windows_i686_msvc",
  "windows_x86_64_gnu",
+ "windows_x86_64_gnullvm",
  "windows_x86_64_msvc",
 ]
 
 [[package]]
+name = "windows_aarch64_gnullvm"
+version = "0.42.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "597a5118570b68bc08d8d59125332c54f1ba9d9adeedeef5b99b02ba2b0698f8"
+
+[[package]]
 name = "windows_aarch64_msvc"
-version = "0.36.1"
+version = "0.42.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9bb8c3fd39ade2d67e9874ac4f3db21f0d710bee00fe7cab16949ec184eeaa47"
+checksum = "e08e8864a60f06ef0d0ff4ba04124db8b0fb3be5776a5cd47641e942e58c4d43"
 
 [[package]]
 name = "windows_i686_gnu"
-version = "0.36.1"
+version = "0.42.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "180e6ccf01daf4c426b846dfc66db1fc518f074baa793aa7d9b9aaeffad6a3b6"
+checksum = "c61d927d8da41da96a81f029489353e68739737d3beca43145c8afec9a31a84f"
 
 [[package]]
 name = "windows_i686_msvc"
-version = "0.36.1"
+version = "0.42.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "e2e7917148b2812d1eeafaeb22a97e4813dfa60a3f8f78ebe204bcc88f12f024"
+checksum = "44d840b6ec649f480a41c8d80f9c65108b92d89345dd94027bfe06ac444d1060"
 
 [[package]]
 name = "windows_x86_64_gnu"
-version = "0.36.1"
+version = "0.42.2"
+source = "registry+https://github.com/rust-lang/crates.io-index"
+checksum = "8de912b8b8feb55c064867cf047dda097f92d51efad5b491dfb98f6bbb70cb36"
+
+[[package]]
+name = "windows_x86_64_gnullvm"
+version = "0.42.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "4dcd171b8776c41b97521e5da127a2d86ad280114807d0b2ab1e462bc764d9e1"
+checksum = "26d41b46a36d453748aedef1486d5c7a85db22e56aff34643984ea85514e94a3"
 
 [[package]]
 name = "windows_x86_64_msvc"
-version = "0.36.1"
+version = "0.42.2"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "c811ca4a8c853ef420abd8592ba53ddbbac90410fab6903b3e79972a631f7680"
+checksum = "9aec5da331524158c6d1a4ac0ab1541149c0b9505fde06423b02f5ef0106b9f0"
 
 [[package]]
 name = "winreg"
 version = "0.10.1"
 source = "registry+https://github.com/rust-lang/crates.io-index"
 checksum = "80d0f4e272c85def139476380b12f9ac60926689dd2e01d4923222f40580869d"
 dependencies = [
@@ -2872,17 +3073,17 @@
 checksum = "6d1526bbe5aaeb5eb06885f4d987bcdfa5e23187055de9b83fe00156a821fabc"
 dependencies = [
  "libc",
 ]
 
 [[package]]
 name = "zip"
-version = "0.6.3"
+version = "0.6.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "537ce7411d25e54e8ae21a7ce0b15840e7bfcff15b51d697ec3266cc76bdf080"
+checksum = "0445d0fbc924bb93539b4316c11afb121ea39296f99a3c4c9edad09e3658cdef"
 dependencies = [
  "aes",
  "byteorder",
  "bzip2",
  "constant_time_eq",
  "crc32fast",
  "crossbeam-utils",
@@ -2911,14 +3112,15 @@
 dependencies = [
  "libc",
  "zstd-sys",
 ]
 
 [[package]]
 name = "zstd-sys"
-version = "2.0.1+zstd.1.5.2"
+version = "2.0.7+zstd.1.5.4"
 source = "registry+https://github.com/rust-lang/crates.io-index"
-checksum = "9fd07cbbc53846d9145dbffdf6dd09a7a0aa52be46741825f5c97bdd4f73f12b"
+checksum = "94509c3ba2fe55294d752b79842c530ccfab760192521df74a081a78d2b3c7f5"
 dependencies = [
  "cc",
  "libc",
+ "pkg-config",
 ]
```

### Comparing `temporalio-1.1.0/temporalio/bridge/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/Cargo.toml`

 * *Files 2% similar despite different names*

```diff
@@ -15,15 +15,15 @@
 prost-types = "0.11"
 pyo3 = { version = "0.18", features = ["extension-module", "abi3-py37"] }
 pyo3-asyncio = { version = "0.18", features = ["tokio-runtime"] }
 temporal-client = { version = "0.1.0", path = "./sdk-core/client" }
 temporal-sdk-core = { version = "0.1.0", path = "./sdk-core/core" }
 temporal-sdk-core-api = { version = "0.1.0", path = "./sdk-core/core-api" }
 temporal-sdk-core-protos = { version = "0.1.0", path = "./sdk-core/sdk-core-protos" }
-tokio = "1.15"
+tokio = "1.26"
 tokio-stream = "0.1"
 tonic = "0.8"
 tracing = "0.1"
 url = "2.2"
 
 [profile.release]
 opt-level = 3
```

### Comparing `temporalio-1.1.0/temporalio/bridge/client.py` & `temporalio-1.2.0/temporalio/bridge/client.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -20,15 +20,15 @@
     message_pb2 as temporal_dot_api_dot_common_dot_v1_dot_message__pb2,
 )
 from temporalio.api.failure.v1 import (
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n7temporal/sdk/core/activity_result/activity_result.proto\x12\x17\x63oresdk.activity_result\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto"\x95\x02\n\x17\x41\x63tivityExecutionResult\x12\x35\n\tcompleted\x18\x01 \x01(\x0b\x32 .coresdk.activity_result.SuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32 .coresdk.activity_result.FailureH\x00\x12:\n\tcancelled\x18\x03 \x01(\x0b\x32%.coresdk.activity_result.CancellationH\x00\x12I\n\x13will_complete_async\x18\x04 \x01(\x0b\x32*.coresdk.activity_result.WillCompleteAsyncH\x00\x42\x08\n\x06status"\xfc\x01\n\x12\x41\x63tivityResolution\x12\x35\n\tcompleted\x18\x01 \x01(\x0b\x32 .coresdk.activity_result.SuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32 .coresdk.activity_result.FailureH\x00\x12:\n\tcancelled\x18\x03 \x01(\x0b\x32%.coresdk.activity_result.CancellationH\x00\x12\x35\n\x07\x62\x61\x63koff\x18\x04 \x01(\x0b\x32".coresdk.activity_result.DoBackoffH\x00\x42\x08\n\x06status":\n\x07Success\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"<\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"A\n\x0c\x43\x61ncellation\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\x13\n\x11WillCompleteAsync"\x8d\x01\n\tDoBackoff\x12\x0f\n\x07\x61ttempt\x18\x01 \x01(\r\x12\x33\n\x10\x62\x61\x63koff_duration\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12:\n\x16original_schedule_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.Timestampb\x06proto3'
+    b'\n7temporal/sdk/core/activity_result/activity_result.proto\x12\x17\x63oresdk.activity_result\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto"\x95\x02\n\x17\x41\x63tivityExecutionResult\x12\x35\n\tcompleted\x18\x01 \x01(\x0b\x32 .coresdk.activity_result.SuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32 .coresdk.activity_result.FailureH\x00\x12:\n\tcancelled\x18\x03 \x01(\x0b\x32%.coresdk.activity_result.CancellationH\x00\x12I\n\x13will_complete_async\x18\x04 \x01(\x0b\x32*.coresdk.activity_result.WillCompleteAsyncH\x00\x42\x08\n\x06status"\xfc\x01\n\x12\x41\x63tivityResolution\x12\x35\n\tcompleted\x18\x01 \x01(\x0b\x32 .coresdk.activity_result.SuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32 .coresdk.activity_result.FailureH\x00\x12:\n\tcancelled\x18\x03 \x01(\x0b\x32%.coresdk.activity_result.CancellationH\x00\x12\x35\n\x07\x62\x61\x63koff\x18\x04 \x01(\x0b\x32".coresdk.activity_result.DoBackoffH\x00\x42\x08\n\x06status":\n\x07Success\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"<\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"A\n\x0c\x43\x61ncellation\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\x13\n\x11WillCompleteAsync"\x8d\x01\n\tDoBackoff\x12\x0f\n\x07\x61ttempt\x18\x01 \x01(\r\x12\x33\n\x10\x62\x61\x63koff_duration\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration\x12:\n\x16original_schedule_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampB*\xea\x02\'Temporalio::Bridge::Api::ActivityResultb\x06proto3'
 )
 
 
 _ACTIVITYEXECUTIONRESULT = DESCRIPTOR.message_types_by_name["ActivityExecutionResult"]
 _ACTIVITYRESOLUTION = DESCRIPTOR.message_types_by_name["ActivityResolution"]
 _SUCCESS = DESCRIPTOR.message_types_by_name["Success"]
 _FAILURE = DESCRIPTOR.message_types_by_name["Failure"]
@@ -110,14 +110,15 @@
         # @@protoc_insertion_point(class_scope:coresdk.activity_result.DoBackoff)
     },
 )
 _sym_db.RegisterMessage(DoBackoff)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002'Temporalio::Bridge::Api::ActivityResult"
     _ACTIVITYEXECUTIONRESULT._serialized_start = 227
     _ACTIVITYEXECUTIONRESULT._serialized_end = 504
     _ACTIVITYRESOLUTION._serialized_start = 507
     _ACTIVITYRESOLUTION._serialized_end = 759
     _SUCCESS._serialized_start = 761
     _SUCCESS._serialized_end = 819
     _FAILURE._serialized_start = 821
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/activity_result/activity_result_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -15,17 +15,15 @@
     import typing as typing_extensions
 else:
     import typing_extensions
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
 class ActivityExecutionResult(google.protobuf.message.Message):
-    """*
-    Used to report activity completions to core
-    """
+    """Used to report activity completions to core"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMPLETED_FIELD_NUMBER: builtins.int
     FAILED_FIELD_NUMBER: builtins.int
     CANCELLED_FIELD_NUMBER: builtins.int
     WILL_COMPLETE_ASYNC_FIELD_NUMBER: builtins.int
@@ -148,15 +146,15 @@
     ) -> (
         typing_extensions.Literal["completed", "failed", "cancelled", "backoff"] | None
     ): ...
 
 global___ActivityResolution = ActivityResolution
 
 class Success(google.protobuf.message.Message):
-    """* Used to report successful completion either when executing or resolving"""
+    """Used to report successful completion either when executing or resolving"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RESULT_FIELD_NUMBER: builtins.int
     @property
     def result(self) -> temporalio.api.common.v1.message_pb2.Payload: ...
     def __init__(
@@ -170,15 +168,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["result", b"result"]
     ) -> None: ...
 
 global___Success = Success
 
 class Failure(google.protobuf.message.Message):
-    """* Used to report activity failure either when executing or resolving"""
+    """Used to report activity failure either when executing or resolving"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
     def __init__(
@@ -192,15 +190,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["failure", b"failure"]
     ) -> None: ...
 
 global___Failure = Failure
 
 class Cancellation(google.protobuf.message.Message):
-    """*
+    """
     Used to report cancellation from both Core and Lang.
     When Lang reports a cancelled activity, it must put a CancelledFailure in the failure field.
     When Core reports a cancelled activity, it must put an ActivityFailure with CancelledFailure
     as the cause in the failure field.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
@@ -219,29 +217,29 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["failure", b"failure"]
     ) -> None: ...
 
 global___Cancellation = Cancellation
 
 class WillCompleteAsync(google.protobuf.message.Message):
-    """*
+    """
     Used in ActivityExecutionResult to notify Core that this Activity will complete asynchronously.
     Core will forget about this Activity and free up resources used to track this Activity.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     def __init__(
         self,
     ) -> None: ...
 
 global___WillCompleteAsync = WillCompleteAsync
 
 class DoBackoff(google.protobuf.message.Message):
-    """*
+    """
     Issued when a local activity needs to retry but also wants to back off more than would be
     reasonable to WFT heartbeat for. Lang is expected to schedule a timer for the duration
     and then start a local activity of the same type & same inputs with the provided attempt number
     after the timer has elapsed.
 
     This exists because Core does not have a concept of starting commands by itself, they originate
     from lang. So expecting lang to start the timer / next pass of the activity fits more smoothly.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,22 +21,23 @@
     message_pb2 as temporal_dot_api_dot_common_dot_v1_dot_message__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n3temporal/sdk/core/activity_task/activity_task.proto\x12\x15\x63oresdk.activity_task\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/sdk/core/common/common.proto"\x8d\x01\n\x0c\x41\x63tivityTask\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12-\n\x05start\x18\x03 \x01(\x0b\x32\x1c.coresdk.activity_task.StartH\x00\x12/\n\x06\x63\x61ncel\x18\x04 \x01(\x0b\x32\x1d.coresdk.activity_task.CancelH\x00\x42\t\n\x07variant"\xed\x06\n\x05Start\x12\x1a\n\x12workflow_namespace\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x15\n\ractivity_type\x18\x05 \x01(\t\x12\x45\n\rheader_fields\x18\x06 \x03(\x0b\x32..coresdk.activity_task.Start.HeaderFieldsEntry\x12.\n\x05input\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12:\n\x11heartbeat_details\x18\x08 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x32\n\x0escheduled_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x42\n\x1e\x63urrent_attempt_scheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x30\n\x0cstarted_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x0f\n\x07\x61ttempt\x18\x0c \x01(\r\x12<\n\x19schedule_to_close_timeout\x18\r \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x10\n\x08is_local\x18\x11 \x01(\x08\x1aT\n\x11HeaderFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"E\n\x06\x43\x61ncel\x12;\n\x06reason\x18\x01 \x01(\x0e\x32+.coresdk.activity_task.ActivityCancelReason*C\n\x14\x41\x63tivityCancelReason\x12\r\n\tNOT_FOUND\x10\x00\x12\r\n\tCANCELLED\x10\x01\x12\r\n\tTIMED_OUT\x10\x02\x62\x06proto3'
+    b'\n3temporal/sdk/core/activity_task/activity_task.proto\x12\x15\x63oresdk.activity_task\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a%temporal/sdk/core/common/common.proto"\x8d\x01\n\x0c\x41\x63tivityTask\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12-\n\x05start\x18\x03 \x01(\x0b\x32\x1c.coresdk.activity_task.StartH\x00\x12/\n\x06\x63\x61ncel\x18\x04 \x01(\x0b\x32\x1d.coresdk.activity_task.CancelH\x00\x42\t\n\x07variant"\xed\x06\n\x05Start\x12\x1a\n\x12workflow_namespace\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12\x45\n\x12workflow_execution\x18\x03 \x01(\x0b\x32).temporal.api.common.v1.WorkflowExecution\x12\x13\n\x0b\x61\x63tivity_id\x18\x04 \x01(\t\x12\x15\n\ractivity_type\x18\x05 \x01(\t\x12\x45\n\rheader_fields\x18\x06 \x03(\x0b\x32..coresdk.activity_task.Start.HeaderFieldsEntry\x12.\n\x05input\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12:\n\x11heartbeat_details\x18\x08 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x32\n\x0escheduled_time\x18\t \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x42\n\x1e\x63urrent_attempt_scheduled_time\x18\n \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x30\n\x0cstarted_time\x18\x0b \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x0f\n\x07\x61ttempt\x18\x0c \x01(\r\x12<\n\x19schedule_to_close_timeout\x18\r \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\x0e \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0f \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x10\n\x08is_local\x18\x11 \x01(\x08\x1aT\n\x11HeaderFieldsEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"E\n\x06\x43\x61ncel\x12;\n\x06reason\x18\x01 \x01(\x0e\x32+.coresdk.activity_task.ActivityCancelReason*X\n\x14\x41\x63tivityCancelReason\x12\r\n\tNOT_FOUND\x10\x00\x12\r\n\tCANCELLED\x10\x01\x12\r\n\tTIMED_OUT\x10\x02\x12\x13\n\x0fWORKER_SHUTDOWN\x10\x03\x42(\xea\x02%Temporalio::Bridge::Api::ActivityTaskb\x06proto3'
 )
 
 _ACTIVITYCANCELREASON = DESCRIPTOR.enum_types_by_name["ActivityCancelReason"]
 ActivityCancelReason = enum_type_wrapper.EnumTypeWrapper(_ACTIVITYCANCELREASON)
 NOT_FOUND = 0
 CANCELLED = 1
 TIMED_OUT = 2
+WORKER_SHUTDOWN = 3
 
 
 _ACTIVITYTASK = DESCRIPTOR.message_types_by_name["ActivityTask"]
 _START = DESCRIPTOR.message_types_by_name["Start"]
 _START_HEADERFIELDSENTRY = _START.nested_types_by_name["HeaderFieldsEntry"]
 _CANCEL = DESCRIPTOR.message_types_by_name["Cancel"]
 ActivityTask = _reflection.GeneratedProtocolMessageType(
@@ -80,18 +81,19 @@
         # @@protoc_insertion_point(class_scope:coresdk.activity_task.Cancel)
     },
 )
 _sym_db.RegisterMessage(Cancel)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002%Temporalio::Bridge::Api::ActivityTask"
     _START_HEADERFIELDSENTRY._options = None
     _START_HEADERFIELDSENTRY._serialized_options = b"8\001"
     _ACTIVITYCANCELREASON._serialized_start = 1315
-    _ACTIVITYCANCELREASON._serialized_end = 1382
+    _ACTIVITYCANCELREASON._serialized_end = 1403
     _ACTIVITYTASK._serialized_start = 221
     _ACTIVITYTASK._serialized_end = 362
     _START._serialized_start = 365
     _START._serialized_end = 1242
     _START_HEADERFIELDSENTRY._serialized_start = 1158
     _START_HEADERFIELDSENTRY._serialized_end = 1242
     _CANCEL._serialized_start = 1244
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/activity_task/activity_task_pb2.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -31,46 +31,50 @@
     google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[
         _ActivityCancelReason.ValueType
     ],
     builtins.type,
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     NOT_FOUND: _ActivityCancelReason.ValueType  # 0
-    """/ The activity no longer exists according to server (may be already completed)"""
+    """The activity no longer exists according to server (may be already completed)"""
     CANCELLED: _ActivityCancelReason.ValueType  # 1
-    """/ Activity was explicitly cancelled"""
+    """Activity was explicitly cancelled"""
     TIMED_OUT: _ActivityCancelReason.ValueType  # 2
-    """/ Activity timed out"""
+    """Activity timed out"""
+    WORKER_SHUTDOWN: _ActivityCancelReason.ValueType  # 3
+    """Core is shutting down and the graceful timeout has elapsed"""
 
 class ActivityCancelReason(
     _ActivityCancelReason, metaclass=_ActivityCancelReasonEnumTypeWrapper
 ): ...
 
 NOT_FOUND: ActivityCancelReason.ValueType  # 0
-"""/ The activity no longer exists according to server (may be already completed)"""
+"""The activity no longer exists according to server (may be already completed)"""
 CANCELLED: ActivityCancelReason.ValueType  # 1
-"""/ Activity was explicitly cancelled"""
+"""Activity was explicitly cancelled"""
 TIMED_OUT: ActivityCancelReason.ValueType  # 2
-"""/ Activity timed out"""
+"""Activity timed out"""
+WORKER_SHUTDOWN: ActivityCancelReason.ValueType  # 3
+"""Core is shutting down and the graceful timeout has elapsed"""
 global___ActivityCancelReason = ActivityCancelReason
 
 class ActivityTask(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     TASK_TOKEN_FIELD_NUMBER: builtins.int
     START_FIELD_NUMBER: builtins.int
     CANCEL_FIELD_NUMBER: builtins.int
     task_token: builtins.bytes
-    """/ A unique identifier for this task"""
+    """A unique identifier for this task"""
     @property
     def start(self) -> global___Start:
-        """/ Start activity execution."""
+        """Start activity execution."""
     @property
     def cancel(self) -> global___Cancel:
-        """/ Attempt to cancel activity execution."""
+        """Attempt to cancel activity execution."""
     def __init__(
         self,
         *,
         task_token: builtins.bytes = ...,
         start: global___Start | None = ...,
         cancel: global___Cancel | None = ...,
     ) -> None: ...
@@ -295,15 +299,15 @@
             b"workflow_type",
         ],
     ) -> None: ...
 
 global___Start = Start
 
 class Cancel(google.protobuf.message.Message):
-    """/ Attempt to cancel a running activity"""
+    """Attempt to cancel a running activity"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     REASON_FIELD_NUMBER: builtins.int
     reason: global___ActivityCancelReason.ValueType
     def __init__(
         self,
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/bridge/__init__.py` & `temporalio-1.2.0/temporalio/bridge/proto/bridge/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/bridge/bridge_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/bridge/bridge_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n5temporal/sdk/core/child_workflow/child_workflow.proto\x12\x16\x63oresdk.child_workflow\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a%temporal/sdk/core/common/common.proto"\xc3\x01\n\x13\x43hildWorkflowResult\x12\x34\n\tcompleted\x18\x01 \x01(\x0b\x32\x1f.coresdk.child_workflow.SuccessH\x00\x12\x31\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32\x1f.coresdk.child_workflow.FailureH\x00\x12\x39\n\tcancelled\x18\x03 \x01(\x0b\x32$.coresdk.child_workflow.CancellationH\x00\x42\x08\n\x06status":\n\x07Success\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"<\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"A\n\x0c\x43\x61ncellation\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure*\xa4\x01\n\x11ParentClosePolicy\x12#\n\x1fPARENT_CLOSE_POLICY_UNSPECIFIED\x10\x00\x12!\n\x1dPARENT_CLOSE_POLICY_TERMINATE\x10\x01\x12\x1f\n\x1bPARENT_CLOSE_POLICY_ABANDON\x10\x02\x12&\n"PARENT_CLOSE_POLICY_REQUEST_CANCEL\x10\x03*\xae\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01*~\n\x1d\x43hildWorkflowCancellationType\x12\x0b\n\x07\x41\x42\x41NDON\x10\x00\x12\x0e\n\nTRY_CANCEL\x10\x01\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x02\x12\x1f\n\x1bWAIT_CANCELLATION_REQUESTED\x10\x03\x62\x06proto3'
+    b'\n5temporal/sdk/core/child_workflow/child_workflow.proto\x12\x16\x63oresdk.child_workflow\x1a$temporal/api/common/v1/message.proto\x1a%temporal/api/failure/v1/message.proto\x1a%temporal/sdk/core/common/common.proto"\xc3\x01\n\x13\x43hildWorkflowResult\x12\x34\n\tcompleted\x18\x01 \x01(\x0b\x32\x1f.coresdk.child_workflow.SuccessH\x00\x12\x31\n\x06\x66\x61iled\x18\x02 \x01(\x0b\x32\x1f.coresdk.child_workflow.FailureH\x00\x12\x39\n\tcancelled\x18\x03 \x01(\x0b\x32$.coresdk.child_workflow.CancellationH\x00\x42\x08\n\x06status":\n\x07Success\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"<\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"A\n\x0c\x43\x61ncellation\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure*\xa4\x01\n\x11ParentClosePolicy\x12#\n\x1fPARENT_CLOSE_POLICY_UNSPECIFIED\x10\x00\x12!\n\x1dPARENT_CLOSE_POLICY_TERMINATE\x10\x01\x12\x1f\n\x1bPARENT_CLOSE_POLICY_ABANDON\x10\x02\x12&\n"PARENT_CLOSE_POLICY_REQUEST_CANCEL\x10\x03*\xae\x01\n&StartChildWorkflowExecutionFailedCause\x12;\n7START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED\x10\x00\x12G\nCSTART_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS\x10\x01*~\n\x1d\x43hildWorkflowCancellationType\x12\x0b\n\x07\x41\x42\x41NDON\x10\x00\x12\x0e\n\nTRY_CANCEL\x10\x01\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x02\x12\x1f\n\x1bWAIT_CANCELLATION_REQUESTED\x10\x03\x42)\xea\x02&Temporalio::Bridge::Api::ChildWorkflowb\x06proto3'
 )
 
 _PARENTCLOSEPOLICY = DESCRIPTOR.enum_types_by_name["ParentClosePolicy"]
 ParentClosePolicy = enum_type_wrapper.EnumTypeWrapper(_PARENTCLOSEPOLICY)
 _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE = DESCRIPTOR.enum_types_by_name[
     "StartChildWorkflowExecutionFailedCause"
 ]
@@ -100,14 +100,15 @@
         # @@protoc_insertion_point(class_scope:coresdk.child_workflow.Cancellation)
     },
 )
 _sym_db.RegisterMessage(Cancellation)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002&Temporalio::Bridge::Api::ChildWorkflow"
     _PARENTCLOSEPOLICY._serialized_start = 585
     _PARENTCLOSEPOLICY._serialized_end = 749
     _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_start = 752
     _STARTCHILDWORKFLOWEXECUTIONFAILEDCAUSE._serialized_end = 926
     _CHILDWORKFLOWCANCELLATIONTYPE._serialized_start = 928
     _CHILDWORKFLOWCANCELLATIONTYPE._serialized_end = 1054
     _CHILDWORKFLOWRESULT._serialized_start = 198
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/child_workflow/child_workflow_pb2.pyi`

 * *Files 6% similar despite different names*

```diff
@@ -26,38 +26,37 @@
     google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[
         _ParentClosePolicy.ValueType
     ],
     builtins.type,
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     PARENT_CLOSE_POLICY_UNSPECIFIED: _ParentClosePolicy.ValueType  # 0
-    """* Let's the server set the default."""
+    """Let's the server set the default."""
     PARENT_CLOSE_POLICY_TERMINATE: _ParentClosePolicy.ValueType  # 1
-    """* Terminate means terminating the child workflow."""
+    """Terminate means terminating the child workflow."""
     PARENT_CLOSE_POLICY_ABANDON: _ParentClosePolicy.ValueType  # 2
-    """* Abandon means not doing anything on the child workflow."""
+    """Abandon means not doing anything on the child workflow."""
     PARENT_CLOSE_POLICY_REQUEST_CANCEL: _ParentClosePolicy.ValueType  # 3
-    """* Cancel means requesting cancellation on the child workflow."""
+    """Cancel means requesting cancellation on the child workflow."""
 
 class ParentClosePolicy(
     _ParentClosePolicy, metaclass=_ParentClosePolicyEnumTypeWrapper
 ):
-    """*
-    Used by the service to determine the fate of a child workflow
+    """Used by the service to determine the fate of a child workflow
     in case its parent is closed.
     """
 
 PARENT_CLOSE_POLICY_UNSPECIFIED: ParentClosePolicy.ValueType  # 0
-"""* Let's the server set the default."""
+"""Let's the server set the default."""
 PARENT_CLOSE_POLICY_TERMINATE: ParentClosePolicy.ValueType  # 1
-"""* Terminate means terminating the child workflow."""
+"""Terminate means terminating the child workflow."""
 PARENT_CLOSE_POLICY_ABANDON: ParentClosePolicy.ValueType  # 2
-"""* Abandon means not doing anything on the child workflow."""
+"""Abandon means not doing anything on the child workflow."""
 PARENT_CLOSE_POLICY_REQUEST_CANCEL: ParentClosePolicy.ValueType  # 3
-"""* Cancel means requesting cancellation on the child workflow."""
+"""Cancel means requesting cancellation on the child workflow."""
 global___ParentClosePolicy = ParentClosePolicy
 
 class _StartChildWorkflowExecutionFailedCause:
     ValueType = typing.NewType("ValueType", builtins.int)
     V: typing_extensions.TypeAlias = ValueType
 
 class _StartChildWorkflowExecutionFailedCauseEnumTypeWrapper(
@@ -70,15 +69,15 @@
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED: _StartChildWorkflowExecutionFailedCause.ValueType  # 0
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS: _StartChildWorkflowExecutionFailedCause.ValueType  # 1
 
 class StartChildWorkflowExecutionFailedCause(
     _StartChildWorkflowExecutionFailedCause,
     metaclass=_StartChildWorkflowExecutionFailedCauseEnumTypeWrapper,
 ):
-    """* Possible causes of failure to start a child workflow"""
+    """Possible causes of failure to start a child workflow"""
 
 START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED: StartChildWorkflowExecutionFailedCause.ValueType  # 0
 START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS: StartChildWorkflowExecutionFailedCause.ValueType  # 1
 global___StartChildWorkflowExecutionFailedCause = StartChildWorkflowExecutionFailedCause
 
 class _ChildWorkflowCancellationType:
     ValueType = typing.NewType("ValueType", builtins.int)
@@ -88,44 +87,40 @@
     google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[
         _ChildWorkflowCancellationType.ValueType
     ],
     builtins.type,
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     ABANDON: _ChildWorkflowCancellationType.ValueType  # 0
-    """* Do not request cancellation of the child workflow if already scheduled"""
+    """Do not request cancellation of the child workflow if already scheduled"""
     TRY_CANCEL: _ChildWorkflowCancellationType.ValueType  # 1
-    """* Initiate a cancellation request and immediately report cancellation to the parent."""
+    """Initiate a cancellation request and immediately report cancellation to the parent."""
     WAIT_CANCELLATION_COMPLETED: _ChildWorkflowCancellationType.ValueType  # 2
-    """* Wait for child cancellation completion."""
+    """Wait for child cancellation completion."""
     WAIT_CANCELLATION_REQUESTED: _ChildWorkflowCancellationType.ValueType  # 3
-    """* Request cancellation of the child and wait for confirmation that the request was received."""
+    """Request cancellation of the child and wait for confirmation that the request was received."""
 
 class ChildWorkflowCancellationType(
     _ChildWorkflowCancellationType,
     metaclass=_ChildWorkflowCancellationTypeEnumTypeWrapper,
 ):
-    """*
-    Controls at which point to report back to lang when a child workflow is cancelled
-    """
+    """Controls at which point to report back to lang when a child workflow is cancelled"""
 
 ABANDON: ChildWorkflowCancellationType.ValueType  # 0
-"""* Do not request cancellation of the child workflow if already scheduled"""
+"""Do not request cancellation of the child workflow if already scheduled"""
 TRY_CANCEL: ChildWorkflowCancellationType.ValueType  # 1
-"""* Initiate a cancellation request and immediately report cancellation to the parent."""
+"""Initiate a cancellation request and immediately report cancellation to the parent."""
 WAIT_CANCELLATION_COMPLETED: ChildWorkflowCancellationType.ValueType  # 2
-"""* Wait for child cancellation completion."""
+"""Wait for child cancellation completion."""
 WAIT_CANCELLATION_REQUESTED: ChildWorkflowCancellationType.ValueType  # 3
-"""* Request cancellation of the child and wait for confirmation that the request was received."""
+"""Request cancellation of the child and wait for confirmation that the request was received."""
 global___ChildWorkflowCancellationType = ChildWorkflowCancellationType
 
 class ChildWorkflowResult(google.protobuf.message.Message):
-    """*
-    Used by core to resolve child workflow executions.
-    """
+    """Used by core to resolve child workflow executions."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMPLETED_FIELD_NUMBER: builtins.int
     FAILED_FIELD_NUMBER: builtins.int
     CANCELLED_FIELD_NUMBER: builtins.int
     @property
@@ -170,17 +165,15 @@
     def WhichOneof(
         self, oneof_group: typing_extensions.Literal["status", b"status"]
     ) -> typing_extensions.Literal["completed", "failed", "cancelled"] | None: ...
 
 global___ChildWorkflowResult = ChildWorkflowResult
 
 class Success(google.protobuf.message.Message):
-    """*
-    Used in ChildWorkflowResult to report successful completion.
-    """
+    """Used in ChildWorkflowResult to report successful completion."""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RESULT_FIELD_NUMBER: builtins.int
     @property
     def result(self) -> temporalio.api.common.v1.message_pb2.Payload: ...
     def __init__(
@@ -194,16 +187,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["result", b"result"]
     ) -> None: ...
 
 global___Success = Success
 
 class Failure(google.protobuf.message.Message):
-    """*
-    Used in ChildWorkflowResult to report non successful outcomes such as
+    """Used in ChildWorkflowResult to report non successful outcomes such as
     application failures, timeouts, terminations, and cancellations.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     @property
@@ -219,16 +211,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["failure", b"failure"]
     ) -> None: ...
 
 global___Failure = Failure
 
 class Cancellation(google.protobuf.message.Message):
-    """*
-    Used in ChildWorkflowResult to report cancellation.
+    """Used in ChildWorkflowResult to report cancellation.
     Failure should be ChildWorkflowFailure with a CanceledFailure cause.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     @property
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/common/common_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.py`

 * *Files 5% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n%temporal/sdk/core/common/common.proto\x12\x0e\x63oresdk.common\x1a\x1egoogle/protobuf/duration.proto"U\n\x1bNamespacedWorkflowExecution\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\tb\x06proto3'
+    b'\n%temporal/sdk/core/common/common.proto\x12\x0e\x63oresdk.common\x1a\x1egoogle/protobuf/duration.proto"U\n\x1bNamespacedWorkflowExecution\x12\x11\n\tnamespace\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x0e\n\x06run_id\x18\x03 \x01(\tB"\xea\x02\x1fTemporalio::Bridge::Api::Commonb\x06proto3'
 )
 
 
 _NAMESPACEDWORKFLOWEXECUTION = DESCRIPTOR.message_types_by_name[
     "NamespacedWorkflowExecution"
 ]
 NamespacedWorkflowExecution = _reflection.GeneratedProtocolMessageType(
@@ -32,10 +32,11 @@
         # @@protoc_insertion_point(class_scope:coresdk.common.NamespacedWorkflowExecution)
     },
 )
 _sym_db.RegisterMessage(NamespacedWorkflowExecution)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002\037Temporalio::Bridge::Api::Common"
     _NAMESPACEDWORKFLOWEXECUTION._serialized_start = 89
     _NAMESPACEDWORKFLOWEXECUTION._serialized_end = 174
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/common/common_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/common/common_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.py`

 * *Files 4% similar despite different names*

```diff
@@ -39,15 +39,15 @@
     workflow_commands_pb2 as temporal_dot_sdk_dot_core_dot_workflow__commands_dot_workflow__commands__pb2,
 )
 from temporalio.bridge.proto.workflow_completion import (
     workflow_completion_pb2 as temporal_dot_sdk_dot_core_dot_workflow__completion_dot_workflow__completion__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n&temporal/sdk/core/core_interface.proto\x12\x07\x63oresdk\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x33temporal/sdk/core/activity_task/activity_task.proto\x1a%temporal/sdk/core/common/common.proto\x1a\x33temporal/sdk/core/external_data/external_data.proto\x1a?temporal/sdk/core/workflow_activation/workflow_activation.proto\x1a;temporal/sdk/core/workflow_commands/workflow_commands.proto\x1a?temporal/sdk/core/workflow_completion/workflow_completion.proto"Y\n\x11\x41\x63tivityHeartbeat\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"n\n\x16\x41\x63tivityTaskCompletion\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12@\n\x06result\x18\x02 \x01(\x0b\x32\x30.coresdk.activity_result.ActivityExecutionResultb\x06proto3'
+    b'\n&temporal/sdk/core/core_interface.proto\x12\x07\x63oresdk\x1a\x1egoogle/protobuf/duration.proto\x1a\x1bgoogle/protobuf/empty.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x33temporal/sdk/core/activity_task/activity_task.proto\x1a%temporal/sdk/core/common/common.proto\x1a\x33temporal/sdk/core/external_data/external_data.proto\x1a?temporal/sdk/core/workflow_activation/workflow_activation.proto\x1a;temporal/sdk/core/workflow_commands/workflow_commands.proto\x1a?temporal/sdk/core/workflow_completion/workflow_completion.proto"Y\n\x11\x41\x63tivityHeartbeat\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12\x30\n\x07\x64\x65tails\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"n\n\x16\x41\x63tivityTaskCompletion\x12\x12\n\ntask_token\x18\x01 \x01(\x0c\x12@\n\x06result\x18\x02 \x01(\x0b\x32\x30.coresdk.activity_result.ActivityExecutionResultB)\xea\x02&Temporalio::Bridge::Api::CoreInterfaceb\x06proto3'
 )
 
 
 _ACTIVITYHEARTBEAT = DESCRIPTOR.message_types_by_name["ActivityHeartbeat"]
 _ACTIVITYTASKCOMPLETION = DESCRIPTOR.message_types_by_name["ActivityTaskCompletion"]
 ActivityHeartbeat = _reflection.GeneratedProtocolMessageType(
     "ActivityHeartbeat",
@@ -69,12 +69,13 @@
         # @@protoc_insertion_point(class_scope:coresdk.ActivityTaskCompletion)
     },
 )
 _sym_db.RegisterMessage(ActivityTaskCompletion)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002&Temporalio::Bridge::Api::CoreInterface"
     _ACTIVITYHEARTBEAT._serialized_start = 576
     _ACTIVITYHEARTBEAT._serialized_end = 665
     _ACTIVITYTASKCOMPLETION._serialized_start = 667
     _ACTIVITYTASKCOMPLETION._serialized_end = 777
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/core_interface_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/core_interface_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/external_data/external_data_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.py`

 * *Files 23% similar despite different names*

```diff
@@ -13,28 +13,43 @@
 _sym_db = _symbol_database.Default()
 
 
 from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
 from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n3temporal/sdk/core/external_data/external_data.proto\x12\x15\x63oresdk.external_data\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto"\xfe\x01\n\x17LocalActivityMarkerData\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x0f\n\x07\x61ttempt\x18\x02 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x03 \x01(\t\x12\x15\n\ractivity_type\x18\x04 \x01(\t\x12\x31\n\rcomplete_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12*\n\x07\x62\x61\x63koff\x18\x06 \x01(\x0b\x32\x19.google.protobuf.Duration\x12:\n\x16original_schedule_time\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.Timestampb\x06proto3'
+    b'\n3temporal/sdk/core/external_data/external_data.proto\x12\x15\x63oresdk.external_data\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto"\xfe\x01\n\x17LocalActivityMarkerData\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x0f\n\x07\x61ttempt\x18\x02 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x03 \x01(\t\x12\x15\n\ractivity_type\x18\x04 \x01(\t\x12\x31\n\rcomplete_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12*\n\x07\x62\x61\x63koff\x18\x06 \x01(\x0b\x32\x19.google.protobuf.Duration\x12:\n\x16original_schedule_time\x18\x07 \x01(\x0b\x32\x1a.google.protobuf.Timestamp"3\n\x11PatchedMarkerData\x12\n\n\x02id\x18\x01 \x01(\t\x12\x12\n\ndeprecated\x18\x02 \x01(\x08\x42(\xea\x02%Temporalio::Bridge::Api::ExternalDatab\x06proto3'
 )
 
 
 _LOCALACTIVITYMARKERDATA = DESCRIPTOR.message_types_by_name["LocalActivityMarkerData"]
+_PATCHEDMARKERDATA = DESCRIPTOR.message_types_by_name["PatchedMarkerData"]
 LocalActivityMarkerData = _reflection.GeneratedProtocolMessageType(
     "LocalActivityMarkerData",
     (_message.Message,),
     {
         "DESCRIPTOR": _LOCALACTIVITYMARKERDATA,
         "__module__": "temporal.sdk.core.external_data.external_data_pb2"
         # @@protoc_insertion_point(class_scope:coresdk.external_data.LocalActivityMarkerData)
     },
 )
 _sym_db.RegisterMessage(LocalActivityMarkerData)
 
+PatchedMarkerData = _reflection.GeneratedProtocolMessageType(
+    "PatchedMarkerData",
+    (_message.Message,),
+    {
+        "DESCRIPTOR": _PATCHEDMARKERDATA,
+        "__module__": "temporal.sdk.core.external_data.external_data_pb2"
+        # @@protoc_insertion_point(class_scope:coresdk.external_data.PatchedMarkerData)
+    },
+)
+_sym_db.RegisterMessage(PatchedMarkerData)
+
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = b"\352\002%Temporalio::Bridge::Api::ExternalData"
     _LOCALACTIVITYMARKERDATA._serialized_start = 144
     _LOCALACTIVITYMARKERDATA._serialized_end = 398
+    _PATCHEDMARKERDATA._serialized_start = 400
+    _PATCHEDMARKERDATA._serialized_end = 451
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/external_data/external_data_pb2.pyi`

 * *Files 14% similar despite different names*

```diff
@@ -94,7 +94,29 @@
             b"original_schedule_time",
             "seq",
             b"seq",
         ],
     ) -> None: ...
 
 global___LocalActivityMarkerData = LocalActivityMarkerData
+
+class PatchedMarkerData(google.protobuf.message.Message):
+    DESCRIPTOR: google.protobuf.descriptor.Descriptor
+
+    ID_FIELD_NUMBER: builtins.int
+    DEPRECATED_FIELD_NUMBER: builtins.int
+    id: builtins.str
+    """The patch id"""
+    deprecated: builtins.bool
+    """Whether or not the patch is marked deprecated."""
+    def __init__(
+        self,
+        *,
+        id: builtins.str = ...,
+        deprecated: builtins.bool = ...,
+    ) -> None: ...
+    def ClearField(
+        self,
+        field_name: typing_extensions.Literal["deprecated", b"deprecated", "id", b"id"],
+    ) -> None: ...
+
+global___PatchedMarkerData = PatchedMarkerData
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/health/v1/health_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/health/v1/health_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/health/v1/health_pb2.pyi`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/__init__.py` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.py`

 * *Files 2% similar despite different names*

```diff
@@ -32,15 +32,15 @@
     child_workflow_pb2 as temporal_dot_sdk_dot_core_dot_child__workflow_dot_child__workflow__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n?temporal/sdk/core/workflow_activation/workflow_activation.proto\x12\x1b\x63oresdk.workflow_activation\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/duration.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xc3\x01\n\x12WorkflowActivation\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12-\n\ttimestamp\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x14\n\x0cis_replaying\x18\x03 \x01(\x08\x12\x16\n\x0ehistory_length\x18\x04 \x01(\r\x12@\n\x04jobs\x18\x05 \x03(\x0b\x32\x32.coresdk.workflow_activation.WorkflowActivationJob"\xe1\x08\n\x15WorkflowActivationJob\x12\x44\n\x0estart_workflow\x18\x01 \x01(\x0b\x32*.coresdk.workflow_activation.StartWorkflowH\x00\x12<\n\nfire_timer\x18\x02 \x01(\x0b\x32&.coresdk.workflow_activation.FireTimerH\x00\x12K\n\x12update_random_seed\x18\x04 \x01(\x0b\x32-.coresdk.workflow_activation.UpdateRandomSeedH\x00\x12\x44\n\x0equery_workflow\x18\x05 \x01(\x0b\x32*.coresdk.workflow_activation.QueryWorkflowH\x00\x12\x46\n\x0f\x63\x61ncel_workflow\x18\x06 \x01(\x0b\x32+.coresdk.workflow_activation.CancelWorkflowH\x00\x12\x46\n\x0fsignal_workflow\x18\x07 \x01(\x0b\x32+.coresdk.workflow_activation.SignalWorkflowH\x00\x12H\n\x10resolve_activity\x18\x08 \x01(\x0b\x32,.coresdk.workflow_activation.ResolveActivityH\x00\x12G\n\x10notify_has_patch\x18\t \x01(\x0b\x32+.coresdk.workflow_activation.NotifyHasPatchH\x00\x12q\n&resolve_child_workflow_execution_start\x18\n \x01(\x0b\x32?.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartH\x00\x12\x66\n resolve_child_workflow_execution\x18\x0b \x01(\x0b\x32:.coresdk.workflow_activation.ResolveChildWorkflowExecutionH\x00\x12\x66\n resolve_signal_external_workflow\x18\x0c \x01(\x0b\x32:.coresdk.workflow_activation.ResolveSignalExternalWorkflowH\x00\x12u\n(resolve_request_cancel_external_workflow\x18\r \x01(\x0b\x32\x41.coresdk.workflow_activation.ResolveRequestCancelExternalWorkflowH\x00\x12I\n\x11remove_from_cache\x18\x32 \x01(\x0b\x32,.coresdk.workflow_activation.RemoveFromCacheH\x00\x42\t\n\x07variant"\xd9\t\n\rStartWorkflow\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x17\n\x0frandomness_seed\x18\x04 \x01(\x04\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.StartWorkflow.HeadersEntry\x12\x10\n\x08identity\x18\x06 \x01(\t\x12I\n\x14parent_workflow_info\x18\x07 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecution\x12=\n\x1aworkflow_execution_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\'\n\x1f\x63ontinued_from_execution_run_id\x18\x0b \x01(\t\x12J\n\x13\x63ontinued_initiator\x18\x0c \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\r \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0e \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1e\n\x16\x66irst_execution_run_id\x18\x0f \x01(\t\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x11 \x01(\x05\x12\x15\n\rcron_schedule\x18\x12 \x01(\t\x12\x46\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x45\n"cron_schedule_to_schedule_interval\x18\x14 \x01(\x0b\x32\x19.google.protobuf.Duration\x12*\n\x04memo\x18\x15 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x16 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\nstart_time\x18\x17 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x18\n\tFireTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"[\n\x0fResolveActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.activity_result.ActivityResolution"\xd1\x02\n"ResolveChildWorkflowExecutionStart\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12[\n\tsucceeded\x18\x02 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartSuccessH\x00\x12X\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartFailureH\x00\x12]\n\tcancelled\x18\x04 \x01(\x0b\x32H.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartCancelledH\x00\x42\x08\n\x06status";\n)ResolveChildWorkflowExecutionStartSuccess\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xa6\x01\n)ResolveChildWorkflowExecutionStartFailure\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12M\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32>.coresdk.child_workflow.StartChildWorkflowExecutionFailedCause"`\n+ResolveChildWorkflowExecutionStartCancelled\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"i\n\x1dResolveChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.child_workflow.ChildWorkflowResult"+\n\x10UpdateRandomSeed\x12\x17\n\x0frandomness_seed\x18\x01 \x01(\x04"\x84\x02\n\rQueryWorkflow\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12\x12\n\nquery_type\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.QueryWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"B\n\x0e\x43\x61ncelWorkflow\x12\x30\n\x07\x64\x65tails\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x83\x02\n\x0eSignalWorkflow\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12.\n\x05input\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x07headers\x18\x05 \x03(\x0b\x32\x38.coresdk.workflow_activation.SignalWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01""\n\x0eNotifyHasPatch\x12\x10\n\x08patch_id\x18\x01 \x01(\t"_\n\x1dResolveSignalExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"f\n$ResolveRequestCancelExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xa0\x02\n\x0fRemoveFromCache\x12\x0f\n\x07message\x18\x01 \x01(\t\x12K\n\x06reason\x18\x02 \x01(\x0e\x32;.coresdk.workflow_activation.RemoveFromCache.EvictionReason"\xae\x01\n\x0e\x45victionReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0e\n\nCACHE_FULL\x10\x01\x12\x0e\n\nCACHE_MISS\x10\x02\x12\x12\n\x0eNONDETERMINISM\x10\x03\x12\r\n\tLANG_FAIL\x10\x04\x12\x12\n\x0eLANG_REQUESTED\x10\x05\x12\x12\n\x0eTASK_NOT_FOUND\x10\x06\x12\x15\n\x11UNHANDLED_COMMAND\x10\x07\x12\t\n\x05\x46\x41TAL\x10\x08\x62\x06proto3'
+    b'\n?temporal/sdk/core/workflow_activation/workflow_activation.proto\x12\x1b\x63oresdk.workflow_activation\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x1egoogle/protobuf/duration.proto\x1a%temporal/api/failure/v1/message.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a\x37temporal/sdk/core/activity_result/activity_result.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xe5\x01\n\x12WorkflowActivation\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12-\n\ttimestamp\x18\x02 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x14\n\x0cis_replaying\x18\x03 \x01(\x08\x12\x16\n\x0ehistory_length\x18\x04 \x01(\r\x12@\n\x04jobs\x18\x05 \x03(\x0b\x32\x32.coresdk.workflow_activation.WorkflowActivationJob\x12 \n\x18\x61vailable_internal_flags\x18\x06 \x03(\r"\xe1\x08\n\x15WorkflowActivationJob\x12\x44\n\x0estart_workflow\x18\x01 \x01(\x0b\x32*.coresdk.workflow_activation.StartWorkflowH\x00\x12<\n\nfire_timer\x18\x02 \x01(\x0b\x32&.coresdk.workflow_activation.FireTimerH\x00\x12K\n\x12update_random_seed\x18\x04 \x01(\x0b\x32-.coresdk.workflow_activation.UpdateRandomSeedH\x00\x12\x44\n\x0equery_workflow\x18\x05 \x01(\x0b\x32*.coresdk.workflow_activation.QueryWorkflowH\x00\x12\x46\n\x0f\x63\x61ncel_workflow\x18\x06 \x01(\x0b\x32+.coresdk.workflow_activation.CancelWorkflowH\x00\x12\x46\n\x0fsignal_workflow\x18\x07 \x01(\x0b\x32+.coresdk.workflow_activation.SignalWorkflowH\x00\x12H\n\x10resolve_activity\x18\x08 \x01(\x0b\x32,.coresdk.workflow_activation.ResolveActivityH\x00\x12G\n\x10notify_has_patch\x18\t \x01(\x0b\x32+.coresdk.workflow_activation.NotifyHasPatchH\x00\x12q\n&resolve_child_workflow_execution_start\x18\n \x01(\x0b\x32?.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartH\x00\x12\x66\n resolve_child_workflow_execution\x18\x0b \x01(\x0b\x32:.coresdk.workflow_activation.ResolveChildWorkflowExecutionH\x00\x12\x66\n resolve_signal_external_workflow\x18\x0c \x01(\x0b\x32:.coresdk.workflow_activation.ResolveSignalExternalWorkflowH\x00\x12u\n(resolve_request_cancel_external_workflow\x18\r \x01(\x0b\x32\x41.coresdk.workflow_activation.ResolveRequestCancelExternalWorkflowH\x00\x12I\n\x11remove_from_cache\x18\x32 \x01(\x0b\x32,.coresdk.workflow_activation.RemoveFromCacheH\x00\x42\t\n\x07variant"\xd9\t\n\rStartWorkflow\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x17\n\x0frandomness_seed\x18\x04 \x01(\x04\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.StartWorkflow.HeadersEntry\x12\x10\n\x08identity\x18\x06 \x01(\t\x12I\n\x14parent_workflow_info\x18\x07 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecution\x12=\n\x1aworkflow_execution_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\'\n\x1f\x63ontinued_from_execution_run_id\x18\x0b \x01(\t\x12J\n\x13\x63ontinued_initiator\x18\x0c \x01(\x0e\x32-.temporal.api.enums.v1.ContinueAsNewInitiator\x12;\n\x11\x63ontinued_failure\x18\r \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12@\n\x16last_completion_result\x18\x0e \x01(\x0b\x32 .temporal.api.common.v1.Payloads\x12\x1e\n\x16\x66irst_execution_run_id\x18\x0f \x01(\t\x12\x39\n\x0cretry_policy\x18\x10 \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x0f\n\x07\x61ttempt\x18\x11 \x01(\x05\x12\x15\n\rcron_schedule\x18\x12 \x01(\t\x12\x46\n"workflow_execution_expiration_time\x18\x13 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12\x45\n"cron_schedule_to_schedule_interval\x18\x14 \x01(\x0b\x32\x19.google.protobuf.Duration\x12*\n\x04memo\x18\x15 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo\x12\x43\n\x11search_attributes\x18\x16 \x01(\x0b\x32(.temporal.api.common.v1.SearchAttributes\x12.\n\nstart_time\x18\x17 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x18\n\tFireTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"[\n\x0fResolveActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.activity_result.ActivityResolution"\xd1\x02\n"ResolveChildWorkflowExecutionStart\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12[\n\tsucceeded\x18\x02 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartSuccessH\x00\x12X\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32\x46.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartFailureH\x00\x12]\n\tcancelled\x18\x04 \x01(\x0b\x32H.coresdk.workflow_activation.ResolveChildWorkflowExecutionStartCancelledH\x00\x42\x08\n\x06status";\n)ResolveChildWorkflowExecutionStartSuccess\x12\x0e\n\x06run_id\x18\x01 \x01(\t"\xa6\x01\n)ResolveChildWorkflowExecutionStartFailure\x12\x13\n\x0bworkflow_id\x18\x01 \x01(\t\x12\x15\n\rworkflow_type\x18\x02 \x01(\t\x12M\n\x05\x63\x61use\x18\x03 \x01(\x0e\x32>.coresdk.child_workflow.StartChildWorkflowExecutionFailedCause"`\n+ResolveChildWorkflowExecutionStartCancelled\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"i\n\x1dResolveChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12;\n\x06result\x18\x02 \x01(\x0b\x32+.coresdk.child_workflow.ChildWorkflowResult"+\n\x10UpdateRandomSeed\x12\x17\n\x0frandomness_seed\x18\x01 \x01(\x04"\x84\x02\n\rQueryWorkflow\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12\x12\n\nquery_type\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12H\n\x07headers\x18\x05 \x03(\x0b\x32\x37.coresdk.workflow_activation.QueryWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"B\n\x0e\x43\x61ncelWorkflow\x12\x30\n\x07\x64\x65tails\x18\x01 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload"\x83\x02\n\x0eSignalWorkflow\x12\x13\n\x0bsignal_name\x18\x01 \x01(\t\x12.\n\x05input\x18\x02 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x10\n\x08identity\x18\x03 \x01(\t\x12I\n\x07headers\x18\x05 \x03(\x0b\x32\x38.coresdk.workflow_activation.SignalWorkflow.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01""\n\x0eNotifyHasPatch\x12\x10\n\x08patch_id\x18\x01 \x01(\t"_\n\x1dResolveSignalExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"f\n$ResolveRequestCancelExternalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x31\n\x07\x66\x61ilure\x18\x02 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xc1\x02\n\x0fRemoveFromCache\x12\x0f\n\x07message\x18\x01 \x01(\t\x12K\n\x06reason\x18\x02 \x01(\x0e\x32;.coresdk.workflow_activation.RemoveFromCache.EvictionReason"\xcf\x01\n\x0e\x45victionReason\x12\x0f\n\x0bUNSPECIFIED\x10\x00\x12\x0e\n\nCACHE_FULL\x10\x01\x12\x0e\n\nCACHE_MISS\x10\x02\x12\x12\n\x0eNONDETERMINISM\x10\x03\x12\r\n\tLANG_FAIL\x10\x04\x12\x12\n\x0eLANG_REQUESTED\x10\x05\x12\x12\n\x0eTASK_NOT_FOUND\x10\x06\x12\x15\n\x11UNHANDLED_COMMAND\x10\x07\x12\t\n\x05\x46\x41TAL\x10\x08\x12\x1f\n\x1bPAGINATION_OR_HISTORY_FETCH\x10\tB.\xea\x02+Temporalio::Bridge::Api::WorkflowActivationb\x06proto3'
 )
 
 
 _WORKFLOWACTIVATION = DESCRIPTOR.message_types_by_name["WorkflowActivation"]
 _WORKFLOWACTIVATIONJOB = DESCRIPTOR.message_types_by_name["WorkflowActivationJob"]
 _STARTWORKFLOW = DESCRIPTOR.message_types_by_name["StartWorkflow"]
 _STARTWORKFLOW_HEADERSENTRY = _STARTWORKFLOW.nested_types_by_name["HeadersEntry"]
@@ -302,58 +302,61 @@
         # @@protoc_insertion_point(class_scope:coresdk.workflow_activation.RemoveFromCache)
     },
 )
 _sym_db.RegisterMessage(RemoveFromCache)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = (
+        b"\352\002+Temporalio::Bridge::Api::WorkflowActivation"
+    )
     _STARTWORKFLOW_HEADERSENTRY._options = None
     _STARTWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _QUERYWORKFLOW_HEADERSENTRY._options = None
     _QUERYWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _SIGNALWORKFLOW_HEADERSENTRY._options = None
     _SIGNALWORKFLOW_HEADERSENTRY._serialized_options = b"8\001"
     _WORKFLOWACTIVATION._serialized_start = 428
-    _WORKFLOWACTIVATION._serialized_end = 623
-    _WORKFLOWACTIVATIONJOB._serialized_start = 626
-    _WORKFLOWACTIVATIONJOB._serialized_end = 1747
-    _STARTWORKFLOW._serialized_start = 1750
-    _STARTWORKFLOW._serialized_end = 2991
-    _STARTWORKFLOW_HEADERSENTRY._serialized_start = 2912
-    _STARTWORKFLOW_HEADERSENTRY._serialized_end = 2991
-    _FIRETIMER._serialized_start = 2993
-    _FIRETIMER._serialized_end = 3017
-    _RESOLVEACTIVITY._serialized_start = 3019
-    _RESOLVEACTIVITY._serialized_end = 3110
-    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_start = 3113
-    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_end = 3450
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_start = 3452
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_end = 3511
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_start = 3514
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_end = 3680
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_start = 3682
-    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_end = 3778
-    _RESOLVECHILDWORKFLOWEXECUTION._serialized_start = 3780
-    _RESOLVECHILDWORKFLOWEXECUTION._serialized_end = 3885
-    _UPDATERANDOMSEED._serialized_start = 3887
-    _UPDATERANDOMSEED._serialized_end = 3930
-    _QUERYWORKFLOW._serialized_start = 3933
-    _QUERYWORKFLOW._serialized_end = 4193
-    _QUERYWORKFLOW_HEADERSENTRY._serialized_start = 2912
-    _QUERYWORKFLOW_HEADERSENTRY._serialized_end = 2991
-    _CANCELWORKFLOW._serialized_start = 4195
-    _CANCELWORKFLOW._serialized_end = 4261
-    _SIGNALWORKFLOW._serialized_start = 4264
-    _SIGNALWORKFLOW._serialized_end = 4523
-    _SIGNALWORKFLOW_HEADERSENTRY._serialized_start = 2912
-    _SIGNALWORKFLOW_HEADERSENTRY._serialized_end = 2991
-    _NOTIFYHASPATCH._serialized_start = 4525
-    _NOTIFYHASPATCH._serialized_end = 4559
-    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_start = 4561
-    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_end = 4656
-    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_start = 4658
-    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_end = 4760
-    _REMOVEFROMCACHE._serialized_start = 4763
-    _REMOVEFROMCACHE._serialized_end = 5051
-    _REMOVEFROMCACHE_EVICTIONREASON._serialized_start = 4877
-    _REMOVEFROMCACHE_EVICTIONREASON._serialized_end = 5051
+    _WORKFLOWACTIVATION._serialized_end = 657
+    _WORKFLOWACTIVATIONJOB._serialized_start = 660
+    _WORKFLOWACTIVATIONJOB._serialized_end = 1781
+    _STARTWORKFLOW._serialized_start = 1784
+    _STARTWORKFLOW._serialized_end = 3025
+    _STARTWORKFLOW_HEADERSENTRY._serialized_start = 2946
+    _STARTWORKFLOW_HEADERSENTRY._serialized_end = 3025
+    _FIRETIMER._serialized_start = 3027
+    _FIRETIMER._serialized_end = 3051
+    _RESOLVEACTIVITY._serialized_start = 3053
+    _RESOLVEACTIVITY._serialized_end = 3144
+    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_start = 3147
+    _RESOLVECHILDWORKFLOWEXECUTIONSTART._serialized_end = 3484
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_start = 3486
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTSUCCESS._serialized_end = 3545
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_start = 3548
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTFAILURE._serialized_end = 3714
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_start = 3716
+    _RESOLVECHILDWORKFLOWEXECUTIONSTARTCANCELLED._serialized_end = 3812
+    _RESOLVECHILDWORKFLOWEXECUTION._serialized_start = 3814
+    _RESOLVECHILDWORKFLOWEXECUTION._serialized_end = 3919
+    _UPDATERANDOMSEED._serialized_start = 3921
+    _UPDATERANDOMSEED._serialized_end = 3964
+    _QUERYWORKFLOW._serialized_start = 3967
+    _QUERYWORKFLOW._serialized_end = 4227
+    _QUERYWORKFLOW_HEADERSENTRY._serialized_start = 2946
+    _QUERYWORKFLOW_HEADERSENTRY._serialized_end = 3025
+    _CANCELWORKFLOW._serialized_start = 4229
+    _CANCELWORKFLOW._serialized_end = 4295
+    _SIGNALWORKFLOW._serialized_start = 4298
+    _SIGNALWORKFLOW._serialized_end = 4557
+    _SIGNALWORKFLOW_HEADERSENTRY._serialized_start = 2946
+    _SIGNALWORKFLOW_HEADERSENTRY._serialized_end = 3025
+    _NOTIFYHASPATCH._serialized_start = 4559
+    _NOTIFYHASPATCH._serialized_end = 4593
+    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_start = 4595
+    _RESOLVESIGNALEXTERNALWORKFLOW._serialized_end = 4690
+    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_start = 4692
+    _RESOLVEREQUESTCANCELEXTERNALWORKFLOW._serialized_end = 4794
+    _REMOVEFROMCACHE._serialized_start = 4797
+    _REMOVEFROMCACHE._serialized_end = 5118
+    _REMOVEFROMCACHE_EVICTIONREASON._serialized_start = 4911
+    _REMOVEFROMCACHE_EVICTIONREASON._serialized_end = 5118
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_activation/workflow_activation_pb2.pyi`

 * *Files 4% similar despite different names*

```diff
@@ -26,60 +26,72 @@
     import typing as typing_extensions
 else:
     import typing_extensions
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
 class WorkflowActivation(google.protobuf.message.Message):
-    """/ An instruction to the lang sdk to run some workflow code, whether for the first time or from
-    / a cached state.
+    """An instruction to the lang sdk to run some workflow code, whether for the first time or from
+    a cached state.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_ID_FIELD_NUMBER: builtins.int
     TIMESTAMP_FIELD_NUMBER: builtins.int
     IS_REPLAYING_FIELD_NUMBER: builtins.int
     HISTORY_LENGTH_FIELD_NUMBER: builtins.int
     JOBS_FIELD_NUMBER: builtins.int
+    AVAILABLE_INTERNAL_FLAGS_FIELD_NUMBER: builtins.int
     run_id: builtins.str
-    """/ The id of the currently active run of the workflow. Also used as a cache key. There may
-    / only ever be one active workflow task (and hence activation) of a run at one time.
+    """The id of the currently active run of the workflow. Also used as a cache key. There may
+    only ever be one active workflow task (and hence activation) of a run at one time.
     """
     @property
     def timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
-        """/ The current time as understood by the workflow, which is set by workflow task started events"""
+        """The current time as understood by the workflow, which is set by workflow task started events"""
     is_replaying: builtins.bool
-    """/ Whether or not the activation is replaying past events"""
+    """Whether or not the activation is replaying past events"""
     history_length: builtins.int
-    """/ Current history length as determined by the event id of the most recently processed event.
-    / This ensures that the number is always deterministic
+    """Current history length as determined by the event id of the most recently processed event.
+    This ensures that the number is always deterministic
     """
     @property
     def jobs(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         global___WorkflowActivationJob
     ]:
-        """/ The things to do upon activating the workflow"""
+        """The things to do upon activating the workflow"""
+    @property
+    def available_internal_flags(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
+        """Internal flags which are available for use by lang. If `is_replaying` is false, all
+        internal flags may be used. This is not a delta - all previously used flags always
+        appear since this representation is cheap.
+        """
     def __init__(
         self,
         *,
         run_id: builtins.str = ...,
         timestamp: google.protobuf.timestamp_pb2.Timestamp | None = ...,
         is_replaying: builtins.bool = ...,
         history_length: builtins.int = ...,
         jobs: collections.abc.Iterable[global___WorkflowActivationJob] | None = ...,
+        available_internal_flags: collections.abc.Iterable[builtins.int] | None = ...,
     ) -> None: ...
     def HasField(
         self, field_name: typing_extensions.Literal["timestamp", b"timestamp"]
     ) -> builtins.bool: ...
     def ClearField(
         self,
         field_name: typing_extensions.Literal[
+            "available_internal_flags",
+            b"available_internal_flags",
             "history_length",
             b"history_length",
             "is_replaying",
             b"is_replaying",
             "jobs",
             b"jobs",
             "run_id",
@@ -105,66 +117,66 @@
     RESOLVE_CHILD_WORKFLOW_EXECUTION_START_FIELD_NUMBER: builtins.int
     RESOLVE_CHILD_WORKFLOW_EXECUTION_FIELD_NUMBER: builtins.int
     RESOLVE_SIGNAL_EXTERNAL_WORKFLOW_FIELD_NUMBER: builtins.int
     RESOLVE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_FIELD_NUMBER: builtins.int
     REMOVE_FROM_CACHE_FIELD_NUMBER: builtins.int
     @property
     def start_workflow(self) -> global___StartWorkflow:
-        """/ Begin a workflow for the first time"""
+        """Begin a workflow for the first time"""
     @property
     def fire_timer(self) -> global___FireTimer:
-        """/ A timer has fired, allowing whatever was waiting on it (if anything) to proceed"""
+        """A timer has fired, allowing whatever was waiting on it (if anything) to proceed"""
     @property
     def update_random_seed(self) -> global___UpdateRandomSeed:
-        """/ Workflow was reset. The randomness seed must be updated."""
+        """Workflow was reset. The randomness seed must be updated."""
     @property
     def query_workflow(self) -> global___QueryWorkflow:
-        """/ A request to query the workflow was received."""
+        """A request to query the workflow was received."""
     @property
     def cancel_workflow(self) -> global___CancelWorkflow:
-        """/ A request to cancel the workflow was received."""
+        """A request to cancel the workflow was received."""
     @property
     def signal_workflow(self) -> global___SignalWorkflow:
-        """/ A request to signal the workflow was received."""
+        """A request to signal the workflow was received."""
     @property
     def resolve_activity(self) -> global___ResolveActivity:
-        """/ An activity was resolved, result could be completed, failed or cancelled"""
+        """An activity was resolved, result could be completed, failed or cancelled"""
     @property
     def notify_has_patch(self) -> global___NotifyHasPatch:
-        """/ A patch marker has been detected and lang is being told that change exists. This
-        / job is strange in that it is sent pre-emptively to lang without any corresponding
-        / command being sent first.
+        """A patch marker has been detected and lang is being told that change exists. This
+        job is strange in that it is sent pre-emptively to lang without any corresponding
+        command being sent first.
         """
     @property
     def resolve_child_workflow_execution_start(
         self,
     ) -> global___ResolveChildWorkflowExecutionStart:
-        """/ A child workflow execution has started or failed to start"""
+        """A child workflow execution has started or failed to start"""
     @property
     def resolve_child_workflow_execution(
         self,
     ) -> global___ResolveChildWorkflowExecution:
-        """/ A child workflow was resolved, result could be completed or failed"""
+        """A child workflow was resolved, result could be completed or failed"""
     @property
     def resolve_signal_external_workflow(
         self,
     ) -> global___ResolveSignalExternalWorkflow:
-        """/ An attempt to signal an external workflow resolved"""
+        """An attempt to signal an external workflow resolved"""
     @property
     def resolve_request_cancel_external_workflow(
         self,
     ) -> global___ResolveRequestCancelExternalWorkflow:
-        """/ An attempt to cancel an external workflow resolved"""
+        """An attempt to cancel an external workflow resolved"""
     @property
     def remove_from_cache(self) -> global___RemoveFromCache:
-        """/ Remove the workflow identified by the [WorkflowActivation] containing this job from the cache
-        / after performing the activation.
-        /
-        / If other job variant are present in the list, this variant will be the last job in the
-        / job list. The string value is a reason for eviction.
+        """Remove the workflow identified by the [WorkflowActivation] containing this job from the cache
+        after performing the activation.
+
+        If other job variant are present in the list, this variant will be the last job in the
+        job list. The string value is a reason for eviction.
         """
     def __init__(
         self,
         *,
         start_workflow: global___StartWorkflow | None = ...,
         fire_timer: global___FireTimer | None = ...,
         update_random_seed: global___UpdateRandomSeed | None = ...,
@@ -524,41 +536,41 @@
             b"workflow_type",
         ],
     ) -> None: ...
 
 global___StartWorkflow = StartWorkflow
 
 class FireTimer(google.protobuf.message.Message):
-    """/ Notify a workflow that a timer has fired"""
+    """Notify a workflow that a timer has fired"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding StartTimer command"""
+    """Sequence number as provided by lang in the corresponding StartTimer command"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["seq", b"seq"]
     ) -> None: ...
 
 global___FireTimer = FireTimer
 
 class ResolveActivity(google.protobuf.message.Message):
-    """/ Notify a workflow that an activity has been resolved"""
+    """Notify a workflow that an activity has been resolved"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     RESULT_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding ScheduleActivity command"""
+    """Sequence number as provided by lang in the corresponding ScheduleActivity command"""
     @property
     def result(
         self,
     ) -> (
         temporalio.bridge.proto.activity_result.activity_result_pb2.ActivityResolution
     ): ...
     def __init__(
@@ -574,26 +586,26 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["result", b"result", "seq", b"seq"]
     ) -> None: ...
 
 global___ResolveActivity = ResolveActivity
 
 class ResolveChildWorkflowExecutionStart(google.protobuf.message.Message):
-    """/ Notify a workflow that a start child workflow execution request has succeeded, failed or was
-    / cancelled.
+    """Notify a workflow that a start child workflow execution request has succeeded, failed or was
+    cancelled.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     SUCCEEDED_FIELD_NUMBER: builtins.int
     FAILED_FIELD_NUMBER: builtins.int
     CANCELLED_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command"""
+    """Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command"""
     @property
     def succeeded(self) -> global___ResolveChildWorkflowExecutionStartSuccess: ...
     @property
     def failed(self) -> global___ResolveChildWorkflowExecutionStartFailure: ...
     @property
     def cancelled(self) -> global___ResolveChildWorkflowExecutionStartCancelled: ...
     def __init__(
@@ -635,15 +647,15 @@
     def WhichOneof(
         self, oneof_group: typing_extensions.Literal["status", b"status"]
     ) -> typing_extensions.Literal["succeeded", "failed", "cancelled"] | None: ...
 
 global___ResolveChildWorkflowExecutionStart = ResolveChildWorkflowExecutionStart
 
 class ResolveChildWorkflowExecutionStartSuccess(google.protobuf.message.Message):
-    """/ Simply pass the run_id to lang"""
+    """Simply pass the run_id to lang"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_ID_FIELD_NUMBER: builtins.int
     run_id: builtins.str
     def __init__(
         self,
@@ -655,24 +667,24 @@
     ) -> None: ...
 
 global___ResolveChildWorkflowExecutionStartSuccess = (
     ResolveChildWorkflowExecutionStartSuccess
 )
 
 class ResolveChildWorkflowExecutionStartFailure(google.protobuf.message.Message):
-    """/ Provide lang the cause of failure"""
+    """Provide lang the cause of failure"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     WORKFLOW_ID_FIELD_NUMBER: builtins.int
     WORKFLOW_TYPE_FIELD_NUMBER: builtins.int
     CAUSE_FIELD_NUMBER: builtins.int
     workflow_id: builtins.str
-    """/ Lang should have this information but it's more convenient to pass it back
-    / for error construction on the lang side.
+    """Lang should have this information but it's more convenient to pass it back
+    for error construction on the lang side.
     """
     workflow_type: builtins.str
     cause: temporalio.bridge.proto.child_workflow.child_workflow_pb2.StartChildWorkflowExecutionFailedCause.ValueType
     def __init__(
         self,
         *,
         workflow_id: builtins.str = ...,
@@ -692,16 +704,16 @@
     ) -> None: ...
 
 global___ResolveChildWorkflowExecutionStartFailure = (
     ResolveChildWorkflowExecutionStartFailure
 )
 
 class ResolveChildWorkflowExecutionStartCancelled(google.protobuf.message.Message):
-    """/ `failure` should be ChildWorkflowFailure with cause set to CancelledFailure.
-    / The failure is constructed in core for lang's convenience.
+    """`failure` should be ChildWorkflowFailure with cause set to CancelledFailure.
+    The failure is constructed in core for lang's convenience.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
@@ -718,22 +730,22 @@
     ) -> None: ...
 
 global___ResolveChildWorkflowExecutionStartCancelled = (
     ResolveChildWorkflowExecutionStartCancelled
 )
 
 class ResolveChildWorkflowExecution(google.protobuf.message.Message):
-    """/ Notify a workflow that a child workflow execution has been resolved"""
+    """Notify a workflow that a child workflow execution has been resolved"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     RESULT_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command"""
+    """Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command"""
     @property
     def result(
         self,
     ) -> (
         temporalio.bridge.proto.child_workflow.child_workflow_pb2.ChildWorkflowResult
     ): ...
     def __init__(
@@ -749,15 +761,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["result", b"result", "seq", b"seq"]
     ) -> None: ...
 
 global___ResolveChildWorkflowExecution = ResolveChildWorkflowExecution
 
 class UpdateRandomSeed(google.protobuf.message.Message):
-    """/ Update the workflow's random seed"""
+    """Update the workflow's random seed"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RANDOMNESS_SEED_FIELD_NUMBER: builtins.int
     randomness_seed: builtins.int
     def __init__(
         self,
@@ -768,15 +780,15 @@
         self,
         field_name: typing_extensions.Literal["randomness_seed", b"randomness_seed"],
     ) -> None: ...
 
 global___UpdateRandomSeed = UpdateRandomSeed
 
 class QueryWorkflow(google.protobuf.message.Message):
-    """/ Query a workflow"""
+    """Query a workflow"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     class HeadersEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
@@ -799,33 +811,33 @@
         ) -> None: ...
 
     QUERY_ID_FIELD_NUMBER: builtins.int
     QUERY_TYPE_FIELD_NUMBER: builtins.int
     ARGUMENTS_FIELD_NUMBER: builtins.int
     HEADERS_FIELD_NUMBER: builtins.int
     query_id: builtins.str
-    """/ For PollWFTResp `query` field, this will be set to the special value `legacy`. For the
-    / `queries` field, the server provides a unique identifier. If it is a `legacy` query,
-    / lang cannot issue any commands in response other than to answer the query.
+    """For PollWFTResp `query` field, this will be set to the special value `legacy`. For the
+    `queries` field, the server provides a unique identifier. If it is a `legacy` query,
+    lang cannot issue any commands in response other than to answer the query.
     """
     query_type: builtins.str
-    """/ The query's function/method/etc name"""
+    """The query's function/method/etc name"""
     @property
     def arguments(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]: ...
     @property
     def headers(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Headers attached to the query"""
+        """Headers attached to the query"""
     def __init__(
         self,
         *,
         query_id: builtins.str = ...,
         query_type: builtins.str = ...,
         arguments: collections.abc.Iterable[
             temporalio.api.common.v1.message_pb2.Payload
@@ -849,26 +861,26 @@
             b"query_type",
         ],
     ) -> None: ...
 
 global___QueryWorkflow = QueryWorkflow
 
 class CancelWorkflow(google.protobuf.message.Message):
-    """/ Cancel a running workflow"""
+    """Cancel a running workflow"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     DETAILS_FIELD_NUMBER: builtins.int
     @property
     def details(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Information from the cancellation request"""
+        """Information from the cancellation request"""
     def __init__(
         self,
         *,
         details: collections.abc.Iterable[temporalio.api.common.v1.message_pb2.Payload]
         | None = ...,
     ) -> None: ...
     def ClearField(
@@ -974,21 +986,21 @@
 
 class ResolveSignalExternalWorkflow(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding SignalExternalWorkflowExecution
-    / command
+    """Sequence number as provided by lang in the corresponding SignalExternalWorkflowExecution
+    command
     """
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
-        """/ If populated, this signal either failed to be sent or was cancelled depending on failure
-        / type / info.
+        """If populated, this signal either failed to be sent or was cancelled depending on failure
+        type / info.
         """
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
     ) -> None: ...
@@ -1004,21 +1016,21 @@
 
 class ResolveRequestCancelExternalWorkflow(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     FAILURE_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Sequence number as provided by lang in the corresponding
-    / RequestCancelExternalWorkflowExecution command
+    """Sequence number as provided by lang in the corresponding
+    RequestCancelExternalWorkflowExecution command
     """
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure:
-        """/ If populated, this signal either failed to be sent or was cancelled depending on failure
-        / type / info.
+        """If populated, this signal either failed to be sent or was cancelled depending on failure
+        type / info.
         """
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
     ) -> None: ...
@@ -1067,14 +1079,16 @@
         """There was new work that must be handled while we attempted to complete the WFT. Ex:
         a new signal came in while trying to complete the workflow.
         """
         FATAL: RemoveFromCache._EvictionReason.ValueType  # 8
         """There was some fatal error processing the workflow, typically an internal error, but
         can also happen if then network drops out while paginating. Check message string.
         """
+        PAGINATION_OR_HISTORY_FETCH: RemoveFromCache._EvictionReason.ValueType  # 9
+        """Something went wrong attempting to fetch more history events."""
 
     class EvictionReason(_EvictionReason, metaclass=_EvictionReasonEnumTypeWrapper): ...
     UNSPECIFIED: RemoveFromCache.EvictionReason.ValueType  # 0
     CACHE_FULL: RemoveFromCache.EvictionReason.ValueType  # 1
     """Workflow cache is full"""
     CACHE_MISS: RemoveFromCache.EvictionReason.ValueType  # 2
     """Workflow received a partial task but was not in the cache. Typically it won't be in the
@@ -1094,14 +1108,16 @@
     """There was new work that must be handled while we attempted to complete the WFT. Ex:
     a new signal came in while trying to complete the workflow.
     """
     FATAL: RemoveFromCache.EvictionReason.ValueType  # 8
     """There was some fatal error processing the workflow, typically an internal error, but
     can also happen if then network drops out while paginating. Check message string.
     """
+    PAGINATION_OR_HISTORY_FETCH: RemoveFromCache.EvictionReason.ValueType  # 9
+    """Something went wrong attempting to fetch more history events."""
 
     MESSAGE_FIELD_NUMBER: builtins.int
     REASON_FIELD_NUMBER: builtins.int
     message: builtins.str
     reason: global___RemoveFromCache.EvictionReason.ValueType
     def __init__(
         self,
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/__init__.py` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.py`

 * *Files 1% similar despite different names*

```diff
@@ -30,15 +30,15 @@
     child_workflow_pb2 as temporal_dot_sdk_dot_core_dot_child__workflow_dot_child__workflow__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n;temporal/sdk/core/workflow_commands/workflow_commands.proto\x12\x19\x63oresdk.workflow_commands\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/failure/v1/message.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xac\r\n\x0fWorkflowCommand\x12<\n\x0bstart_timer\x18\x01 \x01(\x0b\x32%.coresdk.workflow_commands.StartTimerH\x00\x12H\n\x11schedule_activity\x18\x02 \x01(\x0b\x32+.coresdk.workflow_commands.ScheduleActivityH\x00\x12\x42\n\x10respond_to_query\x18\x03 \x01(\x0b\x32&.coresdk.workflow_commands.QueryResultH\x00\x12S\n\x17request_cancel_activity\x18\x04 \x01(\x0b\x32\x30.coresdk.workflow_commands.RequestCancelActivityH\x00\x12>\n\x0c\x63\x61ncel_timer\x18\x05 \x01(\x0b\x32&.coresdk.workflow_commands.CancelTimerH\x00\x12[\n\x1b\x63omplete_workflow_execution\x18\x06 \x01(\x0b\x32\x34.coresdk.workflow_commands.CompleteWorkflowExecutionH\x00\x12S\n\x17\x66\x61il_workflow_execution\x18\x07 \x01(\x0b\x32\x30.coresdk.workflow_commands.FailWorkflowExecutionH\x00\x12g\n"continue_as_new_workflow_execution\x18\x08 \x01(\x0b\x32\x39.coresdk.workflow_commands.ContinueAsNewWorkflowExecutionH\x00\x12W\n\x19\x63\x61ncel_workflow_execution\x18\t \x01(\x0b\x32\x32.coresdk.workflow_commands.CancelWorkflowExecutionH\x00\x12\x45\n\x10set_patch_marker\x18\n \x01(\x0b\x32).coresdk.workflow_commands.SetPatchMarkerH\x00\x12`\n\x1estart_child_workflow_execution\x18\x0b \x01(\x0b\x32\x36.coresdk.workflow_commands.StartChildWorkflowExecutionH\x00\x12\x62\n\x1f\x63\x61ncel_child_workflow_execution\x18\x0c \x01(\x0b\x32\x37.coresdk.workflow_commands.CancelChildWorkflowExecutionH\x00\x12w\n*request_cancel_external_workflow_execution\x18\r \x01(\x0b\x32\x41.coresdk.workflow_commands.RequestCancelExternalWorkflowExecutionH\x00\x12h\n"signal_external_workflow_execution\x18\x0e \x01(\x0b\x32:.coresdk.workflow_commands.SignalExternalWorkflowExecutionH\x00\x12Q\n\x16\x63\x61ncel_signal_workflow\x18\x0f \x01(\x0b\x32/.coresdk.workflow_commands.CancelSignalWorkflowH\x00\x12S\n\x17schedule_local_activity\x18\x10 \x01(\x0b\x32\x30.coresdk.workflow_commands.ScheduleLocalActivityH\x00\x12^\n\x1drequest_cancel_local_activity\x18\x11 \x01(\x0b\x32\x35.coresdk.workflow_commands.RequestCancelLocalActivityH\x00\x12\x66\n!upsert_workflow_search_attributes\x18\x12 \x01(\x0b\x32\x39.coresdk.workflow_commands.UpsertWorkflowSearchAttributesH\x00\x12Y\n\x1amodify_workflow_properties\x18\x13 \x01(\x0b\x32\x33.coresdk.workflow_commands.ModifyWorkflowPropertiesH\x00\x42\t\n\x07variant"S\n\nStartTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x38\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration"\x1a\n\x0b\x43\x61ncelTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xc7\x05\n\x10ScheduleActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12I\n\x07headers\x18\x06 \x03(\x0b\x32\x38.coresdk.workflow_commands.ScheduleActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0b \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x12\x1e\n\x16\x64o_not_eagerly_execute\x18\x0e \x01(\x08\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\xee\x05\n\x15ScheduleLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\r\x12:\n\x16original_schedule_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12N\n\x07headers\x18\x06 \x03(\x0b\x32=.coresdk.workflow_commands.ScheduleLocalActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x38\n\x15local_retry_threshold\x18\x0c \x01(\x0b\x32\x19.google.protobuf.Duration\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"$\n\x15RequestCancelActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r")\n\x1aRequestCancelLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r"\x9c\x01\n\x0bQueryResult\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12<\n\tsucceeded\x18\x02 \x01(\x0b\x32\'.coresdk.workflow_commands.QuerySuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.FailureH\x00\x42\t\n\x07variant"A\n\x0cQuerySuccess\x12\x31\n\x08response\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"L\n\x19\x43ompleteWorkflowExecution\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"J\n\x15\x46\x61ilWorkflowExecution\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xbe\x06\n\x1e\x43ontinueAsNewWorkflowExecution\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x37\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12Q\n\x04memo\x18\x06 \x03(\x0b\x32\x43.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.MemoEntry\x12W\n\x07headers\x18\x07 \x03(\x0b\x32\x46.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.HeadersEntry\x12j\n\x11search_attributes\x18\x08 \x03(\x0b\x32O.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.SearchAttributesEntry\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x19\n\x17\x43\x61ncelWorkflowExecution"6\n\x0eSetPatchMarker\x12\x10\n\x08patch_id\x18\x01 \x01(\t\x12\x12\n\ndeprecated\x18\x02 \x01(\x08"\xa3\t\n\x1bStartChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x03 \x01(\t\x12\x15\n\rworkflow_type\x18\x04 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12.\n\x05input\x18\x06 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12=\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x46\n\x13parent_close_policy\x18\n \x01(\x0e\x32).coresdk.child_workflow.ParentClosePolicy\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12T\n\x07headers\x18\x0f \x03(\x0b\x32\x43.coresdk.workflow_commands.StartChildWorkflowExecution.HeadersEntry\x12N\n\x04memo\x18\x10 \x03(\x0b\x32@.coresdk.workflow_commands.StartChildWorkflowExecution.MemoEntry\x12g\n\x11search_attributes\x18\x11 \x03(\x0b\x32L.coresdk.workflow_commands.StartChildWorkflowExecution.SearchAttributesEntry\x12P\n\x11\x63\x61ncellation_type\x18\x12 \x01(\x0e\x32\x35.coresdk.child_workflow.ChildWorkflowCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01":\n\x1c\x43\x61ncelChildWorkflowExecution\x12\x1a\n\x12\x63hild_workflow_seq\x18\x01 \x01(\r"\xa7\x01\n&RequestCancelExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x42\x08\n\x06target"\x8f\x03\n\x1fSignalExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12-\n\x04\x61rgs\x18\x05 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12X\n\x07headers\x18\x06 \x03(\x0b\x32G.coresdk.workflow_commands.SignalExternalWorkflowExecution.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x42\x08\n\x06target"#\n\x14\x43\x61ncelSignalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xe6\x01\n\x1eUpsertWorkflowSearchAttributes\x12j\n\x11search_attributes\x18\x01 \x03(\x0b\x32O.coresdk.workflow_commands.UpsertWorkflowSearchAttributes.SearchAttributesEntry\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"O\n\x18ModifyWorkflowProperties\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo*X\n\x18\x41\x63tivityCancellationType\x12\x0e\n\nTRY_CANCEL\x10\x00\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x01\x12\x0b\n\x07\x41\x42\x41NDON\x10\x02\x62\x06proto3'
+    b'\n;temporal/sdk/core/workflow_commands/workflow_commands.proto\x12\x19\x63oresdk.workflow_commands\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a$temporal/api/common/v1/message.proto\x1a$temporal/api/enums/v1/workflow.proto\x1a%temporal/api/failure/v1/message.proto\x1a\x35temporal/sdk/core/child_workflow/child_workflow.proto\x1a%temporal/sdk/core/common/common.proto"\xac\r\n\x0fWorkflowCommand\x12<\n\x0bstart_timer\x18\x01 \x01(\x0b\x32%.coresdk.workflow_commands.StartTimerH\x00\x12H\n\x11schedule_activity\x18\x02 \x01(\x0b\x32+.coresdk.workflow_commands.ScheduleActivityH\x00\x12\x42\n\x10respond_to_query\x18\x03 \x01(\x0b\x32&.coresdk.workflow_commands.QueryResultH\x00\x12S\n\x17request_cancel_activity\x18\x04 \x01(\x0b\x32\x30.coresdk.workflow_commands.RequestCancelActivityH\x00\x12>\n\x0c\x63\x61ncel_timer\x18\x05 \x01(\x0b\x32&.coresdk.workflow_commands.CancelTimerH\x00\x12[\n\x1b\x63omplete_workflow_execution\x18\x06 \x01(\x0b\x32\x34.coresdk.workflow_commands.CompleteWorkflowExecutionH\x00\x12S\n\x17\x66\x61il_workflow_execution\x18\x07 \x01(\x0b\x32\x30.coresdk.workflow_commands.FailWorkflowExecutionH\x00\x12g\n"continue_as_new_workflow_execution\x18\x08 \x01(\x0b\x32\x39.coresdk.workflow_commands.ContinueAsNewWorkflowExecutionH\x00\x12W\n\x19\x63\x61ncel_workflow_execution\x18\t \x01(\x0b\x32\x32.coresdk.workflow_commands.CancelWorkflowExecutionH\x00\x12\x45\n\x10set_patch_marker\x18\n \x01(\x0b\x32).coresdk.workflow_commands.SetPatchMarkerH\x00\x12`\n\x1estart_child_workflow_execution\x18\x0b \x01(\x0b\x32\x36.coresdk.workflow_commands.StartChildWorkflowExecutionH\x00\x12\x62\n\x1f\x63\x61ncel_child_workflow_execution\x18\x0c \x01(\x0b\x32\x37.coresdk.workflow_commands.CancelChildWorkflowExecutionH\x00\x12w\n*request_cancel_external_workflow_execution\x18\r \x01(\x0b\x32\x41.coresdk.workflow_commands.RequestCancelExternalWorkflowExecutionH\x00\x12h\n"signal_external_workflow_execution\x18\x0e \x01(\x0b\x32:.coresdk.workflow_commands.SignalExternalWorkflowExecutionH\x00\x12Q\n\x16\x63\x61ncel_signal_workflow\x18\x0f \x01(\x0b\x32/.coresdk.workflow_commands.CancelSignalWorkflowH\x00\x12S\n\x17schedule_local_activity\x18\x10 \x01(\x0b\x32\x30.coresdk.workflow_commands.ScheduleLocalActivityH\x00\x12^\n\x1drequest_cancel_local_activity\x18\x11 \x01(\x0b\x32\x35.coresdk.workflow_commands.RequestCancelLocalActivityH\x00\x12\x66\n!upsert_workflow_search_attributes\x18\x12 \x01(\x0b\x32\x39.coresdk.workflow_commands.UpsertWorkflowSearchAttributesH\x00\x12Y\n\x1amodify_workflow_properties\x18\x13 \x01(\x0b\x32\x33.coresdk.workflow_commands.ModifyWorkflowPropertiesH\x00\x42\t\n\x07variant"S\n\nStartTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x38\n\x15start_to_fire_timeout\x18\x02 \x01(\x0b\x32\x19.google.protobuf.Duration"\x1a\n\x0b\x43\x61ncelTimer\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xc7\x05\n\x10ScheduleActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12I\n\x07headers\x18\x06 \x03(\x0b\x32\x38.coresdk.workflow_commands.ScheduleActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x34\n\x11heartbeat_timeout\x18\x0b \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0c \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x12\x1e\n\x16\x64o_not_eagerly_execute\x18\x0e \x01(\x08\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\xee\x05\n\x15ScheduleLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x13\n\x0b\x61\x63tivity_id\x18\x02 \x01(\t\x12\x15\n\ractivity_type\x18\x03 \x01(\t\x12\x0f\n\x07\x61ttempt\x18\x04 \x01(\r\x12:\n\x16original_schedule_time\x18\x05 \x01(\x0b\x32\x1a.google.protobuf.Timestamp\x12N\n\x07headers\x18\x06 \x03(\x0b\x32=.coresdk.workflow_commands.ScheduleLocalActivity.HeadersEntry\x12\x32\n\targuments\x18\x07 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12<\n\x19schedule_to_close_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12<\n\x19schedule_to_start_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x16start_to_close_timeout\x18\n \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x39\n\x0cretry_policy\x18\x0b \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x38\n\x15local_retry_threshold\x18\x0c \x01(\x0b\x32\x19.google.protobuf.Duration\x12N\n\x11\x63\x61ncellation_type\x18\r \x01(\x0e\x32\x33.coresdk.workflow_commands.ActivityCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"$\n\x15RequestCancelActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r")\n\x1aRequestCancelLocalActivity\x12\x0b\n\x03seq\x18\x01 \x01(\r"\x9c\x01\n\x0bQueryResult\x12\x10\n\x08query_id\x18\x01 \x01(\t\x12<\n\tsucceeded\x18\x02 \x01(\x0b\x32\'.coresdk.workflow_commands.QuerySuccessH\x00\x12\x32\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32 .temporal.api.failure.v1.FailureH\x00\x42\t\n\x07variant"A\n\x0cQuerySuccess\x12\x31\n\x08response\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"L\n\x19\x43ompleteWorkflowExecution\x12/\n\x06result\x18\x01 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload"J\n\x15\x46\x61ilWorkflowExecution\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure"\xbe\x06\n\x1e\x43ontinueAsNewWorkflowExecution\x12\x15\n\rworkflow_type\x18\x01 \x01(\t\x12\x12\n\ntask_queue\x18\x02 \x01(\t\x12\x32\n\targuments\x18\x03 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12\x37\n\x14workflow_run_timeout\x18\x04 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\x05 \x01(\x0b\x32\x19.google.protobuf.Duration\x12Q\n\x04memo\x18\x06 \x03(\x0b\x32\x43.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.MemoEntry\x12W\n\x07headers\x18\x07 \x03(\x0b\x32\x46.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.HeadersEntry\x12j\n\x11search_attributes\x18\x08 \x03(\x0b\x32O.coresdk.workflow_commands.ContinueAsNewWorkflowExecution.SearchAttributesEntry\x12\x39\n\x0cretry_policy\x18\t \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"\x19\n\x17\x43\x61ncelWorkflowExecution"6\n\x0eSetPatchMarker\x12\x10\n\x08patch_id\x18\x01 \x01(\t\x12\x12\n\ndeprecated\x18\x02 \x01(\x08"\xa3\t\n\x1bStartChildWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12\x11\n\tnamespace\x18\x02 \x01(\t\x12\x13\n\x0bworkflow_id\x18\x03 \x01(\t\x12\x15\n\rworkflow_type\x18\x04 \x01(\t\x12\x12\n\ntask_queue\x18\x05 \x01(\t\x12.\n\x05input\x18\x06 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12=\n\x1aworkflow_execution_timeout\x18\x07 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x37\n\x14workflow_run_timeout\x18\x08 \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x38\n\x15workflow_task_timeout\x18\t \x01(\x0b\x32\x19.google.protobuf.Duration\x12\x46\n\x13parent_close_policy\x18\n \x01(\x0e\x32).coresdk.child_workflow.ParentClosePolicy\x12N\n\x18workflow_id_reuse_policy\x18\x0c \x01(\x0e\x32,.temporal.api.enums.v1.WorkflowIdReusePolicy\x12\x39\n\x0cretry_policy\x18\r \x01(\x0b\x32#.temporal.api.common.v1.RetryPolicy\x12\x15\n\rcron_schedule\x18\x0e \x01(\t\x12T\n\x07headers\x18\x0f \x03(\x0b\x32\x43.coresdk.workflow_commands.StartChildWorkflowExecution.HeadersEntry\x12N\n\x04memo\x18\x10 \x03(\x0b\x32@.coresdk.workflow_commands.StartChildWorkflowExecution.MemoEntry\x12g\n\x11search_attributes\x18\x11 \x03(\x0b\x32L.coresdk.workflow_commands.StartChildWorkflowExecution.SearchAttributesEntry\x12P\n\x11\x63\x61ncellation_type\x18\x12 \x01(\x0e\x32\x35.coresdk.child_workflow.ChildWorkflowCancellationType\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aL\n\tMemoEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01":\n\x1c\x43\x61ncelChildWorkflowExecution\x12\x1a\n\x12\x63hild_workflow_seq\x18\x01 \x01(\r"\xa7\x01\n&RequestCancelExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x42\x08\n\x06target"\x8f\x03\n\x1fSignalExternalWorkflowExecution\x12\x0b\n\x03seq\x18\x01 \x01(\r\x12I\n\x12workflow_execution\x18\x02 \x01(\x0b\x32+.coresdk.common.NamespacedWorkflowExecutionH\x00\x12\x1b\n\x11\x63hild_workflow_id\x18\x03 \x01(\tH\x00\x12\x13\n\x0bsignal_name\x18\x04 \x01(\t\x12-\n\x04\x61rgs\x18\x05 \x03(\x0b\x32\x1f.temporal.api.common.v1.Payload\x12X\n\x07headers\x18\x06 \x03(\x0b\x32G.coresdk.workflow_commands.SignalExternalWorkflowExecution.HeadersEntry\x1aO\n\x0cHeadersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01\x42\x08\n\x06target"#\n\x14\x43\x61ncelSignalWorkflow\x12\x0b\n\x03seq\x18\x01 \x01(\r"\xe6\x01\n\x1eUpsertWorkflowSearchAttributes\x12j\n\x11search_attributes\x18\x01 \x03(\x0b\x32O.coresdk.workflow_commands.UpsertWorkflowSearchAttributes.SearchAttributesEntry\x1aX\n\x15SearchAttributesEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12.\n\x05value\x18\x02 \x01(\x0b\x32\x1f.temporal.api.common.v1.Payload:\x02\x38\x01"O\n\x18ModifyWorkflowProperties\x12\x33\n\rupserted_memo\x18\x01 \x01(\x0b\x32\x1c.temporal.api.common.v1.Memo*X\n\x18\x41\x63tivityCancellationType\x12\x0e\n\nTRY_CANCEL\x10\x00\x12\x1f\n\x1bWAIT_CANCELLATION_COMPLETED\x10\x01\x12\x0b\n\x07\x41\x42\x41NDON\x10\x02\x42,\xea\x02)Temporalio::Bridge::Api::WorkflowCommandsb\x06proto3'
 )
 
 _ACTIVITYCANCELLATIONTYPE = DESCRIPTOR.enum_types_by_name["ActivityCancellationType"]
 ActivityCancellationType = enum_type_wrapper.EnumTypeWrapper(_ACTIVITYCANCELLATIONTYPE)
 TRY_CANCEL = 0
 WAIT_CANCELLATION_COMPLETED = 1
 ABANDON = 2
@@ -438,14 +438,17 @@
         # @@protoc_insertion_point(class_scope:coresdk.workflow_commands.ModifyWorkflowProperties)
     },
 )
 _sym_db.RegisterMessage(ModifyWorkflowProperties)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
+    DESCRIPTOR._serialized_options = (
+        b"\352\002)Temporalio::Bridge::Api::WorkflowCommands"
+    )
     _SCHEDULEACTIVITY_HEADERSENTRY._options = None
     _SCHEDULEACTIVITY_HEADERSENTRY._serialized_options = b"8\001"
     _SCHEDULELOCALACTIVITY_HEADERSENTRY._options = None
     _SCHEDULELOCALACTIVITY_HEADERSENTRY._serialized_options = b"8\001"
     _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._options = None
     _CONTINUEASNEWWORKFLOWEXECUTION_MEMOENTRY._serialized_options = b"8\001"
     _CONTINUEASNEWWORKFLOWEXECUTION_HEADERSENTRY._options = None
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_commands/workflow_commands_pb2.pyi`

 * *Files 2% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 """
 @generated by mypy-protobuf.  Do not edit manually!
 isort:skip_file
-*
+
 Definitions for commands from a workflow in lang SDK to core. While a workflow processes a batch
 of activation jobs, it accumulates these commands to be sent back to core to conclude that
 activation.
 """
 import builtins
 import collections.abc
 import google.protobuf.descriptor
@@ -37,39 +37,39 @@
     google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[
         _ActivityCancellationType.ValueType
     ],
     builtins.type,
 ):  # noqa: F821
     DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
     TRY_CANCEL: _ActivityCancellationType.ValueType  # 0
-    """/ Initiate a cancellation request and immediately report cancellation to the workflow."""
+    """Initiate a cancellation request and immediately report cancellation to the workflow."""
     WAIT_CANCELLATION_COMPLETED: _ActivityCancellationType.ValueType  # 1
-    """/ Wait for activity cancellation completion. Note that activity must heartbeat to receive a
-    / cancellation notification. This can block the cancellation for a long time if activity
-    / doesn't heartbeat or chooses to ignore the cancellation request.
+    """Wait for activity cancellation completion. Note that activity must heartbeat to receive a
+    cancellation notification. This can block the cancellation for a long time if activity
+    doesn't heartbeat or chooses to ignore the cancellation request.
     """
     ABANDON: _ActivityCancellationType.ValueType  # 2
-    """/ Do not request cancellation of the activity and immediately report cancellation to the
-    / workflow
+    """Do not request cancellation of the activity and immediately report cancellation to the
+    workflow
     """
 
 class ActivityCancellationType(
     _ActivityCancellationType, metaclass=_ActivityCancellationTypeEnumTypeWrapper
 ): ...
 
 TRY_CANCEL: ActivityCancellationType.ValueType  # 0
-"""/ Initiate a cancellation request and immediately report cancellation to the workflow."""
+"""Initiate a cancellation request and immediately report cancellation to the workflow."""
 WAIT_CANCELLATION_COMPLETED: ActivityCancellationType.ValueType  # 1
-"""/ Wait for activity cancellation completion. Note that activity must heartbeat to receive a
-/ cancellation notification. This can block the cancellation for a long time if activity
-/ doesn't heartbeat or chooses to ignore the cancellation request.
+"""Wait for activity cancellation completion. Note that activity must heartbeat to receive a
+cancellation notification. This can block the cancellation for a long time if activity
+doesn't heartbeat or chooses to ignore the cancellation request.
 """
 ABANDON: ActivityCancellationType.ValueType  # 2
-"""/ Do not request cancellation of the activity and immediately report cancellation to the
-/ workflow
+"""Do not request cancellation of the activity and immediately report cancellation to the
+workflow
 """
 global___ActivityCancellationType = ActivityCancellationType
 
 class WorkflowCommand(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     START_TIMER_FIELD_NUMBER: builtins.int
@@ -291,15 +291,15 @@
 
 class StartTimer(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     START_TO_FIRE_TIMEOUT_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     @property
     def start_to_fire_timeout(self) -> google.protobuf.duration_pb2.Duration: ...
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         start_to_fire_timeout: google.protobuf.duration_pb2.Duration | None = ...,
@@ -320,15 +320,15 @@
 global___StartTimer = StartTimer
 
 class CancelTimer(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number as passed to `StartTimer`"""
+    """Lang's incremental sequence number as passed to `StartTimer`"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["seq", b"seq"]
@@ -371,15 +371,15 @@
     SCHEDULE_TO_START_TIMEOUT_FIELD_NUMBER: builtins.int
     START_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     HEARTBEAT_TIMEOUT_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CANCELLATION_TYPE_FIELD_NUMBER: builtins.int
     DO_NOT_EAGERLY_EXECUTE_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     activity_id: builtins.str
     activity_type: builtins.str
     task_queue: builtins.str
     """The name of the task queue to place this activity request in"""
     @property
     def headers(
         self,
@@ -388,47 +388,47 @@
     ]: ...
     @property
     def arguments(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Arguments/input to the activity. Called "input" upstream."""
+        """Arguments/input to the activity. Called "input" upstream."""
     @property
     def schedule_to_close_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Indicates how long the caller is willing to wait for an activity completion. Limits how long
-        / retries will be attempted. Either this or start_to_close_timeout_seconds must be specified.
-        / When not specified defaults to the workflow execution timeout.
+        """Indicates how long the caller is willing to wait for an activity completion. Limits how long
+        retries will be attempted. Either this or start_to_close_timeout_seconds must be specified.
+        When not specified defaults to the workflow execution timeout.
         """
     @property
     def schedule_to_start_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Limits time an activity task can stay in a task queue before a worker picks it up. This
-        / timeout is always non retryable as all a retry would achieve is to put it back into the same
-        / queue. Defaults to schedule_to_close_timeout or workflow execution timeout if not specified.
+        """Limits time an activity task can stay in a task queue before a worker picks it up. This
+        timeout is always non retryable as all a retry would achieve is to put it back into the same
+        queue. Defaults to schedule_to_close_timeout or workflow execution timeout if not specified.
         """
     @property
     def start_to_close_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Maximum time an activity is allowed to execute after a pick up by a worker. This timeout is
-        / always retryable. Either this or schedule_to_close_timeout must be specified.
+        """Maximum time an activity is allowed to execute after a pick up by a worker. This timeout is
+        always retryable. Either this or schedule_to_close_timeout must be specified.
         """
     @property
     def heartbeat_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Maximum time allowed between successful worker heartbeats."""
+        """Maximum time allowed between successful worker heartbeats."""
     @property
     def retry_policy(self) -> temporalio.api.common.v1.message_pb2.RetryPolicy:
-        """/ Activities are provided by a default retry policy controlled through the service dynamic
-        / configuration. Retries are happening up to schedule_to_close_timeout. To disable retries set
-        / retry_policy.maximum_attempts to 1.
+        """Activities are provided by a default retry policy controlled through the service dynamic
+        configuration. Retries are happening up to schedule_to_close_timeout. To disable retries set
+        retry_policy.maximum_attempts to 1.
         """
     cancellation_type: global___ActivityCancellationType.ValueType
-    """/ Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed"""
+    """Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed"""
     do_not_eagerly_execute: builtins.bool
-    """/ If set, the worker will not tell the service that it can immediately start executing this
-    / activity. When unset/default, workers will always attempt to do so if activity execution
-    / slots are available.
+    """If set, the worker will not tell the service that it can immediately start executing this
+    activity. When unset/default, workers will always attempt to do so if activity execution
+    slots are available.
     """
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         activity_id: builtins.str = ...,
         activity_type: builtins.str = ...,
@@ -533,76 +533,76 @@
     SCHEDULE_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     SCHEDULE_TO_START_TIMEOUT_FIELD_NUMBER: builtins.int
     START_TO_CLOSE_TIMEOUT_FIELD_NUMBER: builtins.int
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     LOCAL_RETRY_THRESHOLD_FIELD_NUMBER: builtins.int
     CANCELLATION_TYPE_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     activity_id: builtins.str
     activity_type: builtins.str
     attempt: builtins.int
-    """/ Local activities can start with a non-1 attempt, if lang has been told to backoff using
-    / a timer before retrying. It should pass the attempt number from a `DoBackoff` activity
-    / resolution.
+    """Local activities can start with a non-1 attempt, if lang has been told to backoff using
+    a timer before retrying. It should pass the attempt number from a `DoBackoff` activity
+    resolution.
     """
     @property
     def original_schedule_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
-        """/ If this local activity is a retry (as per the attempt field) this needs to be the original
-        / scheduling time (as provided in `DoBackoff`)
+        """If this local activity is a retry (as per the attempt field) this needs to be the original
+        scheduling time (as provided in `DoBackoff`)
         """
     @property
     def headers(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]: ...
     @property
     def arguments(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Arguments/input to the activity."""
+        """Arguments/input to the activity."""
     @property
     def schedule_to_close_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Indicates how long the caller is willing to wait for local activity completion. Limits how
-        / long retries will be attempted. When not specified defaults to the workflow execution
-        / timeout (which may be unset).
+        """Indicates how long the caller is willing to wait for local activity completion. Limits how
+        long retries will be attempted. When not specified defaults to the workflow execution
+        timeout (which may be unset).
         """
     @property
     def schedule_to_start_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Limits time the local activity can idle internally before being executed. That can happen if
-        / the worker is currently at max concurrent local activity executions. This timeout is always
-        / non retryable as all a retry would achieve is to put it back into the same queue. Defaults
-        / to `schedule_to_close_timeout` if not specified and that is set. Must be <=
-        / `schedule_to_close_timeout` when set, otherwise, it will be clamped down.
+        """Limits time the local activity can idle internally before being executed. That can happen if
+        the worker is currently at max concurrent local activity executions. This timeout is always
+        non retryable as all a retry would achieve is to put it back into the same queue. Defaults
+        to `schedule_to_close_timeout` if not specified and that is set. Must be <=
+        `schedule_to_close_timeout` when set, otherwise, it will be clamped down.
         """
     @property
     def start_to_close_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Maximum time the local activity is allowed to execute after the task is dispatched. This
-        / timeout is always retryable. Either or both of `schedule_to_close_timeout` and this must be
-        / specified. If set, this must be <= `schedule_to_close_timeout`, otherwise, it will be
-        / clamped down.
+        """Maximum time the local activity is allowed to execute after the task is dispatched. This
+        timeout is always retryable. Either or both of `schedule_to_close_timeout` and this must be
+        specified. If set, this must be <= `schedule_to_close_timeout`, otherwise, it will be
+        clamped down.
         """
     @property
     def retry_policy(self) -> temporalio.api.common.v1.message_pb2.RetryPolicy:
-        """/ Specify a retry policy for the local activity. By default local activities will be retried
-        / indefinitely.
+        """Specify a retry policy for the local activity. By default local activities will be retried
+        indefinitely.
         """
     @property
     def local_retry_threshold(self) -> google.protobuf.duration_pb2.Duration:
-        """/ If the activity is retrying and backoff would exceed this value, lang will be told to
-        / schedule a timer and retry the activity after. Otherwise, backoff will happen internally in
-        / core. Defaults to 1 minute.
+        """If the activity is retrying and backoff would exceed this value, lang will be told to
+        schedule a timer and retry the activity after. Otherwise, backoff will happen internally in
+        core. Defaults to 1 minute.
         """
     cancellation_type: global___ActivityCancellationType.ValueType
-    """/ Defines how the workflow will wait (or not) for cancellation of the activity to be
-    / confirmed. Lang should default this to `WAIT_CANCELLATION_COMPLETED`, even though proto
-    / will default to `TRY_CANCEL` automatically.
+    """Defines how the workflow will wait (or not) for cancellation of the activity to be
+    confirmed. Lang should default this to `WAIT_CANCELLATION_COMPLETED`, even though proto
+    will default to `TRY_CANCEL` automatically.
     """
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         activity_id: builtins.str = ...,
         activity_type: builtins.str = ...,
@@ -675,15 +675,15 @@
 global___ScheduleLocalActivity = ScheduleLocalActivity
 
 class RequestCancelActivity(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number as passed to `ScheduleActivity`"""
+    """Lang's incremental sequence number as passed to `ScheduleActivity`"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["seq", b"seq"]
@@ -692,15 +692,15 @@
 global___RequestCancelActivity = RequestCancelActivity
 
 class RequestCancelLocalActivity(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number as passed to `ScheduleLocalActivity`"""
+    """Lang's incremental sequence number as passed to `ScheduleLocalActivity`"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["seq", b"seq"]
@@ -711,15 +711,15 @@
 class QueryResult(google.protobuf.message.Message):
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     QUERY_ID_FIELD_NUMBER: builtins.int
     SUCCEEDED_FIELD_NUMBER: builtins.int
     FAILED_FIELD_NUMBER: builtins.int
     query_id: builtins.str
-    """/ Corresponds to the id provided in the activation job"""
+    """Corresponds to the id provided in the activation job"""
     @property
     def succeeded(self) -> global___QuerySuccess: ...
     @property
     def failed(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
     def __init__(
         self,
         *,
@@ -769,15 +769,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["response", b"response"]
     ) -> None: ...
 
 global___QuerySuccess = QuerySuccess
 
 class CompleteWorkflowExecution(google.protobuf.message.Message):
-    """/ Issued when the workflow completes successfully"""
+    """Issued when the workflow completes successfully"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RESULT_FIELD_NUMBER: builtins.int
     @property
     def result(self) -> temporalio.api.common.v1.message_pb2.Payload: ...
     def __init__(
@@ -791,15 +791,15 @@
     def ClearField(
         self, field_name: typing_extensions.Literal["result", b"result"]
     ) -> None: ...
 
 global___CompleteWorkflowExecution = CompleteWorkflowExecution
 
 class FailWorkflowExecution(google.protobuf.message.Message):
-    """/ Issued when the workflow errors out"""
+    """Issued when the workflow errors out"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
     def __init__(
@@ -1004,28 +1004,28 @@
             b"workflow_type",
         ],
     ) -> None: ...
 
 global___ContinueAsNewWorkflowExecution = ContinueAsNewWorkflowExecution
 
 class CancelWorkflowExecution(google.protobuf.message.Message):
-    """/ Indicate a workflow has completed as cancelled. Generally sent as a response to an activation
-    / containing a cancellation job.
+    """Indicate a workflow has completed as cancelled. Generally sent as a response to an activation
+    containing a cancellation job.
     """
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     def __init__(
         self,
     ) -> None: ...
 
 global___CancelWorkflowExecution = CancelWorkflowExecution
 
 class SetPatchMarker(google.protobuf.message.Message):
-    """/ A request to set/check if a certain patch is present or not"""
+    """A request to set/check if a certain patch is present or not"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     PATCH_ID_FIELD_NUMBER: builtins.int
     DEPRECATED_FIELD_NUMBER: builtins.int
     patch_id: builtins.str
     """A user-chosen identifier for this patch. If the same identifier is used in multiple places in
@@ -1048,15 +1048,15 @@
             "deprecated", b"deprecated", "patch_id", b"patch_id"
         ],
     ) -> None: ...
 
 global___SetPatchMarker = SetPatchMarker
 
 class StartChildWorkflowExecution(google.protobuf.message.Message):
-    """/ Start a child workflow execution"""
+    """Start a child workflow execution"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     class HeadersEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
@@ -1136,66 +1136,66 @@
     RETRY_POLICY_FIELD_NUMBER: builtins.int
     CRON_SCHEDULE_FIELD_NUMBER: builtins.int
     HEADERS_FIELD_NUMBER: builtins.int
     MEMO_FIELD_NUMBER: builtins.int
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     CANCELLATION_TYPE_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     namespace: builtins.str
     workflow_id: builtins.str
     workflow_type: builtins.str
     task_queue: builtins.str
     @property
     def input(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]: ...
     @property
     def workflow_execution_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Total workflow execution timeout including retries and continue as new."""
+        """Total workflow execution timeout including retries and continue as new."""
     @property
     def workflow_run_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Timeout of a single workflow run."""
+        """Timeout of a single workflow run."""
     @property
     def workflow_task_timeout(self) -> google.protobuf.duration_pb2.Duration:
-        """/ Timeout of a single workflow task."""
+        """Timeout of a single workflow task."""
     parent_close_policy: temporalio.bridge.proto.child_workflow.child_workflow_pb2.ParentClosePolicy.ValueType
-    """/ Default: PARENT_CLOSE_POLICY_TERMINATE."""
+    """Default: PARENT_CLOSE_POLICY_TERMINATE."""
     workflow_id_reuse_policy: temporalio.api.enums.v1.workflow_pb2.WorkflowIdReusePolicy.ValueType
     """string control = 11; (unused from StartChildWorkflowExecutionCommandAttributes)
     Default: WORKFLOW_ID_REUSE_POLICY_ALLOW_DUPLICATE.
     """
     @property
     def retry_policy(self) -> temporalio.api.common.v1.message_pb2.RetryPolicy: ...
     cron_schedule: builtins.str
     @property
     def headers(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Header fields"""
+        """Header fields"""
     @property
     def memo(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Memo fields"""
+        """Memo fields"""
     @property
     def search_attributes(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Search attributes"""
+        """Search attributes"""
     cancellation_type: temporalio.bridge.proto.child_workflow.child_workflow_pb2.ChildWorkflowCancellationType.ValueType
-    """/ Defines behaviour of the underlying workflow when child workflow cancellation has been requested."""
+    """Defines behaviour of the underlying workflow when child workflow cancellation has been requested."""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         namespace: builtins.str = ...,
         workflow_id: builtins.str = ...,
         workflow_type: builtins.str = ...,
@@ -1275,15 +1275,15 @@
             b"workflow_type",
         ],
     ) -> None: ...
 
 global___StartChildWorkflowExecution = StartChildWorkflowExecution
 
 class CancelChildWorkflowExecution(google.protobuf.message.Message):
-    """/ Cancel a child workflow"""
+    """Cancel a child workflow"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     CHILD_WORKFLOW_SEQ_FIELD_NUMBER: builtins.int
     child_workflow_seq: builtins.int
     """Sequence number as given to the `StartChildWorkflowExecution` command"""
     def __init__(
@@ -1297,23 +1297,23 @@
             "child_workflow_seq", b"child_workflow_seq"
         ],
     ) -> None: ...
 
 global___CancelChildWorkflowExecution = CancelChildWorkflowExecution
 
 class RequestCancelExternalWorkflowExecution(google.protobuf.message.Message):
-    """/ Request cancellation of an external workflow execution (which may be a started child)"""
+    """Request cancellation of an external workflow execution (which may be a started child)"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     WORKFLOW_EXECUTION_FIELD_NUMBER: builtins.int
     CHILD_WORKFLOW_ID_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     @property
     def workflow_execution(
         self,
     ) -> temporalio.bridge.proto.common.common_pb2.NamespacedWorkflowExecution:
         """A specific workflow instance"""
     child_workflow_id: builtins.str
     """The desired target must be a child of the issuing workflow, and this is its workflow id"""
@@ -1354,15 +1354,15 @@
     ) -> (
         typing_extensions.Literal["workflow_execution", "child_workflow_id"] | None
     ): ...
 
 global___RequestCancelExternalWorkflowExecution = RequestCancelExternalWorkflowExecution
 
 class SignalExternalWorkflowExecution(google.protobuf.message.Message):
-    """/ Send a signal to an external or child workflow"""
+    """Send a signal to an external or child workflow"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     class HeadersEntry(google.protobuf.message.Message):
         DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
         KEY_FIELD_NUMBER: builtins.int
@@ -1387,38 +1387,38 @@
     SEQ_FIELD_NUMBER: builtins.int
     WORKFLOW_EXECUTION_FIELD_NUMBER: builtins.int
     CHILD_WORKFLOW_ID_FIELD_NUMBER: builtins.int
     SIGNAL_NAME_FIELD_NUMBER: builtins.int
     ARGS_FIELD_NUMBER: builtins.int
     HEADERS_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number, used as the operation identifier"""
+    """Lang's incremental sequence number, used as the operation identifier"""
     @property
     def workflow_execution(
         self,
     ) -> temporalio.bridge.proto.common.common_pb2.NamespacedWorkflowExecution:
         """A specific workflow instance"""
     child_workflow_id: builtins.str
     """The desired target must be a child of the issuing workflow, and this is its workflow id"""
     signal_name: builtins.str
-    """/ Name of the signal handler"""
+    """Name of the signal handler"""
     @property
     def args(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Arguments for the handler"""
+        """Arguments for the handler"""
     @property
     def headers(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ Headers to attach to the signal"""
+        """Headers to attach to the signal"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
         workflow_execution: temporalio.bridge.proto.common.common_pb2.NamespacedWorkflowExecution
         | None = ...,
         child_workflow_id: builtins.str = ...,
@@ -1465,21 +1465,21 @@
     ) -> (
         typing_extensions.Literal["workflow_execution", "child_workflow_id"] | None
     ): ...
 
 global___SignalExternalWorkflowExecution = SignalExternalWorkflowExecution
 
 class CancelSignalWorkflow(google.protobuf.message.Message):
-    """/ Can be used to cancel not-already-sent `SignalExternalWorkflowExecution` commands"""
+    """Can be used to cancel not-already-sent `SignalExternalWorkflowExecution` commands"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     SEQ_FIELD_NUMBER: builtins.int
     seq: builtins.int
-    """/ Lang's incremental sequence number as passed to `SignalExternalWorkflowExecution`"""
+    """Lang's incremental sequence number as passed to `SignalExternalWorkflowExecution`"""
     def __init__(
         self,
         *,
         seq: builtins.int = ...,
     ) -> None: ...
     def ClearField(
         self, field_name: typing_extensions.Literal["seq", b"seq"]
@@ -1515,16 +1515,16 @@
     SEARCH_ATTRIBUTES_FIELD_NUMBER: builtins.int
     @property
     def search_attributes(
         self,
     ) -> google.protobuf.internal.containers.MessageMap[
         builtins.str, temporalio.api.common.v1.message_pb2.Payload
     ]:
-        """/ SearchAttributes fields - equivalent to indexed_fields on api. Key = search index, Value =
-        / value?
+        """SearchAttributes fields - equivalent to indexed_fields on api. Key = search index, Value =
+        value?
         """
     def __init__(
         self,
         *,
         search_attributes: collections.abc.Mapping[
             builtins.str, temporalio.api.common.v1.message_pb2.Payload
         ]
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.py`

 * *Files 9% similar despite different names*

```diff
@@ -9,26 +9,29 @@
 from google.protobuf import symbol_database as _symbol_database
 
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
+from temporalio.api.enums.v1 import (
+    failed_cause_pb2 as temporal_dot_api_dot_enums_dot_v1_dot_failed__cause__pb2,
+)
 from temporalio.api.failure.v1 import (
     message_pb2 as temporal_dot_api_dot_failure_dot_v1_dot_message__pb2,
 )
 from temporalio.bridge.proto.common import (
     common_pb2 as temporal_dot_sdk_dot_core_dot_common_dot_common__pb2,
 )
 from temporalio.bridge.proto.workflow_commands import (
     workflow_commands_pb2 as temporal_dot_sdk_dot_core_dot_workflow__commands_dot_workflow__commands__pb2,
 )
 
 DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(
-    b'\n?temporal/sdk/core/workflow_completion/workflow_completion.proto\x12\x1b\x63oresdk.workflow_completion\x1a%temporal/api/failure/v1/message.proto\x1a%temporal/sdk/core/common/common.proto\x1a;temporal/sdk/core/workflow_commands/workflow_commands.proto"\xac\x01\n\x1cWorkflowActivationCompletion\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12:\n\nsuccessful\x18\x02 \x01(\x0b\x32$.coresdk.workflow_completion.SuccessH\x00\x12\x36\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32$.coresdk.workflow_completion.FailureH\x00\x42\x08\n\x06status"G\n\x07Success\x12<\n\x08\x63ommands\x18\x01 \x03(\x0b\x32*.coresdk.workflow_commands.WorkflowCommand"<\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failureb\x06proto3'
+    b'\n?temporal/sdk/core/workflow_completion/workflow_completion.proto\x12\x1b\x63oresdk.workflow_completion\x1a%temporal/api/failure/v1/message.proto\x1a(temporal/api/enums/v1/failed_cause.proto\x1a%temporal/sdk/core/common/common.proto\x1a;temporal/sdk/core/workflow_commands/workflow_commands.proto"\xac\x01\n\x1cWorkflowActivationCompletion\x12\x0e\n\x06run_id\x18\x01 \x01(\t\x12:\n\nsuccessful\x18\x02 \x01(\x0b\x32$.coresdk.workflow_completion.SuccessH\x00\x12\x36\n\x06\x66\x61iled\x18\x03 \x01(\x0b\x32$.coresdk.workflow_completion.FailureH\x00\x42\x08\n\x06status"d\n\x07Success\x12<\n\x08\x63ommands\x18\x01 \x03(\x0b\x32*.coresdk.workflow_commands.WorkflowCommand\x12\x1b\n\x13used_internal_flags\x18\x06 \x03(\r"\x81\x01\n\x07\x46\x61ilure\x12\x31\n\x07\x66\x61ilure\x18\x01 \x01(\x0b\x32 .temporal.api.failure.v1.Failure\x12\x43\n\x0b\x66orce_cause\x18\x02 \x01(\x0e\x32..temporal.api.enums.v1.WorkflowTaskFailedCauseB.\xea\x02+Temporalio::Bridge::Api::WorkflowCompletionb\x06proto3'
 )
 
 
 _WORKFLOWACTIVATIONCOMPLETION = DESCRIPTOR.message_types_by_name[
     "WorkflowActivationCompletion"
 ]
 _SUCCESS = DESCRIPTOR.message_types_by_name["Success"]
@@ -64,14 +67,17 @@
         # @@protoc_insertion_point(class_scope:coresdk.workflow_completion.Failure)
     },
 )
 _sym_db.RegisterMessage(Failure)
 
 if _descriptor._USE_C_DESCRIPTORS == False:
     DESCRIPTOR._options = None
-    _WORKFLOWACTIVATIONCOMPLETION._serialized_start = 236
-    _WORKFLOWACTIVATIONCOMPLETION._serialized_end = 408
-    _SUCCESS._serialized_start = 410
-    _SUCCESS._serialized_end = 481
-    _FAILURE._serialized_start = 483
-    _FAILURE._serialized_end = 543
+    DESCRIPTOR._serialized_options = (
+        b"\352\002+Temporalio::Bridge::Api::WorkflowCompletion"
+    )
+    _WORKFLOWACTIVATIONCOMPLETION._serialized_start = 278
+    _WORKFLOWACTIVATIONCOMPLETION._serialized_end = 450
+    _SUCCESS._serialized_start = 452
+    _SUCCESS._serialized_end = 552
+    _FAILURE._serialized_start = 555
+    _FAILURE._serialized_end = 684
 # @@protoc_insertion_point(module_scope)
```

### Comparing `temporalio-1.1.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi` & `temporalio-1.2.0/temporalio/bridge/proto/workflow_completion/workflow_completion_pb2.pyi`

 * *Files 20% similar despite different names*

```diff
@@ -4,26 +4,27 @@
 """
 import builtins
 import collections.abc
 import google.protobuf.descriptor
 import google.protobuf.internal.containers
 import google.protobuf.message
 import sys
+import temporalio.api.enums.v1.failed_cause_pb2
 import temporalio.api.failure.v1.message_pb2
 import temporalio.bridge.proto.workflow_commands.workflow_commands_pb2
 
 if sys.version_info >= (3, 8):
     import typing as typing_extensions
 else:
     import typing_extensions
 
 DESCRIPTOR: google.protobuf.descriptor.FileDescriptor
 
 class WorkflowActivationCompletion(google.protobuf.message.Message):
-    """/ Result of a single workflow activation, reported from lang to core"""
+    """Result of a single workflow activation, reported from lang to core"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     RUN_ID_FIELD_NUMBER: builtins.int
     SUCCESSFUL_FIELD_NUMBER: builtins.int
     FAILED_FIELD_NUMBER: builtins.int
     run_id: builtins.str
@@ -61,54 +62,71 @@
     def WhichOneof(
         self, oneof_group: typing_extensions.Literal["status", b"status"]
     ) -> typing_extensions.Literal["successful", "failed"] | None: ...
 
 global___WorkflowActivationCompletion = WorkflowActivationCompletion
 
 class Success(google.protobuf.message.Message):
-    """/ Successful workflow activation with a list of commands generated by the workflow execution"""
+    """Successful workflow activation with a list of commands generated by the workflow execution"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     COMMANDS_FIELD_NUMBER: builtins.int
+    USED_INTERNAL_FLAGS_FIELD_NUMBER: builtins.int
     @property
     def commands(
         self,
     ) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[
         temporalio.bridge.proto.workflow_commands.workflow_commands_pb2.WorkflowCommand
     ]:
         """A list of commands to send back to the temporal server"""
+    @property
+    def used_internal_flags(
+        self,
+    ) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
+        """Any internal flags which the lang SDK used in the processing of this activation"""
     def __init__(
         self,
         *,
         commands: collections.abc.Iterable[
             temporalio.bridge.proto.workflow_commands.workflow_commands_pb2.WorkflowCommand
         ]
         | None = ...,
+        used_internal_flags: collections.abc.Iterable[builtins.int] | None = ...,
     ) -> None: ...
     def ClearField(
-        self, field_name: typing_extensions.Literal["commands", b"commands"]
+        self,
+        field_name: typing_extensions.Literal[
+            "commands", b"commands", "used_internal_flags", b"used_internal_flags"
+        ],
     ) -> None: ...
 
 global___Success = Success
 
 class Failure(google.protobuf.message.Message):
-    """/ Failure to activate or execute a workflow"""
+    """Failure to activate or execute a workflow"""
 
     DESCRIPTOR: google.protobuf.descriptor.Descriptor
 
     FAILURE_FIELD_NUMBER: builtins.int
+    FORCE_CAUSE_FIELD_NUMBER: builtins.int
     @property
     def failure(self) -> temporalio.api.failure.v1.message_pb2.Failure: ...
+    force_cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType
+    """Forces overriding the WFT failure cause"""
     def __init__(
         self,
         *,
         failure: temporalio.api.failure.v1.message_pb2.Failure | None = ...,
+        force_cause: temporalio.api.enums.v1.failed_cause_pb2.WorkflowTaskFailedCause.ValueType = ...,
     ) -> None: ...
     def HasField(
         self, field_name: typing_extensions.Literal["failure", b"failure"]
     ) -> builtins.bool: ...
     def ClearField(
-        self, field_name: typing_extensions.Literal["failure", b"failure"]
+        self,
+        field_name: typing_extensions.Literal[
+            "failure", b"failure", "force_cause", b"force_cause"
+        ],
     ) -> None: ...
 
 global___Failure = Failure
```

### Comparing `temporalio-1.1.0/temporalio/bridge/runtime.py` & `temporalio-1.2.0/temporalio/bridge/runtime.py`

 * *Files 2% similar despite different names*

```diff
@@ -69,7 +69,8 @@
 @dataclass(frozen=True)
 class TelemetryConfig:
     """Python representation of the Rust struct for telemetry config."""
 
     tracing: Optional[TracingConfig]
     logging: Optional[LoggingConfig]
     metrics: Optional[MetricsConfig]
+    global_tags: Mapping[str, str]
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-ci.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose-telem.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/docker/docker-compose.yaml`

 * *Files 11% similar despite different names*

```diff
@@ -5,15 +5,15 @@
     image: cassandra:3.11
     logging:
       driver: none
   #    ports:
   #      - '9042:9042'
 
   temporal:
-    image: temporalio/auto-setup:1.18.3
+    image: temporalio/auto-setup:1.20.0
     ports:
       - "7233:7233"
       - "7234:7234"
 #      - "7235:7235"
 #      - "7239:7239"
 #      - "6933:6933"
 #      - "6934:6934"
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/.buildkite/pipeline.yml`

 * *Files 19% similar despite different names*

```diff
@@ -13,29 +13,27 @@
             - .buildkite/docker/docker-compose-ci.yaml
           env:
             - RUSTDOCFLAGS=-Dwarnings
   - label: "lint"
     agents:
       queue: "default"
       docker: "*"
-    command: "cargo clippy --workspace --all-features --all-targets -- -D warnings && cargo clippy --test integ_tests --test load_tests --all-features -- --D warnings"
+    command: "cargo lint && cargo test-lint"
     timeout_in_minutes: 15
     plugins:
       - docker-compose#v3.0.0:
           run: unit-test
           config:
             - .buildkite/docker/docker-compose.yaml
             - .buildkite/docker/docker-compose-ci.yaml
-          env:
-            - TEMPORAL_SDK_CORE_BRIDGE_FFI_DISABLE_HEADER_CHANGE=true
   - label: "test"
     agents:
       queue: "default"
       docker: "*"
-    command: "cargo tarpaulin --out Html --workspace && cargo test -- --include-ignored"
+    command: "cargo test -- --include-ignored"
     artifact_paths:
       - "tarpaulin-report.html"
       - "machine_coverage/*"
     timeout_in_minutes: 15
     plugins:
       - docker-compose#v3.0.0:
           run: unit-test
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/ARCHITECTURE.md` & `temporalio-1.2.0/temporalio/bridge/sdk-core/ARCHITECTURE.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/README.md` & `temporalio-1.2.0/temporalio/bridge/sdk-core/README.md`

 * *Files 8% similar despite different names*

```diff
@@ -1,41 +1,40 @@
 [![Build status](https://badge.buildkite.com/c23f47f4a827f04daece909963bd3a248496f0cdbabfbecee4.svg?branch=master)](https://buildkite.com/temporal/core-sdk?branch=master)
 
 Core SDK that can be used as a base for other Temporal SDKs. It is currently used as the base of:
 
 - [TypeScript SDK](https://github.com/temporalio/sdk-typescript/)
 - [Python SDK](https://github.com/temporalio/sdk-python/)
+- [.NET SDK](https://github.com/temporalio/sdk-dotnet/)
+- [Ruby SDK](https://github.com/temporalio/sdk-ruby/)
 
 For the reasoning behind the Core SDK, see: 
 
 - [Why Rust powers Temporal’s new Core SDK](https://temporal.io/blog/why-rust-powers-core-sdk).
 
-# Getting started
-
-See the [Architecture](ARCHITECTURE.md) doc for some high-level information.
-
-## Dependencies
-* Protobuf compiler
+See the [Architecture](ARCHITECTURE.md) doc for some high-level information about how Core works
+and how language layers interact with it.
 
 # Development
 
+You will need the `protoc` protobuf compiler installed to build Core.
+
 This repo is composed of multiple crates:
 * temporal-sdk-core-protos `./sdk-core-protos` - Holds the generated proto code and extensions
 * temporal-client `./client` - Defines client(s) for interacting with the Temporal gRPC service
 * temporal-sdk-core-api `./core-api` - Defines the API surface exposed by Core
 * temporal-sdk-core `./core` - The Core implementation
 * temporal-sdk `./sdk` - A (currently prototype) Rust SDK built on top of Core. Used for testing.
 * rustfsm `./fsm` - Implements a procedural macro used by core for defining state machines
     (contains subcrates). It is temporal agnostic.
 
 Visualized (dev dependencies are in blue):
 
 ![Crate dependency graph](./etc/deps.svg)
 
-
 All the following commands are enforced for each pull request:
 
 ## Building and testing
 
 You can buld and test the project using cargo:
 `cargo build`
 `cargo test`
@@ -105,7 +104,14 @@
 ### Error handling
 Any error which is returned from a public interface should be well-typed, and we use 
 [thiserror](https://github.com/dtolnay/thiserror) for that purpose.
 
 Errors returned from things only used in testing are free to use 
 [anyhow](https://github.com/dtolnay/anyhow) for less verbosity.
 
+
+# The Rust "SDK"
+This repo contains a *prototype* Rust sdk in the `sdk/` directory. This SDK should be considered
+pre-alpha in terms of its API surface. Since it's still using Core underneath, it is generally
+functional. We do not currently have any firm plans to productionize this SDK. If you want to write
+workflows and activities in Rust, feel free to use it - but be aware that the API may change at any
+time without warning and we do not provide any support guarantees.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md` & `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/README.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/sticky_queues.puml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg` & `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/diagrams/workflow_internals.svg`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md` & `temporalio-1.2.0/temporalio/bridge/sdk-core/arch_docs/sticky_queues.md`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/lib.rs`

 * *Files 5% similar despite different names*

```diff
@@ -9,34 +9,36 @@
 
 mod metrics;
 mod raw;
 mod retry;
 mod workflow_handle;
 
 pub use crate::retry::{CallType, RetryClient, RETRYABLE_ERROR_CODES};
+pub use metrics::ClientMetricProvider;
 pub use raw::{HealthService, OperatorService, TestService, WorkflowService};
 pub use temporal_sdk_core_protos::temporal::api::{
+    enums::v1::ArchivalState,
     filter::v1::{StartTimeFilter, StatusFilter, WorkflowExecutionFilter, WorkflowTypeFilter},
     workflowservice::v1::{
         list_closed_workflow_executions_request::Filters as ListClosedFilters,
         list_open_workflow_executions_request::Filters as ListOpenFilters,
     },
 };
+pub use tonic;
 pub use workflow_handle::{WorkflowExecutionInfo, WorkflowExecutionResult};
 
 use crate::{
     metrics::{GrpcMetricSvc, MetricsContext},
     raw::{sealed::RawClientLike, AttachMetricLabels},
     sealed::WfHandleClient,
     workflow_handle::UntypedWorkflowHandle,
 };
 use backoff::{exponential, ExponentialBackoff, SystemClock};
-use http::uri::InvalidUri;
+use http::{uri::InvalidUri, Uri};
 use once_cell::sync::OnceCell;
-use opentelemetry::metrics::Meter;
 use parking_lot::RwLock;
 use std::{
     collections::HashMap,
     fmt::{Debug, Formatter},
     ops::{Deref, DerefMut},
     str::FromStr,
     sync::Arc,
@@ -47,14 +49,15 @@
     grpc::health::v1::health_client::HealthClient,
     temporal::api::{
         common::v1::{Header, Payload, Payloads, WorkflowExecution, WorkflowType},
         enums::v1::{TaskQueueKind, WorkflowIdReusePolicy, WorkflowTaskFailedCause},
         failure::v1::Failure,
         operatorservice::v1::operator_service_client::OperatorServiceClient,
         query::v1::WorkflowQuery,
+        replication::v1::ClusterReplicationConfig,
         taskqueue::v1::TaskQueue,
         testservice::v1::test_service_client::TestServiceClient,
         workflowservice::v1::{workflow_service_client::WorkflowServiceClient, *},
     },
     TaskToken,
 };
 use tonic::{
@@ -107,14 +110,22 @@
     /// certs or keys as bytes, loading them from disk itself if needed.
     #[builder(setter(strip_option), default)]
     pub tls_cfg: Option<TlsConfig>,
 
     /// Retry configuration for the server client. Default is [RetryConfig::default]
     #[builder(default)]
     pub retry_config: RetryConfig,
+
+    /// If set, override the origin used when connecting. May be useful in rare situations where tls
+    /// verification needs to use a different name from what should be set as the `:authority`
+    /// header. If [TlsConfig::domain] is set, and this is not, this will be set to
+    /// `https://<domain>`, effectively making the `:authority` header consistent with the domain
+    /// override.
+    #[builder(default)]
+    pub override_origin: Option<Uri>,
 }
 
 /// Configuration options for TLS
 #[derive(Clone, Debug, Default)]
 pub struct TlsConfig {
     /// Bytes representing the root CA certificate used by the server. If not set, and the server's
     /// cert is issued by someone the operating system trusts, verification will still work (ex:
@@ -279,15 +290,15 @@
 
 impl ClientOptions {
     /// Attempt to establish a connection to the Temporal server in a specific namespace. The
     /// returned client is bound to that namespace.
     pub async fn connect(
         &self,
         namespace: impl Into<String>,
-        metrics_meter: Option<&Meter>,
+        metrics_meter: Option<&dyn ClientMetricProvider>,
         headers: Option<Arc<RwLock<HashMap<String, String>>>>,
     ) -> Result<RetryClient<Client>, ClientInitError> {
         let client = self
             .connect_no_namespace(metrics_meter, headers)
             .await?
             .into_inner();
         let client = Client::new(client, namespace.into());
@@ -297,20 +308,25 @@
 
     /// Attempt to establish a connection to the Temporal server and return a gRPC client which is
     /// intercepted with retry, default headers functionality, and metrics if provided.
     ///
     /// See [RetryClient] for more
     pub async fn connect_no_namespace(
         &self,
-        metrics_meter: Option<&Meter>,
+        metrics_meter: Option<&dyn ClientMetricProvider>,
         headers: Option<Arc<RwLock<HashMap<String, String>>>>,
     ) -> Result<RetryClient<ConfiguredClient<TemporalServiceClientWithMetrics>>, ClientInitError>
     {
         let channel = Channel::from_shared(self.target_url.to_string())?;
         let channel = self.add_tls_to_channel(channel).await?;
+        let channel = if let Some(origin) = self.override_origin.clone() {
+            channel.origin(origin)
+        } else {
+            channel
+        };
         let channel = channel.connect().await?;
         let service = ServiceBuilder::new()
             .layer_fn(|channel| GrpcMetricSvc {
                 inner: channel,
                 metrics: metrics_meter.map(|mm| MetricsContext::new(vec![], mm)),
             })
             .service(channel);
@@ -340,37 +356,41 @@
             },
         };
         Ok(RetryClient::new(client, self.retry_config.clone()))
     }
 
     /// If TLS is configured, set the appropriate options on the provided channel and return it.
     /// Passes it through if TLS options not set.
-    async fn add_tls_to_channel(
-        &self,
-        channel: Endpoint,
-    ) -> Result<Endpoint, tonic::transport::Error> {
+    async fn add_tls_to_channel(&self, mut channel: Endpoint) -> Result<Endpoint, ClientInitError> {
         if let Some(tls_cfg) = &self.tls_cfg {
             let mut tls = tonic::transport::ClientTlsConfig::new();
 
             if let Some(root_cert) = &tls_cfg.server_root_ca_cert {
                 let server_root_ca_cert = Certificate::from_pem(root_cert);
                 tls = tls.ca_certificate(server_root_ca_cert);
             }
 
             if let Some(domain) = &tls_cfg.domain {
                 tls = tls.domain_name(domain);
+
+                // This song and dance ultimately is just to make sure the `:authority` header ends
+                // up correct on requests while we use TLS. Setting the header directly in our
+                // interceptor doesn't work since seemingly it is overridden at some point by
+                // something lower level.
+                let uri: Uri = format!("https://{}", domain).parse()?;
+                channel = channel.origin(uri);
             }
 
             if let Some(client_opts) = &tls_cfg.client_tls_config {
                 let client_identity =
                     Identity::from_pem(&client_opts.client_cert, &client_opts.client_private_key);
                 tls = tls.identity(client_identity);
             }
 
-            return channel.tls_config(tls);
+            return channel.tls_config(tls).map_err(Into::into);
         }
         Ok(channel)
     }
 }
 
 /// Interceptor which attaches common metadata (like "client-name") to every outgoing call
 #[derive(Clone)]
@@ -588,14 +608,141 @@
             Namespace::Name(n) => (n, "".to_owned()),
             Namespace::Id(n) => ("".to_owned(), n),
         };
         DescribeNamespaceRequest { namespace, id }
     }
 }
 
+/// Default workflow execution retention for a Namespace is 3 days
+pub const DEFAULT_WORKFLOW_EXECUTION_RETENTION_PERIOD: Duration =
+    Duration::from_secs(60 * 60 * 24 * 3);
+
+/// Helper struct for `register_namespace`.
+#[derive(Clone, derive_builder::Builder)]
+pub struct RegisterNamespaceOptions {
+    /// Name (required)
+    #[builder(setter(into))]
+    pub namespace: String,
+    /// Description (required)
+    #[builder(setter(into))]
+    pub description: String,
+    /// Owner's email
+    #[builder(setter(into), default)]
+    pub owner_email: String,
+    /// Workflow execution retention period
+    #[builder(default = "DEFAULT_WORKFLOW_EXECUTION_RETENTION_PERIOD")]
+    pub workflow_execution_retention_period: Duration,
+    /// Cluster settings
+    #[builder(setter(strip_option, custom), default)]
+    pub clusters: Vec<ClusterReplicationConfig>,
+    /// Active cluster name
+    #[builder(setter(into), default)]
+    pub active_cluster_name: String,
+    /// Custom Data
+    #[builder(default)]
+    pub data: HashMap<String, String>,
+    /// Security Token
+    #[builder(setter(into), default)]
+    pub security_token: String,
+    /// Global namespace
+    #[builder(default)]
+    pub is_global_namespace: bool,
+    /// History Archival setting
+    #[builder(setter(into), default = "ArchivalState::Unspecified")]
+    pub history_archival_state: ArchivalState,
+    /// History Archival uri
+    #[builder(setter(into), default)]
+    pub history_archival_uri: String,
+    /// Visibility Archival setting
+    #[builder(setter(into), default = "ArchivalState::Unspecified")]
+    pub visibility_archival_state: ArchivalState,
+    /// Visibility Archival uri
+    #[builder(setter(into), default)]
+    pub visibility_archival_uri: String,
+}
+
+impl RegisterNamespaceOptions {
+    /// Builder convenience.  Less `use` imports
+    pub fn builder() -> RegisterNamespaceOptionsBuilder {
+        Default::default()
+    }
+}
+
+impl From<RegisterNamespaceOptions> for RegisterNamespaceRequest {
+    fn from(val: RegisterNamespaceOptions) -> Self {
+        RegisterNamespaceRequest {
+            namespace: val.namespace,
+            description: val.description,
+            owner_email: val.owner_email,
+            workflow_execution_retention_period: val
+                .workflow_execution_retention_period
+                .try_into()
+                .ok(),
+            clusters: val.clusters,
+            active_cluster_name: val.active_cluster_name,
+            data: val.data,
+            security_token: val.security_token,
+            is_global_namespace: val.is_global_namespace,
+            history_archival_state: val.history_archival_state as i32,
+            history_archival_uri: val.history_archival_uri,
+            visibility_archival_state: val.visibility_archival_state as i32,
+            visibility_archival_uri: val.visibility_archival_uri,
+        }
+    }
+}
+
+impl RegisterNamespaceOptionsBuilder {
+    /// Custum builder function for convenience
+    /// Warning: setting cluster_names could blow away any previously set cluster configs
+    pub fn cluster_names(&mut self, clusters: Vec<String>) {
+        self.clusters = Some(
+            clusters
+                .into_iter()
+                .map(|s| ClusterReplicationConfig { cluster_name: s })
+                .collect(),
+        );
+    }
+}
+
+/// Helper struct for `signal_with_start_workflow_execution`.
+#[derive(Clone, derive_builder::Builder)]
+pub struct SignalWithStartOptions {
+    /// Input payload for the workflow run
+    #[builder(setter(strip_option), default)]
+    pub input: Option<Payloads>,
+    /// Task Queue to target (required)
+    #[builder(setter(into))]
+    pub task_queue: String,
+    /// Workflow id for the workflow run
+    #[builder(setter(into))]
+    pub workflow_id: String,
+    /// Workflow type for the workflow run
+    #[builder(setter(into))]
+    pub workflow_type: String,
+    #[builder(setter(strip_option), default)]
+    /// Request id for idempotency/deduplication
+    pub request_id: Option<String>,
+    /// The signal name to send (required)
+    #[builder(setter(into))]
+    pub signal_name: String,
+    /// Payloads for the signal
+    #[builder(default)]
+    pub signal_input: Option<Payloads>,
+    #[builder(setter(strip_option), default)]
+    /// Headers for the signal
+    pub signal_header: Option<Header>,
+}
+
+impl SignalWithStartOptions {
+    /// Builder convenience.  Less `use` imports
+    pub fn builder() -> SignalWithStartOptionsBuilder {
+        Default::default()
+    }
+}
+
 /// This trait provides higher-level friendlier interaction with the server.
 /// See the [WorkflowService] trait for a lower-level client.
 #[cfg_attr(test, mockall::automock)]
 #[async_trait::async_trait]
 pub trait WorkflowClientTrait {
     /// Starts workflow execution.
     async fn start_workflow(
@@ -673,23 +820,16 @@
     ) -> Result<SignalWorkflowExecutionResponse>;
 
     /// Send signal and start workflow transcationally
     //#TODO maybe lift the Signal type from sdk::workflow_context::options
     #[allow(clippy::too_many_arguments)]
     async fn signal_with_start_workflow_execution(
         &self,
-        input: Option<Payloads>,
-        task_queue: String,
-        workflow_id: String,
-        workflow_type: String,
-        request_id: Option<String>,
-        options: WorkflowOptions,
-        signal_name: String,
-        signal_input: Option<Payloads>,
-        signal_header: Option<Header>,
+        options: SignalWithStartOptions,
+        workflow_options: WorkflowOptions,
     ) -> Result<SignalWithStartWorkflowExecutionResponse>;
 
     /// Request a query of a certain workflow instance
     async fn query_workflow_execution(
         &self,
         workflow_id: String,
         run_id: String,
@@ -730,46 +870,63 @@
     /// Terminate a currently executing workflow
     async fn terminate_workflow_execution(
         &self,
         workflow_id: String,
         run_id: Option<String>,
     ) -> Result<TerminateWorkflowExecutionResponse>;
 
+    /// Register a new namespace
+    async fn register_namespace(
+        &self,
+        options: RegisterNamespaceOptions,
+    ) -> Result<RegisterNamespaceResponse>;
+
     /// Lists all available namespaces
     async fn list_namespaces(&self) -> Result<ListNamespacesResponse>;
 
     /// Query namespace details
     async fn describe_namespace(&self, namespace: Namespace) -> Result<DescribeNamespaceResponse>;
 
-    /// List open workflows with Standard Visibility filtering
+    /// List open workflow executions with Standard Visibility filtering
     async fn list_open_workflow_executions(
         &self,
         max_page_size: i32,
         next_page_token: Vec<u8>,
         start_time_filter: Option<StartTimeFilter>,
         filters: Option<ListOpenFilters>,
     ) -> Result<ListOpenWorkflowExecutionsResponse>;
 
-    /// List closed workflows Standard Visibility filtering
+    /// List closed workflow executions Standard Visibility filtering
     async fn list_closed_workflow_executions(
         &self,
         max_page_size: i32,
         next_page_token: Vec<u8>,
         start_time_filter: Option<StartTimeFilter>,
         filters: Option<ListClosedFilters>,
     ) -> Result<ListClosedWorkflowExecutionsResponse>;
 
-    /// List workflows with Advanced Visibility filtering
+    /// List workflow executions with Advanced Visibility filtering
     async fn list_workflow_executions(
         &self,
-        max_page_size: i32,
+        page_size: i32,
         next_page_token: Vec<u8>,
         query: String,
     ) -> Result<ListWorkflowExecutionsResponse>;
 
+    /// List archived workflow executions
+    async fn list_archived_workflow_executions(
+        &self,
+        page_size: i32,
+        next_page_token: Vec<u8>,
+        query: String,
+    ) -> Result<ListArchivedWorkflowExecutionsResponse>;
+
+    /// Get Cluster Search Attributes
+    async fn get_search_attributes(&self) -> Result<GetSearchAttributesResponse>;
+
     /// Returns options that were used to initialize the client
     fn get_options(&self) -> &ClientOptions;
 
     /// Returns the namespace this client is bound to
     fn namespace(&self) -> &str;
 }
 
@@ -933,14 +1090,15 @@
         let request = RespondWorkflowTaskFailedRequest {
             task_token: task_token.0,
             cause: cause as i32,
             failure,
             identity: self.inner.options.identity.clone(),
             binary_checksum: self.bound_worker_build_id.clone().unwrap_or_default(),
             namespace: self.namespace.clone(),
+            messages: vec![],
         };
         Ok(self
             .wf_svc()
             .respond_workflow_task_failed(request)
             .await?
             .into_inner())
     }
@@ -969,50 +1127,51 @@
             })
             .await?
             .into_inner())
     }
 
     async fn signal_with_start_workflow_execution(
         &self,
-        input: Option<Payloads>,
-        task_queue: String,
-        workflow_id: String,
-        workflow_type: String,
-        request_id: Option<String>,
-        options: WorkflowOptions,
-        signal_name: String,
-        signal_input: Option<Payloads>,
-        signal_header: Option<Header>,
+        options: SignalWithStartOptions,
+        workflow_options: WorkflowOptions,
     ) -> Result<SignalWithStartWorkflowExecutionResponse> {
         Ok(self
             .wf_svc()
             .signal_with_start_workflow_execution(SignalWithStartWorkflowExecutionRequest {
                 namespace: self.namespace.clone(),
-                workflow_id,
+                workflow_id: options.workflow_id,
                 workflow_type: Some(WorkflowType {
-                    name: workflow_type,
+                    name: options.workflow_type,
                 }),
                 task_queue: Some(TaskQueue {
-                    name: task_queue,
+                    name: options.task_queue,
                     kind: TaskQueueKind::Normal as i32,
                 }),
-                input,
-                signal_name,
-                signal_input,
+                input: options.input,
+                signal_name: options.signal_name,
+                signal_input: options.signal_input,
                 identity: self.inner.options.identity.clone(),
-                request_id: request_id.unwrap_or_else(|| Uuid::new_v4().to_string()),
-                workflow_id_reuse_policy: options.id_reuse_policy as i32,
-                workflow_execution_timeout: options
+                request_id: options
+                    .request_id
+                    .unwrap_or_else(|| Uuid::new_v4().to_string()),
+                workflow_id_reuse_policy: workflow_options.id_reuse_policy as i32,
+                workflow_execution_timeout: workflow_options
                     .execution_timeout
                     .and_then(|d| d.try_into().ok()),
-                workflow_run_timeout: options.execution_timeout.and_then(|d| d.try_into().ok()),
-                workflow_task_timeout: options.task_timeout.and_then(|d| d.try_into().ok()),
-                search_attributes: options.search_attributes.and_then(|d| d.try_into().ok()),
-                cron_schedule: options.cron_schedule.unwrap_or_default(),
-                header: signal_header,
+                workflow_run_timeout: workflow_options
+                    .execution_timeout
+                    .and_then(|d| d.try_into().ok()),
+                workflow_task_timeout: workflow_options
+                    .task_timeout
+                    .and_then(|d| d.try_into().ok()),
+                search_attributes: workflow_options
+                    .search_attributes
+                    .and_then(|d| d.try_into().ok()),
+                cron_schedule: workflow_options.cron_schedule.unwrap_or_default(),
+                header: options.signal_header,
                 ..Default::default()
             })
             .await?
             .into_inner())
     }
 
     async fn query_workflow_execution(
@@ -1136,14 +1295,22 @@
                 identity: self.inner.options.identity.clone(),
                 first_execution_run_id: "".to_string(),
             })
             .await?
             .into_inner())
     }
 
+    async fn register_namespace(
+        &self,
+        options: RegisterNamespaceOptions,
+    ) -> Result<RegisterNamespaceResponse> {
+        let req = Into::<RegisterNamespaceRequest>::into(options);
+        Ok(self.wf_svc().register_namespace(req).await?.into_inner())
+    }
+
     async fn list_namespaces(&self) -> Result<ListNamespacesResponse> {
         Ok(self
             .wf_svc()
             .list_namespaces(ListNamespacesRequest::default())
             .await?
             .into_inner())
     }
@@ -1210,14 +1377,40 @@
                 next_page_token,
                 query,
             })
             .await?
             .into_inner())
     }
 
+    async fn list_archived_workflow_executions(
+        &self,
+        page_size: i32,
+        next_page_token: Vec<u8>,
+        query: String,
+    ) -> Result<ListArchivedWorkflowExecutionsResponse> {
+        Ok(self
+            .wf_svc()
+            .list_archived_workflow_executions(ListArchivedWorkflowExecutionsRequest {
+                namespace: self.namespace.clone(),
+                page_size,
+                next_page_token,
+                query,
+            })
+            .await?
+            .into_inner())
+    }
+
+    async fn get_search_attributes(&self) -> Result<GetSearchAttributesResponse> {
+        Ok(self
+            .wf_svc()
+            .get_search_attributes(GetSearchAttributesRequest {})
+            .await?
+            .into_inner())
+    }
+
     fn get_options(&self) -> &ClientOptions {
         &self.inner.options
     }
 
     fn namespace(&self) -> &str {
         &self.namespace
     }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/metrics.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/metrics.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 use crate::{AttachMetricLabels, LONG_POLL_METHOD_NAMES};
 use futures::{future::BoxFuture, FutureExt};
 use opentelemetry::{
-    metrics::{Counter, Histogram, Meter},
+    metrics::{Counter, Histogram},
     KeyValue,
 };
 use std::{
     sync::Arc,
     task::{Context, Poll},
     time::{Duration, Instant},
 };
@@ -26,26 +26,35 @@
     long_svc_request: Counter<u64>,
     long_svc_request_failed: Counter<u64>,
 
     svc_request_latency: Histogram<u64>,
     long_svc_request_latency: Histogram<u64>,
 }
 
+/// Things that can provide metrics for the client implement this. Trait exists to avoid having
+/// to make a whole new lower-level crate just for a tiny shared wrapper around OTel meters.
+pub trait ClientMetricProvider: Send + Sync {
+    /// Construct a counter metric
+    fn counter(&self, name: &'static str) -> Counter<u64>;
+    /// Construct a histogram metric
+    fn histogram(&self, name: &'static str) -> Histogram<u64>;
+}
+
 impl MetricsContext {
-    pub(crate) fn new(kvs: Vec<KeyValue>, meter: &Meter) -> Self {
+    pub(crate) fn new(kvs: Vec<KeyValue>, metric_provider: &dyn ClientMetricProvider) -> Self {
         Self {
             ctx: opentelemetry::Context::current(),
             kvs: Arc::new(kvs),
             poll_is_long: false,
-            svc_request: meter.u64_counter("request").init(),
-            svc_request_failed: meter.u64_counter("request_failure").init(),
-            long_svc_request: meter.u64_counter("long_request").init(),
-            long_svc_request_failed: meter.u64_counter("long_request_failure").init(),
-            svc_request_latency: meter.u64_histogram("request_latency").init(),
-            long_svc_request_latency: meter.u64_histogram("long_request_latency").init(),
+            svc_request: metric_provider.counter("request"),
+            svc_request_failed: metric_provider.counter("request_failure"),
+            long_svc_request: metric_provider.counter("long_request"),
+            long_svc_request_failed: metric_provider.counter("long_request_failure"),
+            svc_request_latency: metric_provider.histogram("request_latency"),
+            long_svc_request_latency: metric_provider.histogram("long_request_latency"),
         }
     }
 
     /// Extend an existing metrics context with new attributes, returning a new one
     pub(crate) fn with_new_attrs(&self, new_kvs: impl IntoIterator<Item = KeyValue>) -> Self {
         let mut r = self.clone();
         r.add_new_attrs(new_kvs);
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/raw.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/raw.rs`

 * *Files 1% similar despite different names*

```diff
@@ -736,37 +736,46 @@
         ListSchedulesResponse,
         |r| {
             let labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             r.extensions_mut().insert(labels);
         }
     );
     (
-        update_worker_build_id_ordering,
-        UpdateWorkerBuildIdOrderingRequest,
-        UpdateWorkerBuildIdOrderingResponse,
+        update_worker_build_id_compatibility,
+        UpdateWorkerBuildIdCompatibilityRequest,
+        UpdateWorkerBuildIdCompatibilityResponse,
         |r| {
             let mut labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             labels.task_q_str(r.get_ref().task_queue.clone());
             r.extensions_mut().insert(labels);
         }
     );
     (
-        get_worker_build_id_ordering,
-        GetWorkerBuildIdOrderingRequest,
-        GetWorkerBuildIdOrderingResponse,
+        get_worker_build_id_compatibility,
+        GetWorkerBuildIdCompatibilityRequest,
+        GetWorkerBuildIdCompatibilityResponse,
         |r| {
             let mut labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             labels.task_q_str(r.get_ref().task_queue.clone());
             r.extensions_mut().insert(labels);
         }
     );
     (
-        update_workflow,
-        UpdateWorkflowRequest,
-        UpdateWorkflowResponse,
+        update_workflow_execution,
+        UpdateWorkflowExecutionRequest,
+        UpdateWorkflowExecutionResponse,
+        |r| {
+            let labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
+            r.extensions_mut().insert(labels);
+        }
+    );
+    (
+        poll_workflow_execution_update,
+        PollWorkflowExecutionUpdateRequest,
+        PollWorkflowExecutionUpdateResponse,
         |r| {
             let labels = AttachMetricLabels::namespace(r.get_ref().namespace.clone());
             r.extensions_mut().insert(labels);
         }
     );
     (
         start_batch_operation,
@@ -894,15 +903,15 @@
                 let stripped = l.strip_prefix("rpc ").unwrap();
                 (stripped[..stripped.find('(').unwrap()]).trim()
             })
             .collect();
         let no_underscores: HashSet<_> = impl_list.iter().map(|x| x.replace('_', "")).collect();
         for method in methods {
             if !no_underscores.contains(&method.to_lowercase()) {
-                panic!("RPC method {} is not implemented by raw client", method)
+                panic!("RPC method {method} is not implemented by raw client")
             }
         }
     }
     #[test]
     fn verify_all_workflow_service_methods_implemented() {
         // This is less work than trying to hook into the codegen process
         let proto_def =
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/retry.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/retry.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,18 +1,18 @@
 use crate::{
-    ClientOptions, ListClosedFilters, ListOpenFilters, Namespace, Result, RetryConfig,
-    StartTimeFilter, WorkflowClientTrait, WorkflowOptions,
+    ClientOptions, ListClosedFilters, ListOpenFilters, Namespace, RegisterNamespaceOptions, Result,
+    RetryConfig, SignalWithStartOptions, StartTimeFilter, WorkflowClientTrait, WorkflowOptions,
 };
 use backoff::{backoff::Backoff, exponential::ExponentialBackoff, Clock, SystemClock};
 use futures_retry::{ErrorHandler, FutureRetry, RetryPolicy};
 use std::{fmt::Debug, future::Future, sync::Arc, time::Duration};
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::QueryResult,
     temporal::api::{
-        common::v1::{Header, Payload, Payloads},
+        common::v1::{Payload, Payloads},
         enums::v1::WorkflowTaskFailedCause,
         failure::v1::Failure,
         query::v1::WorkflowQuery,
         workflowservice::v1::*,
     },
     TaskToken,
 };
@@ -358,36 +358,22 @@
             payloads.clone(),
             request_id.clone()
         )
     }
 
     async fn signal_with_start_workflow_execution(
         &self,
-        input: Option<Payloads>,
-        task_queue: String,
-        workflow_id: String,
-        workflow_type: String,
-        request_id: Option<String>,
-        options: WorkflowOptions,
-        signal_name: String,
-        signal_input: Option<Payloads>,
-        signal_header: Option<Header>,
+        options: SignalWithStartOptions,
+        workflow_options: WorkflowOptions,
     ) -> Result<SignalWithStartWorkflowExecutionResponse> {
         retry_call!(
             self,
             signal_with_start_workflow_execution,
-            input.clone(),
-            task_queue.clone(),
-            workflow_id.clone(),
-            workflow_type.clone(),
-            request_id.clone(),
             options.clone(),
-            signal_name.clone(),
-            signal_input.clone(),
-            signal_header.clone()
+            workflow_options.clone()
         )
     }
 
     async fn query_workflow_execution(
         &self,
         workflow_id: String,
         run_id: String,
@@ -469,14 +455,21 @@
             self,
             terminate_workflow_execution,
             workflow_id.clone(),
             run_id.clone()
         )
     }
 
+    async fn register_namespace(
+        &self,
+        options: RegisterNamespaceOptions,
+    ) -> Result<RegisterNamespaceResponse> {
+        retry_call!(self, register_namespace, options.clone())
+    }
+
     async fn list_namespaces(&self) -> Result<ListNamespacesResponse> {
         retry_call!(self, list_namespaces,)
     }
 
     async fn describe_namespace(&self, namespace: Namespace) -> Result<DescribeNamespaceResponse> {
         retry_call!(self, describe_namespace, namespace.clone())
     }
@@ -526,14 +519,33 @@
             list_workflow_executions,
             page_size,
             next_page_token.clone(),
             query.clone()
         )
     }
 
+    async fn list_archived_workflow_executions(
+        &self,
+        page_size: i32,
+        next_page_token: Vec<u8>,
+        query: String,
+    ) -> Result<ListArchivedWorkflowExecutionsResponse> {
+        retry_call!(
+            self,
+            list_archived_workflow_executions,
+            page_size,
+            next_page_token.clone(),
+            query.clone()
+        )
+    }
+
+    async fn get_search_attributes(&self) -> Result<GetSearchAttributesResponse> {
+        retry_call!(self, get_search_attributes)
+    }
+
     fn get_options(&self) -> &ClientOptions {
         self.client.get_options()
     }
 
     fn namespace(&self) -> &str {
         self.client.namespace()
     }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/client/src/workflow_handle/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/Cargo.toml`

 * *Files 26% similar despite different names*

```diff
@@ -8,66 +8,72 @@
 homepage = "https://temporal.io/"
 repository = "https://github.com/temporalio/sdk-core"
 keywords = ["temporal", "workflow"]
 categories = ["development-tools"]
 
 [lib]
 
+[features]
+# Do not enable this feature when building production SDKs. If we ever want a user in the field to
+# record WF input data, we can build them a custom SDK or they can build - it adds significant extra
+# code size in the form of [de]serializers.
+save_wf_inputs = ["rmp-serde", "temporal-sdk-core-protos/serde_serialize"]
+
 [dependencies]
 anyhow = "1.0"
 arc-swap = "1.3"
-async-channel = "1.6"
 async-trait = "0.1"
-base64 = "0.20"
+base64 = "0.21"
 crossbeam = "0.8"
 dashmap = "5.0"
 derive_builder = "0.12"
 derive_more = "0.99"
 enum_dispatch = "0.3"
+enum-iterator = "1.4"
 flate2 = "1.0"
 futures = "0.3"
 futures-util = "0.3"
 governor = "0.5"
 http = "0.2"
 hyper = "0.14"
 itertools = "0.10"
 lazy_static = "1.4"
-log = "0.4"
-lru = "0.8"
+lru = "0.10"
 mockall = "0.11"
 nix = "0.26"
 once_cell = "1.5"
 opentelemetry = { version = "0.18", features = ["rt-tokio"] }
 opentelemetry-otlp = { version = "0.11", features = ["tokio", "metrics"] }
 opentelemetry-prometheus = "0.11"
 parking_lot = { version = "0.12", features = ["send_guard"] }
 pin-project = "1.0"
 prometheus = "0.13"
 prost = "0.11"
-prost-types = "0.11"
+prost-types = { version = "0.4", package = "prost-wkt-types" }
 rand = "0.8.3"
 reqwest = { version = "0.11", features = ["json", "stream", "rustls-tls", "tokio-rustls"], default-features = false }
 ringbuf = "0.3"
+rmp-serde = { version = "1.1", optional = true }
 serde = "1.0"
 serde_json = "1.0"
 siphasher = "0.3"
 slotmap = "1.0"
 tar = "0.4"
 thiserror = "1.0"
-tokio = { version = "1.1", features = ["rt", "rt-multi-thread", "parking_lot", "time", "fs", "process"] }
+tokio = { version = "1.26", features = ["rt", "rt-multi-thread", "parking_lot", "time", "fs", "process"] }
 tokio-util = { version = "0.7", features = ["io", "io-util"] }
 tokio-stream = "0.1"
 tonic = { version = "0.8", features = ["tls", "tls-roots"] }
 tracing = "0.1"
 tracing-futures = "0.2"
 tracing-opentelemetry = "0.18"
 tracing-subscriber = { version = "0.3", features = ["parking_lot", "env-filter", "registry"] }
 url = "2.2"
 uuid = { version = "1.1", features = ["v4"] }
-zip = "0.6"
+zip = "0.6.3"
 
 # 1st party local deps
 [dependencies.temporal-sdk-core-api]
 path = "../core-api"
 version = "0.1"
 
 [dependencies.temporal-sdk-core-protos]
@@ -82,36 +88,43 @@
 [dependencies.rustfsm]
 path = "../fsm"
 version = "0.1"
 
 [dev-dependencies]
 assert_matches = "1.4"
 bimap = "0.6.1"
+clap = { version = "4.0", features = ["derive"] }
 criterion = "0.4"
-rstest = "0.16"
+rstest = "0.17"
 temporal-sdk-core-test-utils = { path = "../test-utils" }
 temporal-sdk = { path = "../sdk" }
 
 [build-dependencies]
 tonic-build = "0.8"
 
 [[test]]
 name = "integ_tests"
 path = "../tests/main.rs"
 # Prevents autodiscovery, and hence these getting run with `cargo test`. Run with
 # `cargo test --test integ_tests`
 test = false
 
 [[test]]
-name = "load_tests"
-path = "../tests/load_tests.rs"
+name = "heavy_tests"
+path = "../tests/heavy_tests.rs"
 test = false
+required-features = ["save_wf_inputs"]
 
 [[bench]]
 name = "workflow_replay"
 harness = false
 
 # This is maybe a bit hacky, but we call the runner an "example" because that gets it compiling with
 # the dev-dependencies, which we want.
 [[example]]
 name = "integ_runner"
-path = "../tests/runner.rs"
+path = "../tests/runner.rs"
+
+[[example]]
+name = "wf_input_replay"
+path = "../tests/wf_input_replay.rs"
+required-features = ["save_wf_inputs"]
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/benches/workflow_replay.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/activity_tasks.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,66 +1,72 @@
 use crate::{
     advance_fut, job_assert, prost_dur,
     test_help::{
         build_fake_worker, build_mock_pollers, canned_histories, gen_assert_and_reply,
         mock_manual_poller, mock_poller, mock_poller_from_resps, mock_worker, poll_and_reply,
         single_hist_mock_sg, test_worker_cfg, MockPollCfg, MockWorkerInputs, MocksHolder,
-        ResponseType, WorkflowCachingPolicy, TEST_Q,
+        QueueResponse, ResponseType, WorkerExt, WorkflowCachingPolicy, TEST_Q,
     },
     worker::client::mocks::{mock_manual_workflow_client, mock_workflow_client},
     ActivityHeartbeat, Worker, WorkerConfigBuilder,
 };
 use futures::FutureExt;
 use itertools::Itertools;
 use std::{
     cell::RefCell,
-    collections::{hash_map::Entry, HashMap, VecDeque},
+    collections::{hash_map::Entry, HashMap, HashSet, VecDeque},
+    future,
     rc::Rc,
     sync::{
         atomic::{AtomicUsize, Ordering},
         Arc,
     },
     time::Duration,
 };
 use temporal_client::WorkflowOptions;
 use temporal_sdk::{ActivityOptions, WfContext};
-use temporal_sdk_core_api::{errors::CompleteActivityError, Worker as WorkerTrait};
+use temporal_sdk_core_api::{
+    errors::{CompleteActivityError, PollActivityError},
+    Worker as WorkerTrait,
+};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{
             activity_execution_result, activity_resolution, ActivityExecutionResult,
             ActivityResolution, Success,
         },
-        activity_task::{activity_task, ActivityTask},
+        activity_task::{activity_task, ActivityCancelReason, ActivityTask, Cancel},
         workflow_activation::{workflow_activation_job, ResolveActivity, WorkflowActivationJob},
         workflow_commands::{
             ActivityCancellationType, CompleteWorkflowExecution, RequestCancelActivity,
             ScheduleActivity,
         },
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion,
     },
     temporal::api::{
         command::v1::{command::Attributes, ScheduleActivityTaskCommandAttributes},
         enums::v1::EventType,
+        history::v1::{
+            history_event::Attributes as EventAttributes, ActivityTaskScheduledEventAttributes,
+        },
         workflowservice::v1::{
             PollActivityTaskQueueResponse, RecordActivityTaskHeartbeatResponse,
             RespondActivityTaskCanceledResponse, RespondActivityTaskCompletedResponse,
             RespondActivityTaskFailedResponse, RespondWorkflowTaskCompletedResponse,
         },
     },
     TestHistoryBuilder, DEFAULT_WORKFLOW_TYPE,
 };
 use temporal_sdk_core_test_utils::{fanout_tasks, start_timer_cmd, TestWorker};
-use tokio::{sync::Barrier, time::sleep};
+use tokio::{join, sync::Barrier, time::sleep};
+use tokio_util::sync::CancellationToken;
 
-#[tokio::test]
-async fn max_activities_respected() {
-    let _task_q = "q";
-    let mut tasks = VecDeque::from(vec![
+fn three_tasks() -> VecDeque<PollActivityTaskQueueResponse> {
+    VecDeque::from(vec![
         PollActivityTaskQueueResponse {
             task_token: vec![1],
             activity_id: "act1".to_string(),
             ..Default::default()
         },
         PollActivityTaskQueueResponse {
             task_token: vec![2],
@@ -68,15 +74,21 @@
             ..Default::default()
         },
         PollActivityTaskQueueResponse {
             task_token: vec![3],
             activity_id: "act3".to_string(),
             ..Default::default()
         },
-    ]);
+    ])
+}
+
+#[tokio::test]
+async fn max_activities_respected() {
+    let _task_q = "q";
+    let mut tasks = three_tasks();
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_poll_activity_task()
         .times(3)
         .returning(move |_, _| Ok(tasks.pop_front().unwrap()));
     mock_client
         .expect_complete_activity_task()
@@ -117,15 +129,15 @@
 
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: vec![1],
         result: Some(ActivityExecutionResult::ok(vec![1].into())),
     })
     .await
     .unwrap();
-    core.shutdown().await;
+    core.drain_activity_poller_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn heartbeats_report_cancels_only_once() {
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_record_activity_heartbeat()
@@ -213,38 +225,45 @@
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: act.task_token,
 
         result: Some(ActivityExecutionResult::ok(vec![1].into())),
     })
     .await
     .unwrap();
-    core.shutdown().await;
+    core.drain_activity_poller_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn activity_cancel_interrupts_poll() {
     let mut mock_poller = mock_manual_poller();
+    let shutdown_token = CancellationToken::new();
+    let shutdown_token_clone = shutdown_token.clone();
     let mut poll_resps = VecDeque::from(vec![
         async {
             Some(Ok(PollActivityTaskQueueResponse {
                 task_token: vec![1],
                 heartbeat_timeout: Some(prost_dur!(from_secs(1))),
                 ..Default::default()
             }))
         }
         .boxed(),
         async {
             tokio::time::sleep(Duration::from_millis(500)).await;
             Some(Ok(Default::default()))
         }
         .boxed(),
+        async move {
+            shutdown_token.cancelled().await;
+            None
+        }
+        .boxed(),
     ]);
     mock_poller
         .expect_poll()
-        .times(2)
+        .times(3)
         .returning(move || poll_resps.pop_front().unwrap());
 
     let mut mock_client = mock_manual_workflow_client();
     mock_client
         .expect_record_activity_heartbeat()
         .times(1)
         .returning(|_, _| {
@@ -265,15 +284,15 @@
         ..Default::default()
     };
     let core = mock_worker(MocksHolder::from_mock_worker(mock_client, mw));
     let last_finisher = AtomicUsize::new(0);
     // Perform first poll to get the activity registered
     let act = core.poll_activity_task().await.unwrap();
     // Poll should block until heartbeat is sent, issuing the cancel, and interrupting the poll
-    tokio::join! {
+    join! {
         async {
             core.record_activity_heartbeat(ActivityHeartbeat {
                 task_token: act.task_token,
 
                 details: vec![vec![1_u8, 2, 3].into()],
             });
             last_finisher.store(1, Ordering::SeqCst);
@@ -285,19 +304,20 @@
                 ActivityTaskCompletion {
                     task_token: act.task_token,
 
                     result: Some(ActivityExecutionResult::ok(vec![1].into())),
                 }
             ).await.unwrap();
             last_finisher.store(2, Ordering::SeqCst);
+            shutdown_token_clone.cancel();
         }
     };
     // So that we know we blocked
     assert_eq!(last_finisher.load(Ordering::Acquire), 2);
-    core.shutdown().await;
+    core.drain_activity_poller_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn activity_poll_timeout_retries() {
     let mock_client = mock_workflow_client();
     let mut calls = 0;
     let mut mock_act_poller = mock_poller();
@@ -338,21 +358,18 @@
                         ..Default::default()
                     })
                 }
                 .boxed()
             })
             .collect::<Vec<_>>(),
     );
-    // Because the mock is so fast, it's possible it can return before the cancel channel in
-    // the activity task poll selector. So, the final poll when there are no more tasks must
-    // take a while.
     poll_resps.push_back(
         async {
-            sleep(Duration::from_secs(10)).await;
-            unreachable!("Long poll")
+            future::pending::<()>().await;
+            unreachable!()
         }
         .boxed(),
     );
     let mut calls_map = HashMap::<_, i32>::new();
     mock_client
         .expect_poll_activity_task()
         .returning(move |_, _| poll_resps.pop_front().unwrap());
@@ -427,15 +444,15 @@
                 result: Some(ActivityExecutionResult::cancel_from_details(None)),
             })
             .await
             .unwrap();
     })
     .await;
 
-    worker.shutdown().await;
+    worker.drain_activity_poller_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn activity_timeout_no_double_resolve() {
     let t = canned_histories::activity_double_resolve_repro();
     let core = build_fake_worker("fake_wf_id", t, [3]);
     let activity_id = 1;
@@ -479,15 +496,15 @@
                 ),
                 vec![CompleteWorkflowExecution { result: None }.into()],
             ),
         ],
     )
     .await;
 
-    core.shutdown().await;
+    core.drain_pollers_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn can_heartbeat_acts_during_shutdown() {
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_record_activity_heartbeat()
@@ -525,15 +542,15 @@
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: act.task_token,
 
         result: Some(ActivityExecutionResult::ok(vec![1].into())),
     })
     .await
     .unwrap();
-    shutdown_fut.await;
+    core.drain_activity_poller_and_shutdown().await;
 }
 
 /// Verifies that if a user has tried to record a heartbeat and then immediately after failed the
 /// activity, that we flush those details before reporting the failure completion.
 #[tokio::test]
 async fn complete_act_with_fail_flushes_heartbeat() {
     let last_hb = 50;
@@ -576,15 +593,15 @@
     }
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: act.task_token.clone(),
         result: Some(ActivityExecutionResult::fail("Ahh".into())),
     })
     .await
     .unwrap();
-    core.shutdown().await;
+    core.drain_activity_poller_and_shutdown().await;
 
     // Verify the last seen call to record a heartbeat had the last detail payload
     let last_seen_payload = &last_seen_payload.take().unwrap().payloads[0];
     assert_eq!(last_seen_payload.data, &[last_hb]);
 }
 
 #[tokio::test]
@@ -682,15 +699,15 @@
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
         wf_task.run_id,
         cmds,
     ))
     .await
     .unwrap();
 
-    core.shutdown().await;
+    core.drain_pollers_and_shutdown().await;
 
     assert_eq!(num_eager_requested.load(Ordering::Relaxed), 0);
 }
 
 /// This test verifies that activity tasks which come as replies to completing a WFT are properly
 /// delivered via polling.
 #[tokio::test]
@@ -699,15 +716,15 @@
     // different queue, 3 activities will be executed eagerly as specified by the
     // MAX_EAGER_ACTIVITY_RESERVATIONS_PER_WORKFLOW_TASK constant.
     let wfid = "fake_wf_id";
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
     let act_same_queue_scheduled_ids = (1..4)
-        .map(|i| t.add_activity_task_scheduled(format!("act_id_{}_same_queue", i)))
+        .map(|i| t.add_activity_task_scheduled(format!("act_id_{i}_same_queue")))
         .collect_vec();
     t.add_activity_task_scheduled("act_id_same_queue_not_eager");
     t.add_activity_task_scheduled("act_id_different_queue");
     for scheduled_event_id in act_same_queue_scheduled_ids {
         let started_event_id = t.add_activity_task_started(scheduled_event_id);
         t.add_activity_task_completed(scheduled_event_id, started_event_id, b"hi".into());
     }
@@ -738,40 +755,37 @@
                 .count();
             num_eager_requested_clone.store(count, Ordering::Relaxed);
             Ok(RespondWorkflowTaskCompletedResponse {
                 workflow_task: None,
                 activity_tasks: (1..4)
                     .map(|i| PollActivityTaskQueueResponse {
                         task_token: vec![i],
-                        activity_id: format!("act_id_{}_same_queue", i),
+                        activity_id: format!("act_id_{i}_same_queue"),
                         ..Default::default()
                     })
                     .collect_vec(),
                 reset_history_event_id: 0,
             })
         });
     mock.expect_complete_activity_task()
         .times(3)
         .returning(|_, _| Ok(RespondActivityTaskCompletedResponse::default()));
     let mut mock = single_hist_mock_sg(wfid, t, [1], mock, true);
-    let mut mock_poller = mock_manual_poller();
-    mock_poller
-        .expect_poll()
-        .returning(|| futures::future::pending().boxed());
-    mock.set_act_poller(Box::new(mock_poller));
+    let act_tasks: Vec<QueueResponse<PollActivityTaskQueueResponse>> = vec![];
+    mock.set_act_poller(mock_poller_from_resps(act_tasks));
     mock.worker_cfg(|wc| wc.max_cached_workflows = 2);
     let core = mock_worker(mock);
 
     // Test start
     let wf_task = core.poll_workflow_activation().await.unwrap();
     let mut cmds = (1..4)
         .map(|seq| {
             ScheduleActivity {
                 seq,
-                activity_id: format!("act_id_{}_same_queue", seq),
+                activity_id: format!("act_id_{seq}_same_queue"),
                 task_queue: TEST_Q.to_string(),
                 cancellation_type: ActivityCancellationType::TryCancel as i32,
                 ..Default::default()
             }
             .into()
         })
         .collect_vec();
@@ -812,31 +826,43 @@
             task_token: act_task.task_token.clone(),
             result: Some(ActivityExecutionResult::ok("hi".into())),
         })
         .await
         .unwrap();
     }
 
-    core.shutdown().await;
+    core.drain_pollers_and_shutdown().await;
 
     // Verify only a single eager activity was scheduled (the one on our worker's task queue)
     assert_eq!(num_eager_requested.load(Ordering::Relaxed), 3);
 }
 
 #[tokio::test]
 async fn activity_tasks_from_completion_reserve_slots() {
     let wf_id = "fake_wf_id";
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
-    let schedid = t.add_activity_task_scheduled("1");
+    let schedid = t.add(EventAttributes::ActivityTaskScheduledEventAttributes(
+        ActivityTaskScheduledEventAttributes {
+            activity_id: "1".to_string(),
+            activity_type: Some("act1".into()),
+            ..Default::default()
+        },
+    ));
     let startid = t.add_activity_task_started(schedid);
     t.add_activity_task_completed(schedid, startid, b"hi".into());
     t.add_full_wf_task();
-    let schedid = t.add_activity_task_scheduled("2");
+    let schedid = t.add(EventAttributes::ActivityTaskScheduledEventAttributes(
+        ActivityTaskScheduledEventAttributes {
+            activity_id: "2".to_string(),
+            activity_type: Some("act2".into()),
+            ..Default::default()
+        },
+    ));
     let startid = t.add_activity_task_started(schedid);
     t.add_activity_task_completed(schedid, startid, b"hi".into());
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
 
     let mut mock = mock_workflow_client();
     // Set up two tasks to be returned via normal activity polling
@@ -898,27 +924,33 @@
     mock.set_act_poller(mock_poller_from_resps(act_tasks));
     let core = Arc::new(mock_worker(mock));
     let mut worker = TestWorker::new(core.clone(), TEST_Q.to_string());
 
     // First poll for activities twice, occupying both slots
     let at1 = core.poll_activity_task().await.unwrap();
     let at2 = core.poll_activity_task().await.unwrap();
+    let workflow_complete_token = CancellationToken::new();
+    let workflow_complete_token_clone = workflow_complete_token.clone();
 
-    worker.register_wf(DEFAULT_WORKFLOW_TYPE, move |ctx: WfContext| async move {
-        ctx.activity(ActivityOptions {
-            activity_type: "act1".to_string(),
-            ..Default::default()
-        })
-        .await;
-        ctx.activity(ActivityOptions {
-            activity_type: "act2".to_string(),
-            ..Default::default()
-        })
-        .await;
-        Ok(().into())
+    worker.register_wf(DEFAULT_WORKFLOW_TYPE, move |ctx: WfContext| {
+        let complete_token = workflow_complete_token.clone();
+        async move {
+            ctx.activity(ActivityOptions {
+                activity_type: "act1".to_string(),
+                ..Default::default()
+            })
+            .await;
+            ctx.activity(ActivityOptions {
+                activity_type: "act2".to_string(),
+                ..Default::default()
+            })
+            .await;
+            complete_token.cancel();
+            Ok(().into())
+        }
     });
 
     worker
         .submit_wf(
             wf_id.to_owned(),
             DEFAULT_WORKFLOW_TYPE,
             vec![],
@@ -937,19 +969,26 @@
         core.complete_activity_task(ActivityTaskCompletion {
             task_token: at2.task_token,
             result: Some(ActivityExecutionResult::ok("hi".into())),
         })
         .await
         .unwrap();
         barr.wait().await;
+        // Wait for workflow to complete in order for all eager activities to be requested before shutting down.
+        // After shutdown, no eager activities slots can be allocated.
+        workflow_complete_token_clone.cancelled().await;
+        core.initiate_shutdown();
+        // Even though this test requests eager activity tasks, none are returned in poll responses.
+        let err = core.poll_activity_task().await.unwrap_err();
+        assert_matches!(err, PollActivityError::ShutDown);
     };
     // This wf poll should *not* set the flag that it wants tasks back since both slots are
     // occupied
     let run_fut = async { worker.run_until_done().await.unwrap() };
-    tokio::join!(run_fut, act_completer);
+    join!(run_fut, act_completer);
 }
 
 #[tokio::test]
 async fn retryable_net_error_exhaustion_is_nonfatal() {
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_complete_activity_task()
@@ -970,15 +1009,15 @@
     let act = core.poll_activity_task().await.unwrap();
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: act.task_token,
         result: Some(ActivityExecutionResult::ok(vec![1].into())),
     })
     .await
     .unwrap();
-    core.shutdown().await;
+    core.drain_activity_poller_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn cant_complete_activity_with_unset_result_payload() {
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_poll_activity_task()
@@ -1008,7 +1047,68 @@
         })
         .await;
     assert_matches!(
         res,
         Err(CompleteActivityError::MalformedActivityCompletion { .. })
     )
 }
+
+#[rstest::rstest]
+#[tokio::test]
+async fn graceful_shutdown(#[values(true, false)] at_max_outstanding: bool) {
+    let _task_q = "q";
+    let grace_period = Duration::from_millis(200);
+    let mut tasks = three_tasks();
+    let mut mock_client = mock_workflow_client();
+    mock_client
+        .expect_poll_activity_task()
+        .times(3)
+        .returning(move |_, _| Ok(tasks.pop_front().unwrap()));
+    // They shall all be reported as failed
+    mock_client
+        .expect_fail_activity_task()
+        .times(3)
+        .returning(|_, _| Ok(Default::default()));
+
+    let max_outstanding = if at_max_outstanding { 3_usize } else { 100 };
+    let worker = Worker::new_test(
+        test_worker_cfg()
+            .graceful_shutdown_period(grace_period)
+            .max_outstanding_activities(max_outstanding)
+            .build()
+            .unwrap(),
+        mock_client,
+    );
+
+    let _1 = worker.poll_activity_task().await.unwrap();
+
+    // Wait at least the grace period after one poll - ensuring it doesn't trigger prematurely
+    tokio::time::sleep(grace_period.mul_f32(1.1)).await;
+
+    let _2 = worker.poll_activity_task().await.unwrap();
+    let _3 = worker.poll_activity_task().await.unwrap();
+
+    worker.initiate_shutdown();
+    let expected_tts = HashSet::from([vec![1], vec![2], vec![3]]);
+    let mut seen_tts = HashSet::new();
+    for _ in 1..=3 {
+        let cancel = worker.poll_activity_task().await.unwrap();
+        assert_matches!(
+            cancel.variant,
+            Some(activity_task::Variant::Cancel(Cancel {
+                reason: r
+            })) if r == ActivityCancelReason::WorkerShutdown as i32
+        );
+        seen_tts.insert(cancel.task_token);
+    }
+    assert_eq!(expected_tts, seen_tts);
+    for tt in seen_tts {
+        worker
+            .complete_activity_task(ActivityTaskCompletion {
+                task_token: tt,
+                result: Some(ActivityExecutionResult::cancel_from_details(None)),
+            })
+            .await
+            .unwrap();
+    }
+    worker.drain_pollers_and_shutdown().await;
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/child_workflows.rs`

 * *Files 1% similar despite different names*

```diff
@@ -84,19 +84,20 @@
     });
 
     let start_res = child
         .start(&ctx)
         .await
         .into_started()
         .expect("Child should get started");
-    let cancel_fut = start_res.cancel(&ctx);
-    let resfut = start_res.result();
-    let (cancel_res, res) = join!(cancel_fut, resfut);
-    cancel_res.expect("cancel result is ok");
-    let stat = res.status.expect("child wf result is ok");
+    start_res.cancel(&ctx);
+    let stat = start_res
+        .result()
+        .await
+        .status
+        .expect("child wf result is ok");
     assert_matches!(stat, child_workflow_result::Status::Cancelled(_));
     Ok(().into())
 }
 
 #[tokio::test]
 async fn cancel_child_workflow() {
     let func = WorkflowFunction::new(parent_cancels_child_wf);
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/determinism.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/driven_workflow.rs`

 * *Files 27% similar despite different names*

```diff
@@ -1,107 +1,99 @@
-use crate::{
-    replay::DEFAULT_WORKFLOW_TYPE,
-    test_help::{canned_histories, mock_sdk, mock_sdk_cfg, MockPollCfg, ResponseType},
-    worker::client::mocks::mock_workflow_client,
+use crate::worker::workflow::{OutgoingJob, WFCommand, WorkflowStartedInfo};
+use prost_types::Timestamp;
+use temporal_sdk_core_protos::{
+    coresdk::workflow_activation::{start_workflow_from_attribs, WorkflowActivationJob},
+    temporal::api::history::v1::WorkflowExecutionStartedEventAttributes,
+    utilities::TryIntoOrNone,
 };
-use std::{
-    sync::atomic::{AtomicBool, AtomicUsize, Ordering},
-    time::Duration,
-};
-use temporal_client::WorkflowOptions;
-use temporal_sdk::{WfContext, WorkflowResult};
-use temporal_sdk_core_protos::temporal::api::enums::v1::WorkflowTaskFailedCause;
-
-static DID_FAIL: AtomicBool = AtomicBool::new(false);
-pub async fn timer_wf_fails_once(ctx: WfContext) -> WorkflowResult<()> {
-    ctx.timer(Duration::from_secs(1)).await;
-    if DID_FAIL
-        .compare_exchange(false, true, Ordering::Relaxed, Ordering::Relaxed)
-        .is_ok()
-    {
-        panic!("Ahh");
+
+/// Abstracts away the concept of an actual workflow implementation, handling sending it new
+/// jobs and fetching output from it.
+pub struct DrivenWorkflow {
+    started_attrs: Option<WorkflowStartedInfo>,
+    fetcher: Box<dyn WorkflowFetcher>,
+    /// Outgoing activation jobs that need to be sent to the lang sdk
+    outgoing_wf_activation_jobs: Vec<OutgoingJob>,
+}
+
+impl<WF> From<Box<WF>> for DrivenWorkflow
+where
+    WF: WorkflowFetcher + 'static,
+{
+    fn from(wf: Box<WF>) -> Self {
+        Self {
+            started_attrs: None,
+            fetcher: wf,
+            outgoing_wf_activation_jobs: Default::default(),
+        }
     }
-    Ok(().into())
 }
 
-/// Verifies that workflow panics (which in this case the Rust SDK turns into workflow activation
-/// failures) are turned into unspecified WFT failures.
-#[tokio::test]
-async fn test_panic_wf_task_rejected_properly() {
-    let wf_id = "fakeid";
-    let wf_type = DEFAULT_WORKFLOW_TYPE;
-    let t = canned_histories::workflow_fails_with_failure_after_timer("1");
-    let mock = mock_workflow_client();
-    let mut mh = MockPollCfg::from_resp_batches(wf_id, t, [1, 2, 2], mock);
-    // We should see one wft failure which has unspecified cause, since panics don't have a defined
-    // type.
-    mh.num_expected_fails = 1;
-    mh.expect_fail_wft_matcher =
-        Box::new(|_, cause, _| matches!(cause, WorkflowTaskFailedCause::Unspecified));
-    let mut worker = mock_sdk(mh);
-
-    worker.register_wf(wf_type.to_owned(), timer_wf_fails_once);
-    worker
-        .submit_wf(
-            wf_id.to_owned(),
-            wf_type.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
+impl DrivenWorkflow {
+    /// Start the workflow
+    pub fn start(
+        &mut self,
+        workflow_id: String,
+        randomness_seed: u64,
+        start_time: Timestamp,
+        attribs: WorkflowExecutionStartedEventAttributes,
+    ) {
+        debug!(run_id = %attribs.original_execution_run_id, "Driven WF start");
+        let started_info = WorkflowStartedInfo {
+            workflow_task_timeout: attribs.workflow_task_timeout.clone().try_into_or_none(),
+            workflow_execution_timeout: attribs
+                .workflow_execution_timeout
+                .clone()
+                .try_into_or_none(),
+            memo: attribs.memo.clone(),
+            search_attrs: attribs.search_attributes.clone(),
+            retry_policy: attribs.retry_policy.clone(),
+        };
+        self.send_job(
+            start_workflow_from_attribs(attribs, workflow_id, randomness_seed, start_time).into(),
+        );
+        self.started_attrs = Some(started_info);
+    }
+
+    /// Return the attributes from the workflow execution started event if this workflow has started
+    pub fn get_started_info(&self) -> Option<&WorkflowStartedInfo> {
+        self.started_attrs.as_ref()
+    }
+
+    /// Enqueue a new job to be sent to the driven workflow
+    pub(super) fn send_job(&mut self, job: OutgoingJob) {
+        self.outgoing_wf_activation_jobs.push(job);
+    }
+
+    /// Observe pending jobs
+    pub(super) fn peek_pending_jobs(&self) -> &[OutgoingJob] {
+        self.outgoing_wf_activation_jobs.as_slice()
+    }
+
+    /// Drain all pending jobs, so that they may be sent to the driven workflow
+    pub fn drain_jobs(&mut self) -> Vec<WorkflowActivationJob> {
+        self.outgoing_wf_activation_jobs
+            .drain(..)
+            .map(Into::into)
+            .collect()
+    }
 }
 
-/// Verifies nondeterministic behavior in workflows results in automatic WFT failure with the
-/// appropriate nondeterminism cause.
-#[rstest::rstest]
-#[case::with_cache(true)]
-#[case::without_cache(false)]
-#[tokio::test]
-async fn test_wf_task_rejected_properly_due_to_nondeterminism(#[case] use_cache: bool) {
-    let wf_id = "fakeid";
-    let wf_type = DEFAULT_WORKFLOW_TYPE;
-    let t = canned_histories::single_timer_wf_completes("1");
-    let mock = mock_workflow_client();
-    let mut mh = MockPollCfg::from_resp_batches(
-        wf_id,
-        t,
-        // Two polls are needed, since the first will fail
-        [ResponseType::AllHistory, ResponseType::AllHistory],
-        mock,
-    );
-    // We should see one wft failure which has nondeterminism cause
-    mh.num_expected_fails = 1;
-    mh.expect_fail_wft_matcher =
-        Box::new(|_, cause, _| matches!(cause, WorkflowTaskFailedCause::NonDeterministicError));
-    let mut worker = mock_sdk_cfg(mh, |cfg| {
-        if use_cache {
-            cfg.max_cached_workflows = 2;
-        }
-    });
+impl WorkflowFetcher for DrivenWorkflow {
+    fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
+        self.fetcher.fetch_workflow_iteration_output()
+    }
+}
 
-    let started_count: &'static _ = Box::leak(Box::new(AtomicUsize::new(0)));
-    worker.register_wf(wf_type.to_owned(), move |ctx: WfContext| async move {
-        // The workflow is replaying all of history, so the when it schedules an extra timer it
-        // should not have, it causes a nondeterminism error.
-        if started_count.fetch_add(1, Ordering::Relaxed) == 0 {
-            ctx.timer(Duration::from_secs(1)).await;
-        }
-        ctx.timer(Duration::from_secs(1)).await;
-        Ok(().into())
-    });
-
-    worker
-        .submit_wf(
-            wf_id.to_owned(),
-            wf_type.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-    // Started count is two since we start, restart once due to error, then we unblock the real
-    // timer and proceed without restarting
-    assert_eq!(2, started_count.load(Ordering::Relaxed));
+/// Implementors of this trait represent a way to fetch output from executing/iterating some
+/// workflow code (or a mocked workflow).
+pub trait WorkflowFetcher: Send {
+    /// Obtain any output from the workflow's recent execution(s). Because the lang sdk is
+    /// responsible for calling workflow code as a result of receiving tasks from
+    /// [crate::Core::poll_task], we cannot directly iterate it here. Thus implementations of this
+    /// trait are expected to either buffer output or otherwise produce it on demand when this
+    /// function is called.
+    ///
+    /// In the case of the real [WorkflowBridge] implementation, commands are simply pulled from
+    /// a buffer that the language side sinks into when it calls [crate::Core::complete_task]
+    fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand>;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/local_activities.rs`

 * *Files 2% similar despite different names*

```diff
@@ -4,49 +4,55 @@
     test_help::{
         hist_to_poll_resp, mock_sdk, mock_sdk_cfg, mock_worker, single_hist_mock_sg, MockPollCfg,
         ResponseType,
     },
     worker::{client::mocks::mock_workflow_client, LEGACY_QUERY_ID},
 };
 use anyhow::anyhow;
+use crossbeam::queue::SegQueue;
 use futures::{future::join_all, FutureExt};
 use std::{
     collections::HashMap,
     ops::Sub,
     sync::{
         atomic::{AtomicUsize, Ordering},
         Arc,
     },
     time::{Duration, SystemTime},
 };
 use temporal_client::WorkflowOptions;
 use temporal_sdk::{
     ActContext, ActivityCancelledError, LocalActivityOptions, WfContext, WorkflowResult,
 };
-use temporal_sdk_core_api::Worker;
+use temporal_sdk_core_api::{
+    errors::{PollActivityError, PollWfError},
+    Worker,
+};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::ActivityExecutionResult,
         workflow_activation::{workflow_activation_job, WorkflowActivationJob},
-        workflow_commands::{ActivityCancellationType, QueryResult, QuerySuccess},
+        workflow_commands::{
+            ActivityCancellationType, QueryResult, QuerySuccess, ScheduleLocalActivity,
+        },
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion, AsJsonPayloadExt,
     },
     temporal::api::{
         common::v1::RetryPolicy,
         enums::v1::{EventType, TimeoutType, WorkflowTaskFailedCause},
-        failure::v1::Failure,
-        history::v1::History,
+        failure::v1::{failure::FailureInfo, Failure},
         query::v1::WorkflowQuery,
     },
+    DEFAULT_ACTIVITY_TYPE,
 };
 use temporal_sdk_core_test_utils::{
     schedule_local_activity_cmd, start_timer_cmd, WorkerTestHelpers,
 };
-use tokio::sync::Barrier;
+use tokio::{join, sync::Barrier};
 
 async fn echo(_ctx: ActContext, e: String) -> anyhow::Result<String> {
     Ok(e)
 }
 
 /// This test verifies that when replaying we are able to resolve local activities whose data we
 /// don't see until after the workflow issues the command
@@ -56,15 +62,15 @@
 #[case::replay_cache_off(true, false)]
 #[case::not_replay_cache_off(false, false)]
 #[tokio::test]
 async fn local_act_two_wfts_before_marker(#[case] replay: bool, #[case] cached: bool) {
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_full_wf_task();
     t.add_local_activity_result_marker(1, "1", b"echo".into());
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
 
     let wf_id = "fakeid";
@@ -81,24 +87,24 @@
         }
     });
 
     worker.register_wf(
         DEFAULT_WORKFLOW_TYPE.to_owned(),
         |ctx: WfContext| async move {
             let la = ctx.local_activity(LocalActivityOptions {
-                activity_type: "echo".to_string(),
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
                 input: "hi".as_json_payload().expect("serializes fine"),
                 ..Default::default()
             });
             ctx.timer(Duration::from_secs(1)).await;
             la.await;
             Ok(().into())
         },
     );
-    worker.register_activity("echo", echo);
+    worker.register_activity(DEFAULT_ACTIVITY_TYPE, echo);
     worker
         .submit_wf(
             wf_id.to_owned(),
             DEFAULT_WORKFLOW_TYPE.to_owned(),
             vec![],
             WorkflowOptions::default(),
         )
@@ -108,33 +114,32 @@
 }
 
 pub async fn local_act_fanout_wf(ctx: WfContext) -> WorkflowResult<()> {
     let las: Vec<_> = (1..=50)
         .map(|i| {
             ctx.local_activity(LocalActivityOptions {
                 activity_type: "echo".to_string(),
-                input: format!("Hi {}", i)
+                input: format!("Hi {i}")
                     .as_json_payload()
                     .expect("serializes fine"),
                 ..Default::default()
             })
         })
         .collect();
     ctx.timer(Duration::from_secs(1)).await;
     join_all(las).await;
     Ok(().into())
 }
 
 #[tokio::test]
 async fn local_act_many_concurrent() {
-    crate::telemetry::test_telem_console();
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_full_wf_task();
     for i in 1..=50 {
         t.add_local_activity_result_marker(i, &i.to_string(), b"echo".into());
     }
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
@@ -298,23 +303,23 @@
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
     t.add_local_activity_fail_marker(
         1,
         "1",
         Failure::application_failure("la failed".to_string(), false),
     );
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_full_wf_task();
     t.add_local_activity_fail_marker(
         2,
         "2",
         Failure::application_failure("la failed".to_string(), false),
     );
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "2".to_string());
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
 
     let wf_id = "fakeid";
     let mock = mock_workflow_client();
     let mh = MockPollCfg::from_resp_batches(
@@ -326,15 +331,15 @@
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
 
     worker.register_wf(
         DEFAULT_WORKFLOW_TYPE.to_owned(),
         |ctx: WfContext| async move {
             let la_res = ctx
                 .local_activity(LocalActivityOptions {
-                    activity_type: "echo".to_string(),
+                    activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
                     input: "hi".as_json_payload().expect("serializes fine"),
                     retry_policy: RetryPolicy {
                         initial_interval: Some(prost_dur!(from_millis(65))),
                         // This will make the second backoff 65 seconds, plenty to use timer
                         backoff_coefficient: 1_000.,
                         maximum_interval: Some(prost_dur!(from_secs(600))),
                         maximum_attempts: 3,
@@ -345,17 +350,20 @@
                 .await;
             assert!(la_res.failed());
             // Extra timer just to have an extra workflow task which we can return full history for
             ctx.timer(Duration::from_secs(1)).await;
             Ok(().into())
         },
     );
-    worker.register_activity("echo", move |_ctx: ActContext, _: String| async move {
-        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
-    });
+    worker.register_activity(
+        DEFAULT_ACTIVITY_TYPE,
+        move |_ctx: ActContext, _: String| async move {
+            Result::<(), _>::Err(anyhow!("Oh no I failed!"))
+        },
+    );
     worker
         .submit_wf(
             wf_id.to_owned(),
             DEFAULT_WORKFLOW_TYPE.to_owned(),
             vec![],
             WorkflowOptions::default(),
         )
@@ -407,15 +415,15 @@
     // This repro only works both when cache is off, and there is at least one heartbeat wft
     // before the marker & next command are recorded.
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
     t.add_full_wf_task();
     t.add_local_activity_result_marker(1, "1", "done".into());
-    t.add_get_event_id(EventType::TimerStarted, None);
+    t.add_by_type(EventType::TimerStarted);
     t.add_full_wf_task();
 
     let wf_id = "fakeid";
     let mock = mock_workflow_client();
     // Bug only repros when seeing history up to third wft
     let mh = MockPollCfg::from_resp_batches(wf_id, t, [3], mock);
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 0);
@@ -495,15 +503,15 @@
 
     let wf_fut = async {
         let task = core.poll_workflow_activation().await.unwrap();
         core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
             task.run_id,
             schedule_local_activity_cmd(
                 1,
-                "act-id",
+                "1",
                 ActivityCancellationType::TryCancel,
                 Duration::from_secs(60),
             ),
         ))
         .await
         .unwrap();
         let task = core.poll_workflow_activation().await.unwrap();
@@ -561,23 +569,19 @@
 #[case::real_history(false)]
 #[tokio::test]
 async fn la_resolve_during_legacy_query_does_not_combine(#[case] impossible_query_in_task: bool) {
     // Ensures we do not send an activation with a legacy query and any other work, which should
     // never happen, but there was an issue where an LA resolving could trigger that.
     let wfid = "fake_wf_id";
     let mut t = TestHistoryBuilder::default();
-    let wes_short_wft_timeout = default_wes_attribs();
-    t.add(
-        EventType::WorkflowExecutionStarted,
-        wes_short_wft_timeout.into(),
-    );
+    t.add(default_wes_attribs());
     // Since we don't send queries with start workflow, need one workflow task of something else
     // b/c we want to get an activation with a job and a nonlegacy query
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
 
     // nonlegacy query got here & LA started here
     t.add_full_wf_task();
     // legacy query got here, at the same time that the LA is resolved
     t.add_local_activity_result_marker(1, "1", "whatever".into());
     t.add_workflow_execution_completed();
@@ -611,16 +615,20 @@
                         // resolves & updates machines before we process this task
                         tokio::time::sleep(Duration::from_secs(1)).await;
                     }
                     .boxed(),
                     2,
                 ),
             );
-            // Strip history, we need to look like we hit the cache
-            pr.history = Some(History { events: vec![] });
+            // Strip beginning of history so the only events are WFT sched/started, we need to look
+            // like we hit the cache
+            {
+                let h = pr.history.as_mut().unwrap();
+                h.events = h.events.split_off(6);
+            }
             // In the nonsense server response case, we attach a legacy query, otherwise this
             // response looks like a normal response to a forced WFT heartbeat.
             if impossible_query_in_task {
                 pr.query = Some(WorkflowQuery {
                     query_type: "query-type".to_string(),
                     query_args: Some(b"hi".into()),
                     header: None,
@@ -753,14 +761,23 @@
                     input: "hi".as_json_payload().expect("serializes fine"),
                     // Impossibly small timeout so we timeout in the queue
                     schedule_to_start_timeout: prost_dur!(from_nanos(1)),
                     ..Default::default()
                 })
                 .await;
             assert_eq!(la_res.timed_out(), Some(TimeoutType::ScheduleToStart));
+            let rfail = la_res.unwrap_failure();
+            assert_matches!(
+                rfail.failure_info,
+                Some(FailureInfo::ActivityFailureInfo(_))
+            );
+            assert_matches!(
+                rfail.cause.unwrap().failure_info,
+                Some(FailureInfo::TimeoutFailureInfo(_))
+            );
             Ok(().into())
         },
     );
     worker.register_activity(
         "echo",
         move |_ctx: ActContext, _: String| async move { Ok(()) },
     );
@@ -801,15 +818,15 @@
         |deets| {
             // Really old schedule time, which should _not_ count against schedule_to_start
             deets.original_schedule_time = Some(orig_sched.into());
             // Backoff value must be present since we're simulating timer backoff
             deets.backoff = Some(prost_dur!(from_secs(100)));
         },
     );
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_workflow_task_scheduled_and_started();
 
     let wf_id = "fakeid";
     let mock = mock_workflow_client();
     let mh = MockPollCfg::from_resp_batches(wf_id, t, [ResponseType::AllHistory], mock);
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
@@ -867,64 +884,66 @@
 }
 
 #[tokio::test]
 async fn wft_failure_cancels_running_las() {
     let mut t = TestHistoryBuilder::default();
     t.add_wfe_started_with_wft_timeout(Duration::from_millis(200));
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_workflow_task_scheduled_and_started();
 
     let wf_id = "fakeid";
     let mock = mock_workflow_client();
     let mut mh = MockPollCfg::from_resp_batches(wf_id, t, [1, 2], mock);
     mh.num_expected_fails = 1;
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
 
     worker.register_wf(
         DEFAULT_WORKFLOW_TYPE.to_owned(),
         |ctx: WfContext| async move {
             let la_handle = ctx.local_activity(LocalActivityOptions {
-                activity_type: "echo".to_string(),
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
                 input: "hi".as_json_payload().expect("serializes fine"),
                 ..Default::default()
             });
             tokio::join!(
                 async {
                     ctx.timer(Duration::from_secs(1)).await;
                     panic!("ahhh I'm failing wft")
                 },
                 la_handle
             );
             Ok(().into())
         },
     );
-    worker.register_activity("echo", move |ctx: ActContext, _: String| async move {
-        let res = tokio::time::timeout(Duration::from_millis(500), ctx.cancelled()).await;
-        if res.is_err() {
-            panic!("Activity must be cancelled!!!!");
-        }
-        Result::<(), _>::Err(ActivityCancelledError::default().into())
-    });
+    worker.register_activity(
+        DEFAULT_ACTIVITY_TYPE,
+        move |ctx: ActContext, _: String| async move {
+            let res = tokio::time::timeout(Duration::from_millis(500), ctx.cancelled()).await;
+            if res.is_err() {
+                panic!("Activity must be cancelled!!!!");
+            }
+            Result::<(), _>::Err(ActivityCancelledError::default().into())
+        },
+    );
     worker
         .submit_wf(
             wf_id.to_owned(),
             DEFAULT_WORKFLOW_TYPE.to_owned(),
             vec![],
             WorkflowOptions::default(),
         )
         .await
         .unwrap();
     worker.run_until_done().await.unwrap();
 }
 
 #[tokio::test]
 async fn resolved_las_not_recorded_if_wft_fails_many_times() {
-    crate::telemetry::test_telem_console();
     // We shouldn't record any LA results if the workflow activation is repeatedly failing. There
     // was an issue that, because we stop reporting WFT failures after 2 tries, this meant the WFT
     // was not marked as "completed" and the WFT could accidentally be replied to with LA results.
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_workflow_task_scheduled_and_started();
     t.add_workflow_task_failed_with_failure(
@@ -938,17 +957,15 @@
     let mut mh = MockPollCfg::from_resp_batches(
         wf_id,
         t,
         [1.into(), ResponseType::AllHistory, ResponseType::AllHistory],
         mock,
     );
     mh.num_expected_fails = 2;
-    mh.completion_asserts = Some(Box::new(|_| {
-        panic!("should never successfully complete a WFT");
-    }));
+    mh.num_expected_completions = Some(0.into());
     let mut worker = mock_sdk_cfg(mh, |w| w.max_cached_workflows = 1);
 
     worker.register_wf(
         DEFAULT_WORKFLOW_TYPE.to_owned(),
         |ctx: WfContext| async move {
             ctx.local_activity(LocalActivityOptions {
                 activity_type: "echo".to_string(),
@@ -970,7 +987,139 @@
             vec![],
             WorkflowOptions::default(),
         )
         .await
         .unwrap();
     worker.run_until_done().await.unwrap();
 }
+
+#[tokio::test]
+async fn local_act_records_nonfirst_attempts_ok() {
+    let mut t = TestHistoryBuilder::default();
+    let wft_timeout = Duration::from_millis(200);
+    t.add_wfe_started_with_wft_timeout(wft_timeout);
+    t.add_full_wf_task();
+    t.add_full_wf_task();
+    t.add_full_wf_task();
+    t.add_workflow_task_scheduled_and_started();
+
+    let wf_id = "fakeid";
+    let mock = mock_workflow_client();
+    let mut mh = MockPollCfg::from_resp_batches(wf_id, t, [1, 2, 3], mock);
+    let nonfirst_counts = Arc::new(SegQueue::new());
+    let nfc_c = nonfirst_counts.clone();
+    mh.completion_asserts = Some(Box::new(move |c| {
+        nfc_c.push(
+            c.metering_metadata
+                .nonfirst_local_activity_execution_attempts,
+        );
+    }));
+    let mut worker = mock_sdk_cfg(mh, |wc| {
+        wc.max_cached_workflows = 1;
+        wc.max_outstanding_workflow_tasks = 1;
+    });
+
+    worker.register_wf(
+        DEFAULT_WORKFLOW_TYPE.to_owned(),
+        |ctx: WfContext| async move {
+            ctx.local_activity(LocalActivityOptions {
+                activity_type: "echo".to_string(),
+                input: "hi".as_json_payload().expect("serializes fine"),
+                retry_policy: RetryPolicy {
+                    initial_interval: Some(prost_dur!(from_millis(10))),
+                    backoff_coefficient: 1.0,
+                    maximum_interval: None,
+                    maximum_attempts: 0,
+                    non_retryable_error_types: vec![],
+                },
+                ..Default::default()
+            })
+            .await;
+            Ok(().into())
+        },
+    );
+    worker.register_activity("echo", move |_ctx: ActContext, _: String| async move {
+        Result::<(), _>::Err(anyhow!("I fail"))
+    });
+    worker
+        .submit_wf(
+            wf_id.to_owned(),
+            DEFAULT_WORKFLOW_TYPE.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
+        .await
+        .unwrap();
+    worker.run_until_done().await.unwrap();
+    // 3 workflow tasks
+    assert_eq!(nonfirst_counts.len(), 3);
+    // First task's non-first count should, of course, be 0
+    assert_eq!(nonfirst_counts.pop().unwrap(), 0);
+    // Next two, some nonzero amount which could vary based on test load
+    assert!(nonfirst_counts.pop().unwrap() > 0);
+    assert!(nonfirst_counts.pop().unwrap() > 0);
+}
+
+#[tokio::test]
+async fn local_activities_can_be_delivered_during_shutdown() {
+    let wfid = "fake_wf_id";
+    let mut t = TestHistoryBuilder::default();
+    t.add_wfe_started_with_wft_timeout(Duration::from_millis(200));
+    t.add_full_wf_task();
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add_timer_fired(timer_started_event_id, "1".to_string());
+    t.add_workflow_task_scheduled_and_started();
+
+    let mock = mock_workflow_client();
+    let mut mock = single_hist_mock_sg(
+        wfid,
+        t,
+        [ResponseType::ToTaskNum(1), ResponseType::AllHistory],
+        mock,
+        true,
+    );
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 1);
+    let core = mock_worker(mock);
+
+    let task = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+        task.run_id,
+        start_timer_cmd(1, Duration::from_secs(1)),
+    ))
+    .await
+    .unwrap();
+
+    let task = core.poll_workflow_activation().await.unwrap();
+    // Initiate shutdown once we have the WF activation, but before replying that we want to do an
+    // LA
+    core.initiate_shutdown();
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+        task.run_id,
+        ScheduleLocalActivity {
+            seq: 1,
+            activity_id: "1".to_string(),
+            activity_type: "test_act".to_string(),
+            start_to_close_timeout: Some(prost_dur!(from_secs(30))),
+            ..Default::default()
+        }
+        .into(),
+    ))
+    .await
+    .unwrap();
+
+    let wf_poller = async { core.poll_workflow_activation().await };
+
+    let at_poller = async {
+        let act_task = core.poll_activity_task().await.unwrap();
+        core.complete_activity_task(ActivityTaskCompletion {
+            task_token: act_task.task_token,
+            result: Some(ActivityExecutionResult::ok(vec![1].into())),
+        })
+        .await
+        .unwrap();
+        core.poll_activity_task().await
+    };
+
+    let (wf_r, act_r) = join!(wf_poller, at_poller);
+    assert_matches!(wf_r.unwrap_err(), PollWfError::ShutDown);
+    assert_matches!(act_r.unwrap_err(), PollActivityError::ShutDown);
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/queries.rs`

 * *Files 2% similar despite different names*

```diff
@@ -19,15 +19,15 @@
             query_result, ActivityCancellationType, CompleteWorkflowExecution,
             ContinueAsNewWorkflowExecution, QueryResult, QuerySuccess, RequestCancelActivity,
         },
         workflow_completion::WorkflowActivationCompletion,
     },
     temporal::api::{
         common::v1::Payload,
-        enums::v1::EventType,
+        enums::v1::{CommandType, EventType},
         failure::v1::Failure,
         history::v1::{history_event, ActivityTaskCancelRequestedEventAttributes, History},
         query::v1::WorkflowQuery,
         workflowservice::v1::{
             GetWorkflowExecutionHistoryResponse, RespondWorkflowTaskCompletedResponse,
         },
     },
@@ -144,41 +144,53 @@
         ))
         .await
         .unwrap();
     worker.shutdown().await;
 }
 
 #[rstest::rstest]
-#[case::one_query(1)]
-#[case::multiple_queries(3)]
 #[tokio::test]
-async fn new_queries(#[case] num_queries: usize) {
+async fn new_queries(
+    #[values(1, 3)] num_queries: usize,
+    #[values(false, true)] query_results_after_complete: bool,
+) {
     let wfid = "fake_wf_id";
     let query_resp = "response";
     let t = canned_histories::single_timer("1");
     let mut header = HashMap::new();
     header.insert("head".to_string(), Payload::from(b"er"));
     let tasks = VecDeque::from(vec![hist_to_poll_resp(&t, wfid.to_owned(), 1.into()), {
         let mut pr = hist_to_poll_resp(&t, wfid.to_owned(), ResponseType::OneTask(2));
         pr.queries = HashMap::new();
         for i in 1..=num_queries {
             pr.queries.insert(
-                format!("q{}", i),
+                format!("q{i}"),
                 WorkflowQuery {
                     query_type: "query-type".to_string(),
                     query_args: Some(b"hi".into()),
                     header: Some(header.clone().into()),
                 },
             );
         }
         pr
     }]);
     let mut mock_client = mock_workflow_client();
     mock_client.expect_respond_legacy_query().times(0);
-    let mut mock = single_hist_mock_sg(wfid, t, tasks, mock_client, true);
+    let mut mh = MockPollCfg::from_resp_batches(wfid, t, tasks, mock_workflow_client());
+    mh.completion_asserts = Some(Box::new(move |c| {
+        // If the completion is the one ending the workflow, make sure it includes the query resps
+        if c.commands[0].command_type() == CommandType::CompleteWorkflowExecution {
+            assert_eq!(c.query_responses.len(), num_queries);
+        } else if c.commands[0].command_type() == CommandType::StartTimer {
+            // first reply, no queries here.
+        } else {
+            panic!("Unexpected command in response")
+        }
+    }));
+    let mut mock = build_mock_pollers(mh);
     mock.worker_cfg(|wc| wc.max_cached_workflows = 10);
     let core = mock_worker(mock);
 
     let task = core.poll_workflow_activation().await.unwrap();
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
         task.run_id,
         start_timer_cmd(1, Duration::from_secs(1)),
@@ -199,32 +211,39 @@
             WorkflowActivationJob {
                 variant: Some(workflow_activation_job::Variant::QueryWorkflow(ref q)),
             } => {
                 assert_eq!(q.headers.get("head").unwrap(), &b"er".into());
             }
         );
     }
-    let mut qresults: Vec<_> = (1..=num_queries)
-        .map(|i| {
+
+    let mut commands = vec![];
+    if query_results_after_complete {
+        commands.push(CompleteWorkflowExecution { result: None }.into());
+    }
+    for i in 1..=num_queries {
+        commands.push(
             QueryResult {
-                query_id: format!("q{}", i),
+                query_id: format!("q{i}"),
                 variant: Some(
                     QuerySuccess {
                         response: Some(query_resp.into()),
                     }
                     .into(),
                 ),
             }
-            .into()
-        })
-        .collect();
-    qresults.push(CompleteWorkflowExecution { result: None }.into());
+            .into(),
+        );
+    }
+    if !query_results_after_complete {
+        commands.push(CompleteWorkflowExecution { result: None }.into());
+    }
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
         task.run_id,
-        qresults,
+        commands,
     ))
     .await
     .unwrap();
     core.shutdown().await;
 }
 
 #[tokio::test]
@@ -765,19 +784,18 @@
 #[tokio::test]
 async fn legacy_query_combined_with_timer_fire_repro() {
     let wfid = "fake_wf_id";
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
     let scheduled_event_id = t.add_activity_task_scheduled("1");
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_full_wf_task();
     t.add(
-        EventType::ActivityTaskCancelRequested,
         history_event::Attributes::ActivityTaskCancelRequestedEventAttributes(
             ActivityTaskCancelRequestedEventAttributes {
                 scheduled_event_id,
                 ..Default::default()
             },
         ),
     );
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/replay_flag.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workers.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 use crate::{
     prost_dur,
     test_help::{
         build_fake_worker, build_mock_pollers, canned_histories, mock_manual_poller, mock_worker,
-        MockPollCfg, MockWorkerInputs, MocksHolder, ResponseType,
+        MockPollCfg, MockWorkerInputs, MocksHolder, ResponseType, WorkerExt,
     },
     worker::client::mocks::mock_workflow_client,
     PollActivityError, PollWfError,
 };
 use futures::FutureExt;
 use std::{cell::RefCell, time::Duration};
 use temporal_sdk_core_api::Worker;
@@ -140,21 +140,26 @@
             let res = worker.poll_workflow_activation().await.unwrap();
             // Complete so there's no outstanding WFT and shutdown can finish
             worker
                 .complete_workflow_activation(WorkflowActivationCompletion::empty(res.run_id))
                 .await
                 .unwrap();
             barrier.wait().await;
+            // We need to see workflow poll return shutdown before activity poll will
+            assert_matches!(
+                worker.poll_workflow_activation().await.unwrap_err(),
+                PollWfError::ShutDown
+            );
             assert_matches!(
                 worker.poll_activity_task().await.unwrap_err(),
                 PollActivityError::ShutDown
             );
         }
     );
-    worker.finalize_shutdown().await;
+    worker.drain_pollers_and_shutdown().await;
 }
 
 #[tokio::test]
 async fn complete_with_task_not_found_during_shutdown() {
     let t = canned_histories::single_timer("1");
     let mut mock = mock_workflow_client();
     mock.expect_complete_workflow_task()
@@ -186,17 +191,15 @@
             vec![start_timer_cmd(1, Duration::from_secs(1))],
         ))
         .await
         .unwrap();
         complete_order.borrow_mut().push(1);
     };
     tokio::join!(shutdown_fut, poll_fut, complete_fut);
-    // Shutdown will currently complete first before the actual eviction reply since the
-    // workflow task is marked complete as soon as we get not found back from the server.
-    assert_eq!(&complete_order.into_inner(), &[1, 3, 2])
+    assert_eq!(&complete_order.into_inner(), &[1, 2, 3])
 }
 
 #[tokio::test]
 async fn complete_eviction_after_shutdown_doesnt_panic() {
     let t = canned_histories::single_timer("1");
     let mut mh = build_mock_pollers(MockPollCfg::from_resp_batches(
         "fakeid",
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_cancels.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/core_tests/workflow_tasks.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,60 +1,66 @@
 use crate::{
-    advance_fut, job_assert,
+    advance_fut,
+    internal_flags::CoreInternalFlags,
+    job_assert,
     replay::TestHistoryBuilder,
     test_help::{
         build_fake_worker, build_mock_pollers, build_multihist_mock_sg, canned_histories,
         gen_assert_and_fail, gen_assert_and_reply, hist_to_poll_resp, mock_sdk, mock_sdk_cfg,
         mock_worker, poll_and_reply, poll_and_reply_clears_outstanding_evicts, single_hist_mock_sg,
         test_worker_cfg, FakeWfResponses, MockPollCfg, MocksHolder, ResponseType,
         WorkflowCachingPolicy::{self, AfterEveryReply, NonSticky},
     },
     worker::client::mocks::{mock_manual_workflow_client, mock_workflow_client},
     Worker,
 };
 use futures::{stream, FutureExt};
 use rstest::{fixture, rstest};
 use std::{
-    collections::{HashMap, VecDeque},
+    collections::{HashMap, HashSet, VecDeque},
     sync::{
         atomic::{AtomicU64, Ordering},
         Arc,
     },
     time::Duration,
 };
+use temporal_client::WorkflowOptions;
 use temporal_sdk::{ActivityOptions, CancellableFuture, WfContext};
 use temporal_sdk_core_api::{errors::PollWfError, Worker as WorkerTrait};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{self as ar, activity_resolution, ActivityResolution},
         workflow_activation::{
             remove_from_cache::EvictionReason, workflow_activation_job, FireTimer, ResolveActivity,
             StartWorkflow, UpdateRandomSeed, WorkflowActivationJob,
         },
         workflow_commands::{
             ActivityCancellationType, CancelTimer, CompleteWorkflowExecution,
             ContinueAsNewWorkflowExecution, FailWorkflowExecution, RequestCancelActivity,
-            ScheduleActivity,
+            ScheduleActivity, SetPatchMarker,
         },
         workflow_completion::WorkflowActivationCompletion,
     },
-    default_wes_attribs,
+    default_act_sched, default_wes_attribs,
     temporal::api::{
         command::v1::command::Attributes,
         common::v1::{Payload, RetryPolicy},
         enums::v1::{EventType, WorkflowTaskFailedCause},
         failure::v1::Failure,
-        history::v1::{history_event, TimerFiredEventAttributes},
+        history::v1::{
+            history_event, TimerFiredEventAttributes,
+            WorkflowPropertiesModifiedExternallyEventAttributes,
+        },
         workflowservice::v1::{
             GetWorkflowExecutionHistoryResponse, RespondWorkflowTaskCompletedResponse,
         },
     },
-    DEFAULT_WORKFLOW_TYPE,
+    DEFAULT_ACTIVITY_TYPE, DEFAULT_WORKFLOW_TYPE,
 };
-use temporal_sdk_core_test_utils::{fanout_tasks, start_timer_cmd};
+use temporal_sdk_core_test_utils::{fanout_tasks, start_timer_cmd, WorkerTestHelpers};
 use tokio::{
     join,
     sync::{Barrier, Semaphore},
 };
 
 #[fixture(hist_batches = &[])]
 fn single_timer_setup(hist_batches: &'static [usize]) -> Worker {
@@ -116,15 +122,15 @@
         &worker,
         NonSticky,
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     activity_id: "fake_activity".to_string(),
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::ResolveActivity(_)),
                 vec![CompleteWorkflowExecution { result: None }.into()],
             ),
@@ -241,15 +247,15 @@
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_seq,
                     activity_id: activity_id.to_string(),
                     cancellation_type: ActivityCancellationType::TryCancel as i32,
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::SignalWorkflow(_)),
                 vec![RequestCancelActivity { seq: activity_seq }.into()],
             ),
@@ -277,15 +283,15 @@
         NonSticky,
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_seq,
                     activity_id: activity_id.to_string(),
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                     .into()],
             ),
             // Activity is getting resolved right away as it has been timed out.
             gen_assert_and_reply(
                 &|res| {
                     assert_matches!(
@@ -330,15 +336,15 @@
         NonSticky,
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_seq,
                     activity_id: activity_seq.to_string(),
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                     .into()],
             ),
             // Activity is getting resolved right away as it has been timed out.
             gen_assert_and_reply(
                 &|res| {
                 assert_matches!(
@@ -385,15 +391,15 @@
         NonSticky,
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_seq,
                     activity_id: activity_id.to_string(),
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::SignalWorkflow(_)),
                 vec![RequestCancelActivity { seq: activity_seq }.into()],
             ),
@@ -453,18 +459,18 @@
     let wf_type = DEFAULT_WORKFLOW_TYPE;
     let activity_id = "1";
 
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
     let act_scheduled_event_id = t.add_activity_task_scheduled(activity_id);
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     t.add_timer_fired(timer_started_event_id, "1".to_string());
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
     let act_started_event_id = t.add_activity_task_started(act_scheduled_event_id);
     t.add_activity_task_completed(
         act_scheduled_event_id,
         act_started_event_id,
         Default::default(),
     );
     t.add_full_wf_task();
@@ -472,15 +478,15 @@
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
     let mock = mock_workflow_client();
     let mut worker = mock_sdk(MockPollCfg::from_resp_batches(wfid, t, hist_batches, mock));
 
     worker.register_wf(wf_type.to_owned(), |ctx: WfContext| async move {
         let act_fut = ctx.activity(ActivityOptions {
-            activity_type: "echo_activity".to_string(),
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
             start_to_close_timeout: Some(Duration::from_secs(5)),
             cancellation_type: ActivityCancellationType::Abandon,
             ..Default::default()
         });
         ctx.timer(Duration::from_secs(1)).await;
         act_fut.cancel(&ctx);
         ctx.timer(Duration::from_secs(3)).await;
@@ -538,15 +544,15 @@
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_seq,
                     activity_id: activity_seq.to_string(),
                     cancellation_type: cancel_type as i32,
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::SignalWorkflow(_)),
                 vec![RequestCancelActivity { seq: activity_seq }.into()],
             ),
@@ -606,15 +612,15 @@
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_id,
                     activity_id: activity_id.to_string(),
                     cancellation_type: ActivityCancellationType::WaitCancellationCompleted as i32,
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::SignalWorkflow(_)),
                 vec![RequestCancelActivity { seq: activity_id }.into()],
             ),
@@ -886,18 +892,15 @@
     )
     .await;
 }
 
 #[tokio::test]
 async fn max_wft_respected() {
     let total_wfs = 100;
-    let wf_ids: Vec<_> = (0..total_wfs)
-        .into_iter()
-        .map(|i| format!("fake-wf-{}", i))
-        .collect();
+    let wf_ids: Vec<_> = (0..total_wfs).map(|i| format!("fake-wf-{i}")).collect();
     let hists = wf_ids.iter().map(|wf_id| {
         let hist = canned_histories::single_timer("1");
         FakeWfResponses {
             wf_id: wf_id.to_string(),
             hist,
             response_batches: vec![1.into(), 2.into()],
         }
@@ -943,15 +946,15 @@
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 // Start timer and activity
                 vec![
                     ScheduleActivity {
                         seq: activity_id,
                         activity_id: activity_id.to_string(),
                         cancellation_type: ActivityCancellationType::TryCancel as i32,
-                        ..Default::default()
+                        ..default_act_sched()
                     }
                     .into(),
                     start_timer_cmd(1, Duration::from_secs(1)),
                 ],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::FireTimer(_)),
@@ -985,17 +988,17 @@
         &core,
         NonSticky,
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_id,
-                    activity_id: activity_id.to_string(),
+                    activity_id: "act-1".to_string(),
                     cancellation_type: ActivityCancellationType::TryCancel as i32,
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::SignalWorkflow(_)),
                 vec![
                     RequestCancelActivity { seq: activity_id }.into(),
@@ -1017,16 +1020,16 @@
     )
     .await;
 }
 
 #[tokio::test]
 async fn lots_of_workflows() {
     let total_wfs = 500;
-    let hists = (0..total_wfs).into_iter().map(|i| {
-        let wf_id = format!("fake-wf-{}", i);
+    let hists = (0..total_wfs).map(|i| {
+        let wf_id = format!("fake-wf-{i}");
         let hist = canned_histories::single_timer("1");
         FakeWfResponses {
             wf_id,
             hist,
             response_batches: vec![1.into(), 2.into()],
         }
     });
@@ -1088,15 +1091,15 @@
         &[
             gen_assert_and_reply(
                 &job_assert!(workflow_activation_job::Variant::StartWorkflow(_)),
                 vec![ScheduleActivity {
                     seq: activity_id,
                     activity_id: activity_id.to_string(),
                     cancellation_type: ActivityCancellationType::TryCancel as i32,
-                    ..Default::default()
+                    ..default_act_sched()
                 }
                 .into()],
             ),
             gen_assert_and_reply(
                 &job_assert!(
                     workflow_activation_job::Variant::SignalWorkflow(_),
                     workflow_activation_job::Variant::SignalWorkflow(_),
@@ -1221,22 +1224,21 @@
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_workflow_task_scheduled_and_started();
     // Need to build the first response before adding the timeout events b/c otherwise the history
     // builder will include them in the first task
     let resp_1 = hist_to_poll_resp(&t, wfid.to_owned(), 1.into()).resp;
     t.add_workflow_task_timed_out();
     t.add_full_wf_task();
-    let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
-    t.add(
-        EventType::TimerFired,
-        history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add(history_event::Attributes::TimerFiredEventAttributes(
+        TimerFiredEventAttributes {
             started_event_id: timer_started_event_id,
             timer_id: "1".to_string(),
-        }),
-    );
+        },
+    ));
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
 
     let mut tasks = VecDeque::from(vec![resp_1]);
     // Extend the task list with the now timeout-included version of the task. We add a bunch of
     // them because the poll loop will spin while new tasks are available and it is buffering them
     tasks.extend(
@@ -1260,24 +1262,24 @@
             t.run_id,
             vec![CompleteWorkflowExecution { result: None }.into()],
         ))
         .await
         .unwrap();
     };
     let complete_first = async move {
+        // If the first complete is sent too fast, we may not have had a chance to buffer work.
+        tokio::time::sleep(Duration::from_millis(50)).await;
         core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
             act1.run_id,
             start_timer_cmd(1, Duration::from_secs(1)),
         ))
         .await
         .unwrap();
     };
     join!(poll_fut, complete_first, async {
-        // If the shutdown is sent too too fast, we might not have got a chance to even buffer work
-        tokio::time::sleep(Duration::from_millis(5)).await;
         core.shutdown().await;
     });
 }
 
 #[tokio::test]
 async fn fail_wft_then_recover() {
     let t = canned_histories::long_sequential_timers(1);
@@ -1299,15 +1301,15 @@
 
     let act = core.poll_workflow_activation().await.unwrap();
     // Start an activity instead of a timer, triggering nondeterminism error
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
         act.run_id.clone(),
         vec![ScheduleActivity {
             activity_id: "fake_activity".to_string(),
-            ..Default::default()
+            ..default_act_sched()
         }
         .into()],
     ))
     .await
     .unwrap();
     // We must handle an eviction now
     let evict_act = core.poll_workflow_activation().await.unwrap();
@@ -1351,20 +1353,25 @@
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     // Add this nonsense event here to make applying the poll response fail
     t.add_external_signal_completed(100);
     t.add_full_wf_task();
     t.add_workflow_execution_completed();
 
-    let mh = MockPollCfg::from_resp_batches(
+    let mut mh = MockPollCfg::from_resp_batches(
         "fake_wf_id",
         t,
         [ResponseType::AllHistory],
         mock_workflow_client(),
     );
+    // Fail wft will be called when auto-failing.
+    mh.num_expected_fails = 1;
+    mh.expect_fail_wft_matcher = Box::new(move |_, cause, _| {
+        matches!(cause, WorkflowTaskFailedCause::NonDeterministicError)
+    });
     let mock = build_mock_pollers(mh);
     let core = mock_worker(mock);
     // Poll for first WFT, which is immediately an eviction
     let act = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         act.jobs.as_slice(),
         [WorkflowActivationJob {
@@ -1449,15 +1456,15 @@
 
     let activation = core.poll_workflow_activation().await.unwrap();
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
         activation.run_id,
         ScheduleActivity {
             seq: 1,
             activity_id: "1".to_string(),
-            ..Default::default()
+            ..default_act_sched()
         }
         .into(),
     ))
     .await
     .unwrap();
     let activation = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
@@ -1542,17 +1549,16 @@
     worker
         .complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
             activation.run_id,
             CompleteWorkflowExecution { result: None }.into(),
         ))
         .await
         .unwrap();
-    assert_eq!(worker.available_wft_permits().await, 2);
-
     worker.shutdown().await;
+    assert_eq!(worker.available_wft_permits().await, 2);
 }
 
 #[tokio::test]
 async fn cache_miss_will_fetch_history() {
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
     t.add_full_wf_task();
@@ -1570,14 +1576,16 @@
     mh.mock_client
         .expect_get_workflow_execution_history()
         .times(1)
         .returning(move |_, _, _| Ok(get_exec_resp.clone()));
     let mut mock = build_mock_pollers(mh);
     mock.worker_cfg(|cfg| {
         cfg.max_cached_workflows = 1;
+        // Also verifies tying the WFT permit to the fetch request doesn't get us stuck
+        cfg.max_outstanding_workflow_tasks = 1;
     });
     let worker = mock_worker(mock);
 
     let activation = worker.poll_workflow_activation().await.unwrap();
     assert_eq!(activation.history_length, 3);
     assert_matches!(
         activation.jobs.as_slice(),
@@ -1684,19 +1692,72 @@
     ))
     .await
     .unwrap();
     core.shutdown().await;
 }
 
 #[tokio::test]
+async fn pagination_works_with_tasks_from_completion() {
+    let wfid = "fake_wf_id";
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.add_we_signaled("sig", vec![]);
+    t.add_workflow_task_scheduled_and_started();
+
+    let mut mock = mock_workflow_client();
+    let mut needs_pag_resp = hist_to_poll_resp(&t, wfid.to_owned(), ResponseType::OneTask(2)).resp;
+    needs_pag_resp.next_page_token = vec![1];
+    let complete_resp = RespondWorkflowTaskCompletedResponse {
+        workflow_task: Some(needs_pag_resp),
+        ..Default::default()
+    };
+    mock.expect_complete_workflow_task()
+        .times(1)
+        .returning(move |_| Ok(complete_resp.clone()));
+    mock.expect_complete_workflow_task()
+        .times(1)
+        .returning(|_| Ok(Default::default()));
+
+    let get_exec_resp: GetWorkflowExecutionHistoryResponse =
+        t.get_full_history_info().unwrap().into();
+    mock.expect_get_workflow_execution_history()
+        .returning(move |_, _, _| Ok(get_exec_resp.clone()))
+        .times(1);
+
+    let mut mock = single_hist_mock_sg(wfid, t, [1], mock, true);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 2);
+    let core = mock_worker(mock);
+
+    let wf_task = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(wf_task.run_id))
+        .await
+        .unwrap();
+    let wf_task = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        wf_task.jobs.as_slice(),
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::SignalWorkflow(_)),
+        },]
+    );
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+        wf_task.run_id,
+        vec![CompleteWorkflowExecution { result: None }.into()],
+    ))
+    .await
+    .unwrap();
+    core.shutdown().await;
+}
+
+#[tokio::test]
 async fn poll_faster_than_complete_wont_overflow_cache() {
     // Make workflow tasks for 5 different runs
     let tasks: Vec<_> = (1..=5)
         .map(|i| FakeWfResponses {
-            wf_id: format!("wf-{}", i),
+            wf_id: format!("wf-{i}"),
             hist: canned_histories::single_timer("1"),
             response_batches: vec![ResponseType::ToTaskNum(1)],
         })
         .collect();
     let mut mock_client = mock_workflow_client();
     mock_client
         .expect_complete_workflow_task()
@@ -1897,15 +1958,15 @@
     );
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
         act.run_id,
         ScheduleActivity {
             seq: 1,
             activity_id: activity_id.to_string(),
             cancellation_type: ActivityCancellationType::Abandon as i32,
-            ..Default::default()
+            ..default_act_sched()
         }
         .into(),
     ))
     .await
     .unwrap();
     let act = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
@@ -2010,18 +2071,15 @@
     let mut wes_attrs = default_wes_attribs();
     wes_attrs.memo = Some(memo);
     wes_attrs.search_attributes = Some(search);
     wes_attrs.retry_policy = Some(retry_policy);
     let mut mock_client = mock_workflow_client();
     let hist = {
         let mut t = TestHistoryBuilder::default();
-        t.add(
-            EventType::WorkflowExecutionStarted,
-            wes_attrs.clone().into(),
-        );
+        t.add(wes_attrs.clone());
         t.add_full_wf_task();
         t
     };
     mock_client
         .expect_poll_workflow_task()
         .returning(move |_, _| {
             Ok(hist_to_poll_resp(&hist, wfid.to_owned(), ResponseType::AllHistory).resp)
@@ -2057,34 +2115,476 @@
 }
 
 #[rstest]
 #[tokio::test]
 async fn ignorable_events_are_ok(#[values(true, false)] attribs_unset: bool) {
     let mut t = TestHistoryBuilder::default();
     t.add_by_type(EventType::WorkflowExecutionStarted);
-    let id = t.add_get_event_id(
-        EventType::Unspecified,
-        Some(
-            history_event::Attributes::WorkflowPropertiesModifiedExternallyEventAttributes(
-                Default::default(),
-            ),
-        ),
-    );
-    t.modify_event(id, |e| e.worker_may_ignore = true);
-    if attribs_unset {
-        t.modify_event(id, |e| {
-            e.event_type = EventType::WorkflowPropertiesModifiedExternally as i32;
+    let id = t.add(WorkflowPropertiesModifiedExternallyEventAttributes::default());
+    t.modify_event(id, |e| {
+        e.worker_may_ignore = true;
+        // Ignorable events are ignored if we can't interpret the proto of either the event attribs
+        // or proto - otherwise (this is the _may_ part of may ignore), we'll still try to process
+        // it. That processing may ultimately still choose to do nothing, if we want to _explicitly_
+        // ignore it.
+        if attribs_unset {
             e.attributes = None;
-        });
-    }
+        } else {
+            e.event_type = EventType::Unspecified as i32;
+        }
+    });
     t.add_workflow_task_scheduled_and_started();
 
     let mock = mock_workflow_client();
     let mock = single_hist_mock_sg("wheee", t, [ResponseType::AllHistory], mock, true);
     let core = mock_worker(mock);
 
     let act = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         act.jobs[0].variant,
         Some(workflow_activation_job::Variant::StartWorkflow(_))
     );
 }
+
+#[tokio::test]
+async fn fetching_to_continue_replay_works() {
+    let mut mock_client = mock_workflow_client();
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.add_full_wf_task(); // ends 7
+    let mut need_fetch_resp =
+        hist_to_poll_resp(&t, "wfid".to_owned(), ResponseType::AllHistory).resp;
+    need_fetch_resp.next_page_token = vec![1];
+
+    t.add_full_wf_task();
+    t.add_we_signaled("hi", vec![]); // Need to make there be two complete WFTs
+    t.add_full_wf_task(); // end 14
+    let mut fetch_resp: GetWorkflowExecutionHistoryResponse =
+        t.get_full_history_info().unwrap().into();
+    // And indicate that even *more* needs to be fetched after this, so we see a request for the
+    // next page happen.
+    fetch_resp.next_page_token = vec![2];
+
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add_timer_fired(timer_started_event_id, "1".to_string());
+    t.add_full_wf_task();
+    let final_fetch_resp: GetWorkflowExecutionHistoryResponse =
+        t.get_full_history_info().unwrap().into();
+
+    let tasks = vec![
+        ResponseType::ToTaskNum(1),
+        ResponseType::Raw(need_fetch_resp),
+    ];
+    mock_client
+        .expect_get_workflow_execution_history()
+        .returning(move |_, _, _| Ok(fetch_resp.clone()))
+        .times(1);
+    mock_client
+        .expect_get_workflow_execution_history()
+        .returning(move |_, _, _| Ok(final_fetch_resp.clone()))
+        .times(1);
+    let mut mock = single_hist_mock_sg("wfid", t, tasks, mock_client, true);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 10);
+    let core = mock_worker(mock);
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        act.jobs[0].variant,
+        Some(workflow_activation_job::Variant::StartWorkflow(_))
+    );
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(act.run_id))
+        .await
+        .unwrap();
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        act.jobs.as_slice(),
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::SignalWorkflow(_)),
+        }]
+    );
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmd(
+        act.run_id,
+        start_timer_cmd(1, Duration::from_secs(1)),
+    ))
+    .await
+    .unwrap();
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        act.jobs.as_slice(),
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::FireTimer(_)),
+        }]
+    );
+}
+
+#[tokio::test]
+async fn fetching_error_evicts_wf() {
+    let mut mock_client = mock_workflow_client();
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_workflow_task_scheduled_and_started();
+    t.add_workflow_task_completed();
+    let mut need_fetch_resp =
+        hist_to_poll_resp(&t, "wfid".to_owned(), ResponseType::AllHistory).resp;
+    need_fetch_resp.next_page_token = vec![1];
+    let tasks = vec![
+        ResponseType::ToTaskNum(1),
+        ResponseType::Raw(need_fetch_resp),
+    ];
+    mock_client
+        .expect_get_workflow_execution_history()
+        .returning(move |_, _, _| Err(tonic::Status::not_found("Ahh broken")))
+        .times(1);
+    let mut mock = single_hist_mock_sg("wfid", t, tasks, mock_client, true);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 10);
+    let core = mock_worker(mock);
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        act.jobs[0].variant,
+        Some(workflow_activation_job::Variant::StartWorkflow(_))
+    );
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(act.run_id))
+        .await
+        .unwrap();
+    let evict_act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        evict_act.jobs.as_slice(),
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::RemoveFromCache(r)),
+        }] => r.message.contains("Fetching history failed")
+    );
+}
+
+/// This test verifies that if we fail to fetch a page during a completion, that we don't get stuck
+/// in the complete waiting for the completion to finish.
+#[tokio::test]
+async fn ensure_fetching_fail_during_complete_sends_task_failure() {
+    let wfid = "fake_wf_id";
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task(); // started 3
+    t.add_we_signaled("sig1", vec![]);
+    t.add_full_wf_task(); // started 7
+
+    // Need a command event after here so the paginator will know it has two complete WFTs and
+    // processing can begin before needing to fetch again
+    t.add_by_type(EventType::TimerStarted);
+    t.add_full_wf_task(); // started 11
+    t.add_workflow_execution_completed();
+
+    let mut first_poll = hist_to_poll_resp(&t, wfid, ResponseType::OneTask(4)).resp;
+    // History is partial so fetch will happen. We have to lie here and make up a previous started
+    // which really makes no sense, otherwise the paginator eagerly fetches and will fail before we
+    // ever start anything -- which is good -- but this test wants to make sure a fetching failure
+    // during a completion is handled correctly. That may no longer actually be a thing that can
+    // happen.
+    first_poll.previous_started_event_id = 0;
+    first_poll.started_event_id = 11;
+
+    let mut next_page: GetWorkflowExecutionHistoryResponse =
+        t.get_full_history_info().unwrap().into();
+    next_page.history.as_mut().unwrap().events.truncate(9);
+    next_page.next_page_token = vec![2];
+
+    let mut mock = mock_workflow_client();
+    mock.expect_get_workflow_execution_history()
+        .returning(move |_, _, _| {
+            error!("Called fetch!");
+            Ok(next_page.clone())
+        })
+        .times(1);
+    mock.expect_get_workflow_execution_history()
+        .returning(move |_, _, _| {
+            error!("Called fetch second time!");
+            Err(tonic::Status::not_found("Ahh broken"))
+        })
+        .times(1);
+    mock.expect_fail_workflow_task()
+        .returning(|_, _, _| Ok(Default::default()))
+        .times(1);
+
+    let mut mock = single_hist_mock_sg(wfid, t, [ResponseType::Raw(first_poll)], mock, true);
+    mock.make_wft_stream_interminable();
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 2);
+    let core = mock_worker(mock);
+
+    let wf_task = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(wf_task.run_id))
+        .await
+        .unwrap();
+
+    // Expect to see eviction b/c of history fetching error here.
+    let wf_task = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        wf_task.jobs.as_slice(),
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::RemoveFromCache(c)),
+        }] if c.message.contains("Fetching history")
+    );
+
+    core.shutdown().await;
+}
+
+#[tokio::test]
+async fn lang_internal_flags() {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.set_flags_first_wft(&[], &[1]);
+    t.add_we_signaled("sig1", vec![]);
+    t.add_full_wf_task();
+    t.set_flags_last_wft(&[], &[2]);
+    t.add_we_signaled("sig2", vec![]);
+    t.add_full_wf_task();
+    t.add_workflow_execution_completed();
+
+    let mut mh = MockPollCfg::from_resp_batches(
+        "fake_wf_id",
+        t,
+        [ResponseType::ToTaskNum(2), ResponseType::AllHistory],
+        mock_workflow_client(),
+    );
+    mh.completion_asserts = Some(Box::new(|c| {
+        assert_matches!(c.sdk_metadata.lang_used_flags.as_slice(), &[2]);
+    }));
+    let mut mock = build_mock_pollers(mh);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 1);
+    let core = mock_worker(mock);
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(act.available_internal_flags.as_slice(), [1]);
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(act.run_id))
+        .await
+        .unwrap();
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    let mut completion = WorkflowActivationCompletion::empty(act.run_id);
+    completion.add_internal_flags(2);
+    core.complete_workflow_activation(completion).await.unwrap();
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(act.available_internal_flags.as_slice(), [1, 2]);
+    core.complete_execution(&act.run_id).await;
+    core.shutdown().await;
+}
+
+// Verify we send all core internal flags on the first non-replay WFT
+#[tokio::test]
+async fn core_internal_flags() {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_workflow_task_scheduled_and_started();
+
+    let mut mh = MockPollCfg::from_resp_batches(
+        "fake_wf_id",
+        t,
+        [ResponseType::ToTaskNum(1)],
+        mock_workflow_client(),
+    );
+    mh.completion_asserts = Some(Box::new(move |c| {
+        assert_eq!(
+            c.sdk_metadata
+                .core_used_flags
+                .iter()
+                .copied()
+                .collect::<HashSet<_>>(),
+            CoreInternalFlags::all_except_too_high()
+                .map(|f| f as u32)
+                .collect()
+        );
+    }));
+    let mut mock = build_mock_pollers(mh);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 1);
+    let core = mock_worker(mock);
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    core.complete_execution(&act.run_id).await;
+    core.shutdown().await;
+}
+
+#[tokio::test]
+async fn post_terminal_commands_are_discarded() {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.add_workflow_execution_completed();
+
+    let mut mh = MockPollCfg::from_resp_batches(
+        "fake_wf_id",
+        t,
+        [ResponseType::ToTaskNum(1), ResponseType::AllHistory],
+        mock_workflow_client(),
+    );
+    mh.completion_asserts = Some(Box::new(|c| {
+        // Only the complete execution command should actually be sent
+        assert_eq!(c.commands.len(), 1);
+    }));
+    let mut mock = build_mock_pollers(mh);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 1);
+    let core = mock_worker(mock);
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+        act.run_id,
+        vec![
+            CompleteWorkflowExecution { result: None }.into(),
+            start_timer_cmd(1, Duration::from_secs(1)),
+        ],
+    ))
+    .await
+    .unwrap();
+
+    // This just ensures applying the complete history w/ the completion command works, though
+    // there's no activation.
+    let act = core.poll_workflow_activation().await;
+    assert_matches!(act.unwrap_err(), PollWfError::ShutDown);
+
+    core.shutdown().await;
+}
+
+// Lang expects to always see jobs in this order:
+//   patches, signals, everything else, queries
+#[tokio::test]
+async fn jobs_are_in_appropriate_order() {
+    let p1 = "patchy-mc-patchface";
+    let p2 = "enchi-the-kitty";
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    t.add_has_change_marker(p1, false);
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add_timer_fired(timer_started_event_id, "1".to_string());
+    t.add_we_signaled("yummy-salmon", vec![]);
+    t.add_full_wf_task();
+    t.add_has_change_marker(p2, false);
+    t.add_workflow_execution_completed();
+
+    let mh = MockPollCfg::from_resp_batches(
+        "fake_wf_id",
+        t,
+        [ResponseType::AllHistory],
+        mock_workflow_client(),
+    );
+    let mut mock = build_mock_pollers(mh);
+    mock.worker_cfg(|wc| wc.max_cached_workflows = 1);
+    let core = mock_worker(mock);
+
+    let act = core.poll_workflow_activation().await.unwrap();
+    // Patch notifications always come first
+    assert_matches!(
+        act.jobs[0].variant.as_ref().unwrap(),
+        workflow_activation_job::Variant::NotifyHasPatch(_)
+    );
+    assert_matches!(
+        act.jobs[1].variant.as_ref().unwrap(),
+        workflow_activation_job::Variant::StartWorkflow(_)
+    );
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+        act.run_id,
+        vec![
+            SetPatchMarker {
+                patch_id: p1.to_string(),
+                deprecated: false,
+            }
+            .into(),
+            start_timer_cmd(1, Duration::from_secs(1)),
+        ],
+    ))
+    .await
+    .unwrap();
+    let act = core.poll_workflow_activation().await.unwrap();
+    assert_matches!(
+        act.jobs[0].variant.as_ref().unwrap(),
+        workflow_activation_job::Variant::NotifyHasPatch(_)
+    );
+    assert_matches!(
+        act.jobs[1].variant.as_ref().unwrap(),
+        workflow_activation_job::Variant::SignalWorkflow(_)
+    );
+    assert_matches!(
+        act.jobs[2].variant.as_ref().unwrap(),
+        workflow_activation_job::Variant::FireTimer(_)
+    );
+}
+
+#[rstest]
+#[tokio::test]
+async fn history_length_with_fail_and_timeout(
+    #[values(true, false)] use_cache: bool,
+    #[values(1, 2, 3)] history_responses_case: u8,
+) {
+    let wfid = "fake_wf_id";
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add_timer_fired(timer_started_event_id, "1".to_string());
+    t.add_workflow_task_scheduled_and_started();
+    t.add_workflow_task_failed_with_failure(WorkflowTaskFailedCause::Unspecified, "ahh".into());
+    t.add_workflow_task_scheduled_and_started();
+    t.add_workflow_task_timed_out();
+    t.add_full_wf_task();
+    let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+    t.add_timer_fired(timer_started_event_id, "2".to_string());
+    t.add_full_wf_task();
+    t.add_workflow_execution_completed();
+
+    let mut mock_client = mock_workflow_client();
+    let history_responses = match history_responses_case {
+        1 => vec![ResponseType::AllHistory],
+        2 => vec![
+            ResponseType::ToTaskNum(1),
+            ResponseType::ToTaskNum(2),
+            ResponseType::AllHistory,
+        ],
+        3 => {
+            let mut needs_fetch = hist_to_poll_resp(&t, wfid, ResponseType::ToTaskNum(2)).resp;
+            needs_fetch.next_page_token = vec![1];
+            // Truncate the history a bit in order to force incomplete WFT
+            needs_fetch.history.as_mut().unwrap().events.truncate(6);
+            let needs_fetch_resp = ResponseType::Raw(needs_fetch);
+            let mut empty_fetch_resp: GetWorkflowExecutionHistoryResponse =
+                t.get_history_info(1).unwrap().into();
+            empty_fetch_resp.history.as_mut().unwrap().events = vec![];
+            mock_client
+                .expect_get_workflow_execution_history()
+                .returning(move |_, _, _| Ok(empty_fetch_resp.clone()))
+                .times(1);
+            vec![
+                ResponseType::ToTaskNum(1),
+                needs_fetch_resp,
+                ResponseType::ToTaskNum(2),
+                ResponseType::AllHistory,
+            ]
+        }
+        _ => unreachable!(),
+    };
+
+    let mut mh = MockPollCfg::from_resp_batches(wfid, t, history_responses, mock_client);
+    if history_responses_case == 3 {
+        // Expect the failed pagination fetch
+        mh.num_expected_fails = 1;
+    }
+    let mut worker = mock_sdk_cfg(mh, |wc| {
+        if use_cache {
+            wc.max_cached_workflows = 1;
+        }
+    });
+    worker.register_wf(DEFAULT_WORKFLOW_TYPE, |ctx: WfContext| async move {
+        assert_eq!(ctx.history_length(), 3);
+        ctx.timer(Duration::from_secs(1)).await;
+        assert_eq!(ctx.history_length(), 14);
+        ctx.timer(Duration::from_secs(1)).await;
+        assert_eq!(ctx.history_length(), 19);
+        Ok(().into())
+    });
+    worker
+        .submit_wf(
+            wfid.to_owned(),
+            DEFAULT_WORKFLOW_TYPE.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
+        .await
+        .unwrap();
+    worker.run_until_done().await.unwrap();
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/ephemeral_server/mod.rs`

 * *Files 12% similar despite different names*

```diff
@@ -19,14 +19,17 @@
 use zip::read::read_zipfile_from_stream;
 
 #[cfg(target_family = "unix")]
 use std::os::unix::fs::OpenOptionsExt;
 use std::process::Stdio;
 
 /// Configuration for Temporalite.
+/// Will be removed eventually as its successor, Temporal CLI matures.
+/// We don't care for the duplication between this struct and [TemporalDevServerConfig] and prefer that over another
+/// abstraction since the existence of this struct is temporary.
 #[derive(Debug, Clone, derive_builder::Builder)]
 pub struct TemporaliteConfig {
     /// Required path to executable or download info.
     pub exe: EphemeralExe,
     /// Namespace to use.
     #[builder(default = "\"default\".to_owned()")]
     pub namespace: String,
@@ -55,15 +58,18 @@
     pub async fn start_server(&self) -> anyhow::Result<EphemeralServer> {
         self.start_server_with_output(Stdio::inherit()).await
     }
 
     /// Start a Temporalite server with configurable stdout destination.
     pub async fn start_server_with_output(&self, output: Stdio) -> anyhow::Result<EphemeralServer> {
         // Get exe path
-        let exe_path = self.exe.get_or_download("temporalite").await?;
+        let exe_path = self
+            .exe
+            .get_or_download("temporalite", "temporalite", None)
+            .await?;
 
         // Get free port if not already given
         let port = self.port.unwrap_or_else(|| get_free_port(&self.ip));
 
         // Build arg set
         let mut args = vec![
             "start".to_owned(),
@@ -73,14 +79,16 @@
             self.namespace.clone(),
             "--ip".to_owned(),
             self.ip.clone(),
             "--log-format".to_owned(),
             self.log.0.clone(),
             "--log-level".to_owned(),
             self.log.1.clone(),
+            "--dynamic-config-value".to_owned(),
+            "frontend.enableServerVersionCheck=false".to_owned(),
         ];
         if let Some(db_filename) = &self.db_filename {
             args.push("--filename".to_owned());
             args.push(db_filename.clone());
         } else {
             args.push("--ephemeral".to_owned());
         }
@@ -97,14 +105,97 @@
             has_test_service: false,
             output,
         })
         .await
     }
 }
 
+/// Configuration for Temporal CLI dev server.
+#[derive(Debug, Clone, derive_builder::Builder)]
+pub struct TemporalDevServerConfig {
+    /// Required path to executable or download info.
+    pub exe: EphemeralExe,
+    /// Namespace to use.
+    #[builder(default = "\"default\".to_owned()")]
+    pub namespace: String,
+    /// IP to bind to.
+    #[builder(default = "\"127.0.0.1\".to_owned()")]
+    pub ip: String,
+    /// Port to use or obtains a free one if none given.
+    #[builder(default)]
+    pub port: Option<u16>,
+    /// Sqlite DB filename if persisting or non-persistent if none.
+    #[builder(default)]
+    pub db_filename: Option<String>,
+    /// Whether to enable the UI.
+    #[builder(default)]
+    pub ui: bool,
+    /// Log format and level
+    #[builder(default = "(\"pretty\".to_owned(), \"warn\".to_owned())")]
+    pub log: (String, String),
+    /// Additional arguments to Temporalite.
+    #[builder(default)]
+    pub extra_args: Vec<String>,
+}
+
+impl TemporalDevServerConfig {
+    /// Start a Temporal CLI dev server.
+    pub async fn start_server(&self) -> anyhow::Result<EphemeralServer> {
+        self.start_server_with_output(Stdio::inherit()).await
+    }
+
+    /// Start a Temporal CLI dev server with configurable stdout destination.
+    pub async fn start_server_with_output(&self, output: Stdio) -> anyhow::Result<EphemeralServer> {
+        // Get exe path
+        let exe_path = self
+            .exe
+            .get_or_download("cli", "temporal", Some("tar.gz"))
+            .await?;
+
+        // Get free port if not already given
+        let port = self.port.unwrap_or_else(|| get_free_port(&self.ip));
+
+        // Build arg set
+        let mut args = vec![
+            "server".to_owned(),
+            "start-dev".to_owned(),
+            "--port".to_owned(),
+            port.to_string(),
+            "--namespace".to_owned(),
+            self.namespace.clone(),
+            "--ip".to_owned(),
+            self.ip.clone(),
+            "--log-format".to_owned(),
+            self.log.0.clone(),
+            "--log-level".to_owned(),
+            self.log.1.clone(),
+            "--dynamic-config-value".to_owned(),
+            "frontend.enableServerVersionCheck=false".to_owned(),
+        ];
+        if let Some(db_filename) = &self.db_filename {
+            args.push("--filename".to_owned());
+            args.push(db_filename.clone());
+        }
+        if !self.ui {
+            args.push("--headless".to_owned());
+        }
+        args.extend(self.extra_args.clone());
+
+        // Start
+        EphemeralServer::start(EphemeralServerConfig {
+            exe_path,
+            port,
+            args,
+            has_test_service: false,
+            output,
+        })
+        .await
+    }
+}
+
 /// Configuration for the test server.
 #[derive(Debug, Clone, derive_builder::Builder)]
 pub struct TestServerConfig {
     /// Required path to executable or download info.
     pub exe: EphemeralExe,
     /// Port to use or obtains a free one if none given.
     #[builder(default)]
@@ -119,15 +210,18 @@
     pub async fn start_server(&self) -> anyhow::Result<EphemeralServer> {
         self.start_server_with_output(Stdio::inherit()).await
     }
 
     /// Start a test server with configurable stdout.
     pub async fn start_server_with_output(&self, output: Stdio) -> anyhow::Result<EphemeralServer> {
         // Get exe path
-        let exe_path = self.exe.get_or_download("temporal-test-server").await?;
+        let exe_path = self
+            .exe
+            .get_or_download("temporal-test-server", "temporal-test-server", None)
+            .await?;
 
         // Get free port if not already given
         let port = self.port.unwrap_or_else(|| get_free_port("0.0.0.0"));
 
         // Build arg set
         let mut args = vec![port.to_string()];
         args.extend(self.extra_args.clone());
@@ -168,15 +262,15 @@
         // TODO(cretz): Offer stdio suppression?
         let child = tokio::process::Command::new(config.exe_path)
             .args(config.args)
             .stdin(Stdio::null())
             .stdout(config.output)
             .spawn()?;
         let target = format!("127.0.0.1:{}", config.port);
-        let target_url = format!("http://{}", target);
+        let target_url = format!("http://{target}");
         let success = Ok(EphemeralServer {
             target,
             has_test_service: config.has_test_service,
             child,
         });
 
         // Try to connect every 100ms for 5s
@@ -258,15 +352,15 @@
     },
 }
 
 /// Which version of the exe to download.
 #[derive(Debug, Clone)]
 pub enum EphemeralExeVersion {
     /// Use a default version for the given SDK name and version.
-    Default {
+    SDKDefault {
         /// Name of the SDK to get the default for.
         sdk_name: String,
         /// Version of the SDK to get the default for.
         sdk_version: String,
     },
     /// Specific version.
     Fixed(String),
@@ -276,15 +370,20 @@
 #[serde(rename_all = "camelCase")]
 struct DownloadInfo {
     archive_url: String,
     file_to_extract: String,
 }
 
 impl EphemeralExe {
-    async fn get_or_download(&self, artifact_name: &str) -> anyhow::Result<PathBuf> {
+    async fn get_or_download(
+        &self,
+        artifact_name: &str,
+        downloaded_name_prefix: &str,
+        preferred_format: Option<&str>,
+    ) -> anyhow::Result<PathBuf> {
         match self {
             EphemeralExe::ExistingPath(exe_path) => {
                 let path = PathBuf::from(exe_path);
                 if !path.exists() {
                     return Err(anyhow!("Exe path does not exist"));
                 }
                 Ok(path)
@@ -297,20 +396,20 @@
                 let (platform, out_ext) = match std::env::consts::OS {
                     "windows" => ("windows", ".exe"),
                     "macos" => ("darwin", ""),
                     _ => ("linux", ""),
                 };
                 // Create dest file based on SDK name/version or fixed version
                 let dest = dest_dir.join(match version {
-                    EphemeralExeVersion::Default {
+                    EphemeralExeVersion::SDKDefault {
                         sdk_name,
                         sdk_version,
-                    } => format!("{}-{}-{}{}", artifact_name, sdk_name, sdk_version, out_ext),
+                    } => format!("{downloaded_name_prefix}-{sdk_name}-{sdk_version}{out_ext}"),
                     EphemeralExeVersion::Fixed(version) => {
-                        format!("{}-{}{}", artifact_name, version, out_ext)
+                        format!("{downloaded_name_prefix}-{version}{out_ext}")
                     }
                 });
                 debug!(
                     "Lazily downloading or using existing exe at {}",
                     dest.display()
                 );
 
@@ -322,30 +421,32 @@
                 // Get info about the proper archive and in-archive file
                 let arch = match std::env::consts::ARCH {
                     "x86_64" => "amd64",
                     "arm" | "aarch64" => "arm64",
                     other => return Err(anyhow!("Unsupported arch: {}", other)),
                 };
                 let mut get_info_params = vec![("arch", arch), ("platform", platform)];
+                if let Some(format) = preferred_format {
+                    get_info_params.push(("format", format));
+                }
                 let version_name = match version {
-                    EphemeralExeVersion::Default {
+                    EphemeralExeVersion::SDKDefault {
                         sdk_name,
                         sdk_version,
                     } => {
                         get_info_params.push(("sdk-name", sdk_name.as_str()));
                         get_info_params.push(("sdk-version", sdk_version.as_str()));
                         "default"
                     }
                     EphemeralExeVersion::Fixed(version) => version,
                 };
                 let client = reqwest::Client::new();
                 let info: DownloadInfo = client
                     .get(format!(
-                        "https://temporal.download/{}/{}",
-                        artifact_name, version_name
+                        "https://temporal.download/{artifact_name}/{version_name}"
                     ))
                     .query(&get_info_params)
                     .send()
                     .await?
                     .json()
                     .await?;
 
@@ -367,15 +468,15 @@
         }
     }
 }
 
 fn get_free_port(bind_ip: &str) -> u16 {
     // Can just ask OS to give us a port then close socket. OS's don't give that
     // port back to anyone else anytime soon.
-    std::net::TcpListener::bind(format!("{}:0", bind_ip))
+    std::net::TcpListener::bind(format!("{bind_ip}:0"))
         .unwrap()
         .local_addr()
         .unwrap()
         .port()
 }
 
 /// Returns false if we successfully waited for another download to complete, or
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -9,14 +9,15 @@
 pub extern crate assert_matches;
 #[macro_use]
 extern crate tracing;
 extern crate core;
 
 mod abstractions;
 pub mod ephemeral_server;
+mod internal_flags;
 mod pollers;
 mod protosext;
 pub mod replay;
 pub(crate) mod retry_logic;
 pub mod telemetry;
 mod worker;
 
@@ -32,41 +33,44 @@
     Client, ClientOptions, ClientOptionsBuilder, ClientTlsConfig, RetryClient, RetryConfig,
     TlsConfig, WorkflowClientTrait,
 };
 pub use temporal_sdk_core_api as api;
 pub use temporal_sdk_core_protos as protos;
 pub use temporal_sdk_core_protos::TaskToken;
 pub use url::Url;
+#[cfg(feature = "save_wf_inputs")]
+pub use worker::replay_wf_state_inputs;
 pub use worker::{Worker, WorkerConfig, WorkerConfigBuilder};
 
 use crate::{
     replay::{mock_client_from_histories, Historator, HistoryForReplay},
     telemetry::{
-        metrics::MetricsContext, remove_trace_subscriber_for_current_thread,
-        set_trace_subscriber_for_current_thread, telemetry_init, TelemetryInstance,
+        metrics::{MetricsContext, TemporalMeter},
+        remove_trace_subscriber_for_current_thread, set_trace_subscriber_for_current_thread,
+        telemetry_init, TelemetryInstance,
     },
     worker::client::WorkerClientBag,
 };
 use futures::Stream;
 use std::sync::Arc;
 use temporal_client::{ConfiguredClient, TemporalServiceClientWithMetrics};
 use temporal_sdk_core_api::{
     errors::{CompleteActivityError, PollActivityError, PollWfError},
-    telemetry::{CoreTelemetry, TelemetryOptions},
+    telemetry::TelemetryOptions,
     Worker as WorkerTrait,
 };
 use temporal_sdk_core_protos::coresdk::ActivityHeartbeat;
 
 /// Initialize a worker bound to a task queue.
 ///
 /// You will need to have already initialized a [CoreRuntime] which will be used for this worker.
 /// After the worker is initialized, you should use [CoreRuntime::tokio_handle] to run the worker's
 /// async functions.
 ///
-/// Lang implementations may pass in a [temporal_client::ConfiguredClient] directly (or a
+/// Lang implementations may pass in a [ConfiguredClient] directly (or a
 /// [RetryClient] wrapping one, or a handful of other variants of the same idea). When they do so,
 /// this function will always overwrite the client retry configuration, force the client to use the
 /// namespace defined in the worker config, and set the client identity appropriately. IE: Use
 /// [ClientOptions::connect_no_namespace], not [ClientOptions::connect].
 pub fn init_worker<CT>(
     runtime: &CoreRuntime,
     worker_config: WorkerConfig,
@@ -93,17 +97,20 @@
         client,
         worker_config.namespace.clone(),
         client_ident,
         worker_config.worker_build_id.clone(),
         worker_config.use_worker_versioning,
     ));
 
-    let metrics = MetricsContext::top_level(worker_config.namespace.clone(), &runtime.telemetry)
-        .with_task_q(worker_config.task_queue.clone());
-    Ok(Worker::new(worker_config, sticky_q, client_bag, metrics))
+    Ok(Worker::new(
+        worker_config,
+        sticky_q,
+        client_bag,
+        Some(&runtime.telemetry),
+    ))
 }
 
 /// Create a worker for replaying a specific history. It will auto-shutdown as soon as the history
 /// has finished being replayed.
 ///
 /// You do not necessarily need a [CoreRuntime] for replay workers, but it's advisable to create
 /// one and use it to run the replay worker's async functions the same way you would for a normal
@@ -122,15 +129,15 @@
     config.max_cached_workflows = 1;
     config.max_concurrent_wft_polls = 1;
     config.no_remote_activities = true;
     let historator = Historator::new(histories);
     let post_activate = historator.get_post_activate_hook();
     let shutdown_tok = historator.get_shutdown_setter();
     let client = mock_client_from_histories(historator);
-    let mut worker = Worker::new(config, None, Arc::new(client), MetricsContext::no_op());
+    let mut worker = Worker::new(config, None, Arc::new(client), None);
     worker.set_post_activate_hook(post_activate);
     shutdown_tok(worker.shutdown_token());
     Ok(worker)
 }
 
 /// Creates a unique sticky queue name for a worker, iff the config allows for 1 or more cached
 /// workflows.
@@ -254,15 +261,15 @@
 
     /// Get a handle to the tokio runtime used by this Core runtime.
     pub fn tokio_handle(&self) -> tokio::runtime::Handle {
         self.runtime_handle.clone()
     }
 
     /// Returns the metric meter used for recording metrics, if they were enabled.
-    pub fn metric_meter(&self) -> Option<&opentelemetry::metrics::Meter> {
+    pub fn metric_meter(&self) -> Option<TemporalMeter> {
         self.telemetry.get_metric_meter()
     }
 
     /// Return the trace subscriber associated with the telemetry options/instance. Can be used
     /// to manually set the default for a thread or globally using the `tracing` crate, or with
     /// [set_trace_subscriber_for_current_thread]
     pub fn trace_subscriber(&self) -> Arc<dyn tracing::Subscriber + Send + Sync> {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/pollers/poll_buffer.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/protosext/mod.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/replay/mod.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,20 +1,22 @@
 //! This module implements support for creating special core instances and workers which can be used
 //! to replay canned histories. It should be used by Lang SDKs to provide replay capabilities to
 //! users during testing.
 
 use crate::{
-    worker::client::{mocks::mock_manual_workflow_client, WorkerClient},
+    worker::{
+        client::{mocks::mock_manual_workflow_client, WorkerClient},
+        PostActivateHookData,
+    },
     Worker,
 };
 use futures::{FutureExt, Stream, StreamExt};
 use once_cell::sync::OnceCell;
 use parking_lot::Mutex;
 use std::{
-    collections::HashMap,
     pin::Pin,
     sync::Arc,
     task::{Context, Poll},
 };
 use temporal_sdk_core_protos::{
     coresdk::workflow_activation::remove_from_cache::EvictionReason,
     temporal::api::{
@@ -143,33 +145,26 @@
             dat,
             replay_done_tx,
         }
     }
 
     /// Returns a callback that can be used as the post-activation hook for a worker to indicate
     /// we're ready to replay the next history, or whatever else.
-    pub(crate) fn get_post_activate_hook(&self) -> impl Fn(&Worker, &str, usize) + Send + Sync {
-        let dat = self.dat.clone();
+    pub(crate) fn get_post_activate_hook(
+        &self,
+    ) -> impl Fn(&Worker, PostActivateHookData) + Send + Sync {
         let done_tx = self.replay_done_tx.clone();
-        move |worker, activated_run_id, last_processed_event| {
-            // We can't hold the lock while evaluating the hook, or we'd deadlock.
-            let last_event_in_hist = dat
-                .lock()
-                .run_id_to_last_event_num
-                .get(activated_run_id)
-                .cloned();
-            if let Some(le) = last_event_in_hist {
-                if last_processed_event >= le {
-                    worker.request_wf_eviction(
-                        activated_run_id,
-                        "Always evict workflows after replay",
-                        EvictionReason::LangRequested,
-                    );
-                    done_tx.send(activated_run_id.to_string()).unwrap();
-                }
+        move |worker, data| {
+            if !data.replaying {
+                worker.request_wf_eviction(
+                    data.run_id,
+                    "Always evict workflows after replay",
+                    EvictionReason::LangRequested,
+                );
+                done_tx.send(data.run_id.to_string()).unwrap();
             }
         }
     }
 
     pub(crate) fn get_shutdown_setter(&self) -> impl FnOnce(CancellationToken) + 'static {
         let wc = self.worker_closer.clone();
         move |ct| {
@@ -180,36 +175,30 @@
 
 impl Stream for Historator {
     type Item = HistoryForReplay;
 
     fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
         match self.iter.poll_next_unpin(cx) {
             Poll::Ready(Some(history)) => {
-                let run_id = history
+                history
                     .hist
                     .extract_run_id_from_start()
                     .expect(
                         "Histories provided for replay must contain run ids in their workflow \
                                  execution started events",
                     )
                     .to_string();
-                let last_event = history.hist.last_event_id();
-                self.dat
-                    .lock()
-                    .run_id_to_last_event_num
-                    .insert(run_id, last_event as usize);
                 Poll::Ready(Some(history))
             }
             Poll::Ready(None) => {
                 self.dat.lock().all_dispatched = true;
                 Poll::Ready(None)
             }
             o => o,
         }
     }
 }
 
 #[derive(Default)]
 struct HistoratorDat {
-    run_id_to_last_event_num: HashMap<String, usize>,
     all_dispatched: bool,
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/retry_logic.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/log_export.rs`

 * *Files 0% similar despite different names*

```diff
@@ -135,15 +135,15 @@
             serde_json::json!(value.to_string()),
         );
     }
 
     fn record_debug(&mut self, field: &tracing::field::Field, value: &dyn std::fmt::Debug) {
         self.0.insert(
             field.name().to_string(),
-            serde_json::json!(format!("{:?}", value)),
+            serde_json::json!(format!("{value:?}")),
         );
     }
 }
 
 #[cfg(test)]
 mod tests {
     use crate::{telemetry::construct_filter_string, telemetry_init};
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/metrics.rs`

 * *Files 4% similar despite different names*

```diff
@@ -6,28 +6,68 @@
         metrics::{
             aggregators::{histogram, last_value, sum, Aggregator},
             sdk_api::{Descriptor, InstrumentKind},
         },
     },
     Context, KeyValue,
 };
-use std::{sync::Arc, time::Duration};
-use temporal_sdk_core_api::telemetry::CoreTelemetry;
+use std::{ops::Deref, sync::Arc, time::Duration};
+use temporal_client::ClientMetricProvider;
 
 /// Used to track context associated with metrics, and record/update them
 ///
 /// Possible improvement: make generic over some type tag so that methods are only exposed if the
 /// appropriate k/vs have already been set.
 #[derive(Clone)]
 pub(crate) struct MetricsContext {
     ctx: Context,
     kvs: Arc<Vec<KeyValue>>,
     instruments: Arc<Instruments>,
 }
 
+/// Wraps OTel's [Meter] to ensure we name our metrics properly, or any other temporal-specific
+/// metrics customizations
+#[derive(derive_more::Constructor)]
+pub struct TemporalMeter<'a> {
+    inner: &'a Meter,
+    metrics_prefix: &'static str,
+}
+
+impl<'a> TemporalMeter<'a> {
+    pub(crate) fn counter(&self, name: &'static str) -> Counter<u64> {
+        self.inner
+            .u64_counter(self.metrics_prefix.to_string() + name)
+            .init()
+    }
+
+    pub(crate) fn histogram(&self, name: &'static str) -> Histogram<u64> {
+        self.inner
+            .u64_histogram(self.metrics_prefix.to_string() + name)
+            .init()
+    }
+}
+
+impl<'a> ClientMetricProvider for TemporalMeter<'a> {
+    fn counter(&self, name: &'static str) -> Counter<u64> {
+        self.counter(name)
+    }
+
+    fn histogram(&self, name: &'static str) -> Histogram<u64> {
+        self.histogram(name)
+    }
+}
+
+impl<'a> Deref for TemporalMeter<'a> {
+    type Target = dyn ClientMetricProvider + 'a;
+
+    fn deref(&self) -> &Self::Target {
+        self as &Self::Target
+    }
+}
+
 struct Instruments {
     wf_completed_counter: Counter<u64>,
     wf_canceled_counter: Counter<u64>,
     wf_failed_counter: Counter<u64>,
     wf_cont_counter: Counter<u64>,
     wf_e2e_latency: Histogram<u64>,
     wf_task_queue_poll_empty_counter: Counter<u64>,
@@ -50,18 +90,18 @@
 }
 
 impl MetricsContext {
     pub(crate) fn no_op() -> Self {
         Self {
             ctx: Default::default(),
             kvs: Default::default(),
-            instruments: Arc::new(Instruments::new_explicit(
+            instruments: Arc::new(Instruments::new_explicit(TemporalMeter::new(
                 &NoopMeterProvider::new().meter("fakemeter"),
                 "fakemetrics",
-            )),
+            ))),
         }
     }
 
     pub(crate) fn top_level(namespace: String, telemetry: &TelemetryInstance) -> Self {
         let kvs = vec![KeyValue::new(KEY_NAMESPACE, namespace)];
         Self {
             ctx: Context::current(),
@@ -253,50 +293,44 @@
 impl Instruments {
     fn new(telem: &TelemetryInstance) -> Self {
         let no_op_meter: Meter;
         let meter = if let Some(meter) = telem.get_metric_meter() {
             meter
         } else {
             no_op_meter = NoopMeterProvider::default().meter("no_op");
-            &no_op_meter
+            TemporalMeter::new(&no_op_meter, "fakemetrics")
         };
-        Self::new_explicit(meter, telem.metric_prefix)
+        Self::new_explicit(meter)
     }
 
-    fn new_explicit(meter: &Meter, metric_prefix: &'static str) -> Self {
-        let ctr = |name: &'static str| -> Counter<u64> {
-            meter.u64_counter(metric_prefix.to_string() + name).init()
-        };
-        let hst = |name: &'static str| -> Histogram<u64> {
-            meter.u64_histogram(metric_prefix.to_string() + name).init()
-        };
+    fn new_explicit(meter: TemporalMeter) -> Self {
         Self {
-            wf_completed_counter: ctr("workflow_completed"),
-            wf_canceled_counter: ctr("workflow_canceled"),
-            wf_failed_counter: ctr("workflow_failed"),
-            wf_cont_counter: ctr("workflow_continue_as_new"),
-            wf_e2e_latency: hst(WF_E2E_LATENCY_NAME),
-            wf_task_queue_poll_empty_counter: ctr("workflow_task_queue_poll_empty"),
-            wf_task_queue_poll_succeed_counter: ctr("workflow_task_queue_poll_succeed"),
-            wf_task_execution_failure_counter: ctr("workflow_task_queue_poll_failed"),
-            wf_task_sched_to_start_latency: hst(WF_TASK_SCHED_TO_START_LATENCY_NAME),
-            wf_task_replay_latency: hst(WF_TASK_REPLAY_LATENCY_NAME),
-            wf_task_execution_latency: hst(WF_TASK_EXECUTION_LATENCY_NAME),
-            act_poll_no_task: ctr("activity_poll_no_task"),
-            act_task_received_counter: ctr("activity_task_received"),
-            act_execution_failed: ctr("activity_execution_failed"),
-            act_sched_to_start_latency: hst(ACT_SCHED_TO_START_LATENCY_NAME),
-            act_exec_latency: hst(ACT_EXEC_LATENCY_NAME),
+            wf_completed_counter: meter.counter("workflow_completed"),
+            wf_canceled_counter: meter.counter("workflow_canceled"),
+            wf_failed_counter: meter.counter("workflow_failed"),
+            wf_cont_counter: meter.counter("workflow_continue_as_new"),
+            wf_e2e_latency: meter.histogram(WF_E2E_LATENCY_NAME),
+            wf_task_queue_poll_empty_counter: meter.counter("workflow_task_queue_poll_empty"),
+            wf_task_queue_poll_succeed_counter: meter.counter("workflow_task_queue_poll_succeed"),
+            wf_task_execution_failure_counter: meter.counter("workflow_task_execution_failed"),
+            wf_task_sched_to_start_latency: meter.histogram(WF_TASK_SCHED_TO_START_LATENCY_NAME),
+            wf_task_replay_latency: meter.histogram(WF_TASK_REPLAY_LATENCY_NAME),
+            wf_task_execution_latency: meter.histogram(WF_TASK_EXECUTION_LATENCY_NAME),
+            act_poll_no_task: meter.counter("activity_poll_no_task"),
+            act_task_received_counter: meter.counter("activity_task_received"),
+            act_execution_failed: meter.counter("activity_execution_failed"),
+            act_sched_to_start_latency: meter.histogram(ACT_SCHED_TO_START_LATENCY_NAME),
+            act_exec_latency: meter.histogram(ACT_EXEC_LATENCY_NAME),
             // name kept as worker start for compat with old sdk / what users expect
-            worker_registered: ctr("worker_start"),
-            num_pollers: hst(NUM_POLLERS_NAME),
-            task_slots_available: hst(TASK_SLOTS_AVAILABLE_NAME),
-            sticky_cache_hit: ctr("sticky_cache_hit"),
-            sticky_cache_miss: ctr("sticky_cache_miss"),
-            sticky_cache_size: hst(STICKY_CACHE_SIZE_NAME),
+            worker_registered: meter.counter("worker_start"),
+            num_pollers: meter.histogram(NUM_POLLERS_NAME),
+            task_slots_available: meter.histogram(TASK_SLOTS_AVAILABLE_NAME),
+            sticky_cache_hit: meter.counter("sticky_cache_hit"),
+            sticky_cache_miss: meter.counter("sticky_cache_miss"),
+            sticky_cache_size: meter.histogram(STICKY_CACHE_SIZE_NAME),
         }
     }
 }
 
 const KEY_NAMESPACE: &str = "namespace";
 const KEY_WF_TYPE: &str = "workflow_type";
 const KEY_TASK_QUEUE: &str = "task_queue";
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/mod.rs`

 * *Files 9% similar despite different names*

```diff
@@ -23,17 +23,18 @@
     },
     KeyValue,
 };
 use opentelemetry_otlp::WithExportConfig;
 use parking_lot::Mutex;
 use std::{
     cell::RefCell,
-    collections::VecDeque,
+    collections::{HashMap, VecDeque},
     convert::TryInto,
     env,
+    net::SocketAddr,
     sync::{
         atomic::{AtomicBool, Ordering},
         Arc,
     },
     time::Duration,
 };
 use temporal_sdk_core_api::telemetry::{
@@ -43,58 +44,71 @@
 use tonic::metadata::MetadataMap;
 use tracing::{Level, Subscriber};
 use tracing_subscriber::{layer::SubscriberExt, EnvFilter, Layer};
 
 const TELEM_SERVICE_NAME: &str = "temporal-core-sdk";
 
 /// Help you construct an [EnvFilter] compatible filter string which will forward all core module
-/// traces at `core_level` and all others (from 3rd party modules, etc) at `other_levl.
+/// traces at `core_level` and all others (from 3rd party modules, etc) at `other_level`.
 pub fn construct_filter_string(core_level: Level, other_level: Level) -> String {
     format!(
-        "{o},temporal_sdk_core={l},temporal_client={l},temporal_sdk={l}",
-        o = other_level,
-        l = core_level
+        "{other_level},temporal_sdk_core={core_level},temporal_client={core_level},temporal_sdk={core_level}"
     )
 }
 
 /// Holds initialized tracing/metrics exporters, etc
 pub struct TelemetryInstance {
     metric_prefix: &'static str,
     logs_out: Option<Mutex<CoreLogsOut>>,
     metrics: Option<(Box<dyn MeterProvider + Send + Sync + 'static>, Meter)>,
     trace_subscriber: Arc<dyn Subscriber + Send + Sync>,
+    prom_binding: Option<SocketAddr>,
     _keepalive_rx: Receiver<()>,
 }
 
 impl TelemetryInstance {
     fn new(
         trace_subscriber: Arc<dyn Subscriber + Send + Sync>,
         logs_out: Option<Mutex<CoreLogsOut>>,
         metric_prefix: &'static str,
         mut meter_provider: Option<Box<dyn MeterProvider + Send + Sync + 'static>>,
+        prom_binding: Option<SocketAddr>,
         keepalive_rx: Receiver<()>,
     ) -> Self {
         let metrics = meter_provider.take().map(|mp| {
             let meter = mp.meter(TELEM_SERVICE_NAME);
             (mp, meter)
         });
         Self {
             metric_prefix,
             logs_out,
             metrics,
             trace_subscriber,
+            prom_binding,
             _keepalive_rx: keepalive_rx,
         }
     }
 
     /// Returns a trace subscriber which can be used with the tracing crate, or with our own
     /// [set_trace_subscriber_for_current_thread] function.
     pub fn trace_subscriber(&self) -> Arc<dyn Subscriber + Send + Sync> {
         self.trace_subscriber.clone()
     }
+
+    /// Returns the address the Prometheus server is bound to if it is running
+    pub fn prom_port(&self) -> Option<SocketAddr> {
+        self.prom_binding
+    }
+
+    /// Returns our wrapper for OTel metric meters, can be used to, ex: initialize clients
+    pub fn get_metric_meter(&self) -> Option<TemporalMeter> {
+        self.metrics
+            .as_ref()
+            .map(|(_, m)| TemporalMeter::new(m, self.metric_prefix))
+    }
 }
 
 thread_local! {
     static SUB_GUARD: RefCell<Option<tracing::subscriber::DefaultGuard>> = RefCell::new(None);
 }
 /// Set the trace subscriber for the current thread. This must be done in every thread which uses
 /// core stuff, otherwise traces/logs will not be collected on that thread. For example, if using
@@ -127,18 +141,14 @@
     fn fetch_buffered_logs(&self) -> Vec<CoreLog> {
         if let Some(logs_out) = self.logs_out.as_ref() {
             logs_out.lock().pop_iter().collect()
         } else {
             vec![]
         }
     }
-
-    fn get_metric_meter(&self) -> Option<&Meter> {
-        self.metrics.as_ref().map(|(_, m)| m)
-    }
 }
 
 /// Initialize tracing subscribers/output and logging export, returning a [TelemetryInstance]
 /// which can be used to register default / global tracing subscribers.
 ///
 /// You should only call this once per unique [TelemetryOptions]
 ///
@@ -157,14 +167,15 @@
             .thread_name("telemetry")
             .worker_threads(2)
             .enable_all()
             .build()?;
         // Parts of telem dat ====
         let mut logs_out = None;
         let metric_prefix = metric_prefix(&opts);
+        let mut prom_binding = None;
         // =======================
 
         // Tracing subscriber layers =========
         let mut console_pretty_layer = None;
         let mut console_compact_layer = None;
         let mut forward_layer = None;
         let mut export_layer = None;
@@ -206,19 +217,23 @@
             };
         };
 
         let meter_provider = if let Some(ref metrics) = opts.metrics {
             let aggregator = SDKAggSelector { metric_prefix };
             match metrics {
                 MetricsExporter::Prometheus(addr) => {
-                    let srv = PromServer::new(
-                        *addr,
-                        aggregator,
-                        metric_temporality_to_selector(opts.metric_temporality),
-                    )?;
+                    let srv = runtime.block_on(async {
+                        PromServer::new(
+                            *addr,
+                            aggregator,
+                            metric_temporality_to_selector(opts.metric_temporality),
+                            &opts.global_tags,
+                        )
+                    })?;
+                    prom_binding = Some(srv.bound_addr());
                     let mp = srv.exporter.meter_provider()?;
                     runtime.spawn(async move { srv.run().await });
                     Some(Box::new(mp) as Box<dyn MeterProvider + Send + Sync>)
                 }
                 MetricsExporter::Otel(OtelCollectorOptions {
                     url,
                     headers,
@@ -227,15 +242,15 @@
                     let metrics = opentelemetry_otlp::new_pipeline()
                         .metrics(
                             aggregator,
                             metric_temporality_to_selector(opts.metric_temporality),
                             runtime::Tokio,
                         )
                         .with_period(metric_periodicity.unwrap_or_else(|| Duration::from_secs(1)))
-                        .with_resource(default_resource())
+                        .with_resource(default_resource(&opts.global_tags))
                         .with_exporter(
                             opentelemetry_otlp::new_exporter()
                                 .tonic()
                                 .with_endpoint(url.to_string())
                                 .with_metadata(MetadataMap::from_headers(headers.try_into()?)),
                         )
                         .build()?;
@@ -248,15 +263,16 @@
             None
         };
 
         if let Some(ref tracing) = opts.tracing {
             match &tracing.exporter {
                 TraceExporter::Otel(OtelCollectorOptions { url, headers, .. }) => {
                     runtime.block_on(async {
-                        let tracer_cfg = Config::default().with_resource(default_resource());
+                        let tracer_cfg =
+                            Config::default().with_resource(default_resource(&opts.global_tags));
                         let tracer = opentelemetry_otlp::new_pipeline()
                             .tracing()
                             .with_exporter(
                                 opentelemetry_otlp::new_exporter()
                                     .tonic()
                                     .with_endpoint(url.to_string())
                                     .with_metadata(MetadataMap::from_headers(headers.try_into()?)),
@@ -282,14 +298,15 @@
             .with(export_layer);
 
         tx.send(TelemetryInstance::new(
             Arc::new(reg),
             logs_out,
             metric_prefix,
             meter_provider,
+            prom_binding,
             keepalive_rx,
         ))
         .expect("Must be able to send telem instance out of thread");
         // Now keep the thread alive until the telemetry instance is dropped by trying to send
         // something forever
         let _ = keepalive_tx.send(());
         Ok(())
@@ -319,16 +336,20 @@
     Ok(())
 }
 
 fn default_resource_kvs() -> &'static [KeyValue] {
     static INSTANCE: OnceCell<[KeyValue; 1]> = OnceCell::new();
     INSTANCE.get_or_init(|| [KeyValue::new("service.name", TELEM_SERVICE_NAME)])
 }
-fn default_resource() -> Resource {
-    Resource::new(default_resource_kvs().iter().cloned())
+
+fn default_resource(override_values: &HashMap<String, String>) -> Resource {
+    let override_kvs = override_values
+        .iter()
+        .map(|(k, v)| KeyValue::new(k.clone(), v.clone()));
+    Resource::new(default_resource_kvs().iter().cloned()).merge(&Resource::new(override_kvs))
 }
 
 fn metric_temporality_to_selector(
     t: MetricTemporality,
 ) -> impl TemporalitySelector + Send + Sync + Clone {
     match t {
         MetricTemporality::Cumulative => {
@@ -373,14 +394,15 @@
                 })
                 .build()
                 .unwrap(),
         )
         .unwrap();
     }
 }
+use crate::telemetry::metrics::TemporalMeter;
 #[cfg(test)]
 pub use test_initters::*;
 
 /// A trait for using [Display] on the contents of vecs, etc, which don't implement it.
 ///
 /// Dislike this, but, there doesn't seem to be a great alternative. Calling itertools format
 /// inline in an `event!` macro can panic because it gets evaluated twice somehow.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/telemetry/prometheus_server.rs`

 * *Files 15% similar despite different names*

```diff
@@ -1,58 +1,64 @@
 use crate::telemetry::default_resource;
 use hyper::{
     header::CONTENT_TYPE,
+    server::conn::AddrIncoming,
     service::{make_service_fn, service_fn},
     Body, Method, Request, Response, Server,
 };
-use opentelemetry::{
-    metrics::MetricsError,
-    sdk::{
-        export::metrics::{aggregation::TemporalitySelector, AggregatorSelector},
-        metrics::{controllers, processors},
-    },
+use opentelemetry::sdk::{
+    export::metrics::{aggregation::TemporalitySelector, AggregatorSelector},
+    metrics::{controllers, processors},
 };
 use opentelemetry_prometheus::{ExporterBuilder, PrometheusExporter};
 use prometheus::{Encoder, TextEncoder};
-use std::{convert::Infallible, net::SocketAddr, sync::Arc};
+use std::{collections::HashMap, convert::Infallible, net::SocketAddr, sync::Arc, time::Duration};
 
 /// Exposes prometheus metrics for scraping
 pub(super) struct PromServer {
-    addr: SocketAddr,
+    bound_addr: AddrIncoming,
     pub exporter: Arc<PrometheusExporter>,
 }
 
 impl PromServer {
     pub fn new(
         addr: SocketAddr,
         aggregation: impl AggregatorSelector + Send + Sync + 'static,
         temporality: impl TemporalitySelector + Send + Sync + 'static,
-    ) -> Result<Self, MetricsError> {
+        tags: &HashMap<String, String>,
+    ) -> Result<Self, anyhow::Error> {
         let controller =
             controllers::basic(processors::factory(aggregation, temporality).with_memory(true))
-                .with_resource(default_resource())
+                // Because Prom is pull-based, make this always refresh
+                .with_collect_period(Duration::from_secs(0))
+                .with_resource(default_resource(tags))
                 .build();
         let exporter = ExporterBuilder::new(controller).try_init()?;
+        let bound_addr = AddrIncoming::bind(&addr)?;
         Ok(Self {
             exporter: Arc::new(exporter),
-            addr,
+            bound_addr,
         })
     }
 
-    pub async fn run(&self) -> hyper::Result<()> {
+    pub async fn run(self) -> hyper::Result<()> {
         // Spin up hyper server to serve metrics for scraping. We use hyper since we already depend
         // on it via Tonic.
         let expclone = self.exporter.clone();
         let svc = make_service_fn(move |_conn| {
             let expclone = expclone.clone();
             async move { Ok::<_, Infallible>(service_fn(move |req| metrics_req(req, expclone.clone()))) }
         });
-        let server = Server::bind(&self.addr).serve(svc);
+        let server = Server::builder(self.bound_addr).serve(svc);
         server.await
     }
+
+    pub fn bound_addr(&self) -> SocketAddr {
+        self.bound_addr.local_addr()
+    }
 }
 
 /// Serves prometheus metrics in the expected format for scraping
 async fn metrics_req(
     req: Request<Body>,
     exporter: Arc<PrometheusExporter>,
 ) -> Result<Response<Body>, hyper::Error> {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/test_help/mod.rs`

 * *Files 3% similar despite different names*

```diff
@@ -10,14 +10,15 @@
         client::{
             mocks::mock_workflow_client, MockWorkerClient, WorkerClient, WorkflowTaskCompletion,
         },
         new_wft_poller,
     },
     TaskToken, Worker, WorkerConfig, WorkerConfigBuilder,
 };
+use async_trait::async_trait;
 use bimap::BiMap;
 use futures::{future::BoxFuture, stream, stream::BoxStream, FutureExt, Stream, StreamExt};
 use mockall::TimesRange;
 use parking_lot::RwLock;
 use std::{
     collections::{BTreeMap, HashMap, HashSet, VecDeque},
     ops::{Deref, DerefMut},
@@ -25,15 +26,18 @@
     sync::{
         atomic::{AtomicBool, Ordering},
         Arc,
     },
     task::{Context, Poll},
     time::Duration,
 };
-use temporal_sdk_core_api::Worker as WorkerTrait;
+use temporal_sdk_core_api::{
+    errors::{PollActivityError, PollWfError},
+    Worker as WorkerTrait,
+};
 use temporal_sdk_core_protos::{
     coresdk::{
         workflow_activation::WorkflowActivation,
         workflow_commands::workflow_command,
         workflow_completion::{self, workflow_activation_completion, WorkflowActivationCompletion},
     },
     temporal::api::{
@@ -48,15 +52,14 @@
 };
 use temporal_sdk_core_test_utils::TestWorker;
 use tokio::sync::{mpsc::unbounded_channel, Notify};
 use tokio_stream::wrappers::UnboundedReceiverStream;
 use tokio_util::sync::CancellationToken;
 
 pub const TEST_Q: &str = "q";
-pub static NO_MORE_WORK_ERROR_MSG: &str = "No more work to do";
 
 pub fn test_worker_cfg() -> WorkerConfigBuilder {
     let mut wcb = WorkerConfigBuilder::default();
     wcb.namespace("default")
         .task_queue(TEST_Q)
         .worker_build_id("test_bin_id")
         .ignore_evicts_on_shutdown(true)
@@ -144,14 +147,15 @@
     Worker::new_with_pollers(
         mocks.inputs.config,
         sticky_q,
         mocks.client,
         mocks.inputs.wft_stream,
         act_poller,
         MetricsContext::no_op(),
+        None,
         CancellationToken::new(),
     )
 }
 
 pub(crate) fn mock_sdk(poll_cfg: MockPollCfg) -> TestWorker {
     mock_sdk_cfg(poll_cfg, |_| {})
 }
@@ -297,15 +301,15 @@
                 if let Some(f) = t.delay_until {
                     f.await;
                 }
                 Some(Ok(t.resp))
             }
             .boxed()
         } else {
-            async { Some(Err(tonic::Status::cancelled(NO_MORE_WORK_ERROR_MSG))) }.boxed()
+            async { None }.boxed()
         }
     });
     Box::new(mock_poller) as BoxedPoller<T>
 }
 
 pub fn mock_poller<T>() -> MockPoller<T>
 where
@@ -371,14 +375,15 @@
     pub num_expected_fails: usize,
     pub num_expected_legacy_query_resps: usize,
     pub mock_client: MockWorkerClient,
     /// All calls to fail WFTs must match this predicate
     pub expect_fail_wft_matcher:
         Box<dyn Fn(&TaskToken, &WorkflowTaskFailedCause, &Option<Failure>) -> bool + Send>,
     pub completion_asserts: Option<Box<dyn Fn(&WorkflowTaskCompletion) + Send>>,
+    pub num_expected_completions: Option<TimesRange>,
     /// If being used with the Rust SDK, this is set true. It ensures pollers will not error out
     /// early with no work, since we cannot know the exact number of times polling will happen.
     /// Instead, they will just block forever.
     pub using_rust_sdk: bool,
     pub make_poll_stream_interminable: bool,
 }
 
@@ -392,14 +397,15 @@
             hists,
             enforce_correct_number_of_polls,
             num_expected_fails,
             num_expected_legacy_query_resps: 0,
             mock_client: mock_workflow_client(),
             expect_fail_wft_matcher: Box::new(|_, _, _| true),
             completion_asserts: None,
+            num_expected_completions: None,
             using_rust_sdk: false,
             make_poll_stream_interminable: false,
         }
     }
     pub fn from_resp_batches(
         wf_id: &str,
         t: TestHistoryBuilder,
@@ -414,14 +420,15 @@
             }],
             enforce_correct_number_of_polls: true,
             num_expected_fails: 0,
             num_expected_legacy_query_resps: 0,
             mock_client,
             expect_fail_wft_matcher: Box::new(|_, _, _| true),
             completion_asserts: None,
+            num_expected_completions: None,
             using_rust_sdk: false,
             make_poll_stream_interminable: false,
         }
     }
 }
 
 #[derive(Default, Clone)]
@@ -583,24 +590,28 @@
             all_work_was_completed: all_work_delivered,
         }
         .map(Ok)
         .boxed(),
     );
 
     let outstanding = outstanding_wf_task_tokens.clone();
-    cfg.mock_client
-        .expect_complete_workflow_task()
-        .returning(move |comp| {
-            if let Some(ass) = cfg.completion_asserts.as_ref() {
-                // tee hee
-                ass(&comp)
-            }
-            outstanding.release_token(&comp.task_token);
-            Ok(RespondWorkflowTaskCompletedResponse::default())
-        });
+    let expect_completes = cfg.mock_client.expect_complete_workflow_task();
+    if let Some(range) = cfg.num_expected_completions {
+        expect_completes.times(range);
+    } else if cfg.completion_asserts.is_some() {
+        expect_completes.times(1..);
+    }
+    expect_completes.returning(move |comp| {
+        if let Some(ass) = cfg.completion_asserts.as_ref() {
+            // tee hee
+            ass(&comp)
+        }
+        outstanding.release_token(&comp.task_token);
+        Ok(RespondWorkflowTaskCompletedResponse::default())
+    });
     let outstanding = outstanding_wf_task_tokens.clone();
     cfg.mock_client
         .expect_fail_workflow_task()
         .withf(cfg.expect_fail_wft_matcher)
         .times::<TimesRange>(cfg.num_expected_fails.into())
         .returning(move |tt, _, _| {
             outstanding.release_token(&tt);
@@ -838,14 +849,15 @@
     (
         asserter,
         workflow_completion::Failure {
             failure: Some(Failure {
                 message: "Intentional test failure".to_string(),
                 ..Default::default()
             }),
+            ..Default::default()
         }
         .into(),
     )
 }
 
 /// Generate asserts for [poll_and_reply] by passing patterns to match against the job list
 #[macro_export]
@@ -883,7 +895,47 @@
 macro_rules! prost_dur {
     ($dur_call:ident $args:tt) => {
         std::time::Duration::$dur_call$args
             .try_into()
             .expect("test duration fits")
     };
 }
+
+#[async_trait]
+pub(crate) trait WorkerExt {
+    /// Initiate shutdown, drain the pollers, and wait for shutdown to complete.
+    async fn drain_pollers_and_shutdown(self);
+    /// Initiate shutdown, drain the *activity* poller, and wait for shutdown to complete.
+    /// Takes a ref because of that one test that needs it.
+    async fn drain_activity_poller_and_shutdown(&self);
+}
+
+#[async_trait]
+impl WorkerExt for Worker {
+    async fn drain_pollers_and_shutdown(self) {
+        self.initiate_shutdown();
+        tokio::join!(
+            async {
+                assert_matches!(
+                    self.poll_activity_task().await.unwrap_err(),
+                    PollActivityError::ShutDown
+                );
+            },
+            async {
+                assert_matches!(
+                    self.poll_workflow_activation().await.unwrap_err(),
+                    PollWfError::ShutDown
+                );
+            }
+        );
+        self.finalize_shutdown().await;
+    }
+
+    async fn drain_activity_poller_and_shutdown(&self) {
+        self.initiate_shutdown();
+        assert_matches!(
+            self.poll_activity_task().await.unwrap_err(),
+            PollActivityError::ShutDown
+        );
+        self.shutdown().await;
+    }
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/activity_heartbeat_manager.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,8 +1,9 @@
 use crate::{
+    abstractions::take_cell::TakeCell,
     worker::{activities::PendingActivityCancel, client::WorkerClient},
     TaskToken,
 };
 use futures::StreamExt;
 use std::{
     collections::{hash_map::Entry, HashMap},
     sync::Arc,
@@ -13,29 +14,26 @@
     temporal::api::{
         common::v1::Payload, workflowservice::v1::RecordActivityTaskHeartbeatResponse,
     },
 };
 use tokio::{
     sync::{
         mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
-        Mutex, Notify,
+        Notify,
     },
     task::JoinHandle,
 };
 use tokio_util::sync::CancellationToken;
 
 /// Used to supply new heartbeat events to the activity heartbeat manager, or to send a shutdown
 /// request.
 pub(crate) struct ActivityHeartbeatManager {
-    /// Cancellations that have been received when heartbeating are queued here and can be consumed
-    /// by [fetch_cancellations]
-    incoming_cancels: Mutex<UnboundedReceiver<PendingActivityCancel>>,
     shutdown_token: CancellationToken,
     /// Used during `shutdown` to await until all inflight requests are sent.
-    join_handle: Mutex<Option<JoinHandle<()>>>,
+    join_handle: TakeCell<JoinHandle<()>>,
     heartbeat_tx: UnboundedSender<HeartbeatAction>,
 }
 
 #[derive(Debug)]
 enum HeartbeatAction {
     SendHeartbeat(ValidActivityHeartbeat),
     Evict {
@@ -70,38 +68,135 @@
     /// Heartbeat referenced an activity that we don't think exists. It may have completed already.
     #[error("Heartbeat has been sent for activity that either completed or never started on this worker.")]
     UnknownActivity,
     /// There was a set heartbeat timeout, but it was not parseable. A valid timeout is requried
     /// to heartbeat.
     #[error("Unable to parse activity heartbeat timeout.")]
     InvalidHeartbeatTimeout,
-    /// Core is shutting down and thus new heartbeats are not accepted
-    #[error("New heartbeat requests are not accepted while shutting down")]
-    ShuttingDown,
 }
 
 /// Manages activity heartbeating for a worker. Allows sending new heartbeats or requesting and
 /// awaiting for the shutdown. When shutdown is requested, signal gets sent to all processors, which
 /// allows them to complete gracefully.
 impl ActivityHeartbeatManager {
+    /// Creates a new instance of an activity heartbeat manager and returns a handle to the user,
+    /// which allows to send new heartbeats and initiate the shutdown.
+    /// Returns the manager and a channel that buffers cancellation notifications to be sent to Lang.
+    pub(super) fn new(
+        client: Arc<dyn WorkerClient>,
+        cancels_tx: UnboundedSender<PendingActivityCancel>,
+    ) -> Self {
+        let (heartbeat_stream_state, heartbeat_tx_source, shutdown_token) =
+            HeartbeatStreamState::new();
+        let heartbeat_tx = heartbeat_tx_source.clone();
+
+        let join_handle = tokio::spawn(
+            // The stream of incoming heartbeats uses unfold to carry state across each item in the
+            // stream. The closure checks if, for any given activity, we should heartbeat or not
+            // depending on its delay and when we last issued a heartbeat for it.
+            futures::stream::unfold(heartbeat_stream_state, move |mut hb_states| {
+                async move {
+                    let hb = tokio::select! {
+                        biased;
+
+                        _ = hb_states.cancellation_token.cancelled() => {
+                            return None
+                        }
+                        hb = hb_states.incoming_hbs.recv() => match hb {
+                            None => return None,
+                            Some(hb) => hb,
+                        }
+                    };
+
+                    Some((
+                        match hb {
+                            HeartbeatAction::SendHeartbeat(hb) => hb_states.record(hb),
+                            HeartbeatAction::CompleteReport(tt) => hb_states.handle_report_completed(tt),
+                            HeartbeatAction::CompleteThrottle(tt) => hb_states.handle_throttle_completed(tt),
+                            HeartbeatAction::Evict{ token, on_complete } => hb_states.evict(token, on_complete),
+                        },
+                        hb_states,
+                    ))
+                }
+            })
+                // Filters out `None`s
+                .filter_map(|opt| async { opt })
+                .for_each_concurrent(None, move |action| {
+                    let heartbeat_tx = heartbeat_tx_source.clone();
+                    let sg = client.clone();
+                    let cancels_tx = cancels_tx.clone();
+                    async move {
+                        match action {
+                            HeartbeatExecutorAction::Sleep(tt, duration, cancellation_token) => {
+                                tokio::select! {
+                                _ = cancellation_token.cancelled() => (),
+                                _ = tokio::time::sleep(duration) => {
+                                    let _ = heartbeat_tx.send(HeartbeatAction::CompleteThrottle(tt));
+                                },
+                            };
+                            }
+                            HeartbeatExecutorAction::Report { task_token: tt, details } => {
+                                match sg
+                                    .record_activity_heartbeat(tt.clone(), details.into_payloads())
+                                    .await
+                                {
+                                    Ok(RecordActivityTaskHeartbeatResponse { cancel_requested }) => {
+                                        if cancel_requested {
+                                            cancels_tx
+                                                .send(PendingActivityCancel::new(
+                                                    tt.clone(),
+                                                    ActivityCancelReason::Cancelled,
+                                                ))
+                                                .expect(
+                                                    "Receive half of heartbeat cancels not blocked",
+                                                );
+                                        }
+                                    }
+                                    // Send cancels for any activity that learns its workflow already
+                                    // finished (which is one thing not found implies - other reasons
+                                    // would seem equally valid).
+                                    Err(s) if s.code() == tonic::Code::NotFound => {
+                                        debug!(task_token = %tt,
+                                           "Activity not found when recording heartbeat");
+                                        cancels_tx
+                                            .send(PendingActivityCancel::new(
+                                                tt.clone(),
+                                                ActivityCancelReason::NotFound,
+                                            ))
+                                            .expect("Receive half of heartbeat cancels not blocked");
+                                    }
+                                    Err(e) => {
+                                        warn!("Error when recording heartbeat: {:?}", e);
+                                    }
+                                };
+                                let _ = heartbeat_tx.send(HeartbeatAction::CompleteReport(tt));
+                            }
+                        }
+                    }
+                }),
+        );
+
+        Self {
+            join_handle: TakeCell::new(join_handle),
+            shutdown_token,
+            heartbeat_tx,
+        }
+    }
     /// Records a new heartbeat, the first call will result in an immediate call to the server,
     /// while rapid successive calls would accumulate for up to `delay` and then latest heartbeat
     /// details will be sent to the server.
     ///
     /// It is important that this function is never called with a task token equal to one given
     /// to [Self::evict] after it has been called, doing so will cause a memory leak, as there is
     /// no longer an efficient way to forget about that task token.
     pub(super) fn record(
         &self,
         hb: ActivityHeartbeat,
         throttle_interval: Duration,
     ) -> Result<(), ActivityHeartbeatError> {
-        if self.shutdown_token.is_cancelled() {
-            return Err(ActivityHeartbeatError::ShuttingDown);
-        }
         self.heartbeat_tx
             .send(HeartbeatAction::SendHeartbeat(ValidActivityHeartbeat {
                 task_token: TaskToken(hb.task_token),
                 details: hb.details,
                 throttle_interval,
             }))
             .expect("Receive half of the heartbeats event channel must not be dropped");
@@ -117,27 +212,19 @@
         let _ = self.heartbeat_tx.send(HeartbeatAction::Evict {
             token: task_token,
             on_complete: completed.clone(),
         });
         completed.notified().await;
     }
 
-    /// Returns a future that resolves any time there is a new activity cancel that must be
-    /// dispatched to lang
-    pub(super) async fn next_pending_cancel(&self) -> Option<PendingActivityCancel> {
-        self.incoming_cancels.lock().await.recv().await
-    }
-
-    // TODO: Can own self now!
     /// Initiates shutdown procedure by stopping lifecycle loop and awaiting for all in-flight
     /// heartbeat requests to be flushed to the server.
     pub(super) async fn shutdown(&self) {
         self.shutdown_token.cancel();
-        let mut handle = self.join_handle.lock().await;
-        if let Some(h) = handle.take() {
+        if let Some(h) = self.join_handle.take_once() {
             let handle_r = h.await;
             if let Err(e) = handle_r {
                 if !e.is_cancelled() {
                     error!(
                         "Unexpected error joining heartbeating tasks during shutdown: {:?}",
                         e
                     )
@@ -297,118 +384,14 @@
         }
         // Since there's nothing to flush immediately report back that eviction is finished
         on_complete.notify_one();
         None
     }
 }
 
-impl ActivityHeartbeatManager {
-    /// Creates a new instance of an activity heartbeat manager and returns a handle to the user,
-    /// which allows to send new heartbeats and initiate the shutdown.
-    pub fn new(client: Arc<dyn WorkerClient>) -> Self {
-        let (heartbeat_stream_state, heartbeat_tx_source, shutdown_token) =
-            HeartbeatStreamState::new();
-        let (cancels_tx, cancels_rx) = unbounded_channel();
-        let heartbeat_tx = heartbeat_tx_source.clone();
-
-        let join_handle = tokio::spawn(
-            // The stream of incoming heartbeats uses unfold to carry state across each item in the
-            // stream. The closure checks if, for any given activity, we should heartbeat or not
-            // depending on its delay and when we last issued a heartbeat for it.
-            futures::stream::unfold(heartbeat_stream_state, move |mut hb_states| {
-                async move {
-                    let hb = tokio::select! {
-                        biased;
-
-                        _ = hb_states.cancellation_token.cancelled() => {
-                            return None
-                        }
-                        hb = hb_states.incoming_hbs.recv() => match hb {
-                            None => return None,
-                            Some(hb) => hb,
-                        }
-                    };
-
-                    Some((
-                        match hb {
-                            HeartbeatAction::SendHeartbeat(hb) => hb_states.record(hb),
-                            HeartbeatAction::CompleteReport(tt) => hb_states.handle_report_completed(tt),
-                            HeartbeatAction::CompleteThrottle(tt) => hb_states.handle_throttle_completed(tt),
-                            HeartbeatAction::Evict{ token, on_complete } => hb_states.evict(token, on_complete),
-                        },
-                        hb_states,
-                    ))
-                }
-            })
-            // Filters out `None`s
-            .filter_map(|opt| async { opt })
-            .for_each_concurrent(None, move |action| {
-                let heartbeat_tx = heartbeat_tx_source.clone();
-                let sg = client.clone();
-                let cancels_tx = cancels_tx.clone();
-                async move {
-                    match action {
-                        HeartbeatExecutorAction::Sleep(tt, duration, cancellation_token) => {
-                            tokio::select! {
-                                _ = cancellation_token.cancelled() => (),
-                                _ = tokio::time::sleep(duration) => {
-                                    let _ = heartbeat_tx.send(HeartbeatAction::CompleteThrottle(tt));
-                                },
-                            };
-                        }
-                        HeartbeatExecutorAction::Report { task_token: tt, details } => {
-                            match sg
-                                .record_activity_heartbeat(tt.clone(), details.into_payloads())
-                                .await
-                            {
-                                Ok(RecordActivityTaskHeartbeatResponse { cancel_requested }) => {
-                                    if cancel_requested {
-                                        cancels_tx
-                                            .send(PendingActivityCancel::new(
-                                                tt.clone(),
-                                                ActivityCancelReason::Cancelled,
-                                            ))
-                                            .expect(
-                                                "Receive half of heartbeat cancels not blocked",
-                                            );
-                                    }
-                                }
-                                // Send cancels for any activity that learns its workflow already
-                                // finished (which is one thing not found implies - other reasons
-                                // would seem equally valid).
-                                Err(s) if s.code() == tonic::Code::NotFound => {
-                                    debug!(task_token = %tt,
-                                           "Activity not found when recording heartbeat");
-                                    cancels_tx
-                                        .send(PendingActivityCancel::new(
-                                            tt.clone(),
-                                            ActivityCancelReason::NotFound,
-                                        ))
-                                        .expect("Receive half of heartbeat cancels not blocked");
-                                }
-                                Err(e) => {
-                                    warn!("Error when recording heartbeat: {:?}", e);
-                                }
-                            };
-                            let _ = heartbeat_tx.send(HeartbeatAction::CompleteReport(tt));
-                        }
-                    }
-                }
-            }),
-        );
-
-        Self {
-            incoming_cancels: Mutex::new(cancels_rx),
-            join_handle: Mutex::new(Some(join_handle)),
-            shutdown_token,
-            heartbeat_tx,
-        }
-    }
-}
-
 #[cfg(test)]
 mod test {
     use super::*;
 
     use crate::worker::client::mocks::mock_workflow_client;
     use std::time::Duration;
     use temporal_sdk_core_protos::temporal::api::{
@@ -421,15 +404,16 @@
     #[tokio::test]
     async fn process_heartbeats_and_shutdown() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(2);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         // Send 2 heartbeat requests for 20ms apart.
         // The first heartbeat should be sent right away, and
         // the second should be throttled until 50ms have passed.
         for i in 0_u8..2 {
             record_heartbeat(&hm, fake_task_token.clone(), i, Duration::from_millis(50));
             sleep(Duration::from_millis(20)).await;
@@ -442,35 +426,36 @@
     #[tokio::test]
     async fn send_heartbeats_less_frequently_than_throttle_interval() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(3);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         // Heartbeats always get sent if recorded less frequently than the throttle interval
         for i in 0_u8..3 {
             record_heartbeat(&hm, fake_task_token.clone(), i, Duration::from_millis(10));
             sleep(Duration::from_millis(20)).await;
         }
-        // sleep again to let heartbeats be flushed
         hm.shutdown().await;
     }
 
     /// Ensure that heartbeat can be called from a tight loop without any throttle_interval, resulting in two
     /// interactions with the server - one immediately and one after 500ms after the throttle_interval.
     #[tokio::test]
     async fn process_tight_loop_and_shutdown() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(1);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         // Send a whole bunch of heartbeats very fast. We should still only send one total.
         for i in 0_u8..50 {
             record_heartbeat(&hm, fake_task_token.clone(), i, Duration::from_millis(2000));
             // Let it propagate
             sleep(Duration::from_millis(10)).await;
         }
@@ -481,15 +466,16 @@
     #[tokio::test]
     async fn report_heartbeat_after_timeout() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(2);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         record_heartbeat(&hm, fake_task_token.clone(), 0, Duration::from_millis(100));
         sleep(Duration::from_millis(500)).await;
         record_heartbeat(&hm, fake_task_token, 1, Duration::from_millis(100));
         // Let it propagate
         sleep(Duration::from_millis(50)).await;
         hm.shutdown().await;
@@ -498,15 +484,16 @@
     #[tokio::test]
     async fn evict_works() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(2);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         record_heartbeat(&hm, fake_task_token.clone(), 0, Duration::from_millis(100));
         // Let it propagate
         sleep(Duration::from_millis(10)).await;
         hm.evict(fake_task_token.clone().into()).await;
         record_heartbeat(&hm, fake_task_token, 0, Duration::from_millis(100));
         // Let it propagate
@@ -518,50 +505,22 @@
     #[tokio::test]
     async fn evict_immediate_after_record() {
         let mut mock_client = mock_workflow_client();
         mock_client
             .expect_record_activity_heartbeat()
             .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
             .times(1);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
+        let (cancel_tx, _cancel_rx) = unbounded_channel();
+        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client), cancel_tx);
         let fake_task_token = vec![1, 2, 3];
         record_heartbeat(&hm, fake_task_token.clone(), 0, Duration::from_millis(100));
         hm.evict(fake_task_token.clone().into()).await;
         hm.shutdown().await;
     }
 
-    /// Recording new heartbeats after shutdown is not allowed, and will result in error.
-    #[tokio::test]
-    async fn record_after_shutdown() {
-        let mut mock_client = mock_workflow_client();
-        mock_client
-            .expect_record_activity_heartbeat()
-            .returning(|_, _| Ok(RecordActivityTaskHeartbeatResponse::default()))
-            .times(0);
-        let hm = ActivityHeartbeatManager::new(Arc::new(mock_client));
-        hm.shutdown().await;
-        match hm.record(
-            ActivityHeartbeat {
-                task_token: vec![1, 2, 3],
-                details: vec![Payload {
-                    // payload doesn't matter in this case, as it shouldn't get sent anyways.
-                    ..Default::default()
-                }],
-            },
-            Duration::from_millis(1000),
-        ) {
-            Ok(_) => {
-                unreachable!("heartbeat should not be recorded after the shutdown");
-            }
-            Err(e) => {
-                matches!(e, ActivityHeartbeatError::ShuttingDown);
-            }
-        }
-    }
-
     fn record_heartbeat(
         hm: &ActivityHeartbeatManager,
         task_token: Vec<u8>,
         payload_data: u8,
         throttle_interval: Duration,
     ) {
         hm.record(
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities/local_activities.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,34 @@
 use crate::{
-    abstractions::{dbg_panic, MeteredSemaphore, OwnedMeteredSemPermit},
+    abstractions::{dbg_panic, MeteredSemaphore, OwnedMeteredSemPermit, UsedMeteredSemPermit},
     protosext::ValidScheduleLA,
     retry_logic::RetryPolicyExt,
+    worker::workflow::HeartbeatTimeoutMsg,
     MetricsContext, TaskToken,
 };
 use futures::{stream::BoxStream, Stream};
-use futures_util::{stream, StreamExt};
+use futures_util::{future, future::AbortRegistration, stream, StreamExt};
 use parking_lot::{Mutex, MutexGuard};
 use std::{
     collections::{hash_map::Entry, HashMap},
     fmt::{Debug, Formatter},
     pin::Pin,
     task::{Context, Poll},
     time::{Duration, Instant, SystemTime},
 };
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{Cancellation, Failure as ActFail, Success},
         activity_task::{activity_task, ActivityCancelReason, ActivityTask, Cancel, Start},
     },
-    temporal::api::{common::v1::WorkflowExecution, enums::v1::TimeoutType},
+    temporal::api::{
+        common::v1::WorkflowExecution,
+        enums::v1::TimeoutType,
+        failure::v1::{failure, Failure as APIFailure, TimeoutFailureInfo},
+    },
 };
 use tokio::{
     sync::{
         mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
         Notify,
     },
     task::JoinHandle,
@@ -46,34 +51,53 @@
 }
 
 #[derive(Debug)]
 pub(crate) struct LocalInFlightActInfo {
     pub la_info: NewLocalAct,
     pub dispatch_time: Instant,
     pub attempt: u32,
-    _permit: OwnedMeteredSemPermit,
+    _permit: UsedMeteredSemPermit,
 }
 
 #[derive(Debug, Clone)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 pub(crate) enum LocalActivityExecutionResult {
     Completed(Success),
     Failed(ActFail),
     TimedOut(ActFail),
     Cancelled(Cancellation),
 }
 impl LocalActivityExecutionResult {
     pub(crate) fn empty_cancel() -> Self {
         Self::Cancelled(Cancellation::from_details(None))
     }
     pub(crate) fn timeout(tt: TimeoutType) -> Self {
-        Self::TimedOut(ActFail::timeout(tt))
+        Self::TimedOut(ActFail {
+            failure: Some(APIFailure {
+                message: "Activity timed out".to_string(),
+                failure_info: Some(failure::FailureInfo::TimeoutFailureInfo(
+                    TimeoutFailureInfo {
+                        timeout_type: tt as i32,
+                        last_heartbeat_details: None,
+                    },
+                )),
+                ..Default::default()
+            }),
+        })
     }
 }
 
 #[derive(Debug, Clone)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 pub(crate) struct LocalActivityResolution {
     pub seq: u32,
     pub result: LocalActivityExecutionResult,
     pub runtime: Duration,
     pub attempt: u32,
     pub backoff: Option<prost_types::Duration>,
     pub original_schedule_time: Option<SystemTime>,
@@ -97,15 +121,25 @@
 }
 
 #[derive(Debug, derive_more::From)]
 #[allow(clippy::large_enum_variant)]
 pub(crate) enum LocalActRequest {
     New(NewLocalAct),
     Cancel(ExecutingLAId),
+    #[from(ignore)]
     CancelAllInRun(String),
+    StartHeartbeatTimeout {
+        send_on_elapse: HeartbeatTimeoutMsg,
+        deadline: Instant,
+        abort_reg: AbortRegistration,
+    },
+    /// Tell the LA manager that a workflow task was responded to (completed or failed) for a
+    /// certain run id
+    #[from(ignore)]
+    IndicateWorkflowTaskCompleted(String),
 }
 
 #[derive(Debug, Clone, Eq, PartialEq, Hash)]
 pub(crate) struct ExecutingLAId {
     pub run_id: String,
     pub seq_num: u32,
 }
@@ -113,14 +147,18 @@
 pub(crate) struct LocalActivityManager {
     /// Just so we can provide activity tasks the same namespace as the worker
     namespace: String,
     /// Sink for new activity execution requests
     act_req_tx: UnboundedSender<NewOrRetry>,
     /// Cancels need a different queue since they should be taken first, and don't take a permit
     cancels_req_tx: UnboundedSender<CancelOrTimeout>,
+    /// For the emission of heartbeat timeouts, back into the workflow machines. This channel
+    /// needs to come in from above us, because we cannot rely on callers getting the next
+    /// activation as a way to deliver heartbeats.
+    heartbeat_timeout_tx: UnboundedSender<HeartbeatTimeoutMsg>,
     /// Wakes every time a complete is processed
     complete_notify: Notify,
     /// Set once workflows have finished shutting down, and thus we know we will no longer receive
     /// any requests to spawn new LAs
     workflows_have_shut_down: CancellationToken,
 
     rcvs: tokio::sync::Mutex<RcvChans>,
@@ -131,14 +169,18 @@
 struct LocalActivityInfo {
     task_token: TaskToken,
     /// Tasks for the current backoff until the next retry, if any.
     backing_off_task: Option<JoinHandle<()>>,
     /// Tasks / info about timeouts associated with this LA. May be empty for very brief periods
     /// while the LA id has been generated, but it has not yet been scheduled.
     timeout_bag: Option<TimeoutBag>,
+    /// True once the first workflow task this LA started in has elapsed
+    first_wft_has_ended: bool,
+    /// Attempts at executing this LA during the current WFT
+    attempts_in_wft: usize,
 }
 
 struct LAMData {
     /// Maps local activity identifiers to information about them
     la_info: HashMap<ExecutingLAId, LocalActivityInfo>,
     /// Activities that have been issued to lang but not yet completed
     outstanding_activity_tasks: HashMap<TaskToken, LocalInFlightActInfo>,
@@ -152,14 +194,15 @@
     }
 }
 
 impl LocalActivityManager {
     pub(crate) fn new(
         max_concurrent: usize,
         namespace: String,
+        heartbeat_timeout_tx: UnboundedSender<HeartbeatTimeoutMsg>,
         metrics_context: MetricsContext,
     ) -> Self {
         let (act_req_tx, act_req_rx) = unbounded_channel();
         let (cancels_req_tx, cancels_req_rx) = unbounded_channel();
         let shutdown_complete_tok = CancellationToken::new();
         let semaphore = MeteredSemaphore::new(
             max_concurrent,
@@ -172,30 +215,33 @@
                 act_req_rx,
                 semaphore,
                 cancels_req_rx,
                 shutdown_complete_tok.clone(),
             )),
             act_req_tx,
             cancels_req_tx,
+            heartbeat_timeout_tx,
             complete_notify: Notify::new(),
             shutdown_complete_tok,
             dat: Mutex::new(LAMData {
                 outstanding_activity_tasks: Default::default(),
                 la_info: Default::default(),
                 next_tt_num: 0,
             }),
             workflows_have_shut_down: Default::default(),
         }
     }
 
     #[cfg(test)]
     fn test(max_concurrent: usize) -> Self {
+        let (hb_tx, _hb_rx) = unbounded_channel();
         Self::new(
             max_concurrent,
             "fake_ns".to_string(),
+            hb_tx,
             MetricsContext::no_op(),
         )
     }
 
     #[cfg(test)]
     pub(crate) fn num_outstanding(&self) -> usize {
         self.dat.lock().outstanding_activity_tasks.len()
@@ -217,17 +263,17 @@
     ) -> Vec<LocalActivityResolution> {
         if self.workflows_have_shut_down.is_cancelled() {
             dbg_panic!("Tried to enqueue local activity after workflows were shut down");
             return vec![];
         }
         let mut immediate_resolutions = vec![];
         for req in reqs {
-            debug!(local_activity = ?req, "Queuing local activity");
             match req {
                 LocalActRequest::New(act) => {
+                    debug!(local_activity=?act, "Queuing local activity");
                     let id = ExecutingLAId {
                         run_id: act.workflow_exec_info.run_id.clone(),
                         seq_num: act.schedule_cmd.seq,
                     };
                     let mut dlock = self.dat.lock();
                     let tt = dlock.gen_next_token();
                     match dlock.la_info.entry(id) {
@@ -244,14 +290,16 @@
                             // Insert the task token now, before we may or may not dispatch the
                             // activity, so we can enforce idempotency. Prevents two identical LAs
                             // ending up in the queue at once.
                             let lai = ve.insert(LocalActivityInfo {
                                 task_token: tt,
                                 backing_off_task: None,
                                 timeout_bag: None,
+                                first_wft_has_ended: false,
+                                attempts_in_wft: 0,
                             });
 
                             // Set up timeouts for the new activity
                             match TimeoutBag::new(&act, self.cancels_req_tx.clone()) {
                                 Ok(tb) => {
                                     lai.timeout_bag = Some(tb);
 
@@ -260,36 +308,63 @@
                                     );
                                 }
                                 Err(res) => immediate_resolutions.push(res),
                             }
                         }
                     }
                 }
+                LocalActRequest::StartHeartbeatTimeout {
+                    send_on_elapse,
+                    deadline,
+                    abort_reg,
+                } => {
+                    let chan = self.heartbeat_timeout_tx.clone();
+                    tokio::spawn(future::Abortable::new(
+                        async move {
+                            tokio::time::sleep_until(deadline.into()).await;
+                            let _ = chan.send(send_on_elapse);
+                        },
+                        abort_reg,
+                    ));
+                }
                 LocalActRequest::Cancel(id) => {
+                    debug!(id=?id, "Cancelling local activity");
                     let mut dlock = self.dat.lock();
                     if let Some(lai) = dlock.la_info.get_mut(&id) {
                         if let Some(immediate_res) = self.cancel_one_la(id.seq_num, lai) {
                             immediate_resolutions.push(immediate_res);
                         }
                     }
                 }
                 LocalActRequest::CancelAllInRun(run_id) => {
+                    debug!(run_id=%run_id, "Cancelling all local activities for run");
                     let mut dlock = self.dat.lock();
                     // Even if we've got 100k+ LAs this should only take a ms or two. Not worth
                     // adding another map to keep in sync.
                     let las_for_run = dlock
                         .la_info
                         .iter_mut()
                         .filter(|(id, _)| id.run_id == run_id);
                     for (laid, lainf) in las_for_run {
                         if let Some(immediate_res) = self.cancel_one_la(laid.seq_num, lainf) {
                             immediate_resolutions.push(immediate_res);
                         }
                     }
                 }
+                LocalActRequest::IndicateWorkflowTaskCompleted(run_id) => {
+                    let mut dlock = self.dat.lock();
+                    let las_for_run = dlock
+                        .la_info
+                        .iter_mut()
+                        .filter(|(id, _)| id.run_id == run_id);
+                    for (_, lainf) in las_for_run {
+                        lainf.first_wft_has_ended = true;
+                        lainf.attempts_in_wft = 0;
+                    }
+                }
             }
         }
         immediate_resolutions
     }
 
     /// Returns the next pending local-activity related action, or None if shutdown has initiated
     /// and there are no more remaining actions to take.
@@ -390,15 +465,15 @@
         }
         dat.outstanding_activity_tasks.insert(
             tt.clone(),
             LocalInFlightActInfo {
                 la_info: la_info_for_in_flight_map,
                 dispatch_time: Instant::now(),
                 attempt,
-                _permit: permit,
+                _permit: permit.into_used(),
             },
         );
 
         let (schedule_to_close, start_to_close) = sa.close_timeouts.into_sched_and_start();
         Some(DispatchOrTimeoutLA::Dispatch(ActivityTask {
             task_token: tt.0,
             variant: Some(activity_task::Variant::Start(Start {
@@ -496,14 +571,22 @@
                                 .expect("Receive half of LA request channel cannot be dropped");
                         });
                         dlock.la_info.insert(
                             exec_id,
                             LocalActivityInfo {
                                 task_token: tt,
                                 backing_off_task: Some(jh),
+                                first_wft_has_ended: maybe_old_lai
+                                    .as_ref()
+                                    .map(|old| old.first_wft_has_ended)
+                                    .unwrap_or_default(),
+                                attempts_in_wft: maybe_old_lai
+                                    .as_ref()
+                                    .map(|old| old.attempts_in_wft + 1)
+                                    .unwrap_or(1),
                                 timeout_bag: maybe_old_lai.and_then(|old| old.timeout_bag),
                             },
                         );
 
                         LACompleteAction::WillBeRetried
                     } else {
                         LACompleteAction::Report(info)
@@ -522,17 +605,34 @@
 
     pub(crate) async fn wait_all_outstanding_tasks_finished(&self) {
         while !self.set_shutdown_complete_if_ready(&mut self.dat.lock()) {
             self.complete_notify.notified().await;
         }
     }
 
+    /// Try to close the activity stream as soon as worker shutdown is initiated. This is required
+    /// for activity-only workers where since workflows are not polled and the activity poller might
+    /// get "stuck".
+    pub(crate) fn shutdown_initiated(&self) {
+        self.set_shutdown_complete_if_ready(&mut self.dat.lock());
+    }
+
+    pub(crate) fn get_nonfirst_attempt_count(&self, for_run_id: &str) -> usize {
+        let dlock = self.dat.lock();
+        dlock
+            .la_info
+            .iter()
+            .filter(|(id, info)| id.run_id == for_run_id && info.first_wft_has_ended)
+            .map(|(_, info)| info.attempts_in_wft)
+            .sum()
+    }
+
     fn set_shutdown_complete_if_ready(&self, dlock: &mut MutexGuard<LAMData>) -> bool {
         let nothing_outstanding = dlock.outstanding_activity_tasks.is_empty();
-        if nothing_outstanding {
+        if nothing_outstanding && self.workflows_have_shut_down.is_cancelled() {
             self.shutdown_complete_tok.cancel();
         }
         nothing_outstanding
     }
 
     fn cancel_one_la(
         &self,
@@ -748,16 +848,16 @@
     };
     use tokio::task::yield_now;
 
     impl DispatchOrTimeoutLA {
         fn unwrap(self) -> ActivityTask {
             match self {
                 DispatchOrTimeoutLA::Dispatch(t) => t,
-                DispatchOrTimeoutLA::Timeout { .. } => {
-                    panic!("Timeout returned when expected a task")
+                _ => {
+                    panic!("Non-dispatched action returned")
                 }
             }
         }
     }
 
     #[tokio::test]
     async fn max_concurrent_respected() {
@@ -1132,8 +1232,62 @@
 
         // Verify that if we now enqueue the same act again, after the task is outstanding, we still
         // don't add it.
         lam.enqueue([new_la.into()]);
         assert_eq!(lam.num_outstanding(), 1);
         assert!(lam.rcvs.lock().await.next().now_or_never().is_none());
     }
+
+    #[tokio::test]
+    async fn nonfirst_la_attempt_count_is_accurate() {
+        let run_id = "run_id";
+        let lam = LocalActivityManager::test(10);
+        let new_la = NewLocalAct {
+            schedule_cmd: ValidScheduleLA {
+                seq: 1,
+                activity_id: 1.to_string(),
+                retry_policy: RetryPolicy {
+                    initial_interval: Some(prost_dur!(from_millis(1))),
+                    backoff_coefficient: 1.0,
+                    ..Default::default()
+                },
+                local_retry_threshold: Duration::from_secs(500),
+                ..Default::default()
+            },
+            workflow_type: "".to_string(),
+            workflow_exec_info: WorkflowExecution {
+                workflow_id: "".to_string(),
+                run_id: run_id.to_string(),
+            },
+            schedule_time: SystemTime::now(),
+        };
+        lam.enqueue([new_la.clone().into()]);
+        let spinfail = || async {
+            for _ in 1..=10 {
+                let next = lam.next_pending().await.unwrap().unwrap();
+                let tt = TaskToken(next.task_token);
+                lam.complete(
+                    &tt,
+                    &LocalActivityExecutionResult::Failed(Default::default()),
+                );
+            }
+        };
+
+        // Fail a bunch of times
+        spinfail().await;
+        // Nonfirst attempt count should still be zero
+        let count = lam.get_nonfirst_attempt_count(run_id);
+        assert_eq!(count, 0);
+
+        for _ in 1..=2 {
+            // This should work over multiple WFTs
+            // say the first wft was completed
+            lam.enqueue([LocalActRequest::IndicateWorkflowTaskCompleted(
+                run_id.to_string(),
+            )]);
+            // Do some more attempts
+            spinfail().await;
+            let count = lam.get_nonfirst_attempt_count(run_id);
+            assert_eq!(count, 10);
+        }
+    }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,481 +1,692 @@
-mod activity_heartbeat_manager;
-mod local_activities;
-
-pub(crate) use local_activities::{
-    DispatchOrTimeoutLA, ExecutingLAId, LACompleteAction, LocalActRequest,
-    LocalActivityExecutionResult, LocalActivityManager, LocalActivityResolution,
-    LocalInFlightActInfo, NewLocalAct,
+mod activities;
+pub(crate) mod client;
+mod workflow;
+
+pub use temporal_sdk_core_api::worker::{WorkerConfig, WorkerConfigBuilder};
+#[cfg(feature = "save_wf_inputs")]
+pub use workflow::replay_wf_state_inputs;
+
+pub(crate) use activities::{
+    ExecutingLAId, LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
+    NewLocalAct,
 };
+#[cfg(test)]
+pub(crate) use workflow::ManagedWFFunc;
+pub(crate) use workflow::{wft_poller::new_wft_poller, LEGACY_QUERY_ID};
 
-use crate::telemetry::metrics::eager;
 use crate::{
-    abstractions::{MeteredSemaphore, OwnedMeteredSemPermit},
-    pollers::BoxedActPoller,
-    telemetry::metrics::{activity_type, activity_worker_type, workflow_type, MetricsContext},
+    errors::CompleteWfError,
+    pollers::{
+        new_activity_task_buffer, new_workflow_task_buffer, BoxedActPoller, Poller,
+        WorkflowTaskPoller,
+    },
+    protosext::{validate_activity_completion, ValidPollWFTQResponse},
+    telemetry::{
+        metrics::{
+            activity_poller, local_activity_worker_type, workflow_poller, workflow_sticky_poller,
+            MetricsContext,
+        },
+        TelemetryInstance,
+    },
     worker::{
-        activities::activity_heartbeat_manager::ActivityHeartbeatError, client::WorkerClient,
+        activities::{DispatchOrTimeoutLA, LACompleteAction, LocalActivityManager},
+        client::WorkerClient,
+        workflow::{LAReqSink, LocalResolution, WorkflowBasics, Workflows},
     },
-    PollActivityError, TaskToken,
-};
-use activity_heartbeat_manager::ActivityHeartbeatManager;
-use dashmap::DashMap;
-use governor::{
-    clock::DefaultClock,
-    middleware::NoOpMiddleware,
-    state::{InMemoryState, NotKeyed},
-    Quota, RateLimiter,
+    ActivityHeartbeat, CompleteActivityError, PollActivityError, PollWfError, WorkerTrait,
 };
+use activities::{LocalInFlightActInfo, WorkerActivityTasks};
+use futures::Stream;
 use std::{
     convert::TryInto,
-    sync::Arc,
-    time::{Duration, Instant},
+    future,
+    sync::{
+        atomic::{AtomicBool, Ordering},
+        Arc,
+    },
 };
 use temporal_sdk_core_protos::{
     coresdk::{
-        activity_result::{self as ar, activity_execution_result as aer},
-        activity_task::{ActivityCancelReason, ActivityTask},
-        ActivityHeartbeat,
+        activity_result::activity_execution_result,
+        activity_task::ActivityTask,
+        workflow_activation::{remove_from_cache::EvictionReason, WorkflowActivation},
+        workflow_completion::WorkflowActivationCompletion,
+        ActivityTaskCompletion,
     },
     temporal::api::{
-        failure::v1::{failure::FailureInfo, CanceledFailureInfo, Failure},
-        workflowservice::v1::PollActivityTaskQueueResponse,
+        enums::v1::TaskQueueKind,
+        taskqueue::v1::{StickyExecutionAttributes, TaskQueue},
+        workflowservice::v1::{get_system_info_response, PollActivityTaskQueueResponse},
     },
+    TaskToken,
 };
-use tokio::sync::Notify;
-use tracing::Span;
+use tokio::sync::mpsc::unbounded_channel;
+use tokio_util::sync::CancellationToken;
 
-#[derive(Debug, derive_more::Constructor)]
-struct PendingActivityCancel {
-    task_token: TaskToken,
-    reason: ActivityCancelReason,
-}
+/// A worker polls on a certain task queue
+pub struct Worker {
+    config: WorkerConfig,
+    wf_client: Arc<dyn WorkerClient>,
+
+    /// Manages all workflows and WFT processing
+    workflows: Workflows,
+    /// Manages activity tasks for this worker/task queue
+    at_task_mgr: Option<WorkerActivityTasks>,
+    /// Manages local activities
+    local_act_mgr: Arc<LocalActivityManager>,
+    /// Has shutdown been called?
+    shutdown_token: CancellationToken,
+    /// Will be called at the end of each activation completion
+    #[allow(clippy::type_complexity)] // Sorry clippy, there's no simple way to re-use here.
+    post_activate_hook: Option<Box<dyn Fn(&Self, PostActivateHookData) + Send + Sync>>,
+    /// Set when non-local activities are complete and should stop being polled
+    non_local_activities_complete: Arc<AtomicBool>,
+    /// Set when local activities are complete and should stop being polled
+    local_activities_complete: Arc<AtomicBool>,
+}
+
+#[async_trait::async_trait]
+impl WorkerTrait for Worker {
+    async fn poll_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
+        self.next_workflow_activation().await
+    }
+
+    #[instrument(skip(self))]
+    async fn poll_activity_task(&self) -> Result<ActivityTask, PollActivityError> {
+        loop {
+            match self.activity_poll().await.transpose() {
+                Some(r) => break r,
+                None => {
+                    tokio::task::yield_now().await;
+                    continue;
+                }
+            }
+        }
+    }
 
-/// Contains details that core wants to store while an activity is running.
-#[derive(Debug)]
-struct InFlightActInfo {
-    pub activity_type: String,
-    pub workflow_type: String,
-    /// Only kept for logging reasons
-    pub workflow_id: String,
-    /// Only kept for logging reasons
-    pub workflow_run_id: String,
-    start_time: Instant,
-}
+    async fn complete_workflow_activation(
+        &self,
+        completion: WorkflowActivationCompletion,
+    ) -> Result<(), CompleteWfError> {
+        self.complete_workflow_activation(completion).await
+    }
 
-/// Augments [InFlightActInfo] with details specific to remote activities
-struct RemoteInFlightActInfo {
-    pub base: InFlightActInfo,
-    /// Used to calculate aggregation delay between activity heartbeats.
-    pub heartbeat_timeout: Option<prost_types::Duration>,
-    /// Set to true if we have already issued a cancellation activation to lang for this activity
-    pub issued_cancel_to_lang: bool,
-    /// Set to true if we have already learned from the server this activity doesn't exist. EX:
-    /// we have learned from heartbeating and issued a cancel task, in which case we may simply
-    /// discard the reply.
-    pub known_not_found: bool,
-    /// The permit from the max concurrent semaphore
-    _permit: OwnedMeteredSemPermit,
-}
-impl RemoteInFlightActInfo {
-    fn new(poll_resp: &PollActivityTaskQueueResponse, permit: OwnedMeteredSemPermit) -> Self {
-        let wec = poll_resp.workflow_execution.clone().unwrap_or_default();
-        Self {
-            base: InFlightActInfo {
-                activity_type: poll_resp.activity_type.clone().unwrap_or_default().name,
-                workflow_type: poll_resp.workflow_type.clone().unwrap_or_default().name,
-                workflow_id: wec.workflow_id,
-                workflow_run_id: wec.run_id,
-                start_time: Instant::now(),
-            },
-            heartbeat_timeout: poll_resp.heartbeat_timeout.clone(),
-            issued_cancel_to_lang: false,
-            known_not_found: false,
-            _permit: permit,
-        }
+    async fn complete_activity_task(
+        &self,
+        completion: ActivityTaskCompletion,
+    ) -> Result<(), CompleteActivityError> {
+        let task_token = TaskToken(completion.task_token);
+        let status = if let Some(s) = completion.result.and_then(|r| r.status) {
+            s
+        } else {
+            return Err(CompleteActivityError::MalformedActivityCompletion {
+                reason: "Activity completion had empty result/status field".to_owned(),
+                completion: None,
+            });
+        };
+
+        self.complete_activity(task_token, status).await
     }
-}
 
-struct NonPollActBuffer {
-    tx: async_channel::Sender<PermittedTqResp>,
-    rx: async_channel::Receiver<PermittedTqResp>,
-}
-impl NonPollActBuffer {
-    pub fn new() -> Self {
-        let (tx, rx) = async_channel::unbounded();
-        Self { tx, rx }
+    fn record_activity_heartbeat(&self, details: ActivityHeartbeat) {
+        self.record_heartbeat(details);
     }
 
-    pub async fn next(&self) -> PermittedTqResp {
-        self.rx.recv().await.expect("Send half cannot be dropped")
+    fn request_workflow_eviction(&self, run_id: &str) {
+        self.request_wf_eviction(
+            run_id,
+            "Eviction explicitly requested by lang",
+            EvictionReason::LangRequested,
+        );
     }
-}
 
-pub(crate) struct WorkerActivityTasks {
-    /// Centralizes management of heartbeat issuing / throttling
-    heartbeat_manager: ActivityHeartbeatManager,
-    /// Activities that have been issued to lang but not yet completed
-    outstanding_activity_tasks: DashMap<TaskToken, RemoteInFlightActInfo>,
-    /// Buffers activity task polling in the event we need to return a cancellation while a poll is
-    /// ongoing.
-    poller: BoxedActPoller,
-    /// Holds activity tasks we have received by non-polling means. EX: In direct response to
-    /// workflow task completion.
-    non_poll_tasks: NonPollActBuffer,
-    /// Ensures we stay at or below this worker's maximum concurrent activity limit
-    activities_semaphore: Arc<MeteredSemaphore>,
-    /// Enables per-worker rate-limiting of activity tasks
-    ratelimiter: Option<RateLimiter<NotKeyed, InMemoryState, DefaultClock, NoOpMiddleware>>,
-    /// Wakes every time an activity is removed from the outstanding map
-    complete_notify: Notify,
+    fn get_config(&self) -> &WorkerConfig {
+        &self.config
+    }
 
-    metrics: MetricsContext,
+    /// Begins the shutdown process, tells pollers they should stop. Is idempotent.
+    fn initiate_shutdown(&self) {
+        if !self.shutdown_token.is_cancelled() {
+            info!(
+                task_queue=%self.config.task_queue,
+                namespace=%self.config.namespace,
+                "Initiated shutdown",
+            );
+        }
+        self.shutdown_token.cancel();
+        // First, we want to stop polling of both activity and workflow tasks
+        if let Some(atm) = self.at_task_mgr.as_ref() {
+            atm.initiate_shutdown();
+        }
+        // Let the manager know that shutdown has been initiated to try to unblock the local
+        // activity poll in case this worker is an activity-only worker.
+        self.local_act_mgr.shutdown_initiated();
+        if !self.workflows.ever_polled() {
+            self.local_act_mgr.workflows_have_shutdown();
+        }
+    }
+
+    async fn shutdown(&self) {
+        self.shutdown().await
+    }
 
-    max_heartbeat_throttle_interval: Duration,
-    default_heartbeat_throttle_interval: Duration,
+    async fn finalize_shutdown(self) {
+        self.shutdown().await;
+        self.finalize_shutdown().await
+    }
 }
 
-impl WorkerActivityTasks {
+impl Worker {
     pub(crate) fn new(
-        max_activity_tasks: usize,
-        max_worker_act_per_sec: Option<f64>,
-        poller: BoxedActPoller,
+        config: WorkerConfig,
+        sticky_queue_name: Option<String>,
         client: Arc<dyn WorkerClient>,
+        telem_instance: Option<&TelemetryInstance>,
+    ) -> Self {
+        info!(task_queue=%config.task_queue,
+              namespace=%config.namespace,
+              "Initializing worker");
+        let metrics = if let Some(ti) = telem_instance {
+            MetricsContext::top_level(config.namespace.clone(), ti)
+                .with_task_q(config.task_queue.clone())
+        } else {
+            MetricsContext::no_op()
+        };
+        metrics.worker_registered();
+
+        let shutdown_token = CancellationToken::new();
+        let max_nonsticky_polls = if sticky_queue_name.is_some() {
+            config.max_nonsticky_polls()
+        } else {
+            config.max_concurrent_wft_polls
+        };
+        let max_sticky_polls = config.max_sticky_polls();
+        let wft_metrics = metrics.with_new_attrs([workflow_poller()]);
+        let mut wf_task_poll_buffer = new_workflow_task_buffer(
+            client.clone(),
+            config.task_queue.clone(),
+            false,
+            max_nonsticky_polls,
+            max_nonsticky_polls * 2,
+            shutdown_token.child_token(),
+        );
+        wf_task_poll_buffer.set_num_pollers_handler(move |np| wft_metrics.record_num_pollers(np));
+        let sticky_queue_poller = sticky_queue_name.as_ref().map(|sqn| {
+            let sticky_metrics = metrics.with_new_attrs([workflow_sticky_poller()]);
+            let mut sp = new_workflow_task_buffer(
+                client.clone(),
+                sqn.clone(),
+                true,
+                max_sticky_polls,
+                max_sticky_polls * 2,
+                shutdown_token.child_token(),
+            );
+            sp.set_num_pollers_handler(move |np| sticky_metrics.record_num_pollers(np));
+            sp
+        });
+        let act_poll_buffer = if config.no_remote_activities {
+            None
+        } else {
+            let mut ap = new_activity_task_buffer(
+                client.clone(),
+                config.task_queue.clone(),
+                config.max_concurrent_at_polls,
+                config.max_concurrent_at_polls * 2,
+                config.max_task_queue_activities_per_second,
+                shutdown_token.child_token(),
+            );
+            let act_metrics = metrics.with_new_attrs([activity_poller()]);
+            ap.set_num_pollers_handler(move |np| act_metrics.record_num_pollers(np));
+            Some(Box::from(ap)
+                as Box<
+                    dyn Poller<PollActivityTaskQueueResponse> + Send + Sync,
+                >)
+        };
+        let wf_task_poll_buffer = Box::new(WorkflowTaskPoller::new(
+            wf_task_poll_buffer,
+            sticky_queue_poller,
+        ));
+        let wft_stream = new_wft_poller(wf_task_poll_buffer, metrics.clone());
+        Self::new_with_pollers(
+            config,
+            sticky_queue_name,
+            client,
+            wft_stream,
+            act_poll_buffer,
+            metrics,
+            telem_instance,
+            shutdown_token,
+        )
+    }
+
+    #[cfg(test)]
+    pub(crate) fn new_test(config: WorkerConfig, client: impl WorkerClient + 'static) -> Self {
+        Self::new(config, None, Arc::new(client), None)
+    }
+
+    #[allow(clippy::too_many_arguments)] // Not much worth combining here
+    pub(crate) fn new_with_pollers(
+        mut config: WorkerConfig,
+        sticky_queue_name: Option<String>,
+        client: Arc<dyn WorkerClient>,
+        wft_stream: impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> + Send + 'static,
+        act_poller: Option<BoxedActPoller>,
         metrics: MetricsContext,
-        max_heartbeat_throttle_interval: Duration,
-        default_heartbeat_throttle_interval: Duration,
+        telem_instance: Option<&TelemetryInstance>,
+        shutdown_token: CancellationToken,
     ) -> Self {
+        let (hb_tx, hb_rx) = unbounded_channel();
+        let local_act_mgr = Arc::new(LocalActivityManager::new(
+            config.max_outstanding_local_activities,
+            config.namespace.clone(),
+            hb_tx,
+            metrics.with_new_attrs([local_activity_worker_type()]),
+        ));
+        let at_task_mgr = act_poller.map(|ap| {
+            WorkerActivityTasks::new(
+                config.max_outstanding_activities,
+                config.max_worker_activities_per_second,
+                ap,
+                client.clone(),
+                metrics.clone(),
+                config.max_heartbeat_throttle_interval,
+                config.default_heartbeat_throttle_interval,
+                config.graceful_shutdown_period,
+            )
+        });
+        let poll_on_non_local_activities = at_task_mgr.is_some();
+        if !poll_on_non_local_activities {
+            info!("Activity polling is disabled for this worker");
+        };
+        let la_sink = LAReqSink::new(local_act_mgr.clone(), config.wf_state_inputs.clone());
         Self {
-            heartbeat_manager: ActivityHeartbeatManager::new(client),
-            outstanding_activity_tasks: Default::default(),
-            poller,
-            non_poll_tasks: NonPollActBuffer::new(),
-            activities_semaphore: Arc::new(MeteredSemaphore::new(
-                max_activity_tasks,
-                metrics.with_new_attrs([activity_worker_type()]),
-                MetricsContext::available_task_slots,
-            )),
-            ratelimiter: max_worker_act_per_sec.and_then(|ps| {
-                Quota::with_period(Duration::from_secs_f64(ps.recip())).map(RateLimiter::direct)
-            }),
-            complete_notify: Notify::new(),
-            metrics,
-            max_heartbeat_throttle_interval,
-            default_heartbeat_throttle_interval,
+            wf_client: client.clone(),
+            workflows: Workflows::new(
+                build_wf_basics(
+                    &mut config,
+                    metrics,
+                    shutdown_token.child_token(),
+                    client.capabilities().cloned().unwrap_or_default(),
+                ),
+                sticky_queue_name.map(|sq| StickyExecutionAttributes {
+                    worker_task_queue: Some(TaskQueue {
+                        name: sq,
+                        kind: TaskQueueKind::Sticky as i32,
+                    }),
+                    schedule_to_start_timeout: Some(
+                        config
+                            .sticky_queue_schedule_to_start_timeout
+                            .try_into()
+                            .expect("timeout fits into proto"),
+                    ),
+                }),
+                client,
+                wft_stream,
+                la_sink,
+                local_act_mgr.clone(),
+                hb_rx,
+                at_task_mgr
+                    .as_ref()
+                    .map(|mgr| mgr.get_handle_for_workflows()),
+                telem_instance,
+            ),
+            at_task_mgr,
+            local_act_mgr,
+            config,
+            shutdown_token,
+            post_activate_hook: None,
+            // Complete if there configured not to poll on non-local activities.
+            non_local_activities_complete: Arc::new(AtomicBool::new(!poll_on_non_local_activities)),
+            local_activities_complete: Default::default(),
         }
     }
 
-    pub(crate) fn notify_shutdown(&self) {
-        self.poller.notify_shutdown();
+    /// Will shutdown the worker. Does not resolve until all outstanding workflow tasks have been
+    /// completed
+    async fn shutdown(&self) {
+        self.initiate_shutdown();
+        // We need to wait for all local activities to finish so no more workflow task heartbeats
+        // will be generated
+        self.local_act_mgr
+            .wait_all_outstanding_tasks_finished()
+            .await;
+        // Wait for workflows to finish
+        self.workflows
+            .shutdown()
+            .await
+            .expect("Workflow processing terminates cleanly");
+        // Wait for activities to finish
+        if let Some(acts) = self.at_task_mgr.as_ref() {
+            acts.shutdown().await;
+        }
     }
 
-    /// Wait for all outstanding activity tasks to finish
-    pub(crate) async fn wait_all_finished(&self) {
-        while !self.outstanding_activity_tasks.is_empty() {
-            self.complete_notify.notified().await
+    /// Finish shutting down by consuming the background pollers and freeing all resources
+    async fn finalize_shutdown(self) {
+        self.shutdown().await;
+        if let Some(b) = self.at_task_mgr {
+            b.shutdown().await;
         }
     }
 
-    pub(crate) async fn shutdown(self) {
-        self.poller.shutdown_box().await;
-        self.heartbeat_manager.shutdown().await;
+    pub(crate) fn shutdown_token(&self) -> CancellationToken {
+        self.shutdown_token.clone()
     }
 
-    /// Wait until not at the outstanding activity limit, and then poll for an activity task.
-    ///
-    /// Returns `Ok(None)` if no activity is ready and the overall polling loop should be retried.
-    pub(crate) async fn poll(&self) -> Result<Option<ActivityTask>, PollActivityError> {
-        let poll_with_semaphore = async {
-            // Acquire and subsequently forget a permit for an outstanding activity. When they are
-            // completed, we must add a new permit to the semaphore, since holding the permit the
-            // entire time lang does work would be a challenge.
-            let perm = self
-                .activities_semaphore
-                .acquire_owned()
-                .await
-                .expect("outstanding activity semaphore not closed");
-            if let Some(ref rl) = self.ratelimiter {
-                rl.until_ready().await;
-            }
-            (self.poller.poll().await, perm)
-        };
+    /// Returns number of currently cached workflows
+    pub async fn cached_workflows(&self) -> usize {
+        self.workflows
+            .get_state_info()
+            .await
+            .map(|r| r.cached_workflows)
+            .unwrap_or_default()
+    }
 
-        tokio::select! {
-            biased;
+    /// Returns number of currently outstanding workflow tasks
+    #[cfg(test)]
+    pub(crate) async fn outstanding_workflow_tasks(&self) -> usize {
+        self.workflows
+            .get_state_info()
+            .await
+            .map(|r| r.outstanding_wft)
+            .unwrap_or_default()
+    }
 
-            cancel_task = self.next_pending_cancel_task() => {
-                cancel_task
-            }
-            task = self.non_poll_tasks.next() => {
-                Ok(Some(self.about_to_issue_task(task, true)))
+    #[allow(unused)]
+    pub(crate) async fn available_wft_permits(&self) -> usize {
+        self.workflows.available_wft_permits()
+    }
+
+    /// Get new activity tasks (may be local or nonlocal). Local activities are returned first
+    /// before polling the server if there are any.
+    ///
+    /// Returns `Ok(None)` in the event of a poll timeout or if the polling loop should otherwise
+    /// be restarted
+    async fn activity_poll(&self) -> Result<Option<ActivityTask>, PollActivityError> {
+        let local_activities_complete = self.local_activities_complete.load(Ordering::Relaxed);
+        let non_local_activities_complete =
+            self.non_local_activities_complete.load(Ordering::Relaxed);
+        if local_activities_complete && non_local_activities_complete {
+            return Err(PollActivityError::ShutDown);
+        }
+        let act_mgr_poll = async {
+            if non_local_activities_complete {
+                future::pending::<()>().await;
+                unreachable!()
             }
-            (work, permit) = poll_with_semaphore => {
-                match work {
-                    Some(Ok(work)) => {
-                        if work == PollActivityTaskQueueResponse::default() {
-                            // Timeout
-                            self.metrics.act_poll_timeout();
-                            return Ok(None)
-                        }
-                        let work = self.about_to_issue_task(PermittedTqResp {
-                           resp: work, permit
-                        }, false);
-                        Ok(Some(work))
+            if let Some(ref act_mgr) = self.at_task_mgr {
+                let res = act_mgr.poll().await;
+                if let Err(err) = res.as_ref() {
+                    if matches!(err, PollActivityError::ShutDown) {
+                        self.non_local_activities_complete
+                            .store(true, Ordering::Relaxed);
+                        return Ok(None);
                     }
-                    None => {
-                        Err(PollActivityError::ShutDown)
+                };
+                res.map(Some)
+            } else {
+                // We expect the local activity branch below to produce shutdown when appropriate if
+                // there are no activity pollers.
+                future::pending::<()>().await;
+                unreachable!()
+            }
+        };
+        let local_activities_poll = async {
+            if local_activities_complete {
+                future::pending::<()>().await;
+                unreachable!()
+            }
+            match self.local_act_mgr.next_pending().await {
+                Some(DispatchOrTimeoutLA::Dispatch(r)) => Ok(Some(r)),
+                Some(DispatchOrTimeoutLA::Timeout {
+                    run_id,
+                    resolution,
+                    task,
+                }) => {
+                    self.notify_local_result(&run_id, LocalResolution::LocalActivity(resolution));
+                    Ok(task)
+                }
+                None => {
+                    if self.shutdown_token.is_cancelled() {
+                        self.local_activities_complete
+                            .store(true, Ordering::Relaxed);
                     }
-                    Some(Err(e)) => Err(e.into())
+                    Ok(None)
                 }
             }
-        }
-    }
+        };
 
-    pub(crate) async fn complete(
-        &self,
-        task_token: TaskToken,
-        status: aer::Status,
-        client: &dyn WorkerClient,
-    ) {
-        if let Some((_, act_info)) = self.outstanding_activity_tasks.remove(&task_token) {
-            let act_metrics = self.metrics.with_new_attrs([
-                activity_type(act_info.base.activity_type),
-                workflow_type(act_info.base.workflow_type),
-            ]);
-            Span::current().record("workflow_id", act_info.base.workflow_id);
-            Span::current().record("run_id", act_info.base.workflow_run_id);
-            act_metrics.act_execution_latency(act_info.base.start_time.elapsed());
-            let known_not_found = act_info.known_not_found;
-
-            self.heartbeat_manager.evict(task_token.clone()).await;
-            self.complete_notify.notify_waiters();
-
-            // No need to report activities which we already know the server doesn't care about
-            if !known_not_found {
-                let maybe_net_err = match status {
-                    aer::Status::WillCompleteAsync(_) => None,
-                    aer::Status::Completed(ar::Success { result }) => client
-                        .complete_activity_task(task_token.clone(), result.map(Into::into))
-                        .await
-                        .err(),
-                    aer::Status::Failed(ar::Failure { failure }) => {
-                        act_metrics.act_execution_failed();
-                        client
-                            .fail_activity_task(task_token.clone(), failure.map(Into::into))
-                            .await
-                            .err()
-                    }
-                    aer::Status::Cancelled(ar::Cancellation { failure }) => {
-                        let details = if let Some(Failure {
-                            failure_info:
-                                Some(FailureInfo::CanceledFailureInfo(CanceledFailureInfo { details })),
-                            ..
-                        }) = failure
-                        {
-                            details
-                        } else {
-                            warn!(task_token = ? task_token,
-                                "Expected activity cancelled status with CanceledFailureInfo");
-                            None
-                        };
-                        client
-                            .cancel_activity_task(task_token.clone(), details.map(Into::into))
-                            .await
-                            .err()
-                    }
-                };
+        tokio::select! {
+            biased;
 
-                if let Some(e) = maybe_net_err {
-                    if e.code() == tonic::Code::NotFound {
-                        warn!(task_token = ?task_token, details = ?e, "Activity not found on \
-                        completion. This may happen if the activity has already been cancelled but \
-                        completed anyway.");
-                    } else {
-                        warn!(error=?e, "Network error while completing activity");
-                    };
-                };
-            };
-        } else {
-            warn!(
-                "Attempted to complete activity task {} but we were not tracking it",
-                &task_token
-            );
+            r = local_activities_poll => r,
+            r = act_mgr_poll => r,
         }
     }
 
     /// Attempt to record an activity heartbeat
-    pub(crate) fn record_heartbeat(
-        &self,
-        details: ActivityHeartbeat,
-    ) -> Result<(), ActivityHeartbeatError> {
-        // TODO: Propagate these back as cancels. Silent fails is too nonobvious
-        let heartbeat_timeout: Duration = self
-            .outstanding_activity_tasks
-            .get(&TaskToken(details.task_token.clone()))
-            .ok_or(ActivityHeartbeatError::UnknownActivity)?
-            .heartbeat_timeout
-            .clone()
-            // We treat None as 0 (even though heartbeat_timeout is never set to None by the server)
-            .unwrap_or_default()
-            .try_into()
-            // This technically should never happen since prost duration should be directly mappable
-            // to std::time::Duration.
-            .or(Err(ActivityHeartbeatError::InvalidHeartbeatTimeout))?;
-
-        // There is a bug in the server that translates non-set heartbeat timeouts into 0 duration.
-        // That's why we treat 0 the same way as None, otherwise we wouldn't know which aggregation
-        // delay to use, and using 0 is not a good idea as SDK would hammer the server too hard.
-        let throttle_interval = if heartbeat_timeout.as_millis() == 0 {
-            self.default_heartbeat_throttle_interval
-        } else {
-            heartbeat_timeout.mul_f64(0.8)
-        };
-        let throttle_interval =
-            std::cmp::min(throttle_interval, self.max_heartbeat_throttle_interval);
-        self.heartbeat_manager.record(details, throttle_interval)
-    }
-
-    /// Returns a handle that the workflows management side can use to interact with this manager
-    pub(crate) fn get_handle_for_workflows(&self) -> ActivitiesFromWFTsHandle {
-        ActivitiesFromWFTsHandle {
-            sem: self.activities_semaphore.clone(),
-            tx: self.non_poll_tasks.tx.clone(),
+    pub(crate) fn record_heartbeat(&self, details: ActivityHeartbeat) {
+        if let Some(at_mgr) = self.at_task_mgr.as_ref() {
+            let tt = details.task_token.clone();
+            if let Err(e) = at_mgr.record_heartbeat(details) {
+                warn!(task_token = ?tt, details = ?e, "Activity heartbeat failed.");
+            }
         }
     }
 
-    async fn next_pending_cancel_task(&self) -> Result<Option<ActivityTask>, PollActivityError> {
-        let next_pc = self.heartbeat_manager.next_pending_cancel().await;
-        // Issue cancellations for anything we noticed was cancelled during heartbeating
-        if let Some(PendingActivityCancel { task_token, reason }) = next_pc {
-            // It's possible that activity has been completed and we no longer have an
-            // outstanding activity task. This is fine because it means that we no
-            // longer need to cancel this activity, so we'll just ignore such orphaned
-            // cancellations.
-            if let Some(mut details) = self.outstanding_activity_tasks.get_mut(&task_token) {
-                if details.issued_cancel_to_lang {
-                    // Don't double-issue cancellations
-                    return Ok(None);
+    #[instrument(skip(self, task_token, status),
+                 fields(task_token=%&task_token, status=%&status,
+                        task_queue=%self.config.task_queue, workflow_id, run_id))]
+    pub(crate) async fn complete_activity(
+        &self,
+        task_token: TaskToken,
+        status: activity_execution_result::Status,
+    ) -> Result<(), CompleteActivityError> {
+        validate_activity_completion(&status)?;
+        if task_token.is_local_activity_task() {
+            let as_la_res: LocalActivityExecutionResult = status.try_into()?;
+            match self.local_act_mgr.complete(&task_token, &as_la_res) {
+                LACompleteAction::Report(info) => self.complete_local_act(as_la_res, info, None),
+                LACompleteAction::LangDoesTimerBackoff(backoff, info) => {
+                    // This la needs to write a failure marker, and then we will tell lang how
+                    // long of a timer to schedule to back off for. We do this because there are
+                    // no other situations where core generates "internal" commands so it is much
+                    // simpler for lang to reply with the timer / next LA command than to do it
+                    // internally. Plus, this backoff hack we'd like to eliminate eventually.
+                    self.complete_local_act(as_la_res, info, Some(backoff));
                 }
-
-                details.issued_cancel_to_lang = true;
-                if reason == ActivityCancelReason::NotFound {
-                    details.known_not_found = true;
+                LACompleteAction::WillBeRetried => {
+                    // Nothing to do here
+                }
+                LACompleteAction::Untracked => {
+                    warn!("Tried to complete untracked local activity {}", task_token);
                 }
-                Ok(Some(ActivityTask::cancel_from_ids(task_token.0, reason)))
-            } else {
-                debug!(task_token = ?task_token, "Unknown activity task when issuing cancel");
-                // If we can't find the activity here, it's already been completed,
-                // in which case issuing a cancel again is pointless.
-                Ok(None)
             }
+            return Ok(());
+        }
+
+        if let Some(atm) = &self.at_task_mgr {
+            atm.complete(task_token, status, &*self.wf_client).await;
         } else {
-            // The only situation where the next cancel would return none is if the manager
-            // was dropped, which can only happen on shutdown.
-            Err(PollActivityError::ShutDown)
+            error!(
+                "Tried to complete activity {} on a worker that does not have an activity manager",
+                task_token
+            );
         }
+        Ok(())
     }
 
-    /// Called when there is a new act task about to be bubbled up out of the manager
-    fn about_to_issue_task(&self, task: PermittedTqResp, is_eager: bool) -> ActivityTask {
-        if let Some(ref act_type) = task.resp.activity_type {
-            if let Some(ref wf_type) = task.resp.workflow_type {
-                self.metrics
-                    .with_new_attrs([
-                        activity_type(act_type.name.clone()),
-                        workflow_type(wf_type.name.clone()),
-                        eager(is_eager),
-                    ])
-                    .act_task_received();
-            }
+    #[instrument(skip(self), fields(run_id, workflow_id, task_queue=%self.config.task_queue))]
+    pub(crate) async fn next_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
+        let r = self.workflows.next_workflow_activation().await;
+        // In the event workflows are shutdown, begin shutdown of everything else, since that's
+        // about to happen anyway. Tell the local activity manager that, so that it can know to
+        // cancel any remaining outstanding LAs and shutdown.
+        if matches!(r, Err(PollWfError::ShutDown)) {
+            // This is covering the situation where WFT pollers dying is the reason for shutdown
+            self.initiate_shutdown();
+            self.local_act_mgr.workflows_have_shutdown();
         }
-        // There could be an else statement here but since the response should always contain both
-        // activity_type and workflow_type, we won't bother.
-
-        if let Some(dur) = task.resp.sched_to_start() {
-            self.metrics.act_sched_to_start_latency(dur);
-        };
-
-        self.outstanding_activity_tasks.insert(
-            task.resp.task_token.clone().into(),
-            RemoteInFlightActInfo::new(&task.resp, task.permit),
-        );
+        r
+    }
 
-        ActivityTask::start_from_poll_resp(task.resp)
+    #[instrument(skip(self, completion),
+                 fields(completion=%&completion, run_id=%completion.run_id, workflow_id,
+                        task_queue=%self.config.task_queue))]
+    pub(crate) async fn complete_workflow_activation(
+        &self,
+        completion: WorkflowActivationCompletion,
+    ) -> Result<(), CompleteWfError> {
+        self.workflows
+            .activation_completed(
+                completion,
+                false,
+                self.post_activate_hook
+                    .as_ref()
+                    .map(|h| |data: PostActivateHookData| h(self, data)),
+            )
+            .await?;
+        Ok(())
     }
 
-    #[cfg(test)]
-    pub(crate) fn remaining_activity_capacity(&self) -> usize {
-        self.activities_semaphore.available_permits()
+    /// Request a workflow eviction
+    pub(crate) fn request_wf_eviction(
+        &self,
+        run_id: &str,
+        message: impl Into<String>,
+        reason: EvictionReason,
+    ) {
+        self.workflows.request_eviction(run_id, message, reason);
     }
-}
 
-/// Provides facilities for the workflow side of things to interact with the activity manager.
-/// Allows for the handling of activities returned by WFT completions.
-pub(crate) struct ActivitiesFromWFTsHandle {
-    sem: Arc<MeteredSemaphore>,
-    tx: async_channel::Sender<PermittedTqResp>,
-}
+    /// Sets a function to be called at the end of each activation completion
+    pub(crate) fn set_post_activate_hook(
+        &mut self,
+        callback: impl Fn(&Self, PostActivateHookData) + Send + Sync + 'static,
+    ) {
+        self.post_activate_hook = Some(Box::new(callback))
+    }
 
-impl ActivitiesFromWFTsHandle {
-    /// Returns a handle that can be used to reserve an activity slot. EX: When requesting eager
-    /// dispatch of an activity to this worker upon workflow task completion
-    pub(crate) fn reserve_slot(&self) -> Option<OwnedMeteredSemPermit> {
-        self.sem.try_acquire_owned().ok()
+    fn complete_local_act(
+        &self,
+        la_res: LocalActivityExecutionResult,
+        info: LocalInFlightActInfo,
+        backoff: Option<prost_types::Duration>,
+    ) {
+        self.notify_local_result(
+            &info.la_info.workflow_exec_info.run_id,
+            LocalResolution::LocalActivity(LocalActivityResolution {
+                seq: info.la_info.schedule_cmd.seq,
+                result: la_res,
+                runtime: info.dispatch_time.elapsed(),
+                attempt: info.attempt,
+                backoff,
+                original_schedule_time: info.la_info.schedule_cmd.original_schedule_time,
+            }),
+        )
     }
 
-    /// Queue new activity tasks for dispatch received from non-polling sources (ex: eager returns
-    /// from WFT completion)
-    pub(crate) fn add_tasks(&self, tasks: impl IntoIterator<Item = PermittedTqResp>) {
-        for t in tasks.into_iter() {
-            // Technically we should be reporting `activity_task_received` here, but for simplicity
-            // and time insensitivity, that metric is tracked in `about_to_issue_task`.
-            self.tx.try_send(t).expect("Receive half cannot be dropped");
-        }
+    fn notify_local_result(&self, run_id: &str, res: LocalResolution) {
+        self.workflows.notify_of_local_result(run_id, res);
     }
 }
 
-pub(crate) struct PermittedTqResp {
-    pub permit: OwnedMeteredSemPermit,
-    pub resp: PollActivityTaskQueueResponse,
+pub struct PostActivateHookData<'a> {
+    pub run_id: &'a str,
+    pub most_recent_event: usize,
+    pub replaying: bool,
+}
+
+fn build_wf_basics(
+    config: &mut WorkerConfig,
+    metrics: MetricsContext,
+    shutdown_token: CancellationToken,
+    server_capabilities: get_system_info_response::Capabilities,
+) -> WorkflowBasics {
+    WorkflowBasics {
+        max_cached_workflows: config.max_cached_workflows,
+        max_outstanding_wfts: config.max_outstanding_workflow_tasks,
+        shutdown_token,
+        metrics,
+        namespace: config.namespace.clone(),
+        task_queue: config.task_queue.clone(),
+        ignore_evicts_on_shutdown: config.ignore_evicts_on_shutdown,
+        fetching_concurrency: config.fetching_concurrency,
+        server_capabilities,
+        #[cfg(feature = "save_wf_inputs")]
+        wf_state_inputs: config.wf_state_inputs.take(),
+    }
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
     use crate::{
-        test_help::mock_poller_from_resps, worker::client::mocks::mock_manual_workflow_client,
+        advance_fut, test_help::test_worker_cfg, worker::client::mocks::mock_workflow_client,
     };
+    use futures::FutureExt;
+
+    use temporal_sdk_core_protos::temporal::api::workflowservice::v1::PollActivityTaskQueueResponse;
 
     #[tokio::test]
-    async fn per_worker_ratelimit() {
-        let poller = mock_poller_from_resps([
-            PollActivityTaskQueueResponse {
-                task_token: vec![1],
-                activity_id: "act1".to_string(),
-                ..Default::default()
-            }
-            .into(),
-            PollActivityTaskQueueResponse {
-                task_token: vec![2],
-                activity_id: "act2".to_string(),
-                ..Default::default()
-            }
-            .into(),
-        ]);
-        let atm = WorkerActivityTasks::new(
-            10,
-            Some(2.0),
-            poller,
-            Arc::new(mock_manual_workflow_client()),
-            MetricsContext::no_op(),
-            Duration::from_secs(1),
-            Duration::from_secs(1),
+    async fn activity_timeouts_maintain_permit() {
+        let mut mock_client = mock_workflow_client();
+        mock_client
+            .expect_poll_activity_task()
+            .returning(|_, _| Ok(PollActivityTaskQueueResponse::default()));
+
+        let cfg = test_worker_cfg()
+            .max_outstanding_activities(5_usize)
+            .build()
+            .unwrap();
+        let worker = Worker::new_test(cfg, mock_client);
+        let fut = worker.poll_activity_task();
+        advance_fut!(fut);
+        assert_eq!(
+            worker
+                .at_task_mgr
+                .as_ref()
+                .unwrap()
+                .remaining_activity_capacity(),
+            4
         );
-        let start = Instant::now();
-        atm.poll().await.unwrap().unwrap();
-        atm.poll().await.unwrap().unwrap();
-        // At least half a second will have elapsed since we only allow 2 tasks per second.
-        // With no ratelimit, even on a slow CI server with lots of load, this would typically take
-        // low single digit ms or less.
-        assert!(start.elapsed() > Duration::from_secs_f64(0.5));
+    }
+
+    #[tokio::test]
+    async fn activity_errs_dont_eat_permits() {
+        let mut mock_client = mock_workflow_client();
+        mock_client
+            .expect_poll_activity_task()
+            .returning(|_, _| Err(tonic::Status::internal("ahhh")));
+
+        let cfg = test_worker_cfg()
+            .max_outstanding_activities(5_usize)
+            .build()
+            .unwrap();
+        let worker = Worker::new_test(cfg, mock_client);
+        assert!(worker.activity_poll().await.is_err());
+        assert_eq!(worker.at_task_mgr.unwrap().remaining_activity_capacity(), 5);
+    }
+
+    #[test]
+    fn max_polls_calculated_properly() {
+        let mut wcb = WorkerConfigBuilder::default();
+        let cfg = wcb
+            .namespace("default")
+            .task_queue("whatever")
+            .worker_build_id("test_bin_id")
+            .max_concurrent_wft_polls(5_usize)
+            .build()
+            .unwrap();
+        assert_eq!(cfg.max_nonsticky_polls(), 1);
+        assert_eq!(cfg.max_sticky_polls(), 4);
+    }
+
+    #[test]
+    fn max_polls_zero_is_err() {
+        assert!(test_worker_cfg()
+            .max_concurrent_wft_polls(0_usize)
+            .build()
+            .is_err());
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client/mocks.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,19 +1,37 @@
 use super::*;
 use futures::Future;
 
+pub(crate) static DEFAULT_TEST_CAPABILITIES: &Capabilities = &Capabilities {
+    signal_and_query_header: true,
+    internal_error_differentiation: true,
+    activity_failure_include_heartbeat: true,
+    supports_schedules: true,
+    encoded_failure_attributes: true,
+    build_id_based_versioning: true,
+    upsert_memo: true,
+    eager_workflow_start: true,
+    sdk_metadata: true,
+};
+
 #[cfg(test)]
 /// Create a mock client primed with basic necessary expectations
 pub(crate) fn mock_workflow_client() -> MockWorkerClient {
-    MockWorkerClient::new()
+    let mut r = MockWorkerClient::new();
+    r.expect_capabilities()
+        .returning(|| Some(DEFAULT_TEST_CAPABILITIES));
+    r
 }
 
 /// Create a mock manual client primed with basic necessary expectations
 pub(crate) fn mock_manual_workflow_client() -> MockManualWorkerClient {
-    MockManualWorkerClient::new()
+    let mut r = MockManualWorkerClient::new();
+    r.expect_capabilities()
+        .returning(|| Some(DEFAULT_TEST_CAPABILITIES));
+    r
 }
 
 // Need a version of the mock that can return futures so we can return potentially pending
 // results. This is really annoying b/c of the async trait stuff. Need
 // https://github.com/asomers/mockall/issues/189 to be fixed for it to go away.
 mockall::mock! {
     pub(crate) ManualWorkerClient {}
@@ -79,9 +97,11 @@
 
         fn respond_legacy_query<'a, 'b>(
             &self,
             task_token: TaskToken,
             query_result: QueryResult,
         ) -> impl Future<Output = Result<RespondQueryTaskCompletedResponse>> + Send + 'b
             where 'a: 'b, Self: 'b;
+
+        fn capabilities(&self) -> Option<&'static get_system_info_response::Capabilities>;
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/client.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/client.rs`

 * *Files 6% similar despite different names*

```diff
@@ -3,20 +3,24 @@
 pub(crate) mod mocks;
 
 use temporal_client::{Client, RetryClient, WorkflowService};
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::QueryResult,
     temporal::api::{
         command::v1::Command,
-        common::v1::{Payloads, WorkflowExecution},
+        common::v1::{
+            MeteringMetadata, Payloads, WorkerVersionCapabilities, WorkerVersionStamp,
+            WorkflowExecution,
+        },
         enums::v1::{TaskQueueKind, WorkflowTaskFailedCause},
         failure::v1::Failure,
         query::v1::WorkflowQueryResult,
-        taskqueue::v1::{StickyExecutionAttributes, TaskQueue, TaskQueueMetadata, VersionId},
-        workflowservice::v1::*,
+        sdk::v1::WorkflowTaskCompletedMetadata,
+        taskqueue::v1::{StickyExecutionAttributes, TaskQueue, TaskQueueMetadata},
+        workflowservice::v1::{get_system_info_response::Capabilities, *},
     },
     TaskToken,
 };
 
 type Result<T, E = tonic::Status> = std::result::Result<T, E>;
 
 /// Contains everything a worker needs to interact with the server
@@ -105,14 +109,17 @@
         page_token: Vec<u8>,
     ) -> Result<GetWorkflowExecutionHistoryResponse>;
     async fn respond_legacy_query(
         &self,
         task_token: TaskToken,
         query_result: QueryResult,
     ) -> Result<RespondQueryTaskCompletedResponse>;
+
+    #[allow(clippy::needless_lifetimes)] // Clippy is wrong here
+    fn capabilities<'a>(&'a self) -> Option<&'a get_system_info_response::Capabilities>;
 }
 
 #[async_trait::async_trait]
 impl WorkerClient for WorkerClientBag {
     async fn poll_workflow_task(
         &self,
         task_queue: String,
@@ -130,16 +137,16 @@
             }),
             identity: self.identity.clone(),
             binary_checksum: if self.use_versioning {
                 "".to_string()
             } else {
                 self.worker_build_id.clone()
             },
-            worker_versioning_id: Some(VersionId {
-                worker_build_id: self.versioning_build_id(),
+            worker_version_capabilities: Some(WorkerVersionCapabilities {
+                build_id: self.versioning_build_id(),
             }),
         };
 
         Ok(self
             .client
             .clone()
             .poll_workflow_task_queue(request)
@@ -158,16 +165,16 @@
                 name: task_queue,
                 kind: TaskQueueKind::Normal as i32,
             }),
             identity: self.identity.clone(),
             task_queue_metadata: max_tasks_per_sec.map(|tps| TaskQueueMetadata {
                 max_tasks_per_second: Some(tps),
             }),
-            worker_versioning_id: Some(VersionId {
-                worker_build_id: self.versioning_build_id(),
+            worker_version_capabilities: Some(WorkerVersionCapabilities {
+                build_id: self.versioning_build_id(),
             }),
         };
 
         Ok(self
             .client
             .clone()
             .poll_activity_task_queue(request)
@@ -182,17 +189,19 @@
         let request = RespondWorkflowTaskCompletedRequest {
             task_token: request.task_token.into(),
             commands: request.commands,
             identity: self.identity.clone(),
             sticky_attributes: request.sticky_attributes,
             return_new_workflow_task: request.return_new_workflow_task,
             force_create_new_workflow_task: request.force_create_new_workflow_task,
-            worker_versioning_id: Some(VersionId {
-                worker_build_id: self.versioning_build_id(),
+            worker_version_stamp: Some(WorkerVersionStamp {
+                build_id: self.versioning_build_id(),
+                bundle_id: "".to_string(),
             }),
+            messages: vec![],
             binary_checksum: self.worker_build_id.clone(),
             query_results: request
                 .query_responses
                 .into_iter()
                 .map(|qr| {
                     let (id, completed_type, query_result, error_message) = qr.into_components();
                     (
@@ -202,14 +211,16 @@
                             answer: query_result,
                             error_message,
                         },
                     )
                 })
                 .collect(),
             namespace: self.namespace.clone(),
+            sdk_metadata: Some(request.sdk_metadata),
+            metering_metadata: Some(request.metering_metadata),
         };
         Ok(self
             .client
             .clone()
             .respond_workflow_task_completed(request)
             .await?
             .into_inner())
@@ -298,14 +309,15 @@
         let request = RespondWorkflowTaskFailedRequest {
             task_token: task_token.0,
             cause: cause as i32,
             failure,
             identity: self.identity.clone(),
             binary_checksum: self.worker_build_id.clone(),
             namespace: self.namespace.clone(),
+            messages: vec![],
         };
         Ok(self
             .client
             .clone()
             .respond_workflow_task_failed(request)
             .await?
             .into_inner())
@@ -348,14 +360,18 @@
                 query_result,
                 error_message,
                 namespace: self.namespace.clone(),
             })
             .await?
             .into_inner())
     }
+
+    fn capabilities(&self) -> Option<&Capabilities> {
+        self.client.get_client().inner().capabilities()
+    }
 }
 
 /// A version of [RespondWorkflowTaskCompletedRequest] that will finish being filled out by the
 /// server client
 #[derive(Debug, Clone, PartialEq)]
 pub(crate) struct WorkflowTaskCompletion {
     /// The task token that would've been received from polling for a workflow activation
@@ -366,8 +382,12 @@
     pub sticky_attributes: Option<StickyExecutionAttributes>,
     /// Responses to queries in the `queries` field of the workflow task.
     pub query_responses: Vec<QueryResult>,
     /// Indicate that the task completion should return a new WFT if one is available
     pub return_new_workflow_task: bool,
     /// Force a new WFT to be created after this completion
     pub force_create_new_workflow_task: bool,
+    /// SDK-specific metadata to send
+    pub sdk_metadata: WorkflowTaskCompletedMetadata,
+    /// Metering info
+    pub metering_metadata: MeteringMetadata,
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs`

 * *Files 20% similar despite different names*

```diff
@@ -1,584 +1,731 @@
-mod activities;
-pub(crate) mod client;
-mod workflow;
-
-pub use temporal_sdk_core_api::worker::{WorkerConfig, WorkerConfigBuilder};
-
-pub(crate) use activities::{
-    ExecutingLAId, LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
-    NewLocalAct,
-};
-#[cfg(test)]
-pub(crate) use workflow::ManagedWFFunc;
-pub(crate) use workflow::{wft_poller::new_wft_poller, LEGACY_QUERY_ID};
+//! This crate contains testing functionality that can be useful when building SDKs against Core,
+//! or even when testing workflows written in SDKs that use Core.
+
+#[macro_use]
+extern crate tracing;
+
+pub mod canned_histories;
+pub mod wf_input_saver;
+pub mod workflows;
 
 use crate::{
-    errors::CompleteWfError,
-    pollers::{
-        new_activity_task_buffer, new_workflow_task_buffer, BoxedActPoller, Poller,
-        WorkflowTaskPoller,
-    },
-    protosext::{validate_activity_completion, ValidPollWFTQResponse},
-    telemetry::metrics::{
-        activity_poller, local_activity_worker_type, workflow_poller, workflow_sticky_poller,
-        MetricsContext,
-    },
-    worker::{
-        activities::{DispatchOrTimeoutLA, LACompleteAction, LocalActivityManager},
-        client::WorkerClient,
-        workflow::{LocalResolution, WorkflowBasics, Workflows},
+    stream::{Stream, TryStreamExt},
+    wf_input_saver::stream_to_file,
+};
+use base64::{prelude::BASE64_STANDARD, Engine};
+use futures::{future, stream, stream::FuturesUnordered, StreamExt};
+use parking_lot::Mutex;
+use prost::Message;
+use rand::{distributions::Standard, Rng};
+use std::{
+    convert::TryFrom, env, future::Future, net::SocketAddr, path::PathBuf, sync::Arc,
+    time::Duration,
+};
+use temporal_client::{
+    Client, ClientTlsConfig, RetryClient, TlsConfig, WorkflowClientTrait, WorkflowExecutionInfo,
+    WorkflowOptions,
+};
+use temporal_sdk::{
+    interceptors::{FailOnNondeterminismInterceptor, WorkerInterceptor},
+    IntoActivityFunc, Worker, WorkflowFunction,
+};
+use temporal_sdk_core::{
+    ephemeral_server::{EphemeralExe, EphemeralExeVersion},
+    init_replay_worker, init_worker,
+    replay::HistoryForReplay,
+    ClientOptions, ClientOptionsBuilder, CoreRuntime, WorkerConfig, WorkerConfigBuilder,
+};
+use temporal_sdk_core_api::{
+    errors::{PollActivityError, PollWfError},
+    telemetry::{
+        Logger, MetricsExporter, OtelCollectorOptions, TelemetryOptions, TelemetryOptionsBuilder,
+        TraceExportConfig, TraceExporter,
     },
-    ActivityHeartbeat, CompleteActivityError, PollActivityError, PollWfError, WorkerTrait,
+    Worker as CoreWorker,
 };
-use activities::{LocalInFlightActInfo, WorkerActivityTasks};
-use futures::Stream;
-use std::{convert::TryInto, future, sync::Arc};
 use temporal_sdk_core_protos::{
     coresdk::{
-        activity_result::activity_execution_result,
-        activity_task::ActivityTask,
-        workflow_activation::{remove_from_cache::EvictionReason, WorkflowActivation},
+        workflow_commands::{
+            workflow_command, ActivityCancellationType, CompleteWorkflowExecution,
+            ScheduleActivity, ScheduleLocalActivity, StartTimer,
+        },
         workflow_completion::WorkflowActivationCompletion,
-        ActivityTaskCompletion,
     },
-    temporal::api::{
-        enums::v1::TaskQueueKind,
-        taskqueue::v1::{StickyExecutionAttributes, TaskQueue},
-        workflowservice::v1::PollActivityTaskQueueResponse,
-    },
-    TaskToken,
+    temporal::api::{common::v1::Payload, history::v1::History},
+    DEFAULT_ACTIVITY_TYPE,
 };
-use tokio_util::sync::CancellationToken;
+use tokio::sync::{mpsc::unbounded_channel, OnceCell};
+use url::Url;
 
-/// A worker polls on a certain task queue
-pub struct Worker {
-    config: WorkerConfig,
-    wf_client: Arc<dyn WorkerClient>,
-
-    /// Manages all workflows and WFT processing
-    workflows: Workflows,
-    /// Manages activity tasks for this worker/task queue
-    at_task_mgr: Option<WorkerActivityTasks>,
-    /// Manages local activities
-    local_act_mgr: Arc<LocalActivityManager>,
-    /// Has shutdown been called?
-    shutdown_token: CancellationToken,
-    /// Will be called at the end of each activation completion
-    #[allow(clippy::type_complexity)] // Sorry clippy, there's no simple way to re-use here.
-    post_activate_hook: Option<Box<dyn Fn(&Self, &str, usize) + Send + Sync>>,
+pub const NAMESPACE: &str = "default";
+pub const TEST_Q: &str = "q";
+/// The env var used to specify where the integ tests should point
+pub const INTEG_SERVER_TARGET_ENV_VAR: &str = "TEMPORAL_SERVICE_ADDRESS";
+pub const INTEG_USE_TLS_ENV_VAR: &str = "TEMPORAL_USE_TLS";
+/// This env var is set (to any value) if temporal CLI dev server is in use
+pub const INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR: &str = "INTEG_TEMPORAL_DEV_SERVER_ON";
+/// This env var is set (to any value) if the test server is in use
+pub const INTEG_TEST_SERVER_USED_ENV_VAR: &str = "INTEG_TEST_SERVER_ON";
+
+/// If set, turn export traces and metrics to the OTel collector at the given URL
+const OTEL_URL_ENV_VAR: &str = "TEMPORAL_INTEG_OTEL_URL";
+/// If set, enable direct scraping of prom metrics on the specified port
+const PROM_ENABLE_ENV_VAR: &str = "TEMPORAL_INTEG_PROM_PORT";
+#[macro_export]
+macro_rules! prost_dur {
+    ($dur_call:ident $args:tt) => {
+        std::time::Duration::$dur_call$args
+            .try_into()
+            .expect("test duration fits")
+    };
 }
 
-#[async_trait::async_trait]
-impl WorkerTrait for Worker {
-    async fn poll_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
-        self.next_workflow_activation().await
-    }
+/// Create a worker instance which will use the provided test name to base the task queue and wf id
+/// upon. Returns the instance and the task queue name (which is also the workflow id).
+pub async fn init_core_and_create_wf(test_name: &str) -> CoreWfStarter {
+    let mut starter = CoreWfStarter::new(test_name);
+    let _ = starter.get_worker().await;
+    starter.start_wf().await;
+    starter
+}
 
-    #[instrument(skip(self))]
-    async fn poll_activity_task(&self) -> Result<ActivityTask, PollActivityError> {
-        loop {
-            match self.activity_poll().await.transpose() {
-                Some(r) => break r,
-                None => {
-                    tokio::task::yield_now().await;
-                    continue;
-                }
-            }
+/// Create a worker replay instance preloaded with provided histories. Returns the worker impl.
+pub fn init_core_replay_preloaded<I>(test_name: &str, histories: I) -> Arc<dyn CoreWorker>
+where
+    I: IntoIterator<Item = HistoryForReplay> + 'static,
+    <I as IntoIterator>::IntoIter: Send,
+{
+    init_core_replay_stream(test_name, stream::iter(histories))
+}
+pub fn init_core_replay_stream<I>(test_name: &str, histories: I) -> Arc<dyn CoreWorker>
+where
+    I: Stream<Item = HistoryForReplay> + Send + 'static,
+{
+    init_integ_telem();
+    let worker_cfg = WorkerConfigBuilder::default()
+        .namespace(NAMESPACE)
+        .task_queue(test_name)
+        .worker_build_id("test_bin_id")
+        .build()
+        .expect("Configuration options construct properly");
+    let worker =
+        init_replay_worker(worker_cfg, histories).expect("Replay worker must init properly");
+    Arc::new(worker)
+}
+pub fn replay_sdk_worker<I>(histories: I) -> Worker
+where
+    I: IntoIterator<Item = HistoryForReplay> + 'static,
+    <I as IntoIterator>::IntoIter: Send,
+{
+    replay_sdk_worker_stream(stream::iter(histories))
+}
+pub fn replay_sdk_worker_stream<I>(histories: I) -> Worker
+where
+    I: Stream<Item = HistoryForReplay> + Send + 'static,
+{
+    let core = init_core_replay_stream("replay_worker_test", histories);
+    let mut worker = Worker::new_from_core(core, "replay_q".to_string());
+    worker.set_worker_interceptor(Box::new(FailOnNondeterminismInterceptor {}));
+    worker
+}
+
+/// Load history from a file containing the protobuf serialization of it
+pub async fn history_from_proto_binary(path_from_root: &str) -> Result<History, anyhow::Error> {
+    let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
+    path.push("..");
+    path.push(path_from_root);
+    let bytes = tokio::fs::read(path).await?;
+    Ok(History::decode(&*bytes)?)
+}
+
+static INTEG_TESTS_RT: once_cell::sync::OnceCell<CoreRuntime> = once_cell::sync::OnceCell::new();
+pub fn init_integ_telem() {
+    INTEG_TESTS_RT.get_or_init(|| {
+        let telemetry_options = get_integ_telem_options();
+        let rt =
+            CoreRuntime::new_assume_tokio(telemetry_options).expect("Core runtime inits cleanly");
+        let _ = tracing::subscriber::set_global_default(rt.trace_subscriber());
+        rt
+    });
+}
+
+/// Implements a builder pattern to help integ tests initialize core and create workflows
+pub struct CoreWfStarter {
+    /// Used for both the task queue and workflow id
+    task_queue_name: String,
+    pub worker_config: WorkerConfig,
+    /// Options to use when starting workflow(s)
+    pub workflow_options: WorkflowOptions,
+    initted_worker: OnceCell<InitializedWorker>,
+}
+struct InitializedWorker {
+    worker: Arc<dyn CoreWorker>,
+    client: Arc<RetryClient<Client>>,
+}
+
+impl CoreWfStarter {
+    pub fn new(test_name: &str) -> Self {
+        init_integ_telem();
+        let rand_bytes: Vec<u8> = rand::thread_rng().sample_iter(&Standard).take(6).collect();
+        let task_q_salt = BASE64_STANDARD.encode(rand_bytes);
+        let task_queue = format!("{test_name}_{task_q_salt}");
+        Self {
+            task_queue_name: task_queue.to_owned(),
+            worker_config: WorkerConfigBuilder::default()
+                .namespace(NAMESPACE)
+                .task_queue(task_queue)
+                .worker_build_id("test_build_id")
+                .max_cached_workflows(1000_usize)
+                .build()
+                .unwrap(),
+            initted_worker: OnceCell::new(),
+            workflow_options: Default::default(),
         }
     }
 
-    async fn complete_workflow_activation(
-        &self,
-        completion: WorkflowActivationCompletion,
-    ) -> Result<(), CompleteWfError> {
-        self.complete_workflow_activation(completion).await
+    pub async fn worker(&mut self) -> TestWorker {
+        let mut w = TestWorker::new(
+            self.get_worker().await,
+            self.worker_config.task_queue.clone(),
+        );
+        w.client = Some(self.get_client().await);
+
+        w
+    }
+
+    pub async fn shutdown(&mut self) {
+        self.get_worker().await.shutdown().await;
+    }
+
+    pub async fn get_worker(&mut self) -> Arc<dyn CoreWorker> {
+        self.get_or_init().await.worker.clone()
+    }
+
+    pub async fn get_client(&mut self) -> Arc<RetryClient<Client>> {
+        self.get_or_init().await.client.clone()
     }
 
-    async fn complete_activity_task(
+    /// Start the workflow defined by the builder and return run id
+    pub async fn start_wf(&mut self) -> String {
+        self.start_wf_with_id(self.task_queue_name.clone()).await
+    }
+
+    pub async fn start_with_worker(
         &self,
-        completion: ActivityTaskCompletion,
-    ) -> Result<(), CompleteActivityError> {
-        let task_token = TaskToken(completion.task_token);
-        let status = if let Some(s) = completion.result.and_then(|r| r.status) {
-            s
-        } else {
-            return Err(CompleteActivityError::MalformedActivityCompletion {
-                reason: "Activity completion had empty result/status field".to_owned(),
-                completion: None,
-            });
-        };
+        wf_name: impl Into<String>,
+        worker: &mut TestWorker,
+    ) -> String {
+        worker
+            .submit_wf(
+                self.task_queue_name.clone(),
+                wf_name.into(),
+                vec![],
+                self.workflow_options.clone(),
+            )
+            .await
+            .unwrap()
+    }
 
-        self.complete_activity(task_token, status).await
+    pub async fn start_wf_with_id(&self, workflow_id: String) -> String {
+        self.initted_worker
+            .get()
+            .expect(
+                "Worker must be initted before starting a workflow.\
+                             Tests must call `get_worker` first.",
+            )
+            .client
+            .start_workflow(
+                vec![],
+                self.worker_config.task_queue.clone(),
+                workflow_id,
+                self.task_queue_name.clone(),
+                None,
+                self.workflow_options.clone(),
+            )
+            .await
+            .unwrap()
+            .run_id
     }
 
-    fn record_activity_heartbeat(&self, details: ActivityHeartbeat) {
-        self.record_heartbeat(details);
+    /// Fetch the history for the indicated workflow and replay it using the provided worker.
+    /// Can be used after completing workflows normally to ensure replay works as well.
+    pub async fn fetch_history_and_replay(
+        &mut self,
+        wf_id: impl Into<String>,
+        run_id: impl Into<String>,
+        worker: &mut Worker,
+    ) -> Result<(), anyhow::Error> {
+        let wf_id = wf_id.into();
+        // Fetch history and replay it
+        let history = self
+            .get_client()
+            .await
+            .get_workflow_execution_history(wf_id.clone(), Some(run_id.into()), vec![])
+            .await?
+            .history
+            .expect("history field must be populated");
+        let with_id = HistoryForReplay::new(history, wf_id);
+        let replay_worker = init_core_replay_preloaded(worker.task_queue(), [with_id]);
+        worker.with_new_core_worker(replay_worker);
+        worker.set_worker_interceptor(Box::new(FailOnNondeterminismInterceptor {}));
+        worker.run().await.unwrap();
+        Ok(())
     }
 
-    fn request_workflow_eviction(&self, run_id: &str) {
-        self.request_wf_eviction(
-            run_id,
-            "Eviction explicitly requested by lang",
-            EvictionReason::LangRequested,
-        );
+    pub fn get_task_queue(&self) -> &str {
+        &self.worker_config.task_queue
     }
 
-    fn get_config(&self) -> &WorkerConfig {
-        &self.config
+    pub fn get_wf_id(&self) -> &str {
+        &self.task_queue_name
     }
 
-    /// Begins the shutdown process, tells pollers they should stop. Is idempotent.
-    fn initiate_shutdown(&self) {
-        self.shutdown_token.cancel();
-        // First, we want to stop polling of both activity and workflow tasks
-        if let Some(atm) = self.at_task_mgr.as_ref() {
-            atm.notify_shutdown();
-        }
-        info!(
-            task_queue=%self.config.task_queue,
-            namespace=%self.config.namespace,
-            "Initiated shutdown",
-        );
+    pub fn max_cached_workflows(&mut self, num: usize) -> &mut Self {
+        self.worker_config.max_cached_workflows = num;
+        self
     }
 
-    async fn shutdown(&self) {
-        self.shutdown().await
+    pub fn max_wft(&mut self, max: usize) -> &mut Self {
+        self.worker_config.max_outstanding_workflow_tasks = max;
+        self
     }
 
-    async fn finalize_shutdown(self) {
-        self.shutdown().await;
-        self.finalize_shutdown().await
+    pub fn max_at(&mut self, max: usize) -> &mut Self {
+        self.worker_config.max_outstanding_activities = max;
+        self
     }
-}
 
-impl Worker {
-    pub(crate) fn new(
-        config: WorkerConfig,
-        sticky_queue_name: Option<String>,
-        client: Arc<dyn WorkerClient>,
-        metrics: MetricsContext,
-    ) -> Self {
-        info!(task_queue=%config.task_queue,
-              namespace=%config.namespace,
-              "Initializing worker");
-        metrics.worker_registered();
-
-        let shutdown_token = CancellationToken::new();
-        let max_nonsticky_polls = if sticky_queue_name.is_some() {
-            config.max_nonsticky_polls()
-        } else {
-            config.max_concurrent_wft_polls
-        };
-        let max_sticky_polls = config.max_sticky_polls();
-        let wft_metrics = metrics.with_new_attrs([workflow_poller()]);
-        let mut wf_task_poll_buffer = new_workflow_task_buffer(
-            client.clone(),
-            config.task_queue.clone(),
-            false,
-            max_nonsticky_polls,
-            max_nonsticky_polls * 2,
-            shutdown_token.child_token(),
-        );
-        wf_task_poll_buffer.set_num_pollers_handler(move |np| wft_metrics.record_num_pollers(np));
-        let sticky_queue_poller = sticky_queue_name.as_ref().map(|sqn| {
-            let sticky_metrics = metrics.with_new_attrs([workflow_sticky_poller()]);
-            let mut sp = new_workflow_task_buffer(
-                client.clone(),
-                sqn.clone(),
-                true,
-                max_sticky_polls,
-                max_sticky_polls * 2,
-                shutdown_token.child_token(),
-            );
-            sp.set_num_pollers_handler(move |np| sticky_metrics.record_num_pollers(np));
-            sp
-        });
-        let act_poll_buffer = if config.no_remote_activities {
-            None
-        } else {
-            let mut ap = new_activity_task_buffer(
-                client.clone(),
-                config.task_queue.clone(),
-                config.max_concurrent_at_polls,
-                config.max_concurrent_at_polls * 2,
-                config.max_task_queue_activities_per_second,
-                shutdown_token.child_token(),
-            );
-            let act_metrics = metrics.with_new_attrs([activity_poller()]);
-            ap.set_num_pollers_handler(move |np| act_metrics.record_num_pollers(np));
-            Some(Box::from(ap)
-                as Box<
-                    dyn Poller<PollActivityTaskQueueResponse> + Send + Sync,
-                >)
-        };
-        let wf_task_poll_buffer = Box::new(WorkflowTaskPoller::new(
-            wf_task_poll_buffer,
-            sticky_queue_poller,
-        ));
-        let wft_stream = new_wft_poller(wf_task_poll_buffer, metrics.clone());
-        Self::new_with_pollers(
-            config,
-            sticky_queue_name,
-            client,
-            wft_stream,
-            act_poll_buffer,
-            metrics,
-            shutdown_token,
-        )
-    }
-
-    #[cfg(test)]
-    pub(crate) fn new_test(config: WorkerConfig, client: impl WorkerClient + 'static) -> Self {
-        Self::new(config, None, Arc::new(client), MetricsContext::no_op())
-    }
-
-    pub(crate) fn new_with_pollers(
-        config: WorkerConfig,
-        sticky_queue_name: Option<String>,
-        client: Arc<dyn WorkerClient>,
-        wft_stream: impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> + Send + 'static,
-        act_poller: Option<BoxedActPoller>,
-        metrics: MetricsContext,
-        shutdown_token: CancellationToken,
-    ) -> Self {
-        let local_act_mgr = Arc::new(LocalActivityManager::new(
-            config.max_outstanding_local_activities,
-            config.namespace.clone(),
-            metrics.with_new_attrs([local_activity_worker_type()]),
-        ));
-        let lam_clone = local_act_mgr.clone();
-        let local_act_req_sink = move |requests| lam_clone.enqueue(requests);
-        let at_task_mgr = act_poller.map(|ap| {
-            WorkerActivityTasks::new(
-                config.max_outstanding_activities,
-                config.max_worker_activities_per_second,
-                ap,
-                client.clone(),
-                metrics.clone(),
-                config.max_heartbeat_throttle_interval,
-                config.default_heartbeat_throttle_interval,
-            )
-        });
-        if at_task_mgr.is_none() {
-            info!("Activity polling is disabled for this worker");
-        }
-        Self {
-            wf_client: client.clone(),
-            workflows: Workflows::new(
-                WorkflowBasics {
-                    max_cached_workflows: config.max_cached_workflows,
-                    max_outstanding_wfts: config.max_outstanding_workflow_tasks,
-                    shutdown_token: shutdown_token.child_token(),
-                    metrics,
-                    namespace: config.namespace.clone(),
-                    task_queue: config.task_queue.clone(),
-                    ignore_evicts_on_shutdown: config.ignore_evicts_on_shutdown,
-                },
-                sticky_queue_name.map(|sq| StickyExecutionAttributes {
-                    worker_task_queue: Some(TaskQueue {
-                        name: sq,
-                        kind: TaskQueueKind::Sticky as i32,
-                    }),
-                    schedule_to_start_timeout: Some(
-                        config
-                            .sticky_queue_schedule_to_start_timeout
-                            .try_into()
-                            .expect("timeout fits into proto"),
-                    ),
-                }),
-                client,
-                wft_stream,
-                local_act_req_sink,
-                at_task_mgr
-                    .as_ref()
-                    .map(|mgr| mgr.get_handle_for_workflows()),
-            ),
-            at_task_mgr,
-            local_act_mgr,
-            config,
-            shutdown_token,
-            post_activate_hook: None,
-        }
+    pub fn max_local_at(&mut self, max: usize) -> &mut Self {
+        self.worker_config.max_outstanding_local_activities = max;
+        self
     }
 
-    /// Will shutdown the worker. Does not resolve until all outstanding workflow tasks have been
-    /// completed
-    async fn shutdown(&self) {
-        self.initiate_shutdown();
-        // Next we need to wait for all local activities to finish so no more workflow task
-        // heartbeats will be generated
-        self.local_act_mgr
-            .wait_all_outstanding_tasks_finished()
-            .await;
-        // Wait for workflows to finish
-        self.workflows
-            .shutdown()
-            .await
-            .expect("Workflow processing terminates cleanly");
-        // Wait for activities to finish
-        if let Some(acts) = self.at_task_mgr.as_ref() {
-            acts.wait_all_finished().await;
-        }
+    pub fn max_at_polls(&mut self, max: usize) -> &mut Self {
+        self.worker_config.max_concurrent_at_polls = max;
+        self
     }
 
-    /// Finish shutting down by consuming the background pollers and freeing all resources
-    async fn finalize_shutdown(self) {
-        if let Some(b) = self.at_task_mgr {
-            b.shutdown().await;
-        }
+    pub fn no_remote_activities(&mut self) -> &mut Self {
+        self.worker_config.no_remote_activities = true;
+        self
     }
 
-    pub(crate) fn shutdown_token(&self) -> CancellationToken {
-        self.shutdown_token.clone()
+    pub fn enable_wf_state_input_recording(&mut self) -> &mut Self {
+        let (ser_tx, ser_rx) = unbounded_channel();
+        let worker_cfg_clone = self.worker_config.clone();
+        tokio::spawn(async move {
+            stream_to_file(&worker_cfg_clone, ser_rx).await.unwrap();
+        });
+        self.worker_config.wf_state_inputs = Some(ser_tx);
+        self
     }
 
-    /// Returns number of currently cached workflows
-    pub async fn cached_workflows(&self) -> usize {
-        self.workflows
-            .get_state_info()
+    async fn get_or_init(&mut self) -> &InitializedWorker {
+        self.initted_worker
+            .get_or_init(|| async {
+                let client = Arc::new(
+                    get_integ_server_options()
+                        .connect(self.worker_config.namespace.clone(), None, None)
+                        .await
+                        .expect("Must connect"),
+                );
+                let worker = init_worker(
+                    INTEG_TESTS_RT.get().unwrap(),
+                    self.worker_config.clone(),
+                    client.clone(),
+                )
+                .expect("Worker inits cleanly");
+                InitializedWorker {
+                    worker: Arc::new(worker),
+                    client,
+                }
+            })
             .await
-            .map(|r| r.cached_workflows)
-            .unwrap_or_default()
     }
+}
 
-    /// Returns number of currently outstanding workflow tasks
-    #[cfg(test)]
-    pub(crate) async fn outstanding_workflow_tasks(&self) -> usize {
-        self.workflows
-            .get_state_info()
-            .await
-            .map(|r| r.outstanding_wft)
-            .unwrap_or_default()
+/// Provides conveniences for running integ tests with the SDK (against real server or mocks)
+pub struct TestWorker {
+    inner: Worker,
+    pub core_worker: Arc<dyn CoreWorker>,
+    client: Option<Arc<RetryClient<Client>>>,
+    pub started_workflows: Mutex<Vec<WorkflowExecutionInfo>>,
+    /// If set true (default), and a client is available, we will fetch workflow results to
+    /// determine when they have all completed.
+    pub fetch_results: bool,
+    iceptor: Option<TestWorkerCompletionIceptor>,
+}
+impl TestWorker {
+    /// Create a new test worker
+    pub fn new(core_worker: Arc<dyn CoreWorker>, task_queue: impl Into<String>) -> Self {
+        let inner = Worker::new_from_core(core_worker.clone(), task_queue);
+        let iceptor = TestWorkerCompletionIceptor::new(
+            TestWorkerShutdownCond::NoAutoShutdown,
+            Arc::new(inner.shutdown_handle()),
+        );
+        Self {
+            inner,
+            core_worker,
+            client: None,
+            started_workflows: Mutex::new(vec![]),
+            fetch_results: true,
+            iceptor: Some(iceptor),
+        }
     }
 
-    #[cfg(test)]
-    pub(crate) async fn available_wft_permits(&self) -> usize {
-        self.workflows
-            .get_state_info()
-            .await
-            .expect("You can only check for available permits before shutdown")
-            .available_wft_permits
+    pub fn inner_mut(&mut self) -> &mut Worker {
+        &mut self.inner
     }
 
-    /// Get new activity tasks (may be local or nonlocal). Local activities are returned first
-    /// before polling the server if there are any.
-    ///
-    /// Returns `Ok(None)` in the event of a poll timeout or if the polling loop should otherwise
-    /// be restarted
-    async fn activity_poll(&self) -> Result<Option<ActivityTask>, PollActivityError> {
-        let act_mgr_poll = async {
-            if let Some(ref act_mgr) = self.at_task_mgr {
-                act_mgr.poll().await
-            } else {
-                // We expect the local activity branch below to produce shutdown when appropriate if
-                // there are no activity pollers.
-                future::pending::<()>().await;
-                unreachable!()
-            }
-        };
+    // TODO: Maybe trait-ify?
+    pub fn register_wf<F: Into<WorkflowFunction>>(
+        &mut self,
+        workflow_type: impl Into<String>,
+        wf_function: F,
+    ) {
+        self.inner.register_wf(workflow_type, wf_function)
+    }
 
-        tokio::select! {
-            biased;
+    pub fn register_activity<A, R, O>(
+        &mut self,
+        activity_type: impl Into<String>,
+        act_function: impl IntoActivityFunc<A, R, O>,
+    ) {
+        self.inner.register_activity(activity_type, act_function)
+    }
 
-            r = self.local_act_mgr.next_pending() => {
-                match r {
-                    Some(DispatchOrTimeoutLA::Dispatch(r)) => Ok(Some(r)),
-                    Some(DispatchOrTimeoutLA::Timeout { run_id, resolution, task }) => {
-                        self.notify_local_result(
-                            &run_id, LocalResolution::LocalActivity(resolution));
-                        Ok(task)
-                    },
-                    None => {
-                        if self.shutdown_token.is_cancelled() {
-                            return Err(PollActivityError::ShutDown);
-                        }
-                        Ok(None)
-                    }
-                }
-            },
-            r = act_mgr_poll => r,
+    /// Create a workflow, asking the server to start it with the provided workflow ID and using the
+    /// provided workflow function.
+    ///
+    /// Increments the expected Workflow run count.
+    ///
+    /// Returns the run id of the started workflow
+    pub async fn submit_wf(
+        &self,
+        workflow_id: impl Into<String>,
+        workflow_type: impl Into<String>,
+        input: Vec<Payload>,
+        options: WorkflowOptions,
+    ) -> Result<String, anyhow::Error> {
+        if let Some(c) = self.client.as_ref() {
+            let wfid = workflow_id.into();
+            let res = c
+                .start_workflow(
+                    input,
+                    self.inner.task_queue().to_string(),
+                    wfid.clone(),
+                    workflow_type.into(),
+                    None,
+                    options,
+                )
+                .await?;
+            self.started_workflows.lock().push(WorkflowExecutionInfo {
+                namespace: c.namespace().to_string(),
+                workflow_id: wfid,
+                run_id: Some(res.run_id.clone()),
+            });
+            Ok(res.run_id)
+        } else {
+            Ok("fake_run_id".to_string())
         }
     }
 
-    /// Attempt to record an activity heartbeat
-    pub(crate) fn record_heartbeat(&self, details: ActivityHeartbeat) {
-        if let Some(at_mgr) = self.at_task_mgr.as_ref() {
-            let tt = details.task_token.clone();
-            if let Err(e) = at_mgr.record_heartbeat(details) {
-                warn!(task_token = ?tt, details = ?e, "Activity heartbeat failed.");
+    /// Runs until all expected workflows have completed
+    pub async fn run_until_done(&mut self) -> Result<(), anyhow::Error> {
+        self.run_until_done_intercepted(Option::<TestWorkerCompletionIceptor>::None)
+            .await
+    }
+
+    /// See [Self::run_until_done], but allows configuration of some low-level interception.
+    pub async fn run_until_done_intercepted(
+        &mut self,
+        interceptor: Option<impl WorkerInterceptor + 'static>,
+    ) -> Result<(), anyhow::Error> {
+        let mut iceptor = self.iceptor.take().unwrap();
+        // Automatically use results-based complete detection if we have a client
+        if self.fetch_results {
+            if let Some(c) = self.client.clone() {
+                iceptor.condition = TestWorkerShutdownCond::GetResults(
+                    std::mem::take(&mut self.started_workflows.lock()),
+                    c,
+                );
             }
         }
+        iceptor.next = interceptor.map(|i| Box::new(i) as Box<dyn WorkerInterceptor>);
+        let get_results_waiter = iceptor.wait_all_wfs();
+        self.inner.set_worker_interceptor(Box::new(iceptor));
+        tokio::try_join!(self.inner.run(), get_results_waiter)?;
+        Ok(())
     }
+}
 
-    #[instrument(skip(self, task_token, status),
-                 fields(task_token=%&task_token, status=%&status,
-                        task_queue=%self.config.task_queue, workflow_id, run_id))]
-    pub(crate) async fn complete_activity(
-        &self,
-        task_token: TaskToken,
-        status: activity_execution_result::Status,
-    ) -> Result<(), CompleteActivityError> {
-        validate_activity_completion(&status)?;
-        if task_token.is_local_activity_task() {
-            let as_la_res: LocalActivityExecutionResult = status.try_into()?;
-            match self.local_act_mgr.complete(&task_token, &as_la_res) {
-                LACompleteAction::Report(info) => self.complete_local_act(as_la_res, info, None),
-                LACompleteAction::LangDoesTimerBackoff(backoff, info) => {
-                    // This la needs to write a failure marker, and then we will tell lang how
-                    // long of a timer to schedule to back off for. We do this because there are
-                    // no other situations where core generates "internal" commands so it is much
-                    // simpler for lang to reply with the timer / next LA command than to do it
-                    // internally. Plus, this backoff hack we'd like to eliminate eventually.
-                    self.complete_local_act(as_la_res, info, Some(backoff));
-                }
-                LACompleteAction::WillBeRetried => {
-                    // Nothing to do here
-                }
-                LACompleteAction::Untracked => {
-                    warn!("Tried to complete untracked local activity {}", task_token);
-                }
-            }
-            return Ok(());
+pub type BoxDynActivationHook = Box<dyn Fn(&WorkflowActivationCompletion)>;
+
+pub enum TestWorkerShutdownCond {
+    GetResults(Vec<WorkflowExecutionInfo>, Arc<RetryClient<Client>>),
+    NoAutoShutdown,
+}
+/// Implements calling the shutdown handle when the expected number of test workflows has completed
+pub struct TestWorkerCompletionIceptor {
+    condition: TestWorkerShutdownCond,
+    shutdown_handle: Arc<dyn Fn()>,
+    every_activation: Option<BoxDynActivationHook>,
+    next: Option<Box<dyn WorkerInterceptor>>,
+}
+impl TestWorkerCompletionIceptor {
+    pub fn new(condition: TestWorkerShutdownCond, shutdown_handle: Arc<dyn Fn()>) -> Self {
+        Self {
+            condition,
+            shutdown_handle,
+            every_activation: None,
+            next: None,
         }
+    }
 
-        if let Some(atm) = &self.at_task_mgr {
-            atm.complete(task_token, status, &*self.wf_client).await;
+    fn wait_all_wfs(&mut self) -> impl Future<Output = Result<(), anyhow::Error>> + 'static {
+        if let TestWorkerShutdownCond::GetResults(ref mut wfs, ref client) = self.condition {
+            let wfs = std::mem::take(wfs);
+            let shutdown_h = self.shutdown_handle.clone();
+            let client = (**client).clone();
+            let stream = stream::iter(
+                wfs.into_iter()
+                    .map(move |info| info.bind_untyped(client.clone())),
+            )
+            .map(Ok);
+            future::Either::Left(async move {
+                stream
+                    .try_for_each_concurrent(None, |wh| async move {
+                        wh.get_workflow_result(Default::default()).await?;
+                        Ok::<_, anyhow::Error>(())
+                    })
+                    .await?;
+                shutdown_h();
+                Ok(())
+            })
         } else {
-            error!(
-                "Tried to complete activity {} on a worker that does not have an activity manager",
-                task_token
-            );
+            future::Either::Right(future::ready(Ok(())))
+        }
+    }
+}
+#[async_trait::async_trait(?Send)]
+impl WorkerInterceptor for TestWorkerCompletionIceptor {
+    async fn on_workflow_activation_completion(&self, completion: &WorkflowActivationCompletion) {
+        if let Some(func) = self.every_activation.as_ref() {
+            func(completion);
+        }
+        if completion.has_execution_ending() {
+            info!("Workflow {} says it's finishing", &completion.run_id);
+        }
+        if let Some(n) = self.next.as_ref() {
+            n.on_workflow_activation_completion(completion).await;
         }
-        Ok(())
     }
 
-    #[instrument(skip(self), fields(run_id, workflow_id, task_queue=%self.config.task_queue))]
-    pub(crate) async fn next_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
-        let r = self.workflows.next_workflow_activation().await;
-        // In the event workflows are shutdown, begin shutdown of everything else, since that's
-        // about to happen anyway. Tell the local activity manager that, so that it can know to
-        // cancel any remaining outstanding LAs and shutdown.
-        if matches!(r, Err(PollWfError::ShutDown)) {
-            self.initiate_shutdown();
-            self.local_act_mgr.workflows_have_shutdown();
-        }
-        r
-    }
-
-    #[instrument(skip(self, completion),
-                 fields(completion=%&completion, run_id=%completion.run_id, workflow_id,
-                        task_queue=%self.config.task_queue))]
-    pub(crate) async fn complete_workflow_activation(
-        &self,
-        completion: WorkflowActivationCompletion,
-    ) -> Result<(), CompleteWfError> {
-        let run_id = completion.run_id.clone();
-        let most_recent_event = self.workflows.activation_completed(completion).await?;
-        if let Some(h) = &self.post_activate_hook {
-            h(self, &run_id, most_recent_event);
+    fn on_shutdown(&self, sdk_worker: &Worker) {
+        if let Some(n) = self.next.as_ref() {
+            n.on_shutdown(sdk_worker);
         }
-        Ok(())
     }
+}
 
-    /// Request a workflow eviction
-    pub(crate) fn request_wf_eviction(
-        &self,
-        run_id: &str,
-        message: impl Into<String>,
-        reason: EvictionReason,
-    ) {
-        self.workflows.request_eviction(run_id, message, reason);
+/// Returns the client options used to connect to the server used for integration tests.
+pub fn get_integ_server_options() -> ClientOptions {
+    let temporal_server_address = match env::var(INTEG_SERVER_TARGET_ENV_VAR) {
+        Ok(addr) => addr,
+        Err(_) => "http://localhost:7233".to_owned(),
+    };
+    let url = Url::try_from(&*temporal_server_address).unwrap();
+    let mut cb = ClientOptionsBuilder::default();
+    cb.identity("integ_tester".to_string())
+        .target_url(url)
+        .client_name("temporal-core".to_string())
+        .client_version("0.1.0".to_string());
+    if let Some(tls) = get_integ_tls_config() {
+        cb.tls_cfg(tls);
+    };
+    cb.build().unwrap()
+}
+
+pub fn get_integ_tls_config() -> Option<TlsConfig> {
+    if env::var(INTEG_USE_TLS_ENV_VAR).is_ok() {
+        let root = std::fs::read("../.cloud_certs/ca.pem").unwrap();
+        let client_cert = std::fs::read("../.cloud_certs/client.pem").unwrap();
+        let client_private_key = std::fs::read("../.cloud_certs/client.key").unwrap();
+        Some(TlsConfig {
+            server_root_ca_cert: Some(root),
+            domain: None,
+            client_tls_config: Some(ClientTlsConfig {
+                client_cert,
+                client_private_key,
+            }),
+        })
+    } else {
+        None
     }
+}
 
-    /// Sets a function to be called at the end of each activation completion
-    pub(crate) fn set_post_activate_hook(
-        &mut self,
-        callback: impl Fn(&Self, &str, usize) + Send + Sync + 'static,
-    ) {
-        self.post_activate_hook = Some(Box::new(callback))
+pub fn get_integ_telem_options() -> TelemetryOptions {
+    let mut ob = TelemetryOptionsBuilder::default();
+    let filter_string =
+        env::var("RUST_LOG").unwrap_or_else(|_| "temporal_sdk_core=INFO".to_string());
+    if let Some(url) = env::var(OTEL_URL_ENV_VAR)
+        .ok()
+        .map(|x| x.parse::<Url>().unwrap())
+    {
+        let opts = OtelCollectorOptions {
+            url,
+            headers: Default::default(),
+            metric_periodicity: None,
+        };
+        ob.tracing(TraceExportConfig {
+            filter: filter_string.clone(),
+            exporter: TraceExporter::Otel(opts.clone()),
+        });
+        ob.metrics(MetricsExporter::Otel(opts));
     }
+    if let Some(addr) = env::var(PROM_ENABLE_ENV_VAR)
+        .ok()
+        .map(|x| SocketAddr::new([127, 0, 0, 1].into(), x.parse().unwrap()))
+    {
+        ob.metrics(MetricsExporter::Prometheus(addr));
+    }
+    ob.logging(Logger::Console {
+        filter: filter_string,
+    })
+    .build()
+    .unwrap()
+}
 
-    fn complete_local_act(
-        &self,
-        la_res: LocalActivityExecutionResult,
-        info: LocalInFlightActInfo,
-        backoff: Option<prost_types::Duration>,
-    ) {
-        self.notify_local_result(
-            &info.la_info.workflow_exec_info.run_id,
-            LocalResolution::LocalActivity(LocalActivityResolution {
-                seq: info.la_info.schedule_cmd.seq,
-                result: la_res,
-                runtime: info.dispatch_time.elapsed(),
-                attempt: info.attempt,
-                backoff,
-                original_schedule_time: info.la_info.schedule_cmd.original_schedule_time,
-            }),
-        )
+pub fn default_cached_download() -> EphemeralExe {
+    EphemeralExe::CachedDownload {
+        version: EphemeralExeVersion::SDKDefault {
+            sdk_name: "sdk-rust".to_string(),
+            sdk_version: "0.1.0".to_string(),
+        },
+        dest_dir: None,
     }
+}
+
+pub fn schedule_activity_cmd(
+    seq: u32,
+    task_q: &str,
+    activity_id: &str,
+    cancellation_type: ActivityCancellationType,
+    activity_timeout: Duration,
+    heartbeat_timeout: Duration,
+) -> workflow_command::Variant {
+    ScheduleActivity {
+        seq,
+        activity_id: activity_id.to_string(),
+        activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+        task_queue: task_q.to_owned(),
+        schedule_to_start_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        start_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        schedule_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        heartbeat_timeout: Some(heartbeat_timeout.try_into().expect("duration fits")),
+        cancellation_type: cancellation_type as i32,
+        ..Default::default()
+    }
+    .into()
+}
+
+pub fn schedule_local_activity_cmd(
+    seq: u32,
+    activity_id: &str,
+    cancellation_type: ActivityCancellationType,
+    activity_timeout: Duration,
+) -> workflow_command::Variant {
+    ScheduleLocalActivity {
+        seq,
+        activity_id: activity_id.to_string(),
+        activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+        schedule_to_start_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        start_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        schedule_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
+        cancellation_type: cancellation_type as i32,
+        ..Default::default()
+    }
+    .into()
+}
 
-    fn notify_local_result(&self, run_id: &str, res: LocalResolution) {
-        self.workflows.notify_of_local_result(run_id, res);
+pub fn start_timer_cmd(seq: u32, duration: Duration) -> workflow_command::Variant {
+    StartTimer {
+        seq,
+        start_to_fire_timeout: Some(duration.try_into().expect("duration fits")),
     }
+    .into()
 }
 
-#[cfg(test)]
-mod tests {
-    use super::*;
-    use crate::{test_help::test_worker_cfg, worker::client::mocks::mock_workflow_client};
-    use temporal_sdk_core_protos::temporal::api::workflowservice::v1::PollActivityTaskQueueResponse;
-
-    #[tokio::test]
-    async fn activity_timeouts_dont_eat_permits() {
-        let mut mock_client = mock_workflow_client();
-        mock_client
-            .expect_poll_activity_task()
-            .returning(|_, _| Ok(PollActivityTaskQueueResponse::default()));
-
-        let cfg = test_worker_cfg()
-            .max_outstanding_activities(5_usize)
-            .build()
-            .unwrap();
-        let worker = Worker::new_test(cfg, mock_client);
-        assert_eq!(worker.activity_poll().await.unwrap(), None);
-        assert_eq!(worker.at_task_mgr.unwrap().remaining_activity_capacity(), 5);
-    }
-
-    #[tokio::test]
-    async fn activity_errs_dont_eat_permits() {
-        let mut mock_client = mock_workflow_client();
-        mock_client
-            .expect_poll_activity_task()
-            .returning(|_, _| Err(tonic::Status::internal("ahhh")));
-
-        let cfg = test_worker_cfg()
-            .max_outstanding_activities(5_usize)
-            .build()
-            .unwrap();
-        let worker = Worker::new_test(cfg, mock_client);
-        assert!(worker.activity_poll().await.is_err());
-        assert_eq!(worker.at_task_mgr.unwrap().remaining_activity_capacity(), 5);
-    }
-
-    #[test]
-    fn max_polls_calculated_properly() {
-        let mut wcb = WorkerConfigBuilder::default();
-        let cfg = wcb
-            .namespace("default")
-            .task_queue("whatever")
-            .worker_build_id("test_bin_id")
-            .max_concurrent_wft_polls(5_usize)
-            .build()
-            .unwrap();
-        assert_eq!(cfg.max_nonsticky_polls(), 1);
-        assert_eq!(cfg.max_sticky_polls(), 4);
-    }
-
-    #[test]
-    fn max_polls_zero_is_err() {
-        assert!(test_worker_cfg()
-            .max_concurrent_wft_polls(0_usize)
-            .build()
-            .is_err());
+/// Given a desired number of concurrent executions and a provided function that produces a future,
+/// run that many instances of the future concurrently.
+///
+/// Annoyingly, because of a sorta-bug in the way async blocks work, the async block produced by
+/// the closure must be `async move` if it uses the provided iteration number. On the plus side,
+/// since you're usually just accessing core in the closure, if core is a reference everything just
+/// works. See <https://github.com/rust-lang/rust/issues/81653>
+pub async fn fanout_tasks<FutureMaker, Fut>(num: usize, fm: FutureMaker)
+where
+    FutureMaker: Fn(usize) -> Fut,
+    Fut: Future,
+{
+    let mut tasks = FuturesUnordered::new();
+    for i in 0..num {
+        tasks.push(fm(i));
     }
+
+    while tasks.next().await.is_some() {}
+}
+
+#[async_trait::async_trait]
+pub trait WorkerTestHelpers {
+    async fn complete_execution(&self, run_id: &str);
+    async fn complete_timer(&self, run_id: &str, seq: u32, duration: Duration);
+}
+
+#[async_trait::async_trait]
+impl<T> WorkerTestHelpers for T
+where
+    T: CoreWorker + ?Sized,
+{
+    async fn complete_execution(&self, run_id: &str) {
+        self.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+            run_id.to_string(),
+            vec![CompleteWorkflowExecution { result: None }.into()],
+        ))
+        .await
+        .unwrap();
+    }
+
+    async fn complete_timer(&self, run_id: &str, seq: u32, duration: Duration) {
+        self.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+            run_id.to_string(),
+            vec![StartTimer {
+                seq,
+                start_to_fire_timeout: Some(duration.try_into().expect("duration fits")),
+            }
+            .into()],
+        ))
+        .await
+        .unwrap();
+    }
+}
+
+/// Initiate shutdown, drain the pollers, and wait for shutdown to complete.
+pub async fn drain_pollers_and_shutdown(worker: &Arc<dyn CoreWorker>) {
+    worker.initiate_shutdown();
+    tokio::join!(
+        async {
+            assert!(matches!(
+                worker.poll_activity_task().await.unwrap_err(),
+                PollActivityError::ShutDown
+            ));
+        },
+        async {
+            assert!(matches!(
+                worker.poll_workflow_activation().await.unwrap_err(),
+                PollWfError::ShutDown,
+            ));
+        }
+    );
+    worker.shutdown().await;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/bridge.rs`

 * *Files 4% similar despite different names*

```diff
@@ -21,17 +21,15 @@
                 incoming_commands: rx,
             },
             tx,
         )
     }
 }
 
-#[async_trait::async_trait]
 impl WorkflowFetcher for WorkflowBridge {
-    async fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
+    fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
         let in_cmds = self.incoming_commands.try_recv();
-
         let in_cmds = in_cmds.unwrap_or_else(|_| vec![WFCommand::NoCommandsFromLang]);
         debug!(in_cmds = %in_cmds.display(), "wf bridge iteration fetch");
         in_cmds
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/activity_state_machine.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,29 +1,30 @@
 #![allow(clippy::large_enum_variant)]
 
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
+use crate::{
+    internal_flags::CoreInternalFlags,
+    worker::workflow::{machines::HistEventData, InternalFlagsRef},
+};
 use rustfsm::{fsm, MachineError, StateMachine, TransitionResult};
 use std::convert::{TryFrom, TryInto};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{self as ar, activity_resolution, ActivityResolution, Cancellation},
         workflow_activation::ResolveActivity,
         workflow_commands::{ActivityCancellationType, ScheduleActivity},
     },
     temporal::api::{
         command::v1::{command, Command, RequestCancelActivityTaskCommandAttributes},
         common::v1::{ActivityType, Payload, Payloads},
         enums::v1::{CommandType, EventType, RetryState},
-        failure::v1::{
-            self as failure, failure::FailureInfo, ActivityFailureInfo, CanceledFailureInfo,
-            Failure,
-        },
+        failure::v1::{failure::FailureInfo, ActivityFailureInfo, CanceledFailureInfo, Failure},
         history::v1::{
             history_event, ActivityTaskCanceledEventAttributes,
             ActivityTaskCompletedEventAttributes, ActivityTaskFailedEventAttributes,
             ActivityTaskTimedOutEventAttributes, HistoryEvent,
         },
     },
 };
@@ -33,32 +34,32 @@
     command ActivityMachineCommand;
     error WFMachinesError;
     shared_state SharedState;
 
     Created --(Schedule, on_schedule)--> ScheduleCommandCreated;
 
     ScheduleCommandCreated --(CommandScheduleActivityTask) --> ScheduleCommandCreated;
-    ScheduleCommandCreated --(ActivityTaskScheduled(i64),
+    ScheduleCommandCreated --(ActivityTaskScheduled(ActTaskScheduledData),
         shared on_activity_task_scheduled) --> ScheduledEventRecorded;
     ScheduleCommandCreated --(Cancel, shared on_canceled) --> Canceled;
 
     ScheduledEventRecorded --(ActivityTaskStarted(i64), shared on_task_started) --> Started;
     ScheduledEventRecorded --(ActivityTaskTimedOut(ActivityTaskTimedOutEventAttributes),
         shared on_task_timed_out) --> TimedOut;
     ScheduledEventRecorded --(Cancel, shared on_canceled) --> ScheduledActivityCancelCommandCreated;
-    ScheduledEventRecorded --(Abandon, shared on_abandoned) --> Canceled;
+    ScheduledEventRecorded --(Abandon, on_abandoned) --> Canceled;
 
     Started --(ActivityTaskCompleted(ActivityTaskCompletedEventAttributes),
         on_activity_task_completed) --> Completed;
     Started --(ActivityTaskFailed(ActivityTaskFailedEventAttributes),
         shared on_activity_task_failed) --> Failed;
     Started --(ActivityTaskTimedOut(ActivityTaskTimedOutEventAttributes),
         shared on_activity_task_timed_out) --> TimedOut;
     Started --(Cancel, shared on_canceled) --> StartedActivityCancelCommandCreated;
-    Started --(Abandon, shared on_abandoned) --> Canceled;
+    Started --(Abandon, on_abandoned) --> Canceled;
 
     ScheduledActivityCancelCommandCreated --(CommandRequestCancelActivityTask) --> ScheduledActivityCancelCommandCreated;
     ScheduledActivityCancelCommandCreated --(ActivityTaskCancelRequested) --> ScheduledActivityCancelEventRecorded;
 
     ScheduledActivityCancelEventRecorded --(ActivityTaskCanceled(ActivityTaskCanceledEventAttributes),
         shared on_activity_task_canceled) --> Canceled;
     ScheduledActivityCancelEventRecorded --(ActivityTaskStarted(i64)) --> StartedActivityCancelEventRecorded;
@@ -85,155 +86,158 @@
 #[derive(Debug, derive_more::Display)]
 pub(super) enum ActivityMachineCommand {
     #[display(fmt = "Complete")]
     Complete(Option<Payloads>),
     #[display(fmt = "Fail")]
     Fail(Failure),
     #[display(fmt = "Cancel")]
-    Cancel(Option<Payloads>),
+    Cancel(Option<ActivityTaskCanceledEventAttributes>),
     #[display(fmt = "RequestCancellation")]
     RequestCancellation(Command),
 }
 
-/// Creates a new activity state machine and a command to schedule it on the server.
-pub(super) fn new_activity(attribs: ScheduleActivity) -> NewMachineWithCommand {
-    let (activity, add_cmd) = ActivityMachine::new_scheduled(attribs);
-    NewMachineWithCommand {
-        command: add_cmd,
-        machine: activity.into(),
-    }
+pub(super) struct ActTaskScheduledData {
+    event_id: i64,
+    act_type: String,
+    act_id: String,
+    last_task_in_history: bool,
 }
 
 impl ActivityMachine {
     /// Create a new activity and immediately schedule it.
-    fn new_scheduled(attribs: ScheduleActivity) -> (Self, Command) {
-        let mut s = Self {
-            state: Created {}.into(),
-            shared_state: SharedState {
-                cancellation_type: ActivityCancellationType::from_i32(attribs.cancellation_type)
+    pub(super) fn new_scheduled(
+        attrs: ScheduleActivity,
+        internal_flags: InternalFlagsRef,
+    ) -> NewMachineWithCommand {
+        let mut s = Self::from_parts(
+            Created {}.into(),
+            SharedState {
+                cancellation_type: ActivityCancellationType::from_i32(attrs.cancellation_type)
                     .unwrap(),
-                attrs: attribs,
-                ..Default::default()
+                attrs,
+                internal_flags,
+                scheduled_event_id: 0,
+                started_event_id: 0,
+                cancelled_before_sent: false,
             },
-        };
+        );
         OnEventWrapper::on_event_mut(&mut s, ActivityMachineEvents::Schedule)
             .expect("Scheduling activities doesn't fail");
-        let cmd = Command {
+        let command = Command {
             command_type: CommandType::ScheduleActivityTask as i32,
             attributes: Some(s.shared_state().attrs.clone().into()),
         };
-        (s, cmd)
+        NewMachineWithCommand {
+            command,
+            machine: s.into(),
+        }
     }
 
     fn machine_responses_from_cancel_request(&self, cancel_cmd: Command) -> Vec<MachineResponse> {
         let mut r = vec![MachineResponse::IssueNewCommand(cancel_cmd)];
         if self.shared_state.cancellation_type
             != ActivityCancellationType::WaitCancellationCompleted
         {
             r.push(MachineResponse::PushWFJob(
                 self.create_cancelation_resolve(None).into(),
             ));
         }
         r
     }
 
-    fn create_cancelation_resolve(&self, details: Option<Payload>) -> ResolveActivity {
+    fn create_cancelation_resolve(
+        &self,
+        attrs: Option<ActivityTaskCanceledEventAttributes>,
+    ) -> ResolveActivity {
+        let attrs = attrs.unwrap_or_default();
         ResolveActivity {
             seq: self.shared_state.attrs.seq,
             result: Some(ActivityResolution {
                 status: Some(activity_resolution::Status::Cancelled(Cancellation {
-                    failure: Some(Failure {
-                        message: "Activity cancelled".to_string(),
-                        cause: Some(Box::from(Failure {
-                            failure_info: Some(FailureInfo::CanceledFailureInfo(
-                                CanceledFailureInfo {
-                                    details: details.map(Into::into),
-                                },
-                            )),
-                            ..Default::default()
-                        })),
-                        failure_info: Some(FailureInfo::ActivityFailureInfo(ActivityFailureInfo {
-                            scheduled_event_id: self.shared_state.scheduled_event_id,
-                            started_event_id: self.shared_state.started_event_id,
-                            activity_type: Some(ActivityType {
-                                name: self.shared_state.attrs.activity_type.clone(),
-                            }),
-                            activity_id: self.shared_state.attrs.activity_id.clone(),
-                            retry_state: RetryState::CancelRequested as i32,
-                            ..Default::default()
-                        })),
-                        ..Default::default()
-                    }),
+                    failure: Some(new_cancel_failure(&self.shared_state, attrs)),
                 })),
             }),
         }
     }
 }
 
-impl TryFrom<HistoryEvent> for ActivityMachineEvents {
+impl TryFrom<HistEventData> for ActivityMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let last_task_in_history = e.current_task_is_last_in_history;
+        let e = e.event;
         Ok(match e.event_type() {
-            EventType::ActivityTaskScheduled => Self::ActivityTaskScheduled(e.event_id),
+            EventType::ActivityTaskScheduled => {
+                if let Some(history_event::Attributes::ActivityTaskScheduledEventAttributes(
+                    attrs,
+                )) = e.attributes
+                {
+                    Self::ActivityTaskScheduled(ActTaskScheduledData {
+                        event_id: e.event_id,
+                        act_id: attrs.activity_id,
+                        act_type: attrs.activity_type.unwrap_or_default().name,
+                        last_task_in_history,
+                    })
+                } else {
+                    return Err(WFMachinesError::Fatal(format!(
+                        "Activity scheduled attributes were unset: {e}"
+                    )));
+                }
+            }
             EventType::ActivityTaskStarted => Self::ActivityTaskStarted(e.event_id),
             EventType::ActivityTaskCompleted => {
                 if let Some(history_event::Attributes::ActivityTaskCompletedEventAttributes(
                     attrs,
                 )) = e.attributes
                 {
                     Self::ActivityTaskCompleted(attrs)
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Activity completion attributes were unset: {}",
-                        e
+                        "Activity completion attributes were unset: {e}"
                     )));
                 }
             }
             EventType::ActivityTaskFailed => {
                 if let Some(history_event::Attributes::ActivityTaskFailedEventAttributes(attrs)) =
                     e.attributes
                 {
                     Self::ActivityTaskFailed(attrs)
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Activity failure attributes were unset: {}",
-                        e
+                        "Activity failure attributes were unset: {e}"
                     )));
                 }
             }
             EventType::ActivityTaskTimedOut => {
                 if let Some(history_event::Attributes::ActivityTaskTimedOutEventAttributes(attrs)) =
                     e.attributes
                 {
                     Self::ActivityTaskTimedOut(attrs)
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Activity timeout attributes were unset: {}",
-                        e
+                        "Activity timeout attributes were unset: {e}"
                     )));
                 }
             }
             EventType::ActivityTaskCancelRequested => Self::ActivityTaskCancelRequested,
             EventType::ActivityTaskCanceled => {
                 if let Some(history_event::Attributes::ActivityTaskCanceledEventAttributes(attrs)) =
                     e.attributes
                 {
                     Self::ActivityTaskCanceled(attrs)
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Activity cancellation attributes were unset: {}",
-                        e
+                        "Activity cancellation attributes were unset: {e}"
                     )));
                 }
             }
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Activity machine does not handle this event: {}",
-                    e
+                    "Activity machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl WFMachinesAdapter for ActivityMachine {
@@ -264,18 +268,16 @@
                     }),
                 }
                 .into()]
             }
             ActivityMachineCommand::RequestCancellation(c) => {
                 self.machine_responses_from_cancel_request(c)
             }
-            ActivityMachineCommand::Cancel(details) => {
-                vec![self
-                    .create_cancelation_resolve(convert_payloads(event_info, details)?)
-                    .into()]
+            ActivityMachineCommand::Cancel(attrs) => {
+                vec![self.create_cancelation_resolve(attrs).into()]
             }
         })
     }
 
     fn matches_event(&self, event: &HistoryEvent) -> bool {
         matches!(
             event.event_type(),
@@ -326,41 +328,35 @@
         let res = vec
             .into_iter()
             .flat_map(|amc| match amc {
                 ActivityMachineCommand::RequestCancellation(cmd) => {
                     self.machine_responses_from_cancel_request(cmd)
                 }
                 ActivityMachineCommand::Cancel(details) => {
-                    vec![self
-                        .create_cancelation_resolve(
-                            details
-                                .map(TryInto::try_into)
-                                .transpose()
-                                .unwrap_or_default(),
-                        )
-                        .into()]
+                    vec![self.create_cancelation_resolve(details).into()]
                 }
-                x => panic!("Invalid cancel event response {:?}", x),
+                x => panic!("Invalid cancel event response {x:?}"),
             })
             .collect();
         Ok(res)
     }
 
     fn was_cancelled_before_sent_to_server(&self) -> bool {
         self.shared_state().cancelled_before_sent
     }
 }
 
-#[derive(Default, Clone)]
+#[derive(Clone)]
 pub(super) struct SharedState {
     scheduled_event_id: i64,
     started_event_id: i64,
     attrs: ScheduleActivity,
     cancellation_type: ActivityCancellationType,
     cancelled_before_sent: bool,
+    internal_flags: InternalFlagsRef,
 }
 
 #[derive(Default, Clone)]
 pub(super) struct Created {}
 
 impl Created {
     pub(super) fn on_schedule(self) -> ActivityMachineTransition<ScheduleCommandCreated> {
@@ -371,77 +367,80 @@
 
 #[derive(Default, Clone)]
 pub(super) struct ScheduleCommandCreated {}
 
 impl ScheduleCommandCreated {
     pub(super) fn on_activity_task_scheduled(
         self,
-        dat: SharedState,
-        scheduled_event_id: i64,
+        dat: &mut SharedState,
+        sched_dat: ActTaskScheduledData,
     ) -> ActivityMachineTransition<ScheduledEventRecorded> {
-        ActivityMachineTransition::ok_shared(
-            vec![],
-            ScheduledEventRecorded::default(),
-            SharedState {
-                scheduled_event_id,
-                ..dat
-            },
-        )
+        if dat.internal_flags.borrow_mut().try_use(
+            CoreInternalFlags::IdAndTypeDeterminismChecks,
+            sched_dat.last_task_in_history,
+        ) {
+            if sched_dat.act_id != dat.attrs.activity_id {
+                return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
+                    "Activity id of scheduled event '{}' does not \
+                 match activity id of activity command '{}'",
+                    sched_dat.act_id, dat.attrs.activity_id
+                )));
+            }
+            if sched_dat.act_type != dat.attrs.activity_type {
+                return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
+                    "Activity type of scheduled event '{}' does not \
+                 match activity type of activity command '{}'",
+                    sched_dat.act_type, dat.attrs.activity_type
+                )));
+            }
+        }
+        dat.scheduled_event_id = sched_dat.event_id;
+        ActivityMachineTransition::default()
     }
-    pub(super) fn on_canceled(self, dat: SharedState) -> ActivityMachineTransition<Canceled> {
-        let canceled_state = SharedState {
-            cancelled_before_sent: true,
-            ..dat
-        };
+
+    pub(super) fn on_canceled(self, dat: &mut SharedState) -> ActivityMachineTransition<Canceled> {
+        dat.cancelled_before_sent = true;
         match dat.cancellation_type {
-            ActivityCancellationType::Abandon => {
-                ActivityMachineTransition::ok_shared(vec![], Canceled::default(), canceled_state)
-            }
-            _ => notify_lang_activity_cancelled(canceled_state, None),
+            ActivityCancellationType::Abandon => ActivityMachineTransition::default(),
+            _ => notify_lang_activity_cancelled(None),
         }
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct ScheduledEventRecorded {}
 
 impl ScheduledEventRecorded {
     pub(super) fn on_task_started(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         started_event_id: i64,
     ) -> ActivityMachineTransition<Started> {
-        ActivityMachineTransition::ok_shared(
-            vec![],
-            Started::default(),
-            SharedState {
-                started_event_id,
-                ..dat
-            },
-        )
+        dat.started_event_id = started_event_id;
+        ActivityMachineTransition::default()
     }
     pub(super) fn on_task_timed_out(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskTimedOutEventAttributes,
     ) -> ActivityMachineTransition<TimedOut> {
         notify_lang_activity_timed_out(dat, attrs)
     }
 
     pub(super) fn on_canceled(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
     ) -> ActivityMachineTransition<ScheduledActivityCancelCommandCreated> {
         create_request_cancel_activity_task_command(
             dat,
             ScheduledActivityCancelCommandCreated::default(),
         )
     }
-    pub(super) fn on_abandoned(self, dat: SharedState) -> ActivityMachineTransition<Canceled> {
-        notify_lang_activity_cancelled(dat, None)
+    pub(super) fn on_abandoned(self) -> ActivityMachineTransition<Canceled> {
+        notify_lang_activity_cancelled(None)
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct Started {}
 
 impl Started {
@@ -452,63 +451,63 @@
         ActivityMachineTransition::ok(
             vec![ActivityMachineCommand::Complete(attrs.result)],
             Completed::default(),
         )
     }
     pub(super) fn on_activity_task_failed(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskFailedEventAttributes,
     ) -> ActivityMachineTransition<Failed> {
         ActivityMachineTransition::ok(
             vec![ActivityMachineCommand::Fail(new_failure(dat, attrs))],
             Failed::default(),
         )
     }
 
     pub(super) fn on_activity_task_timed_out(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskTimedOutEventAttributes,
     ) -> ActivityMachineTransition<TimedOut> {
         notify_lang_activity_timed_out(dat, attrs)
     }
 
     pub(super) fn on_canceled(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
     ) -> ActivityMachineTransition<StartedActivityCancelCommandCreated> {
         create_request_cancel_activity_task_command(
             dat,
             StartedActivityCancelCommandCreated::default(),
         )
     }
-    pub(super) fn on_abandoned(self, dat: SharedState) -> ActivityMachineTransition<Canceled> {
-        notify_lang_activity_cancelled(dat, None)
+    pub(super) fn on_abandoned(self) -> ActivityMachineTransition<Canceled> {
+        notify_lang_activity_cancelled(None)
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct ScheduledActivityCancelCommandCreated {}
 
 #[derive(Default, Clone)]
 pub(super) struct ScheduledActivityCancelEventRecorded {}
 
 impl ScheduledActivityCancelEventRecorded {
     pub(super) fn on_activity_task_canceled(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskCanceledEventAttributes,
     ) -> ActivityMachineTransition<Canceled> {
-        notify_if_not_already_cancelled(dat, |dat| notify_lang_activity_cancelled(dat, Some(attrs)))
+        notify_if_not_already_cancelled(dat, |_| notify_lang_activity_cancelled(Some(attrs)))
     }
 
     pub(super) fn on_activity_task_timed_out(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskTimedOutEventAttributes,
     ) -> ActivityMachineTransition<TimedOut> {
         notify_if_not_already_cancelled(dat, |dat| notify_lang_activity_timed_out(dat, attrs))
     }
 }
 
 impl From<ScheduledActivityCancelCommandCreated> for ScheduledActivityCancelEventRecorded {
@@ -522,49 +521,49 @@
 
 #[derive(Default, Clone)]
 pub(super) struct StartedActivityCancelEventRecorded {}
 
 impl StartedActivityCancelEventRecorded {
     pub(super) fn on_activity_task_completed(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskCompletedEventAttributes,
     ) -> ActivityMachineTransition<Completed> {
         notify_if_not_already_cancelled(dat, |_| {
             TransitionResult::commands(vec![ActivityMachineCommand::Complete(attrs.result)])
         })
     }
     pub(super) fn on_activity_task_failed(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskFailedEventAttributes,
     ) -> ActivityMachineTransition<Failed> {
         notify_if_not_already_cancelled(dat, |dat| {
             TransitionResult::commands(vec![ActivityMachineCommand::Fail(new_failure(dat, attrs))])
         })
     }
     pub(super) fn on_activity_task_timed_out(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskTimedOutEventAttributes,
     ) -> ActivityMachineTransition<TimedOut> {
         notify_if_not_already_cancelled(dat, |dat| notify_lang_activity_timed_out(dat, attrs))
     }
     pub(super) fn on_activity_task_canceled(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskCanceledEventAttributes,
     ) -> ActivityMachineTransition<Canceled> {
-        notify_if_not_already_cancelled(dat, |dat| notify_lang_activity_cancelled(dat, Some(attrs)))
+        notify_if_not_already_cancelled(dat, |_| notify_lang_activity_cancelled(Some(attrs)))
     }
 }
 
 fn notify_if_not_already_cancelled<S>(
-    dat: SharedState,
-    notifier: impl FnOnce(SharedState) -> ActivityMachineTransition<S>,
+    dat: &mut SharedState,
+    notifier: impl FnOnce(&mut SharedState) -> ActivityMachineTransition<S>,
 ) -> ActivityMachineTransition<S>
 where
     S: Into<ActivityMachineState> + Default,
 {
     match &dat.cancellation_type {
         // At this point if we are in TryCancel mode, we've already sent a cancellation failure
         // to lang unblocking it, so there is no need to send another activation.
@@ -635,47 +634,45 @@
 pub(super) struct TimedOut {}
 
 #[derive(Default, Clone)]
 pub(super) struct Canceled {}
 impl Canceled {
     pub(super) fn on_activity_task_started(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         seq_num: i64,
     ) -> ActivityMachineTransition<Canceled> {
         // Abandoned activities might start anyway. Ignore the result.
         if dat.cancellation_type == ActivityCancellationType::Abandon {
             TransitionResult::default()
         } else {
             TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
                 "Non-Abandon cancel mode activities cannot be started after being cancelled. \
-                 Seq: {:?}",
-                seq_num
+                 Seq: {seq_num:?}"
             )))
         }
     }
     pub(super) fn on_activity_task_completed(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: ActivityTaskCompletedEventAttributes,
     ) -> ActivityMachineTransition<Canceled> {
         // Abandoned activities might complete anyway. Ignore the result.
         if dat.cancellation_type == ActivityCancellationType::Abandon {
             TransitionResult::default()
         } else {
             TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
-                "Non-Abandon cancel mode activities cannot be completed after being cancelled: {:?}",
-                attrs
+                "Non-Abandon cancel mode activities cannot be completed after being cancelled: {attrs:?}"
             )))
         }
     }
 }
 
 fn create_request_cancel_activity_task_command<S>(
-    dat: SharedState,
+    dat: &mut SharedState,
     next_state: S,
 ) -> ActivityMachineTransition<S>
 where
     S: Into<ActivityMachineState>,
 {
     let cmd = Command {
         command_type: CommandType::RequestCancelActivityTask as i32,
@@ -692,106 +689,129 @@
         next_state,
     )
 }
 
 /// Notifies lang side that activity has timed out by sending a failure with timeout error as a cause.
 /// State machine will transition into the TimedOut state.
 fn notify_lang_activity_timed_out(
-    dat: SharedState,
+    dat: &SharedState,
     attrs: ActivityTaskTimedOutEventAttributes,
 ) -> TransitionResult<ActivityMachine, TimedOut> {
-    ActivityMachineTransition::ok_shared(
-        vec![ActivityMachineCommand::Fail(new_timeout_failure(
-            &dat, attrs,
-        ))],
-        TimedOut::default(),
-        dat,
-    )
+    ActivityMachineTransition::commands(vec![ActivityMachineCommand::Fail(new_timeout_failure(
+        dat, attrs,
+    ))])
 }
 
-/// Notifies lang side that activity has been cancelled by sending a failure with cancelled failure
-/// as a cause. Optional cancelled_event, if passed, is used to supply event IDs. State machine will
-/// transition into the `next_state` provided as a parameter.
+/// Returns the transition to indicate activity has been cancelled by sending a failure with
+/// cancelled failure as a cause. Optional cancelled_event, if passed, is used to supply event IDs.
 fn notify_lang_activity_cancelled(
-    dat: SharedState,
     canceled_event: Option<ActivityTaskCanceledEventAttributes>,
 ) -> ActivityMachineTransition<Canceled> {
-    ActivityMachineTransition::ok_shared(
-        vec![ActivityMachineCommand::Cancel(
-            canceled_event.and_then(|e| e.details),
-        )],
-        Canceled::default(),
-        dat,
-    )
+    ActivityMachineTransition::commands(vec![ActivityMachineCommand::Cancel(canceled_event)])
 }
 
-fn new_failure(dat: SharedState, attrs: ActivityTaskFailedEventAttributes) -> Failure {
+fn new_failure(dat: &SharedState, attrs: ActivityTaskFailedEventAttributes) -> Failure {
+    let rs = attrs.retry_state();
     Failure {
         message: "Activity task failed".to_owned(),
         cause: attrs.failure.map(Box::new),
-        failure_info: Some(FailureInfo::ActivityFailureInfo(
-            failure::ActivityFailureInfo {
-                identity: attrs.identity,
-                activity_type: Some(ActivityType {
-                    name: dat.attrs.activity_type,
-                }),
-                activity_id: dat.attrs.activity_id,
-                retry_state: attrs.retry_state,
-                started_event_id: attrs.started_event_id,
-                scheduled_event_id: attrs.scheduled_event_id,
-            },
+        failure_info: Some(activity_fail_info(
+            dat.attrs.activity_type.clone(),
+            dat.attrs.activity_id.clone(),
+            Some(attrs.identity),
+            rs,
+            attrs.started_event_id,
+            attrs.scheduled_event_id,
         )),
         ..Default::default()
     }
 }
 
 fn new_timeout_failure(dat: &SharedState, attrs: ActivityTaskTimedOutEventAttributes) -> Failure {
-    let failure_info = ActivityFailureInfo {
-        activity_id: dat.attrs.activity_id.to_string(),
-        activity_type: Some(ActivityType {
-            name: dat.attrs.activity_type.to_string(),
-        }),
-        scheduled_event_id: attrs.scheduled_event_id,
-        started_event_id: attrs.started_event_id,
-        retry_state: attrs.retry_state,
-        ..Default::default()
-    };
+    let rs = attrs.retry_state();
     Failure {
         message: "Activity task timed out".to_string(),
         cause: attrs.failure.map(Box::new),
-        failure_info: Some(FailureInfo::ActivityFailureInfo(failure_info)),
+        failure_info: Some(activity_fail_info(
+            dat.attrs.activity_type.clone(),
+            dat.attrs.activity_id.clone(),
+            None,
+            rs,
+            attrs.started_event_id,
+            attrs.scheduled_event_id,
+        )),
         ..Default::default()
     }
 }
 
+fn new_cancel_failure(dat: &SharedState, attrs: ActivityTaskCanceledEventAttributes) -> Failure {
+    Failure {
+        message: "Activity cancelled".to_string(),
+        cause: Some(Box::from(Failure {
+            failure_info: Some(FailureInfo::CanceledFailureInfo(CanceledFailureInfo {
+                details: attrs.details.map(Into::into),
+            })),
+            ..Default::default()
+        })),
+        failure_info: Some(activity_fail_info(
+            dat.attrs.activity_type.clone(),
+            dat.attrs.activity_id.clone(),
+            Some(attrs.identity),
+            RetryState::CancelRequested,
+            attrs.started_event_id,
+            attrs.scheduled_event_id,
+        )),
+        ..Default::default()
+    }
+}
+
+pub fn activity_fail_info(
+    act_type: String,
+    act_id: String,
+    identity: Option<String>,
+    retry_state: RetryState,
+    started_event_id: i64,
+    scheduled_event_id: i64,
+) -> FailureInfo {
+    FailureInfo::ActivityFailureInfo(ActivityFailureInfo {
+        identity: identity.unwrap_or_default(),
+        activity_type: Some(ActivityType { name: act_type }),
+        activity_id: act_id,
+        retry_state: retry_state as i32,
+        started_event_id,
+        scheduled_event_id,
+    })
+}
+
 fn convert_payloads(
     event_info: Option<EventInfo>,
     result: Option<Payloads>,
 ) -> Result<Option<Payload>, WFMachinesError> {
     result.map(TryInto::try_into).transpose().map_err(|pe| {
         WFMachinesError::Fatal(format!(
-            "Not exactly one payload in activity result ({}) for event: {:?}",
-            pe, event_info
+            "Not exactly one payload in activity result ({pe}) for event: {event_info:?}"
         ))
     })
 }
 
 #[cfg(test)]
 mod test {
     use super::*;
     use crate::{
-        replay::TestHistoryBuilder, test_help::canned_histories, worker::workflow::ManagedWFFunc,
+        internal_flags::InternalFlags, replay::TestHistoryBuilder, test_help::canned_histories,
+        worker::workflow::ManagedWFFunc,
     };
     use rstest::{fixture, rstest};
-    use std::mem::discriminant;
+    use std::{cell::RefCell, mem::discriminant, rc::Rc};
     use temporal_sdk::{
         ActivityOptions, CancellableFuture, WfContext, WorkflowFunction, WorkflowResult,
     };
-    use temporal_sdk_core_protos::coresdk::workflow_activation::{
-        workflow_activation_job, WorkflowActivationJob,
+    use temporal_sdk_core_protos::{
+        coresdk::workflow_activation::{workflow_activation_job, WorkflowActivationJob},
+        DEFAULT_ACTIVITY_TYPE,
     };
 
     #[fixture]
     fn activity_happy_hist() -> ManagedWFFunc {
         let func = WorkflowFunction::new(activity_wf);
         let t = canned_histories::single_activity("activity-id-1");
         assert_eq!(2, t.get_full_history_info().unwrap().wf_task_count());
@@ -803,15 +823,21 @@
         let func = WorkflowFunction::new(activity_wf);
         let t = canned_histories::single_failed_activity("activity-id-1");
         assert_eq!(2, t.get_full_history_info().unwrap().wf_task_count());
         ManagedWFFunc::new(t, func, vec![])
     }
 
     async fn activity_wf(command_sink: WfContext) -> WorkflowResult<()> {
-        command_sink.activity(ActivityOptions::default()).await;
+        command_sink
+            .activity(ActivityOptions {
+                activity_id: Some("activity-id-1".to_string()),
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+                ..Default::default()
+            })
+            .await;
         Ok(().into())
     }
 
     #[rstest(
         wfm,
         case::success(activity_happy_hist()),
         case::failure(activity_failure_hist())
@@ -891,17 +917,24 @@
     fn cancels_ignored_terminal() {
         for state in [
             ActivityMachineState::Canceled(Canceled {}),
             Failed {}.into(),
             TimedOut {}.into(),
             Completed {}.into(),
         ] {
-            let mut s = ActivityMachine {
-                state: state.clone(),
-                shared_state: Default::default(),
-            };
+            let mut s = ActivityMachine::from_parts(
+                state.clone(),
+                SharedState {
+                    scheduled_event_id: 0,
+                    started_event_id: 0,
+                    attrs: Default::default(),
+                    cancellation_type: Default::default(),
+                    cancelled_before_sent: false,
+                    internal_flags: Rc::new(RefCell::new(InternalFlags::new(&Default::default()))),
+                },
+            );
             let cmds = s.cancel().unwrap();
             assert_eq!(cmds.len(), 0);
-            assert_eq!(discriminant(&state), discriminant(&s.state));
+            assert_eq!(discriminant(&state), discriminant(s.state()));
         }
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_external_state_machine.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::{
         common::NamespacedWorkflowExecution,
         workflow_activation::ResolveRequestCancelExternalWorkflow,
     },
     temporal::api::{
@@ -56,18 +57,15 @@
 
 pub(super) fn new_external_cancel(
     seq: u32,
     workflow_execution: NamespacedWorkflowExecution,
     only_child: bool,
     reason: String,
 ) -> NewMachineWithCommand {
-    let mut s = CancelExternalMachine {
-        state: Created {}.into(),
-        shared_state: SharedState { seq },
-    };
+    let mut s = CancelExternalMachine::from_parts(Created {}.into(), SharedState { seq });
     OnEventWrapper::on_event_mut(&mut s, CancelExternalMachineEvents::Schedule)
         .expect("Scheduling cancel external wf command doesn't fail");
     let cmd_attrs = command::Attributes::RequestCancelExternalWorkflowExecutionCommandAttributes(
         RequestCancelExternalWorkflowExecutionCommandAttributes {
             namespace: workflow_execution.namespace,
             workflow_id: workflow_execution.workflow_id,
             run_id: workflow_execution.run_id,
@@ -141,39 +139,38 @@
                 Ok(Self::CommandRequestCancelExternalWorkflowExecution)
             }
             _ => Err(()),
         }
     }
 }
 
-impl TryFrom<HistoryEvent> for CancelExternalMachineEvents {
+impl TryFrom<HistEventData> for CancelExternalMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::ExternalWorkflowExecutionCancelRequested => {
                 Self::ExternalWorkflowExecutionCancelRequested
             }
             EventType::RequestCancelExternalWorkflowExecutionInitiated => {
                 Self::RequestCancelExternalWorkflowExecutionInitiated
             }
             EventType::RequestCancelExternalWorkflowExecutionFailed => {
                 if let Some(history_event::Attributes::RequestCancelExternalWorkflowExecutionFailedEventAttributes(attrs)) = e.attributes {
                     Self::RequestCancelExternalWorkflowExecutionFailed(attrs.cause())
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Cancelworkflow failed attributes were unset: {}",
-                        e
+                        "Cancelworkflow failed attributes were unset: {e}"
                     )));
                 }
             }
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Cancel external WF machine does not handle this event: {}",
-                    e
+                    "Cancel external WF machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl WFMachinesAdapter for CancelExternalMachine {
@@ -195,15 +192,15 @@
                     CancelExternalWorkflowExecutionFailedCause::Unspecified => "unknown",
                     CancelExternalWorkflowExecutionFailedCause::ExternalWorkflowExecutionNotFound
                     | CancelExternalWorkflowExecutionFailedCause::NamespaceNotFound  => "not found"
                 };
                 vec![ResolveRequestCancelExternalWorkflow {
                     seq: self.shared_state.seq,
                     failure: Some(Failure {
-                        message: format!("Unable to cancel external workflow because {}", reason),
+                        message: format!("Unable to cancel external workflow because {reason}"),
                         failure_info: Some(FailureInfo::ApplicationFailureInfo(
                             ApplicationFailureInfo {
                                 r#type: f.to_string(),
                                 ..Default::default()
                             },
                         )),
                         ..Default::default()
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/cancel_workflow_state_machine.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, HistoryEvent,
     NewMachineWithCommand, OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::CancelWorkflowExecution,
     temporal::api::{
         command::v1::Command,
         enums::v1::{CommandType, EventType},
     },
@@ -29,18 +30,15 @@
 #[derive(thiserror::Error, Debug)]
 pub(super) enum CancelWorkflowMachineError {}
 
 #[derive(Debug, derive_more::Display)]
 pub(super) enum CancelWorkflowCommand {}
 
 pub(super) fn cancel_workflow(attribs: CancelWorkflowExecution) -> NewMachineWithCommand {
-    let mut machine = CancelWorkflowMachine {
-        state: Created {}.into(),
-        shared_state: (),
-    };
+    let mut machine = CancelWorkflowMachine::from_parts(Created {}.into(), ());
     OnEventWrapper::on_event_mut(&mut machine, CancelWorkflowMachineEvents::Schedule)
         .expect("Scheduling continue as new machine doesn't fail");
     let command = Command {
         command_type: CommandType::CancelWorkflowExecution as i32,
         attributes: Some(attribs.into()),
     };
     NewMachineWithCommand {
@@ -68,24 +66,24 @@
     pub(super) fn on_schedule(
         self,
     ) -> CancelWorkflowMachineTransition<CancelWorkflowCommandCreated> {
         TransitionResult::default()
     }
 }
 
-impl TryFrom<HistoryEvent> for CancelWorkflowMachineEvents {
+impl TryFrom<HistEventData> for CancelWorkflowMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match EventType::from_i32(e.event_type) {
             Some(EventType::WorkflowExecutionCanceled) => Self::WorkflowExecutionCanceled,
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Cancel workflow machine does not handle this event: {}",
-                    e
+                    "Cancel workflow machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for CancelWorkflowMachineEvents {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/child_workflow_state_machine.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,16 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, MachineError, TransitionResult};
+use crate::{
+    internal_flags::CoreInternalFlags,
+    worker::workflow::{machines::HistEventData, InternalFlagsRef},
+};
+use rustfsm::{fsm, MachineError, StateMachine, TransitionResult};
 use std::convert::{TryFrom, TryInto};
 use temporal_sdk_core_protos::{
     coresdk::{
         child_workflow::{
             self as wfr, child_workflow_result::Status as ChildWorkflowStatus,
             ChildWorkflowCancellationType, ChildWorkflowResult,
         },
@@ -37,15 +41,15 @@
     pub(super) name ChildWorkflowMachine;
     command ChildWorkflowCommand;
     error WFMachinesError;
     shared_state SharedState;
 
     Created --(Schedule, on_schedule) --> StartCommandCreated;
     StartCommandCreated --(CommandStartChildWorkflowExecution) --> StartCommandCreated;
-    StartCommandCreated --(StartChildWorkflowExecutionInitiated(i64),
+    StartCommandCreated --(StartChildWorkflowExecutionInitiated(ChildWorkflowInitiatedData),
         shared on_start_child_workflow_execution_initiated) --> StartEventRecorded;
     StartCommandCreated --(Cancel, shared on_cancelled) --> Cancelled;
 
     StartEventRecorded --(ChildWorkflowExecutionStarted(ChildWorkflowExecutionStartedEvent),
         shared on_child_workflow_execution_started) --> Started;
     StartEventRecorded --(StartChildWorkflowExecutionFailed(StartChildWorkflowExecutionFailedCause),
         on_start_child_workflow_execution_failed) --> StartFailed;
@@ -66,14 +70,16 @@
     Started --(Cancel, shared on_cancelled) --> Started;
     // Abandon & try cancel modes may immediately move to cancelled
     Started --(Cancel, shared on_cancelled) --> Cancelled;
     Started --(CommandRequestCancelExternalWorkflowExecution) --> Started;
 
     // Ignore any spurious cancellations after resolution
     Cancelled --(Cancel) --> Cancelled;
+    Cancelled --(ChildWorkflowExecutionCancelled,
+        on_child_workflow_execution_cancelled) --> Cancelled;
     Failed --(Cancel) --> Failed;
     StartFailed --(Cancel) --> StartFailed;
     TimedOut --(Cancel) --> TimedOut;
     Completed --(Cancel) --> Completed;
 }
 
 pub struct ChildWorkflowExecutionStartedEvent {
@@ -95,16 +101,46 @@
     StartFail(StartChildWorkflowExecutionFailedCause),
     #[display(fmt = "StartCancel")]
     StartCancel(Failure),
     #[display(fmt = "CancelAfterStarted")]
     IssueCancelAfterStarted { reason: String },
 }
 
+pub(super) struct ChildWorkflowInitiatedData {
+    event_id: i64,
+    wf_type: String,
+    wf_id: String,
+    last_task_in_history: bool,
+}
+
 #[derive(Default, Clone)]
-pub(super) struct Cancelled {}
+pub(super) struct Cancelled {
+    seen_cancelled_event: bool,
+}
+
+impl Cancelled {
+    pub(super) fn on_child_workflow_execution_cancelled(
+        self,
+    ) -> ChildWorkflowMachineTransition<Cancelled> {
+        if self.seen_cancelled_event {
+            ChildWorkflowMachineTransition::Err(WFMachinesError::Fatal(
+                "Child workflow has already seen a ChildWorkflowExecutionCanceledEvent, and now \
+                 another is being applied! This is a bug, please report."
+                    .to_string(),
+            ))
+        } else {
+            ChildWorkflowMachineTransition::ok(
+                [],
+                Cancelled {
+                    seen_cancelled_event: true,
+                },
+            )
+        }
+    }
+}
 
 #[derive(Default, Clone)]
 pub(super) struct Completed {}
 
 #[derive(Default, Clone)]
 pub(super) struct Created {}
 
@@ -119,75 +155,75 @@
 
 #[derive(Default, Clone)]
 pub(super) struct StartCommandCreated {}
 
 impl StartCommandCreated {
     pub(super) fn on_start_child_workflow_execution_initiated(
         self,
-        state: SharedState,
-        initiated_event_id: i64,
+        state: &mut SharedState,
+        event_dat: ChildWorkflowInitiatedData,
     ) -> ChildWorkflowMachineTransition<StartEventRecorded> {
-        ChildWorkflowMachineTransition::ok_shared(
-            vec![],
-            StartEventRecorded::default(),
-            SharedState {
-                initiated_event_id,
-                ..state
-            },
-        )
+        if state.internal_flags.borrow_mut().try_use(
+            CoreInternalFlags::IdAndTypeDeterminismChecks,
+            event_dat.last_task_in_history,
+        ) {
+            if event_dat.wf_id != state.workflow_id {
+                return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
+                    "Child workflow id of scheduled event '{}' does not \
+                     match child workflow id of activity command '{}'",
+                    event_dat.wf_id, state.workflow_id
+                )));
+            }
+            if event_dat.wf_type != state.workflow_type {
+                return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
+                    "Child workflow type of scheduled event '{}' does not \
+                     match child workflow type of activity command '{}'",
+                    event_dat.wf_type, state.workflow_type
+                )));
+            }
+        }
+        state.initiated_event_id = event_dat.event_id;
+        ChildWorkflowMachineTransition::default()
     }
 
     pub(super) fn on_cancelled(
         self,
-        state: SharedState,
+        state: &mut SharedState,
     ) -> ChildWorkflowMachineTransition<Cancelled> {
-        let state = SharedState {
-            cancelled_before_sent: true,
-            ..state
-        };
-        ChildWorkflowMachineTransition::ok_shared(
-            vec![ChildWorkflowCommand::StartCancel(Failure {
-                message: "Child Workflow execution cancelled before scheduled".to_owned(),
-                cause: Some(Box::new(Failure {
-                    failure_info: Some(FailureInfo::CanceledFailureInfo(
-                        failure::CanceledFailureInfo {
-                            ..Default::default()
-                        },
-                    )),
-                    ..Default::default()
-                })),
-                failure_info: failure_info_from_state(&state, RetryState::NonRetryableFailure),
+        state.cancelled_before_sent = true;
+        ChildWorkflowMachineTransition::commands(vec![ChildWorkflowCommand::StartCancel(Failure {
+            message: "Child Workflow execution cancelled before scheduled".to_owned(),
+            cause: Some(Box::new(Failure {
+                failure_info: Some(FailureInfo::CanceledFailureInfo(
+                    failure::CanceledFailureInfo {
+                        ..Default::default()
+                    },
+                )),
                 ..Default::default()
-            })],
-            Cancelled::default(),
-            state,
-        )
+            })),
+            failure_info: failure_info_from_state(state, RetryState::NonRetryableFailure),
+            ..Default::default()
+        })])
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct StartEventRecorded {}
 
 impl StartEventRecorded {
     pub(super) fn on_child_workflow_execution_started(
         self,
-        state: SharedState,
+        state: &mut SharedState,
         event: ChildWorkflowExecutionStartedEvent,
     ) -> ChildWorkflowMachineTransition<Started> {
-        ChildWorkflowMachineTransition::ok_shared(
-            vec![ChildWorkflowCommand::Start(
-                event.workflow_execution.clone(),
-            )],
-            Started::default(),
-            SharedState {
-                started_event_id: event.started_event_id,
-                run_id: event.workflow_execution.run_id,
-                ..state
-            },
-        )
+        state.started_event_id = event.started_event_id;
+        state.run_id = event.workflow_execution.run_id.clone();
+        ChildWorkflowMachineTransition::commands(vec![ChildWorkflowCommand::Start(
+            event.workflow_execution,
+        )])
     }
     pub(super) fn on_start_child_workflow_execution_failed(
         self,
         cause: StartChildWorkflowExecutionFailedCause,
     ) -> ChildWorkflowMachineTransition<StartFailed> {
         ChildWorkflowMachineTransition::ok(
             vec![ChildWorkflowCommand::StartFail(cause)],
@@ -210,30 +246,30 @@
         ChildWorkflowMachineTransition::ok(
             vec![ChildWorkflowCommand::Complete(result)],
             Completed::default(),
         )
     }
     fn on_child_workflow_execution_failed(
         self,
-        state: SharedState,
+        state: &mut SharedState,
         attrs: ChildWorkflowExecutionFailedEventAttributes,
     ) -> ChildWorkflowMachineTransition<Failed> {
         ChildWorkflowMachineTransition::ok(
             vec![ChildWorkflowCommand::Fail(Failure {
                 message: "Child Workflow execution failed".to_owned(),
-                failure_info: failure_info_from_state(&state, attrs.retry_state()),
+                failure_info: failure_info_from_state(state, attrs.retry_state()),
                 cause: attrs.failure.map(Box::new),
                 ..Default::default()
             })],
             Failed::default(),
         )
     }
     fn on_child_workflow_execution_timed_out(
         self,
-        state: SharedState,
+        state: &mut SharedState,
         retry_state: RetryState,
     ) -> ChildWorkflowMachineTransition<TimedOut> {
         ChildWorkflowMachineTransition::ok(
             vec![ChildWorkflowCommand::Fail(Failure {
                 message: "Child Workflow execution timed out".to_owned(),
                 cause: Some(Box::new(Failure {
                     message: "Timed out".to_owned(),
@@ -241,46 +277,51 @@
                         failure::TimeoutFailureInfo {
                             last_heartbeat_details: None,
                             timeout_type: TimeoutType::StartToClose as i32,
                         },
                     )),
                     ..Default::default()
                 })),
-                failure_info: failure_info_from_state(&state, retry_state),
+                failure_info: failure_info_from_state(state, retry_state),
                 ..Default::default()
             })],
             TimedOut::default(),
         )
     }
     fn on_child_workflow_execution_cancelled(self) -> ChildWorkflowMachineTransition<Cancelled> {
-        ChildWorkflowMachineTransition::ok(vec![ChildWorkflowCommand::Cancel], Cancelled::default())
+        ChildWorkflowMachineTransition::ok(
+            vec![ChildWorkflowCommand::Cancel],
+            Cancelled {
+                seen_cancelled_event: true,
+            },
+        )
     }
     fn on_child_workflow_execution_terminated(
         self,
-        state: SharedState,
+        state: &mut SharedState,
     ) -> ChildWorkflowMachineTransition<Terminated> {
         ChildWorkflowMachineTransition::ok(
             vec![ChildWorkflowCommand::Fail(Failure {
                 message: "Child Workflow execution terminated".to_owned(),
                 cause: Some(Box::new(Failure {
                     message: "Terminated".to_owned(),
                     failure_info: Some(FailureInfo::TerminatedFailureInfo(
                         failure::TerminatedFailureInfo {},
                     )),
                     ..Default::default()
                 })),
-                failure_info: failure_info_from_state(&state, RetryState::NonRetryableFailure),
+                failure_info: failure_info_from_state(state, RetryState::NonRetryableFailure),
                 ..Default::default()
             })],
             Terminated::default(),
         )
     }
     fn on_cancelled(
         self,
-        state: SharedState,
+        state: &mut SharedState,
     ) -> ChildWorkflowMachineTransition<StartedOrCancelled> {
         let dest = match state.cancel_type {
             ChildWorkflowCancellationType::Abandon | ChildWorkflowCancellationType::TryCancel => {
                 StartedOrCancelled::Cancelled(Default::default())
             }
             _ => StartedOrCancelled::Started(Default::default()),
         };
@@ -295,57 +336,59 @@
 
 #[derive(Default, Clone)]
 pub(super) struct Terminated {}
 
 #[derive(Default, Clone)]
 pub(super) struct TimedOut {}
 
-#[derive(Default, Clone, Debug)]
+#[derive(Clone, Debug)]
 pub(super) struct SharedState {
     initiated_event_id: i64,
     started_event_id: i64,
     lang_sequence_number: u32,
     namespace: String,
     workflow_id: String,
     run_id: String,
     workflow_type: String,
     cancelled_before_sent: bool,
     cancel_type: ChildWorkflowCancellationType,
-}
-
-/// Creates a new child workflow state machine and a command to start it on the server.
-pub(super) fn new_child_workflow(attribs: StartChildWorkflowExecution) -> NewMachineWithCommand {
-    let (wf, add_cmd) = ChildWorkflowMachine::new_scheduled(attribs);
-    NewMachineWithCommand {
-        command: add_cmd,
-        machine: wf.into(),
-    }
+    internal_flags: InternalFlagsRef,
 }
 
 impl ChildWorkflowMachine {
     /// Create a new child workflow and immediately schedule it.
-    pub(crate) fn new_scheduled(attribs: StartChildWorkflowExecution) -> (Self, Command) {
-        let mut s = Self {
-            state: Created {}.into(),
-            shared_state: SharedState {
+    pub(super) fn new_scheduled(
+        attribs: StartChildWorkflowExecution,
+        internal_flags: InternalFlagsRef,
+    ) -> NewMachineWithCommand {
+        let mut s = Self::from_parts(
+            Created {}.into(),
+            SharedState {
                 lang_sequence_number: attribs.seq,
                 workflow_id: attribs.workflow_id.clone(),
                 workflow_type: attribs.workflow_type.clone(),
                 namespace: attribs.namespace.clone(),
                 cancel_type: attribs.cancellation_type(),
-                ..Default::default()
+                internal_flags,
+                run_id: "".to_string(),
+                initiated_event_id: 0,
+                started_event_id: 0,
+                cancelled_before_sent: false,
             },
-        };
+        );
         OnEventWrapper::on_event_mut(&mut s, ChildWorkflowMachineEvents::Schedule)
             .expect("Scheduling child workflows doesn't fail");
         let cmd = Command {
             command_type: CommandType::StartChildWorkflowExecution as i32,
             attributes: Some(attribs.into()),
         };
-        (s, cmd)
+        NewMachineWithCommand {
+            command: cmd,
+            machine: s.into(),
+        }
     }
 
     fn resolve_cancelled_msg(&self) -> ResolveChildWorkflowExecution {
         let failure = Failure {
             message: "Child Workflow execution cancelled".to_owned(),
             cause: Some(Box::new(Failure {
                 failure_info: Some(FailureInfo::CanceledFailureInfo(
@@ -368,21 +411,39 @@
                     failure: Some(failure),
                 })),
             }),
         }
     }
 }
 
-impl TryFrom<HistoryEvent> for ChildWorkflowMachineEvents {
+impl TryFrom<HistEventData> for ChildWorkflowMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let last_task_in_history = e.current_task_is_last_in_history;
+        let e = e.event;
         Ok(match EventType::from_i32(e.event_type) {
             Some(EventType::StartChildWorkflowExecutionInitiated) => {
-                Self::StartChildWorkflowExecutionInitiated(e.event_id)
+                if let Some(
+                    history_event::Attributes::StartChildWorkflowExecutionInitiatedEventAttributes(
+                        attrs,
+                    ),
+                ) = e.attributes
+                {
+                    Self::StartChildWorkflowExecutionInitiated(ChildWorkflowInitiatedData {
+                        event_id: e.event_id,
+                        wf_type: attrs.workflow_type.unwrap_or_default().name,
+                        wf_id: attrs.workflow_id,
+                        last_task_in_history,
+                    })
+                } else {
+                    return Err(WFMachinesError::Fatal(
+                        "StartChildWorkflowExecutionInitiated attributes were unset".to_string(),
+                    ));
+                }
             }
             Some(EventType::StartChildWorkflowExecutionFailed) => {
                 if let Some(
                     history_event::Attributes::StartChildWorkflowExecutionFailedEventAttributes(
                         StartChildWorkflowExecutionFailedEventAttributes { cause, .. },
                     ),
                 ) = e.attributes
@@ -466,17 +527,16 @@
             Some(EventType::ChildWorkflowExecutionTerminated) => {
                 Self::ChildWorkflowExecutionTerminated
             }
             Some(EventType::ChildWorkflowExecutionCanceled) => {
                 Self::ChildWorkflowExecutionCancelled
             }
             _ => {
-                return Err(WFMachinesError::Fatal(format!(
-                    "Child workflow machine does not handle this event: {:?}",
-                    e
+                return Err(WFMachinesError::Nondeterminism(format!(
+                    "Child workflow machine does not handle this event: {e:?}"
                 )))
             }
         })
     }
 }
 
 impl WFMachinesAdapter for ChildWorkflowMachine {
@@ -608,15 +668,15 @@
         let res = vec
             .into_iter()
             .map(|mc| match mc {
                 c @ ChildWorkflowCommand::StartCancel(_)
                 | c @ ChildWorkflowCommand::IssueCancelAfterStarted { .. } => {
                     self.adapt_response(c, None)
                 }
-                x => panic!("Invalid cancel event response {:?}", x),
+                x => panic!("Invalid cancel event response {x:?}"),
             })
             .collect::<Result<Vec<_>, _>>()?
             .into_iter()
             .flatten()
             .collect();
         Ok(res)
     }
@@ -646,29 +706,29 @@
 
 fn convert_payloads(
     event_info: Option<EventInfo>,
     result: Option<Payloads>,
 ) -> Result<Option<Payload>, WFMachinesError> {
     result.map(TryInto::try_into).transpose().map_err(|pe| {
         WFMachinesError::Fatal(format!(
-            "Not exactly one payload in child workflow result ({}) for event: {:?}",
-            pe, event_info
+            "Not exactly one payload in child workflow result ({pe}) for event: {event_info:?}"
         ))
     })
 }
 
 #[cfg(test)]
 mod test {
     use super::*;
     use crate::{
-        replay::TestHistoryBuilder, test_help::canned_histories, worker::workflow::ManagedWFFunc,
+        internal_flags::InternalFlags, replay::TestHistoryBuilder, test_help::canned_histories,
+        worker::workflow::ManagedWFFunc,
     };
     use anyhow::anyhow;
     use rstest::{fixture, rstest};
-    use std::mem::discriminant;
+    use std::{cell::RefCell, mem::discriminant, rc::Rc};
     use temporal_sdk::{
         CancellableFuture, ChildWorkflowOptions, WfContext, WorkflowFunction, WorkflowResult,
     };
     use temporal_sdk_core_protos::coresdk::{
         child_workflow::child_workflow_result,
         workflow_activation::resolve_child_workflow_execution_start::Status as StartStatus,
     };
@@ -836,23 +896,36 @@
         );
         wfm.shutdown().await.unwrap();
     }
 
     #[test]
     fn cancels_ignored_terminal() {
         for state in [
-            ChildWorkflowMachineState::Cancelled(Cancelled {}),
+            ChildWorkflowMachineState::Cancelled(Cancelled {
+                seen_cancelled_event: false,
+            }),
             Failed {}.into(),
             StartFailed {}.into(),
             TimedOut {}.into(),
             Completed {}.into(),
         ] {
-            let mut s = ChildWorkflowMachine {
-                state: state.clone(),
-                shared_state: Default::default(),
-            };
+            let mut s = ChildWorkflowMachine::from_parts(
+                state.clone(),
+                SharedState {
+                    initiated_event_id: 0,
+                    started_event_id: 0,
+                    lang_sequence_number: 0,
+                    namespace: "".to_string(),
+                    workflow_id: "".to_string(),
+                    run_id: "".to_string(),
+                    workflow_type: "".to_string(),
+                    cancelled_before_sent: false,
+                    cancel_type: Default::default(),
+                    internal_flags: Rc::new(RefCell::new(InternalFlags::new(&Default::default()))),
+                },
+            );
             let cmds = s.cancel().unwrap();
             assert_eq!(cmds.len(), 0);
-            assert_eq!(discriminant(&state), discriminant(&s.state));
+            assert_eq!(discriminant(&state), discriminant(s.state()));
         }
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/complete_workflow_state_machine.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::CompleteWorkflowExecution,
     temporal::api::{
         command::v1::Command,
         enums::v1::{CommandType, EventType},
         history::v1::HistoryEvent,
@@ -14,17 +15,17 @@
 };
 
 fsm! {
     pub(super)
     name CompleteWorkflowMachine;
     command CompleteWFCommand;
     error WFMachinesError;
-    shared_state CompleteWorkflowExecution;
+    shared_state ();
 
-    Created --(Schedule, shared on_schedule) --> CompleteWorkflowCommandCreated;
+    Created --(Schedule, on_schedule) --> CompleteWorkflowCommandCreated;
 
     CompleteWorkflowCommandCreated --(CommandCompleteWorkflowExecution)
         --> CompleteWorkflowCommandCreated;
     CompleteWorkflowCommandCreated --(WorkflowExecutionCompleted)
         --> CompleteWorkflowCommandRecorded;
 }
 
@@ -41,40 +42,37 @@
         machine: machine.into(),
     }
 }
 
 impl CompleteWorkflowMachine {
     /// Create a new WF machine and schedule it
     pub(crate) fn new_scheduled(attribs: CompleteWorkflowExecution) -> (Self, Command) {
-        let mut s = Self {
-            state: Created {}.into(),
-            shared_state: attribs,
-        };
+        let mut s = Self::from_parts(Created { attribs }.into(), ());
         let cmd =
             match OnEventWrapper::on_event_mut(&mut s, CompleteWorkflowMachineEvents::Schedule)
                 .expect("Scheduling complete wf machines doesn't fail")
                 .pop()
             {
                 Some(CompleteWFCommand::AddCommand(c)) => c,
                 _ => panic!("complete wf machine on_schedule must produce command"),
             };
         (s, cmd)
     }
 }
 
-impl TryFrom<HistoryEvent> for CompleteWorkflowMachineEvents {
+impl TryFrom<HistEventData> for CompleteWorkflowMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::WorkflowExecutionCompleted => Self::WorkflowExecutionCompleted,
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Complete workflow machine does not handle this event: {}",
-                    e
+                    "Complete workflow machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for CompleteWorkflowMachineEvents {
@@ -85,24 +83,25 @@
             CommandType::CompleteWorkflowExecution => Self::CommandCompleteWorkflowExecution,
             _ => return Err(()),
         })
     }
 }
 
 #[derive(Default, Clone)]
-pub(super) struct Created {}
+pub(super) struct Created {
+    attribs: CompleteWorkflowExecution,
+}
 
 impl Created {
     pub(super) fn on_schedule(
         self,
-        dat: CompleteWorkflowExecution,
     ) -> CompleteWorkflowMachineTransition<CompleteWorkflowCommandCreated> {
         let cmd = Command {
             command_type: CommandType::CompleteWorkflowExecution as i32,
-            attributes: Some(dat.into()),
+            attributes: Some(self.attribs.into()),
         };
         TransitionResult::commands(vec![CompleteWFCommand::AddCommand(cmd)])
     }
 }
 
 #[derive(thiserror::Error, Debug)]
 pub(super) enum CompleteWorkflowMachineError {}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/continue_as_new_workflow_state_machine.rs`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::{
     Cancellable, EventInfo, HistoryEvent, MachineResponse, NewMachineWithCommand, OnEventWrapper,
     WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::ContinueAsNewWorkflowExecution,
     temporal::api::{
         command::v1::Command,
         enums::v1::{CommandType, EventType},
     },
@@ -26,18 +27,15 @@
         --> ContinueAsNewWorkflowCommandRecorded;
 }
 
 #[derive(Debug, derive_more::Display)]
 pub(super) enum ContinueAsNewWorkflowCommand {}
 
 pub(super) fn continue_as_new(attribs: ContinueAsNewWorkflowExecution) -> NewMachineWithCommand {
-    let mut machine = ContinueAsNewWorkflowMachine {
-        state: Created {}.into(),
-        shared_state: (),
-    };
+    let mut machine = ContinueAsNewWorkflowMachine::from_parts(Created {}.into(), ());
     OnEventWrapper::on_event_mut(&mut machine, ContinueAsNewWorkflowMachineEvents::Schedule)
         .expect("Scheduling continue as new machine doesn't fail");
     let command = Command {
         command_type: CommandType::ContinueAsNewWorkflowExecution as i32,
         attributes: Some(attribs.into()),
     };
     NewMachineWithCommand {
@@ -65,24 +63,24 @@
 
 impl From<ContinueAsNewWorkflowCommandCreated> for ContinueAsNewWorkflowCommandRecorded {
     fn from(_: ContinueAsNewWorkflowCommandCreated) -> Self {
         Self::default()
     }
 }
 
-impl TryFrom<HistoryEvent> for ContinueAsNewWorkflowMachineEvents {
+impl TryFrom<HistEventData> for ContinueAsNewWorkflowMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::WorkflowExecutionContinuedAsNew => Self::WorkflowExecutionContinuedAsNew,
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Continue as new workflow machine does not handle this event: {}",
-                    e
+                    "Continue as new workflow machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for ContinueAsNewWorkflowMachineEvents {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/fail_workflow_state_machine.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,30 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::FailWorkflowExecution,
     temporal::api::{
         command::v1::Command as ProtoCommand,
         enums::v1::{CommandType, EventType},
         history::v1::HistoryEvent,
     },
 };
 
 fsm! {
     pub(super) name FailWorkflowMachine;
     command FailWFCommand;
     error WFMachinesError;
-    shared_state FailWorkflowExecution;
+    shared_state ();
 
-    Created --(Schedule, shared on_schedule) --> FailWorkflowCommandCreated;
+    Created --(Schedule, on_schedule) --> FailWorkflowCommandCreated;
 
     FailWorkflowCommandCreated --(CommandFailWorkflowExecution) --> FailWorkflowCommandCreated;
     FailWorkflowCommandCreated --(WorkflowExecutionFailed) --> FailWorkflowCommandRecorded;
 }
 
 #[derive(Debug, derive_more::Display)]
 pub(super) enum FailWFCommand {
@@ -38,40 +39,36 @@
         machine: machine.into(),
     }
 }
 
 impl FailWorkflowMachine {
     /// Create a new WF machine and schedule it
     pub(crate) fn new_scheduled(attribs: FailWorkflowExecution) -> (Self, ProtoCommand) {
-        let mut s = Self {
-            state: Created {}.into(),
-            shared_state: attribs,
-        };
+        let mut s = Self::from_parts(Created { attribs }.into(), ());
         let cmd = match OnEventWrapper::on_event_mut(&mut s, FailWorkflowMachineEvents::Schedule)
             .expect("Scheduling fail wf machines doesn't fail")
             .pop()
         {
             Some(FailWFCommand::AddCommand(c)) => c,
             _ => panic!("Fail wf machine on_schedule must produce command"),
         };
         (s, cmd)
     }
 }
 
 #[derive(Default, Clone)]
-pub(super) struct Created {}
+pub(super) struct Created {
+    attribs: FailWorkflowExecution,
+}
 
 impl Created {
-    pub(super) fn on_schedule(
-        self,
-        dat: FailWorkflowExecution,
-    ) -> FailWorkflowMachineTransition<FailWorkflowCommandCreated> {
+    pub(super) fn on_schedule(self) -> FailWorkflowMachineTransition<FailWorkflowCommandCreated> {
         let cmd = ProtoCommand {
             command_type: CommandType::FailWorkflowExecution as i32,
-            attributes: Some(dat.into()),
+            attributes: Some(self.attribs.into()),
         };
         TransitionResult::commands(vec![FailWFCommand::AddCommand(cmd)])
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct FailWorkflowCommandCreated {}
@@ -81,24 +78,24 @@
 
 impl From<FailWorkflowCommandCreated> for FailWorkflowCommandRecorded {
     fn from(_: FailWorkflowCommandCreated) -> Self {
         Self::default()
     }
 }
 
-impl TryFrom<HistoryEvent> for FailWorkflowMachineEvents {
+impl TryFrom<HistEventData> for FailWorkflowMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::WorkflowExecutionFailed => Self::WorkflowExecutionFailed,
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Fail workflow machine does not handle this event: {}",
-                    e
+                    "Fail workflow machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for FailWorkflowMachineEvents {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/local_activity_state_machine.rs`

 * *Files 4% similar despite different names*

```diff
@@ -1,14 +1,21 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, OnEventWrapper, WFMachinesAdapter,
     WFMachinesError,
 };
 use crate::{
+    internal_flags::CoreInternalFlags,
     protosext::{CompleteLocalActivityData, HistoryEventExt, ValidScheduleLA},
-    worker::{workflow::OutgoingJob, LocalActivityExecutionResult},
+    worker::{
+        workflow::{
+            machines::{activity_state_machine::activity_fail_info, HistEventData},
+            InternalFlagsRef, OutgoingJob,
+        },
+        LocalActivityExecutionResult,
+    },
 };
 use rustfsm::{fsm, MachineError, StateMachine, TransitionResult};
 use std::{
     convert::TryFrom,
     time::{Duration, SystemTime},
 };
 use temporal_sdk_core_protos::{
@@ -20,16 +27,16 @@
         common::build_local_activity_marker_details,
         external_data::LocalActivityMarkerData,
         workflow_activation::ResolveActivity,
         workflow_commands::ActivityCancellationType,
     },
     temporal::api::{
         command::v1::{Command, RecordMarkerCommandAttributes},
-        enums::v1::{CommandType, EventType},
-        failure::v1::failure::FailureInfo,
+        enums::v1::{CommandType, EventType, RetryState},
+        failure::v1::{failure::FailureInfo, Failure},
         history::v1::HistoryEvent,
     },
     utilities::TryIntoOrNone,
 };
 
 fsm! {
     pub(super) name LocalActivityMachine;
@@ -55,23 +62,25 @@
 
     MarkerCommandCreated --(CommandRecordMarker, on_command_record_marker) --> ResultNotified;
 
     ResultNotified --(MarkerRecorded(CompleteLocalActivityData), shared on_marker_recorded)
       --> MarkerCommandRecorded;
 
     // Replay path ================================================================================
-    // LAs on the replay path should never have handle result explicitly called on them, but do need
-    // to eventually see the marker
+    // LAs on the replay path always need to eventually see the marker
     WaitingMarkerEvent --(MarkerRecorded(CompleteLocalActivityData), shared on_marker_recorded)
       --> MarkerCommandRecorded;
     // If we are told to cancel while waiting for the marker, we still need to wait for the marker.
-    WaitingMarkerEvent --(Cancel, on_cancel_requested) --> WaitingMarkerEventCancelled;
+    WaitingMarkerEvent --(Cancel, on_cancel_requested) --> WaitingMarkerEvent;
+    // Because there could be non-heartbeat WFTs (ex: signals being received) between scheduling
+    // the LA and the marker being recorded, peekahead might not always resolve the LA *before*
+    // scheduling it. This transition accounts for that.
+    WaitingMarkerEvent --(HandleKnownResult(ResolveDat), on_handle_result) --> WaitingMarkerEvent;
     WaitingMarkerEvent --(NoWaitCancel(ActivityCancellationType),
-                          on_no_wait_cancel) --> WaitingMarkerEventCancelled;
-    WaitingMarkerEventCancelled --(HandleResult(ResolveDat), on_handle_result) --> WaitingMarkerEvent;
+                          on_no_wait_cancel) --> WaitingMarkerEvent;
 
     // It is entirely possible to have started the LA while replaying, only to find that we have
     // reached a new WFT and there still was no marker. In such cases we need to execute the LA.
     // This can easily happen if upon first execution, the worker does WFT heartbeating but then
     // dies for some reason.
     WaitingMarkerEvent --(StartedNonReplayWFT, shared on_started_non_replay_wft) --> RequestSent;
 
@@ -107,15 +116,20 @@
 
 impl From<CompleteLocalActivityData> for ResolveDat {
     fn from(d: CompleteLocalActivityData) -> Self {
         ResolveDat {
             result: match d.result {
                 Ok(res) => LocalActivityExecutionResult::Completed(Success { result: Some(res) }),
                 Err(fail) => {
-                    if matches!(fail.failure_info, Some(FailureInfo::CanceledFailureInfo(_))) {
+                    if matches!(fail.failure_info, Some(FailureInfo::CanceledFailureInfo(_)))
+                        || matches!(
+                            fail.cause.as_deref().and_then(|f| f.failure_info.as_ref()),
+                            Some(FailureInfo::CanceledFailureInfo(_))
+                        )
+                    {
                         LocalActivityExecutionResult::Cancelled(Cancellation {
                             failure: Some(fail),
                         })
                     } else {
                         LocalActivityExecutionResult::Failed(ActFail {
                             failure: Some(fail),
                         })
@@ -135,14 +149,15 @@
 /// must resolve before we send a record marker command. A [MachineResponse] may be produced,
 /// to queue the LA for execution if it needs to be.
 pub(super) fn new_local_activity(
     mut attrs: ValidScheduleLA,
     replaying_when_invoked: bool,
     maybe_pre_resolved: Option<ResolveDat>,
     wf_time: Option<SystemTime>,
+    internal_flags: InternalFlagsRef,
 ) -> Result<(LocalActivityMachine, Vec<MachineResponse>), WFMachinesError> {
     let initial_state = if replaying_when_invoked {
         if let Some(dat) = maybe_pre_resolved {
             ReplayingPreResolved { dat }.into()
         } else {
             Replaying {}.into()
         }
@@ -156,22 +171,23 @@
     };
 
     // If the scheduled LA doesn't already have an "original" schedule time, assign one.
     attrs
         .original_schedule_time
         .get_or_insert(SystemTime::now());
 
-    let mut machine = LocalActivityMachine {
-        state: initial_state,
-        shared_state: SharedState {
+    let mut machine = LocalActivityMachine::from_parts(
+        initial_state,
+        SharedState {
             attrs,
             replaying_when_invoked,
             wf_time_when_started: wf_time,
+            internal_flags,
         },
-    };
+    );
 
     let mut res = OnEventWrapper::on_event_mut(&mut machine, LocalActivityMachineEvents::Schedule)
         .expect("Scheduling local activities doesn't fail");
     let mr = if let Some(res) = res.pop() {
         machine
             .adapt_response(res, None)
             .expect("Adapting LA schedule response doesn't fail")
@@ -187,25 +203,34 @@
     /// skipping over the rest. If this machine is in the `ResultNotified` state, that means
     /// command handling should proceed as normal (ie: The command needs to be matched and removed).
     /// The other valid states to make this check in are the `WaitingMarkerEvent[PreResolved]`
     /// states, which will return true.
     ///
     /// Attempting the check in any other state likely means a bug in the SDK.
     pub(super) fn marker_should_get_special_handling(&self) -> Result<bool, WFMachinesError> {
-        match &self.state {
+        match self.state() {
             LocalActivityMachineState::ResultNotified(_) => Ok(false),
             LocalActivityMachineState::WaitingMarkerEvent(_) => Ok(true),
             LocalActivityMachineState::WaitingMarkerEventPreResolved(_) => Ok(true),
             _ => Err(WFMachinesError::Fatal(format!(
                 "Attempted to check for LA marker handling in invalid state {}",
-                self.state
+                self.state()
             ))),
         }
     }
 
+    /// Returns true if the machine will willingly accept data from a marker in its current state.
+    /// IE: Calling [Self::try_resolve_with_dat] makes sense.
+    pub(super) fn will_accept_resolve_marker(&self) -> bool {
+        matches!(
+            self.state(),
+            LocalActivityMachineState::WaitingMarkerEvent(_)
+        )
+    }
+
     /// Must be called if the workflow encounters a non-replay workflow task
     pub(super) fn encountered_non_replay_wft(
         &mut self,
     ) -> Result<Vec<MachineResponse>, WFMachinesError> {
         // This only applies to the waiting-for-marker state. It can safely be ignored in the others
         if !matches!(
             self.state(),
@@ -236,36 +261,53 @@
         &mut self,
         result: LocalActivityExecutionResult,
         runtime: Duration,
         attempt: u32,
         backoff: Option<prost_types::Duration>,
         original_schedule_time: Option<SystemTime>,
     ) -> Result<Vec<MachineResponse>, WFMachinesError> {
-        self.try_resolve_with_dat(ResolveDat {
-            result,
-            complete_time: self.shared_state.wf_time_when_started.map(|t| t + runtime),
-            attempt,
-            backoff,
-            original_schedule_time,
-        })
+        self._try_resolve(
+            ResolveDat {
+                result,
+                complete_time: self.shared_state.wf_time_when_started.map(|t| t + runtime),
+                attempt,
+                backoff,
+                original_schedule_time,
+            },
+            false,
+        )
     }
+
     /// Attempt to resolve the local activity with already known data, ex pre-resolved data
     pub(super) fn try_resolve_with_dat(
         &mut self,
         dat: ResolveDat,
     ) -> Result<Vec<MachineResponse>, WFMachinesError> {
-        let res = OnEventWrapper::on_event_mut(self, LocalActivityMachineEvents::HandleResult(dat))
-            .map_err(|e| match e {
-                MachineError::InvalidTransition => WFMachinesError::Fatal(format!(
-                    "Invalid transition resolving local activity (seq {}) in {}",
-                    self.shared_state.attrs.seq,
-                    self.state(),
-                )),
-                MachineError::Underlying(e) => e,
-            })?;
+        self._try_resolve(dat, true)
+    }
+
+    fn _try_resolve(
+        &mut self,
+        dat: ResolveDat,
+        from_marker: bool,
+    ) -> Result<Vec<MachineResponse>, WFMachinesError> {
+        let evt = if from_marker {
+            LocalActivityMachineEvents::HandleKnownResult(dat)
+        } else {
+            LocalActivityMachineEvents::HandleResult(dat)
+        };
+        let res = OnEventWrapper::on_event_mut(self, evt).map_err(|e| match e {
+            MachineError::InvalidTransition => WFMachinesError::Fatal(format!(
+                "Invalid transition resolving local activity (seq {}, from marker: {}) in {}",
+                self.shared_state.attrs.seq,
+                from_marker,
+                self.state(),
+            )),
+            MachineError::Underlying(e) => e,
+        })?;
 
         Ok(res
             .into_iter()
             .flat_map(|res| {
                 self.adapt_response(res, None)
                     .expect("Adapting LA resolve response doesn't fail")
             })
@@ -274,14 +316,15 @@
 }
 
 #[derive(Clone)]
 pub(super) struct SharedState {
     attrs: ValidScheduleLA,
     replaying_when_invoked: bool,
     wf_time_when_started: Option<SystemTime>,
+    internal_flags: InternalFlagsRef,
 }
 
 impl SharedState {
     fn produce_no_wait_cancel_resolve_dat(&self) -> ResolveDat {
         ResolveDat {
             result: LocalActivityExecutionResult::empty_cancel(),
             // Just don't provide a complete time, which means try-cancel/abandon cancels won't
@@ -315,17 +358,19 @@
 
 #[derive(Default, Clone)]
 pub(super) struct Executing {}
 
 impl Executing {
     pub(super) fn on_schedule(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
     ) -> LocalActivityMachineTransition<RequestSent> {
-        TransitionResult::commands([LocalActivityCommand::RequestActivityExecution(dat.attrs)])
+        TransitionResult::commands([LocalActivityCommand::RequestActivityExecution(
+            dat.attrs.clone(),
+        )])
     }
 }
 
 #[derive(Clone, Copy, PartialEq, Eq)]
 enum ResultType {
     Completed,
     Cancelled,
@@ -427,15 +472,15 @@
 
     fn on_cancel_requested(self) -> LocalActivityMachineTransition<RequestSent> {
         TransitionResult::ok([LocalActivityCommand::RequestCancel], self)
     }
 
     fn on_no_wait_cancel(
         self,
-        shared: SharedState,
+        shared: &mut SharedState,
         cancel_type: ActivityCancellationType,
     ) -> LocalActivityMachineTransition<MarkerCommandCreated> {
         let mut cmds = vec![];
         if matches!(cancel_type, ActivityCancellationType::TryCancel) {
             // For try-cancels also request the cancel
             cmds.push(LocalActivityCommand::RequestCancel);
         }
@@ -466,113 +511,101 @@
 pub(super) struct ResultNotified {
     result_type: ResultType,
 }
 
 impl ResultNotified {
     pub(super) fn on_marker_recorded(
         self,
-        shared: SharedState,
+        shared: &mut SharedState,
         dat: CompleteLocalActivityData,
     ) -> LocalActivityMachineTransition<MarkerCommandRecorded> {
         if self.result_type == ResultType::Completed && dat.result.is_err() {
             return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
                 "Local activity (seq {}) completed successfully locally, but history said \
                  it failed!",
                 shared.attrs.seq
             )));
         } else if self.result_type == ResultType::Failed && dat.result.is_ok() {
             return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
                 "Local activity (seq {}) failed locally, but history said it completed!",
                 shared.attrs.seq
             )));
         }
-        verify_marker_dat!(&shared, &dat, TransitionResult::default())
+        verify_marker_dat!(shared, &dat, TransitionResult::default())
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct WaitingMarkerEvent {
     already_resolved: bool,
 }
 
 impl WaitingMarkerEvent {
     pub(super) fn on_marker_recorded(
         self,
-        shared: SharedState,
+        shared: &mut SharedState,
         dat: CompleteLocalActivityData,
     ) -> LocalActivityMachineTransition<MarkerCommandRecorded> {
         verify_marker_dat!(
-            &shared,
+            shared,
             &dat,
             TransitionResult::commands(if self.already_resolved {
                 vec![]
             } else {
                 vec![LocalActivityCommand::Resolved(dat.into())]
             })
         )
     }
+    fn on_handle_result(
+        self,
+        dat: ResolveDat,
+    ) -> LocalActivityMachineTransition<WaitingMarkerEvent> {
+        TransitionResult::ok(
+            [LocalActivityCommand::Resolved(dat)],
+            WaitingMarkerEvent {
+                already_resolved: true,
+            },
+        )
+    }
     pub(super) fn on_started_non_replay_wft(
         self,
-        mut dat: SharedState,
+        dat: &mut SharedState,
     ) -> LocalActivityMachineTransition<RequestSent> {
         // We aren't really "replaying" anymore for our purposes, and want to record the marker.
         dat.replaying_when_invoked = false;
-        TransitionResult::ok_shared(
-            [LocalActivityCommand::RequestActivityExecution(
-                dat.attrs.clone(),
-            )],
-            RequestSent::default(),
-            dat,
-        )
+        TransitionResult::commands([LocalActivityCommand::RequestActivityExecution(
+            dat.attrs.clone(),
+        )])
     }
 
-    fn on_cancel_requested(self) -> LocalActivityMachineTransition<WaitingMarkerEventCancelled> {
+    fn on_cancel_requested(self) -> LocalActivityMachineTransition<WaitingMarkerEvent> {
         // We still "request a cancel" even though we know the local activity should not be running
         // because the data might be in the pre-resolved list.
-        TransitionResult::ok(
-            [LocalActivityCommand::RequestCancel],
-            WaitingMarkerEventCancelled {},
-        )
+        TransitionResult::ok([LocalActivityCommand::RequestCancel], self)
     }
 
     fn on_no_wait_cancel(
         self,
         _: ActivityCancellationType,
-    ) -> LocalActivityMachineTransition<WaitingMarkerEventCancelled> {
+    ) -> LocalActivityMachineTransition<WaitingMarkerEvent> {
         // Markers are always recorded when cancelling, so this is the same as a normal cancel on
         // the replay path
         self.on_cancel_requested()
     }
 }
 
 #[derive(Default, Clone)]
-pub(super) struct WaitingMarkerEventCancelled {}
-impl WaitingMarkerEventCancelled {
-    fn on_handle_result(
-        self,
-        dat: ResolveDat,
-    ) -> LocalActivityMachineTransition<WaitingMarkerEvent> {
-        TransitionResult::ok(
-            [LocalActivityCommand::Resolved(dat)],
-            WaitingMarkerEvent {
-                already_resolved: true,
-            },
-        )
-    }
-}
-
-#[derive(Default, Clone)]
 pub(super) struct WaitingMarkerEventPreResolved {}
 impl WaitingMarkerEventPreResolved {
     pub(super) fn on_marker_recorded(
         self,
-        shared: SharedState,
+        shared: &mut SharedState,
         dat: CompleteLocalActivityData,
     ) -> LocalActivityMachineTransition<MarkerCommandRecorded> {
-        verify_marker_dat!(&shared, &dat, TransitionResult::default())
+        verify_marker_dat!(shared, &dat, TransitionResult::default())
     }
 }
 
 impl Cancellable for LocalActivityMachine {
     fn cancel(&mut self) -> Result<Vec<MachineResponse>, MachineError<Self::Error>> {
         let event = match self.shared_state.attrs.cancellation_type {
             ct @ ActivityCancellationType::TryCancel | ct @ ActivityCancellationType::Abandon => {
@@ -646,16 +679,69 @@
                                 backoff_duration: Some(b.clone()),
                                 original_schedule_time: original_schedule_time.map(Into::into),
                             }
                             .into(),
                         ),
                     }
                 } else {
-                    result.into()
+                    // Cancels and timeouts are to be wrapped with an activity failure
+                    macro_rules! wrap_fail {
+                        ($me:ident, $fail:ident, $msg:expr, $info:pat) => {
+                            let mut fail = $fail.failure.take();
+                            let fail_info = fail.as_ref().and_then(|f| f.failure_info.as_ref());
+                            if matches!(fail_info, Some($info)) {
+                                fail = Some(Failure {
+                                    message: $msg,
+                                    cause: fail.map(Box::new),
+                                    failure_info: Some(activity_fail_info(
+                                        $me.shared_state.attrs.activity_type.clone(),
+                                        $me.shared_state.attrs.activity_id.clone(),
+                                        None,
+                                        RetryState::CancelRequested,
+                                        0,
+                                        0,
+                                    )),
+                                    ..Default::default()
+                                });
+                            }
+                            $fail.failure = fail;
+                        };
+                    }
+                    match result {
+                        LocalActivityExecutionResult::Completed(c) => ActivityResolution {
+                            status: Some(c.into()),
+                        },
+                        LocalActivityExecutionResult::Failed(f) => ActivityResolution {
+                            status: Some(f.into()),
+                        },
+                        LocalActivityExecutionResult::TimedOut(mut failure) => {
+                            wrap_fail!(
+                                self,
+                                failure,
+                                "Local Activity timed out".to_string(),
+                                FailureInfo::TimeoutFailureInfo(_)
+                            );
+                            ActivityResolution {
+                                status: Some(failure.into()),
+                            }
+                        }
+                        LocalActivityExecutionResult::Cancelled(mut cancel) => {
+                            wrap_fail!(
+                                self,
+                                cancel,
+                                "Local Activity cancelled".to_string(),
+                                FailureInfo::CanceledFailureInfo(_)
+                            );
+                            ActivityResolution {
+                                status: Some(cancel.into()),
+                            }
+                        }
+                    }
                 };
+
                 let mut responses = vec![
                     MachineResponse::PushWFJob(OutgoingJob {
                         variant: ResolveActivity {
                             seq: self.shared_state.attrs.seq,
                             result: Some(resolution),
                         }
                         .into(),
@@ -728,22 +814,22 @@
         Ok(match c {
             CommandType::RecordMarker => Self::CommandRecordMarker,
             _ => return Err(()),
         })
     }
 }
 
-impl TryFrom<HistoryEvent> for LocalActivityMachineEvents {
+impl TryFrom<HistEventData> for LocalActivityMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         if e.event_type() != EventType::MarkerRecorded {
             return Err(WFMachinesError::Nondeterminism(format!(
-                "Local activity machine cannot handle this event: {}",
-                e
+                "Local activity machine cannot handle this event: {e}"
             )));
         }
 
         match e.into_local_activity_marker_details() {
             Some(marker_dat) => Ok(LocalActivityMachineEvents::MarkerRecorded(marker_dat)),
             _ => Err(WFMachinesError::Nondeterminism(
                 "Local activity machine encountered an unparsable marker".to_string(),
@@ -759,34 +845,38 @@
     if shared.attrs.seq != dat.marker_dat.seq {
         return Err(WFMachinesError::Nondeterminism(format!(
             "Local activity marker data has sequence number {} but matched against LA \
             command with sequence number {}",
             dat.marker_dat.seq, shared.attrs.seq
         )));
     }
-
-    Ok(())
-}
-
-impl From<LocalActivityExecutionResult> for ActivityResolution {
-    fn from(lar: LocalActivityExecutionResult) -> Self {
-        match lar {
-            LocalActivityExecutionResult::Completed(c) => ActivityResolution {
-                status: Some(c.into()),
-            },
-            LocalActivityExecutionResult::Failed(f) | LocalActivityExecutionResult::TimedOut(f) => {
-                ActivityResolution {
-                    status: Some(f.into()),
-                }
-            }
-            LocalActivityExecutionResult::Cancelled(cancel) => ActivityResolution {
-                status: Some(cancel.into()),
-            },
+    // Here we use whether or not we were replaying when we _first invoked_ the LA, because we
+    // are always replaying when we see the marker recorded event, and that would make this check
+    // a bit pointless.
+    if shared.internal_flags.borrow_mut().try_use(
+        CoreInternalFlags::IdAndTypeDeterminismChecks,
+        !shared.replaying_when_invoked,
+    ) {
+        if dat.marker_dat.activity_id != shared.attrs.activity_id {
+            return Err(WFMachinesError::Nondeterminism(format!(
+                "Activity id of recorded marker '{}' does not \
+                 match activity id of local activity command '{}'",
+                dat.marker_dat.activity_id, shared.attrs.activity_id
+            )));
+        }
+        if dat.marker_dat.activity_type != shared.attrs.activity_type {
+            return Err(WFMachinesError::Nondeterminism(format!(
+                "Activity type of recorded marker '{}' does not \
+                 match activity type of local activity command '{}'",
+                dat.marker_dat.activity_type, shared.attrs.activity_type
+            )));
         }
     }
+
+    Ok(())
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
     use crate::{
         replay::TestHistoryBuilder, test_help::canned_histories, worker::workflow::ManagedWFFunc,
@@ -796,23 +886,27 @@
     use temporal_sdk::{
         CancellableFuture, LocalActivityOptions, WfContext, WorkflowFunction, WorkflowResult,
     };
     use temporal_sdk_core_protos::{
         coresdk::{
             activity_result::ActivityExecutionResult,
             workflow_activation::{workflow_activation_job, WorkflowActivationJob},
-            workflow_commands::ActivityCancellationType::WaitCancellationCompleted,
         },
         temporal::api::{
             command::v1::command, enums::v1::WorkflowTaskFailedCause, failure::v1::Failure,
         },
+        DEFAULT_ACTIVITY_TYPE,
     };
 
     async fn la_wf(ctx: WfContext) -> WorkflowResult<()> {
-        ctx.local_activity(LocalActivityOptions::default()).await;
+        ctx.local_activity(LocalActivityOptions {
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+            ..Default::default()
+        })
+        .await;
         Ok(().into())
     }
 
     #[rstest]
     #[case::incremental(false, true)]
     #[case::replay(true, true)]
     #[case::incremental_fail(false, false)]
@@ -917,16 +1011,24 @@
         let commands = wfm.get_server_commands().commands;
         assert_eq!(commands.len(), 0);
 
         wfm.shutdown().await.unwrap();
     }
 
     async fn two_la_wf(ctx: WfContext) -> WorkflowResult<()> {
-        ctx.local_activity(LocalActivityOptions::default()).await;
-        ctx.local_activity(LocalActivityOptions::default()).await;
+        ctx.local_activity(LocalActivityOptions {
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+            ..Default::default()
+        })
+        .await;
+        ctx.local_activity(LocalActivityOptions {
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+            ..Default::default()
+        })
+        .await;
         Ok(().into())
     }
 
     #[rstest]
     #[case::incremental(false)]
     #[case::replay(true)]
     #[tokio::test]
@@ -1011,16 +1113,22 @@
         assert_eq!(commands.len(), 0);
 
         wfm.shutdown().await.unwrap();
     }
 
     async fn two_la_wf_parallel(ctx: WfContext) -> WorkflowResult<()> {
         tokio::join!(
-            ctx.local_activity(LocalActivityOptions::default()),
-            ctx.local_activity(LocalActivityOptions::default())
+            ctx.local_activity(LocalActivityOptions {
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+                ..Default::default()
+            }),
+            ctx.local_activity(LocalActivityOptions {
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+                ..Default::default()
+            })
         );
         Ok(().into())
     }
 
     #[rstest]
     #[case::incremental(false)]
     #[case::replay(true)]
@@ -1095,17 +1203,25 @@
         let commands = wfm.get_server_commands().commands;
         assert_eq!(commands.len(), 0);
 
         wfm.shutdown().await.unwrap();
     }
 
     async fn la_timer_la(ctx: WfContext) -> WorkflowResult<()> {
-        ctx.local_activity(LocalActivityOptions::default()).await;
+        ctx.local_activity(LocalActivityOptions {
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+            ..Default::default()
+        })
+        .await;
         ctx.timer(Duration::from_secs(5)).await;
-        ctx.local_activity(LocalActivityOptions::default()).await;
+        ctx.local_activity(LocalActivityOptions {
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+            ..Default::default()
+        })
+        .await;
         Ok(().into())
     }
 
     #[rstest]
     #[case::incremental(false)]
     #[case::replay(true)]
     #[tokio::test]
@@ -1338,37 +1454,47 @@
             ActivityCancellationType::Abandon
         )]
         cancel_type: ActivityCancellationType,
     ) {
         let func = WorkflowFunction::new(move |ctx| async move {
             let la = ctx.local_activity(LocalActivityOptions {
                 cancel_type,
+                activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
                 ..Default::default()
             });
             ctx.timer(Duration::from_secs(1)).await;
             la.cancel(&ctx);
             // This extra timer is here to ensure the presence of another WF task doesn't mess up
             // resolving the LA with cancel on replay
             ctx.timer(Duration::from_secs(1)).await;
             let resolution = la.await;
             assert!(resolution.cancelled());
+            let rfail = resolution.unwrap_failure();
+            assert_matches!(
+                rfail.failure_info,
+                Some(FailureInfo::ActivityFailureInfo(_))
+            );
+            assert_matches!(
+                rfail.cause.unwrap().failure_info,
+                Some(FailureInfo::CanceledFailureInfo(_))
+            );
             Ok(().into())
         });
 
         let mut t = TestHistoryBuilder::default();
         t.add_by_type(EventType::WorkflowExecutionStarted);
         t.add_full_wf_task();
-        let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+        let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
         t.add_timer_fired(timer_started_event_id, "1".to_string());
         t.add_full_wf_task();
         if cancel_type != ActivityCancellationType::WaitCancellationCompleted {
             // With non-wait cancels, the cancel is immediate
             t.add_local_activity_cancel_marker(1, "1");
         }
-        let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+        let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
         if cancel_type == ActivityCancellationType::WaitCancellationCompleted {
             // With wait cancels, the cancel marker is not recorded until activity reports.
             t.add_local_activity_cancel_marker(1, "1");
         }
         t.add_timer_fired(timer_started_event_id, "2".to_string());
         t.add_full_wf_task();
         t.add_workflow_execution_completed();
@@ -1404,24 +1530,25 @@
         } else {
             // Try-cancel/abandon will immediately record marker (when not replaying)
             assert_eq!(commands.len(), 2);
             assert_eq!(commands[0].command_type, CommandType::RecordMarker as i32);
             assert_eq!(commands[1].command_type, CommandType::StartTimer as i32);
         }
 
-        if replay {
-            wfm.get_next_activation().await.unwrap()
+        let commands = if replay {
+            wfm.get_next_activation().await.unwrap();
+            wfm.get_server_commands().commands
         } else {
             // On non replay, there's an additional activation, because completing with the cancel
             // wants to wake up the workflow to see if resolving the LA as cancelled did anything.
             // In this case, it doesn't really, because we just hit the next timer which is also
             // what would have happened if we woke up with new history -- but it does mean we
             // generate the commands at this point. This matters b/c we want to make sure the record
             // marker command is sent as soon as cancel happens.
-            if cancel_type == WaitCancellationCompleted {
+            if cancel_type == ActivityCancellationType::WaitCancellationCompleted {
                 wfm.complete_local_activity(1, ActivityExecutionResult::cancel_from_details(None))
                     .unwrap();
             }
             wfm.get_next_activation().await.unwrap();
             let commands = wfm.get_server_commands().commands;
             assert_eq!(commands.len(), 2);
             if cancel_type == ActivityCancellationType::WaitCancellationCompleted {
@@ -1430,19 +1557,19 @@
             } else {
                 assert_eq!(commands[0].command_type, CommandType::RecordMarker as i32);
                 assert_eq!(commands[1].command_type, CommandType::StartTimer as i32);
             }
 
             wfm.new_history(t.get_history_info(3).unwrap().into())
                 .await
-                .unwrap()
+                .unwrap();
+            wfm.get_next_activation().await.unwrap();
+            wfm.get_server_commands().commands
         };
 
-        wfm.get_next_activation().await.unwrap();
-        let commands = wfm.get_server_commands().commands;
         assert_eq!(commands.len(), 1);
         assert_eq!(
             commands[0].command_type,
             CommandType::CompleteWorkflowExecution as i32
         );
 
         wfm.shutdown().await.unwrap();
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/mod.rs`

 * *Files 7% similar despite different names*

```diff
@@ -14,17 +14,17 @@
 mod timer_state_machine;
 mod upsert_search_attributes_state_machine;
 mod workflow_task_state_machine;
 
 #[cfg(test)]
 mod transition_coverage;
 
-pub(crate) use workflow_machines::{WFMachinesError, WorkflowMachines};
+pub(crate) use workflow_machines::WorkflowMachines;
 
-use crate::telemetry::VecDisplayer;
+use crate::{telemetry::VecDisplayer, worker::workflow::WFMachinesError};
 use activity_state_machine::ActivityMachine;
 use cancel_external_state_machine::CancelExternalMachine;
 use cancel_workflow_state_machine::CancelWorkflowMachine;
 use child_workflow_state_machine::ChildWorkflowMachine;
 use complete_workflow_state_machine::CompleteWorkflowMachine;
 use continue_as_new_workflow_state_machine::ContinueAsNewWorkflowMachine;
 use fail_workflow_state_machine::FailWorkflowMachine;
@@ -69,31 +69,30 @@
     ModifyWorkflowPropertiesMachine,
 }
 
 /// Extends [rustfsm::StateMachine] with some functionality specific to the temporal SDK.
 ///
 /// Formerly known as `EntityStateMachine` in Java.
 #[enum_dispatch::enum_dispatch(Machines)]
-trait TemporalStateMachine: Send {
+trait TemporalStateMachine {
     fn handle_command(
         &mut self,
         command_type: CommandType,
     ) -> Result<Vec<MachineResponse>, WFMachinesError>;
 
     /// Returns true if this machine is compatible with the provided event. Provides a way to know
     /// ahead of time if it's worth trying to call [TemporalStateMachine::handle_event] without
     /// requiring mutable access.
     fn matches_event(&self, event: &HistoryEvent) -> bool;
 
     /// Tell the state machine to handle some event. Returns a list of responses that can be used
     /// to update the overall state of the workflow. EX: To issue outgoing WF activations.
     fn handle_event(
         &mut self,
-        event: HistoryEvent,
-        has_next_event: bool,
+        event: HistEventData,
     ) -> Result<Vec<MachineResponse>, WFMachinesError>;
 
     /// Attempt to cancel the command associated with this state machine, if it is cancellable
     fn cancel(&mut self) -> Result<Vec<MachineResponse>, WFMachinesError>;
 
     /// Should return true if the command was cancelled before we sent it to the server. Always
     /// returns false for non-cancellable machines
@@ -104,17 +103,17 @@
 
     /// Returns a friendly name for the type of this machine
     fn name(&self) -> &str;
 }
 
 impl<SM> TemporalStateMachine for SM
 where
-    SM: StateMachine + WFMachinesAdapter + Cancellable + OnEventWrapper + Clone + Send + 'static,
-    <SM as StateMachine>::Event: TryFrom<HistoryEvent> + TryFrom<CommandType> + Display,
-    WFMachinesError: From<<<SM as StateMachine>::Event as TryFrom<HistoryEvent>>::Error>,
+    SM: StateMachine + WFMachinesAdapter + Cancellable + OnEventWrapper + Clone + 'static,
+    <SM as StateMachine>::Event: TryFrom<HistEventData> + TryFrom<CommandType> + Display,
+    WFMachinesError: From<<<SM as StateMachine>::Event as TryFrom<HistEventData>>::Error>,
     <SM as StateMachine>::Command: Debug + Display,
     <SM as StateMachine>::State: Display,
     <SM as StateMachine>::Error: Into<WFMachinesError> + 'static + Send + Sync,
 {
     fn handle_command(
         &mut self,
         command_type: CommandType,
@@ -148,29 +147,27 @@
 
     fn matches_event(&self, event: &HistoryEvent) -> bool {
         self.matches_event(event)
     }
 
     fn handle_event(
         &mut self,
-        event: HistoryEvent,
-        has_next_event: bool,
+        event_dat: HistEventData,
     ) -> Result<Vec<MachineResponse>, WFMachinesError> {
         trace!(
-            event = %event,
+            event = %event_dat.event,
             machine_name = %self.name(),
             state = %self.state(),
             "handling event"
         );
         let event_info = EventInfo {
-            event_id: event.event_id,
-            event_type: event.event_type(),
-            has_next_event,
+            event_id: event_dat.event.event_id,
+            event_type: event_dat.event.event_type(),
         };
-        let converted_event: <Self as StateMachine>::Event = event.try_into()?;
+        let converted_event: <Self as StateMachine>::Event = event_dat.try_into()?;
 
         match OnEventWrapper::on_event_mut(self, converted_event) {
             Ok(c) => process_machine_commands(self, c, Some(event_info)),
             Err(MachineError::InvalidTransition) => Err(WFMachinesError::Fatal(format!(
                 "{} in state {} says the transition is invalid during event {:?}",
                 self.name(),
                 self.state(),
@@ -241,19 +238,30 @@
 
     /// Returns true if this machine is compatible with the provided event. Provides a way to know
     /// ahead of time if it's worth trying to call [TemporalStateMachine::handle_event] without
     /// requiring mutable access.
     fn matches_event(&self, event: &HistoryEvent) -> bool;
 }
 
+/// Wraps a history event with extra relevant data that a machine might care about while the event
+/// is being applied to it.
+#[derive(Debug, derive_more::Display)]
+#[display(fmt = "{event}")]
+struct HistEventData {
+    event: HistoryEvent,
+    /// Is the current workflow task under replay or not during application of this event?
+    replaying: bool,
+    /// Is the current workflow task the last task in history?
+    current_task_is_last_in_history: bool,
+}
+
 #[derive(Debug, Copy, Clone)]
 struct EventInfo {
     event_id: i64,
     event_type: EventType,
-    has_next_event: bool,
 }
 
 trait Cancellable: StateMachine {
     /// Cancel the machine / the command represented by the machine.
     ///
     /// # Panics
     /// * If the machine is not cancellable. It's a logic error on our part to call it on such
@@ -266,15 +274,15 @@
 
     /// Should return true if the command was cancelled before we sent it to the server
     fn was_cancelled_before_sent_to_server(&self) -> bool {
         false
     }
 }
 
-/// We need to wrap calls to [StateMachine::on_event_mut] to track coverage, or anything else
+/// We need to wrap calls to [StateMachine::on_event] to track coverage, or anything else
 /// we'd like to do on every call.
 pub(crate) trait OnEventWrapper: StateMachine
 where
     <Self as StateMachine>::State: Display,
     <Self as StateMachine>::Event: Display,
     Self: Clone,
 {
@@ -283,15 +291,15 @@
         event: Self::Event,
     ) -> Result<Vec<Self::Command>, MachineError<Self::Error>> {
         #[cfg(test)]
         let from_state = self.state().to_string();
         #[cfg(test)]
         let converted_event_str = event.to_string();
 
-        let res = StateMachine::on_event_mut(self, event);
+        let res = StateMachine::on_event(self, event);
         if res.is_ok() {
             #[cfg(test)]
             add_coverage(
                 self.name().to_owned(),
                 from_state,
                 self.state().to_string(),
                 converted_event_str,
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/modify_workflow_properties_state_machine.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-use super::{
-    workflow_machines::{MachineResponse, WFMachinesError},
-    NewMachineWithCommand,
+use super::{workflow_machines::MachineResponse, NewMachineWithCommand};
+use crate::worker::workflow::{
+    machines::{Cancellable, EventInfo, HistEventData, WFMachinesAdapter},
+    WFMachinesError,
 };
-use crate::worker::workflow::machines::{Cancellable, EventInfo, WFMachinesAdapter};
-use rustfsm::{fsm, TransitionResult};
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use temporal_sdk_core_protos::{
     coresdk::workflow_commands::ModifyWorkflowProperties,
     temporal::api::{
         command::v1::Command,
         enums::v1::{CommandType, EventType},
         history::v1::HistoryEvent,
     },
@@ -24,18 +24,15 @@
 }
 
 /// Instantiates an ModifyWorkflowPropertiesMachine and packs it together with the command to
 /// be sent to server.
 pub(super) fn modify_workflow_properties(
     lang_cmd: ModifyWorkflowProperties,
 ) -> NewMachineWithCommand {
-    let sm = ModifyWorkflowPropertiesMachine {
-        state: Created {}.into(),
-        shared_state: (),
-    };
+    let sm = ModifyWorkflowPropertiesMachine::from_parts(Created {}.into(), ());
     let cmd = Command {
         command_type: CommandType::ModifyWorkflowProperties as i32,
         attributes: Some(lang_cmd.into()),
     };
     NewMachineWithCommand {
         command: cmd,
         machine: sm.into(),
@@ -70,18 +67,19 @@
     fn matches_event(&self, event: &HistoryEvent) -> bool {
         matches!(event.event_type(), EventType::WorkflowPropertiesModified)
     }
 }
 
 impl Cancellable for ModifyWorkflowPropertiesMachine {}
 
-impl TryFrom<HistoryEvent> for ModifyWorkflowPropertiesMachineEvents {
+impl TryFrom<HistEventData> for ModifyWorkflowPropertiesMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         match e.event_type() {
             EventType::WorkflowPropertiesModified => {
                 Ok(ModifyWorkflowPropertiesMachineEvents::CommandRecorded)
             }
             _ => Err(Self::Error::Nondeterminism(format!(
                 "ModifyWorkflowPropertiesMachine does not handle {e}"
             ))),
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/patch_state_machine.rs`

 * *Files 20% similar despite different names*

```diff
@@ -17,27 +17,45 @@
 //! | deprecated marker for change | deprecate_patch | Call allowed                                                                       |
 //! | replaying, no marker         | deprecate_patch | Call allowed                                                                       |
 
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use crate::protosext::HistoryEventExt;
-use rustfsm::{fsm, TransitionResult};
-use std::convert::TryFrom;
+use crate::{
+    internal_flags::CoreInternalFlags,
+    protosext::HistoryEventExt,
+    worker::workflow::{
+        machines::{
+            upsert_search_attributes_state_machine::MAX_SEARCH_ATTR_PAYLOAD_SIZE, HistEventData,
+        },
+        InternalFlagsRef,
+    },
+};
+use anyhow::Context;
+use rustfsm::{fsm, StateMachine, TransitionResult};
+use std::{
+    collections::{BTreeSet, HashMap},
+    convert::TryFrom,
+};
 use temporal_sdk_core_protos::{
     constants::PATCH_MARKER_NAME,
-    coresdk::common::build_has_change_marker_details,
+    coresdk::{common::build_has_change_marker_details, AsJsonPayloadExt},
     temporal::api::{
-        command::v1::{Command, RecordMarkerCommandAttributes},
+        command::v1::{
+            Command, RecordMarkerCommandAttributes, UpsertWorkflowSearchAttributesCommandAttributes,
+        },
+        common::v1::SearchAttributes,
         enums::v1::CommandType,
         history::v1::HistoryEvent,
     },
 };
 
+pub(crate) const VERSION_SEARCH_ATTR_KEY: &str = "TemporalChangeVersion";
+
 fsm! {
     pub(super) name PatchMachine;
     command PatchCommand;
     error WFMachinesError;
     shared_state SharedState;
 
     // Machine is created in either executing or replaying, and then immediately scheduled and
@@ -67,76 +85,113 @@
 /// Patch machines are created when the user invokes `has_change` (or whatever it may be named
 /// in that lang).
 ///
 /// `patch_id`: identifier of a particular change. All calls to get_version that share a change id
 /// are guaranteed to return the same value.
 /// `replaying_when_invoked`: If the workflow is replaying when this invocation occurs, this needs
 /// to be set to true.
-pub(super) fn has_change(
+pub(super) fn has_change<'a>(
     patch_id: String,
     replaying_when_invoked: bool,
     deprecated: bool,
-) -> NewMachineWithCommand {
-    let (machine, command) =
-        PatchMachine::new_scheduled(SharedState { patch_id }, replaying_when_invoked, deprecated);
-    NewMachineWithCommand {
-        command,
-        machine: machine.into(),
-    }
-}
+    seen_in_peekahead: bool,
+    existing_patch_ids: impl Iterator<Item = &'a str>,
+    internal_flags: InternalFlagsRef,
+) -> Result<(NewMachineWithCommand, Vec<MachineResponse>), WFMachinesError> {
+    let shared_state = SharedState { patch_id };
+    let initial_state = if replaying_when_invoked {
+        Replaying {}.into()
+    } else {
+        Executing {}.into()
+    };
+    let command = Command {
+        command_type: CommandType::RecordMarker as i32,
+        attributes: Some(
+            RecordMarkerCommandAttributes {
+                marker_name: PATCH_MARKER_NAME.to_string(),
+                details: build_has_change_marker_details(&shared_state.patch_id, deprecated)
+                    .context("While encoding patch marker details")?,
+                header: None,
+                failure: None,
+            }
+            .into(),
+        ),
+    };
+    let mut machine = PatchMachine::from_parts(initial_state, shared_state);
+
+    OnEventWrapper::on_event_mut(&mut machine, PatchMachineEvents::Schedule)
+        .expect("Patch machine scheduling doesn't fail");
 
-impl PatchMachine {
-    fn new_scheduled(
-        state: SharedState,
-        replaying_when_invoked: bool,
-        deprecated: bool,
-    ) -> (Self, Command) {
-        let initial_state = if replaying_when_invoked {
-            Replaying {}.into()
+    // If we're replaying but this patch isn't in the peekahead, then we wouldn't have
+    // upserted either, and thus should not create the machine
+    let replaying_and_not_in_history = replaying_when_invoked && !seen_in_peekahead;
+    let cannot_use_flag = !internal_flags.borrow_mut().try_use(
+        CoreInternalFlags::UpsertSearchAttributeOnPatch,
+        !replaying_when_invoked,
+    );
+    let maybe_upsert_cmd = if replaying_and_not_in_history || cannot_use_flag {
+        vec![]
+    } else {
+        // Produce an upsert SA command for this patch.
+        let mut all_ids = BTreeSet::from_iter(existing_patch_ids);
+        all_ids.insert(machine.shared_state.patch_id.as_str());
+        let serialized = all_ids
+            .as_json_payload()
+            .context("Could not serialize search attribute value for patch machine")
+            .map_err(|e| WFMachinesError::Fatal(e.to_string()))?;
+
+        if serialized.data.len() >= MAX_SEARCH_ATTR_PAYLOAD_SIZE {
+            warn!(
+                "Serialized size of {VERSION_SEARCH_ATTR_KEY} search attribute update would \
+                 exceed the maximum value size. Skipping this upsert. Be aware that your \
+                 visibility records will not include the following patch: {}",
+                machine.shared_state.patch_id
+            );
+            vec![]
         } else {
-            Executing {}.into()
-        };
-        let cmd = Command {
-            command_type: CommandType::RecordMarker as i32,
-            attributes: Some(
-                RecordMarkerCommandAttributes {
-                    marker_name: PATCH_MARKER_NAME.to_string(),
-                    details: build_has_change_marker_details(&state.patch_id, deprecated),
-                    header: None,
-                    failure: None,
+            let indexed_fields = {
+                let mut m = HashMap::new();
+                m.insert(VERSION_SEARCH_ATTR_KEY.to_string(), serialized);
+                m
+            };
+            vec![MachineResponse::NewCoreOriginatedCommand(
+                UpsertWorkflowSearchAttributesCommandAttributes {
+                    search_attributes: Some(SearchAttributes { indexed_fields }),
                 }
                 .into(),
-            ),
-        };
-        let mut machine = Self {
-            state: initial_state,
-            shared_state: state,
-        };
-        OnEventWrapper::on_event_mut(&mut machine, PatchMachineEvents::Schedule)
-            .expect("Patch machine scheduling doesn't fail");
+            )]
+        }
+    };
 
-        (machine, cmd)
-    }
+    Ok((
+        NewMachineWithCommand {
+            command,
+            machine: machine.into(),
+        },
+        maybe_upsert_cmd,
+    ))
 }
 
+impl PatchMachine {}
+
 #[derive(Default, Clone)]
 pub(super) struct Executing {}
 
 impl Executing {
     pub(super) fn on_schedule(self) -> PatchMachineTransition<MarkerCommandCreated> {
         TransitionResult::default()
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct MarkerCommandCreated {}
 
 impl MarkerCommandCreated {
     pub(super) fn on_command_record_marker(self) -> PatchMachineTransition<Notified> {
-        TransitionResult::commands(vec![])
+        TransitionResult::default()
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct MarkerCommandCreatedReplaying {}
 
 #[derive(Default, Clone)]
@@ -157,15 +212,15 @@
     fn from(_: MarkerCommandCreatedReplaying) -> Self {
         Self::default()
     }
 }
 impl Notified {
     pub(super) fn on_marker_recorded(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         id: String,
     ) -> PatchMachineTransition<MarkerCommandRecorded> {
         if id != dat.patch_id {
             return TransitionResult::Err(WFMachinesError::Nondeterminism(format!(
                 "Change id {} does not match expected id {}",
                 id, dat.patch_id
             )));
@@ -197,60 +252,68 @@
         Ok(match c {
             CommandType::RecordMarker => Self::CommandRecordMarker,
             _ => return Err(()),
         })
     }
 }
 
-impl TryFrom<HistoryEvent> for PatchMachineEvents {
+impl TryFrom<HistEventData> for PatchMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         match e.get_patch_marker_details() {
             Some((id, _)) => Ok(Self::MarkerRecorded(id)),
             _ => Err(WFMachinesError::Nondeterminism(format!(
-                "Change machine cannot handle this event: {}",
-                e
+                "Change machine cannot handle this event: {e}"
             ))),
         }
     }
 }
 
 #[cfg(test)]
 mod tests {
     use crate::{
+        internal_flags::CoreInternalFlags,
         replay::TestHistoryBuilder,
-        worker::workflow::{machines::WFMachinesError, ManagedWFFunc},
+        worker::workflow::{
+            machines::{patch_state_machine::VERSION_SEARCH_ATTR_KEY, WFMachinesError},
+            ManagedWFFunc,
+        },
     };
     use rstest::rstest;
-    use std::time::Duration;
+    use std::{
+        collections::{hash_map::RandomState, HashSet, VecDeque},
+        time::Duration,
+    };
     use temporal_sdk::{ActivityOptions, WfContext, WorkflowFunction};
     use temporal_sdk_core_protos::{
         constants::PATCH_MARKER_NAME,
         coresdk::{
             common::decode_change_marker_details,
             workflow_activation::{workflow_activation_job, NotifyHasPatch, WorkflowActivationJob},
+            AsJsonPayloadExt, FromJsonPayloadExt,
         },
         temporal::api::{
             command::v1::{
                 command::Attributes, RecordMarkerCommandAttributes,
                 ScheduleActivityTaskCommandAttributes,
+                UpsertWorkflowSearchAttributesCommandAttributes,
             },
             common::v1::ActivityType,
             enums::v1::{CommandType, EventType},
             history::v1::{
-                history_event, ActivityTaskCompletedEventAttributes,
-                ActivityTaskScheduledEventAttributes, ActivityTaskStartedEventAttributes,
-                TimerFiredEventAttributes,
+                ActivityTaskCompletedEventAttributes, ActivityTaskScheduledEventAttributes,
+                ActivityTaskStartedEventAttributes, TimerFiredEventAttributes,
             },
         },
     };
 
     const MY_PATCH_ID: &str = "test_patch_id";
-    #[derive(Eq, PartialEq, Copy, Clone)]
+    #[derive(Eq, PartialEq, Copy, Clone, Debug)]
     enum MarkerType {
         Deprecated,
         NotDeprecated,
         NoMarker,
     }
 
     const ONE_SECOND: Duration = Duration::from_secs(1);
@@ -263,59 +326,73 @@
     /// EVENT_TYPE_ACTIVITY_TASK_SCHEDULED
     /// EVENT_TYPE_ACTIVITY_TASK_STARTED
     /// EVENT_TYPE_ACTIVITY_TASK_COMPLETED
     /// EVENT_TYPE_WORKFLOW_TASK_SCHEDULED
     /// EVENT_TYPE_WORKFLOW_TASK_STARTED
     /// EVENT_TYPE_WORKFLOW_TASK_COMPLETED
     /// EVENT_TYPE_WORKFLOW_EXECUTION_COMPLETED
-    fn patch_marker_single_activity(marker_type: MarkerType) -> TestHistoryBuilder {
+    fn patch_marker_single_activity(
+        marker_type: MarkerType,
+        version: usize,
+        replay: bool,
+    ) -> TestHistoryBuilder {
         let mut t = TestHistoryBuilder::default();
         t.add_by_type(EventType::WorkflowExecutionStarted);
         t.add_full_wf_task();
+        t.set_flags_first_wft(
+            &[CoreInternalFlags::UpsertSearchAttributeOnPatch as u32],
+            &[],
+        );
         match marker_type {
-            MarkerType::Deprecated => t.add_has_change_marker(MY_PATCH_ID, true),
-            MarkerType::NotDeprecated => t.add_has_change_marker(MY_PATCH_ID, false),
+            MarkerType::Deprecated => {
+                t.add_has_change_marker(MY_PATCH_ID, true);
+                t.add_upsert_search_attrs_for_patch(&[MY_PATCH_ID.to_string()]);
+            }
+            MarkerType::NotDeprecated => {
+                t.add_has_change_marker(MY_PATCH_ID, false);
+                t.add_upsert_search_attrs_for_patch(&[MY_PATCH_ID.to_string()]);
+            }
             MarkerType::NoMarker => {}
         };
 
-        let scheduled_event_id = t.add_get_event_id(
-            EventType::ActivityTaskScheduled,
-            Some(
-                history_event::Attributes::ActivityTaskScheduledEventAttributes(
-                    ActivityTaskScheduledEventAttributes {
-                        activity_id: "0".to_string(),
-                        activity_type: Some(ActivityType {
-                            name: "".to_string(),
-                        }),
-                        ..Default::default()
-                    },
-                ),
-            ),
-        );
-        let started_event_id = t.add_get_event_id(
-            EventType::ActivityTaskStarted,
-            Some(
-                history_event::Attributes::ActivityTaskStartedEventAttributes(
-                    ActivityTaskStartedEventAttributes {
-                        scheduled_event_id,
-                        ..Default::default()
-                    },
-                ),
-            ),
-        );
-        t.add(
-            EventType::ActivityTaskCompleted,
-            history_event::Attributes::ActivityTaskCompletedEventAttributes(
-                ActivityTaskCompletedEventAttributes {
-                    scheduled_event_id,
-                    started_event_id,
-                    ..Default::default()
-                },
-            ),
-        );
+        let activity_id = if replay {
+            match (marker_type, version) {
+                (_, 1) => "no_change",
+                (MarkerType::NotDeprecated, 2) => "had_change",
+                (MarkerType::Deprecated, 2) => "had_change",
+                (MarkerType::NoMarker, 2) => "no_change",
+                (_, 3) => "had_change",
+                (_, 4) => "had_change",
+                v => panic!("Nonsense marker / version combo {v:?}"),
+            }
+        } else {
+            // If the workflow isn't replaying (we're creating history here for a workflow which
+            // wasn't replaying at the time of scheduling the activity, and has done that, and now
+            // we're feeding back the history it would have produced) then it always has the change,
+            // except in v1.
+            if version > 1 {
+                "had_change"
+            } else {
+                "no_change"
+            }
+        };
+
+        let scheduled_event_id = t.add(ActivityTaskScheduledEventAttributes {
+            activity_id: activity_id.to_string(),
+            ..Default::default()
+        });
+        let started_event_id = t.add(ActivityTaskStartedEventAttributes {
+            scheduled_event_id,
+            ..Default::default()
+        });
+        t.add(ActivityTaskCompletedEventAttributes {
+            scheduled_event_id,
+            started_event_id,
+            ..Default::default()
+        });
         t.add_full_wf_task();
         t.add_workflow_execution_completed();
         t
     }
 
     async fn v1(ctx: &mut WfContext) {
         ctx.activity(ActivityOptions {
@@ -380,15 +457,15 @@
                     v4(&mut ctx).await;
                 }
                 _ => panic!("Invalid workflow version for test setup"),
             }
             Ok(().into())
         });
 
-        let t = patch_marker_single_activity(marker_type);
+        let t = patch_marker_single_activity(marker_type, workflow_version, replaying);
         let histinfo = if replaying {
             t.get_full_history_info()
         } else {
             t.get_history_info(1)
         };
         ManagedWFFunc::new_from_update(histinfo.unwrap().into(), wfn, vec![])
     }
@@ -418,15 +495,15 @@
             CommandType::ScheduleActivityTask as i32
         );
         let act = if replaying {
             wfm.get_next_activation().await
         } else {
             // Feed more history
             wfm.new_history(
-                patch_marker_single_activity(marker_type)
+                patch_marker_single_activity(marker_type, wf_version, replaying)
                     .get_full_history_info()
                     .unwrap()
                     .into(),
             )
             .await
         };
 
@@ -443,22 +520,21 @@
             // should explode b/c non-dep marker is present
             assert_matches!(act.unwrap_err(), WFMachinesError::Nondeterminism(_));
         }
 
         wfm.shutdown().await.unwrap();
     }
 
+    // Note that the not-replaying and no-marker cases don't make sense and hence are absent
     #[rstest]
-    #[case::v2_no_marker_old_path(false, MarkerType::NoMarker, 2)]
     #[case::v2_marker_new_path(false, MarkerType::NotDeprecated, 2)]
     #[case::v2_dep_marker_new_path(false, MarkerType::Deprecated, 2)]
     #[case::v2_replay_no_marker_old_path(true, MarkerType::NoMarker, 2)]
     #[case::v2_replay_marker_new_path(true, MarkerType::NotDeprecated, 2)]
     #[case::v2_replay_dep_marker_new_path(true, MarkerType::Deprecated, 2)]
-    #[case::v3_no_marker_old_path(false, MarkerType::NoMarker, 3)]
     #[case::v3_marker_new_path(false, MarkerType::NotDeprecated, 3)]
     #[case::v3_dep_marker_new_path(false, MarkerType::Deprecated, 3)]
     #[case::v3_replay_no_marker_old_path(true, MarkerType::NoMarker, 3)]
     #[case::v3_replay_marker_new_path(true, MarkerType::NotDeprecated, 3)]
     #[case::v3_replay_dep_marker_new_path(true, MarkerType::Deprecated, 3)]
     #[tokio::test]
     async fn v2_and_v3_changes(
@@ -479,48 +555,63 @@
                         }
                     ))
                 } => patch_id == MY_PATCH_ID
             );
         } else {
             assert_eq!(act.jobs.len(), 1);
         }
-        let commands = wfm.get_server_commands().commands;
-        assert_eq!(commands.len(), 2);
+        let mut commands = VecDeque::from(wfm.get_server_commands().commands);
+        let expected_num_cmds = if marker_type == MarkerType::NoMarker {
+            2
+        } else {
+            3
+        };
+        assert_eq!(commands.len(), expected_num_cmds);
         let dep_flag_expected = wf_version != 2;
         assert_matches!(
-            commands[0].attributes.as_ref().unwrap(),
+            commands.pop_front().unwrap().attributes.as_ref().unwrap(),
             Attributes::RecordMarkerCommandAttributes(
                 RecordMarkerCommandAttributes { marker_name, details,.. })
 
             if marker_name == PATCH_MARKER_NAME
               && decode_change_marker_details(details).unwrap().1 == dep_flag_expected
         );
+        if expected_num_cmds == 3 {
+            assert_matches!(
+                commands.pop_front().unwrap().attributes.as_ref().unwrap(),
+                Attributes::UpsertWorkflowSearchAttributesCommandAttributes(
+                    UpsertWorkflowSearchAttributesCommandAttributes{ search_attributes: Some(attrs) }
+                )
+                if attrs.indexed_fields.get(VERSION_SEARCH_ATTR_KEY).unwrap()
+                  == &[MY_PATCH_ID].as_json_payload().unwrap()
+            );
+        }
         // The only time the "old" timer should fire is in v2, replaying, without a marker.
         let expected_activity_id =
             if replaying && marker_type == MarkerType::NoMarker && wf_version == 2 {
                 "no_change"
             } else {
                 "had_change"
             };
         assert_matches!(
-            commands[1].attributes.as_ref().unwrap(),
+            commands.pop_front().unwrap().attributes.as_ref().unwrap(),
             Attributes::ScheduleActivityTaskCommandAttributes(
                 ScheduleActivityTaskCommandAttributes { activity_id, .. }
             )
             if activity_id == expected_activity_id
         );
 
         let act = if replaying {
             wfm.get_next_activation().await
         } else {
             // Feed more history. Since we are *not* replaying, we *always* "have" the change
             // and the history should have the has-change timer. v3 of course always has the change
             // regardless.
             wfm.new_history(
-                patch_marker_single_activity(marker_type)
+                patch_marker_single_activity(marker_type, wf_version, replaying)
                     .get_full_history_info()
                     .unwrap()
                     .into(),
             )
             .await
         };
 
@@ -559,128 +650,81 @@
             }
             Ok(().into())
         });
 
         let mut t = TestHistoryBuilder::default();
         t.add_by_type(EventType::WorkflowExecutionStarted);
         t.add_full_wf_task();
+        t.set_flags_first_wft(
+            &[CoreInternalFlags::UpsertSearchAttributeOnPatch as u32],
+            &[],
+        );
         if have_marker_in_hist {
             t.add_has_change_marker(MY_PATCH_ID, false);
-            let scheduled_event_id = t.add_get_event_id(
-                EventType::ActivityTaskScheduled,
-                Some(
-                    history_event::Attributes::ActivityTaskScheduledEventAttributes(
-                        ActivityTaskScheduledEventAttributes {
-                            activity_id: "1".to_owned(),
-                            activity_type: Some(ActivityType {
-                                name: "".to_string(),
-                            }),
-                            ..Default::default()
-                        },
-                    ),
-                ),
-            );
-            let started_event_id = t.add_get_event_id(
-                EventType::ActivityTaskStarted,
-                Some(
-                    history_event::Attributes::ActivityTaskStartedEventAttributes(
-                        ActivityTaskStartedEventAttributes {
-                            scheduled_event_id,
-                            ..Default::default()
-                        },
-                    ),
-                ),
-            );
-            t.add(
-                EventType::ActivityTaskCompleted,
-                history_event::Attributes::ActivityTaskCompletedEventAttributes(
-                    ActivityTaskCompletedEventAttributes {
-                        scheduled_event_id,
-                        started_event_id,
-                        // TODO result: Some(Payloads { payloads: vec![Payload{ metadata: Default::default(), data: vec![] }] }),
-                        ..Default::default()
-                    },
-                ),
-            );
-            t.add_full_wf_task();
-            let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
-            t.add(
-                EventType::TimerFired,
-                history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
-                    started_event_id: timer_started_event_id,
-                    timer_id: "1".to_owned(),
+            t.add_upsert_search_attrs_for_patch(&[MY_PATCH_ID.to_string()]);
+            let scheduled_event_id = t.add(ActivityTaskScheduledEventAttributes {
+                activity_id: "1".to_owned(),
+                activity_type: Some(ActivityType {
+                    name: "".to_string(),
                 }),
-            );
+                ..Default::default()
+            });
+            let started_event_id = t.add(ActivityTaskStartedEventAttributes {
+                scheduled_event_id,
+                ..Default::default()
+            });
+            t.add(ActivityTaskCompletedEventAttributes {
+                scheduled_event_id,
+                started_event_id,
+                ..Default::default()
+            });
+            t.add_full_wf_task();
+            let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+            t.add(TimerFiredEventAttributes {
+                started_event_id: timer_started_event_id,
+                timer_id: "1".to_owned(),
+            });
         } else {
-            let started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
-            t.add(
-                EventType::TimerFired,
-                history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
-                    started_event_id,
-                    timer_id: "1".to_owned(),
-                }),
-            );
+            let started_event_id = t.add_by_type(EventType::TimerStarted);
+            t.add(TimerFiredEventAttributes {
+                started_event_id,
+                timer_id: "1".to_owned(),
+            });
             t.add_full_wf_task();
-            let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
-            t.add(
-                EventType::TimerFired,
-                history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
-                    started_event_id: timer_started_event_id,
-                    timer_id: "2".to_owned(),
-                }),
-            );
+            let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+            t.add(TimerFiredEventAttributes {
+                started_event_id: timer_started_event_id,
+                timer_id: "2".to_owned(),
+            });
         }
         t.add_full_wf_task();
 
         if have_marker_in_hist {
-            let scheduled_event_id = t.add_get_event_id(
-                EventType::ActivityTaskScheduled,
-                Some(
-                    history_event::Attributes::ActivityTaskScheduledEventAttributes(
-                        ActivityTaskScheduledEventAttributes {
-                            activity_id: "2".to_string(),
-                            activity_type: Some(ActivityType {
-                                name: "".to_string(),
-                            }),
-                            ..Default::default()
-                        },
-                    ),
-                ),
-            );
-            let started_event_id = t.add_get_event_id(
-                EventType::ActivityTaskStarted,
-                Some(
-                    history_event::Attributes::ActivityTaskStartedEventAttributes(
-                        ActivityTaskStartedEventAttributes {
-                            scheduled_event_id,
-                            ..Default::default()
-                        },
-                    ),
-                ),
-            );
-            t.add(
-                EventType::ActivityTaskCompleted,
-                history_event::Attributes::ActivityTaskCompletedEventAttributes(
-                    ActivityTaskCompletedEventAttributes {
-                        scheduled_event_id,
-                        started_event_id,
-                        // TODO result: Some(Payloads { payloads: vec![Payload{ metadata: Default::default(), data: vec![] }] }),
-                        ..Default::default()
-                    },
-                ),
-            );
-        } else {
-            let started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
-            t.add(
-                EventType::TimerFired,
-                history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
-                    started_event_id,
-                    timer_id: "3".to_owned(),
+            let scheduled_event_id = t.add(ActivityTaskScheduledEventAttributes {
+                activity_id: "2".to_string(),
+                activity_type: Some(ActivityType {
+                    name: "".to_string(),
                 }),
-            );
+                ..Default::default()
+            });
+            let started_event_id = t.add(ActivityTaskStartedEventAttributes {
+                scheduled_event_id,
+                ..Default::default()
+            });
+            t.add(ActivityTaskCompletedEventAttributes {
+                scheduled_event_id,
+                started_event_id,
+                ..Default::default()
+            });
+        } else {
+            let started_event_id = t.add_by_type(EventType::TimerStarted);
+            t.add(TimerFiredEventAttributes {
+                started_event_id,
+                timer_id: "3".to_owned(),
+            });
         }
         t.add_full_wf_task();
         t.add_workflow_execution_completed();
 
         let mut wfm = if replay {
             let mut wfm = ManagedWFFunc::new_from_update(
                 t.get_full_history_info().unwrap().into(),
@@ -701,8 +745,79 @@
                 wfm.process_all_activations().await.unwrap();
             }
             wfm
         };
 
         wfm.shutdown().await.unwrap();
     }
+
+    const SIZE_OVERFLOW_PATCH_AMOUNT: usize = 180;
+    #[rstest]
+    #[case::happy_path(50)]
+    // We start exceeding the 2k size limit at 180 patches with this format
+    #[case::size_overflow(SIZE_OVERFLOW_PATCH_AMOUNT)]
+    #[tokio::test]
+    async fn many_patches_combine_in_search_attrib_update(#[case] num_patches: usize) {
+        let mut t = TestHistoryBuilder::default();
+        t.add_by_type(EventType::WorkflowExecutionStarted);
+        t.add_full_wf_task();
+        t.set_flags_first_wft(
+            &[CoreInternalFlags::UpsertSearchAttributeOnPatch as u32],
+            &[],
+        );
+        for i in 1..=num_patches {
+            let id = format!("patch-{i}");
+            t.add_has_change_marker(&id, false);
+            if i < SIZE_OVERFLOW_PATCH_AMOUNT {
+                t.add_upsert_search_attrs_for_patch(&[id]);
+            }
+            let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+            t.add(TimerFiredEventAttributes {
+                started_event_id: timer_started_event_id,
+                timer_id: i.to_string(),
+            });
+            t.add_full_wf_task();
+        }
+        t.add_workflow_execution_completed();
+
+        let mut wfm = ManagedWFFunc::new_from_update(
+            t.get_history_info(1).unwrap().into(),
+            WorkflowFunction::new(move |ctx: WfContext| async move {
+                for i in 1..=num_patches {
+                    let _dontcare = ctx.patched(&format!("patch-{i}"));
+                    ctx.timer(ONE_SECOND).await;
+                }
+                Ok(().into())
+            }),
+            vec![],
+        );
+        // Iterate through all activations/responses except the final one with complete workflow
+        for i in 2..=num_patches + 1 {
+            wfm.get_next_activation().await.unwrap();
+            let cmds = wfm.get_server_commands();
+            wfm.new_history(t.get_history_info(i).unwrap().into())
+                .await
+                .unwrap();
+            if i > SIZE_OVERFLOW_PATCH_AMOUNT {
+                assert_eq!(2, cmds.commands.len());
+                assert_matches!(cmds.commands[1].command_type(), CommandType::StartTimer);
+                continue;
+            }
+            assert_eq!(3, cmds.commands.len());
+            let attrs = assert_matches!(
+                cmds.commands[1].attributes.as_ref().unwrap(),
+                Attributes::UpsertWorkflowSearchAttributesCommandAttributes(
+                    UpsertWorkflowSearchAttributesCommandAttributes{ search_attributes: Some(attrs) }
+                )
+                  => attrs
+            );
+            let expected_patches: HashSet<String, _> =
+                (1..i).map(|i| format!("patch-{i}")).collect();
+            let deserialized = HashSet::<String, RandomState>::from_json_payload(
+                attrs.indexed_fields.get(VERSION_SEARCH_ATTR_KEY).unwrap(),
+            )
+            .unwrap();
+            assert_eq!(deserialized, expected_patches);
+        }
+        wfm.shutdown().await.unwrap();
+    }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/signal_external_state_machine.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
     OnEventWrapper, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, MachineError, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, MachineError, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::{
         common::NamespacedWorkflowExecution,
         workflow_activation::ResolveSignalExternalWorkflow,
         workflow_commands::{
             signal_external_workflow_execution as sig_we, SignalExternalWorkflowExecution,
@@ -81,18 +82,16 @@
                 run_id: "".to_string(),
             },
             true,
         ),
         Some(sig_we::Target::WorkflowExecution(we)) => (we, false),
     };
 
-    let mut s = SignalExternalMachine {
-        state: Created {}.into(),
-        shared_state: SharedState { seq: attrs.seq },
-    };
+    let mut s =
+        SignalExternalMachine::from_parts(Created {}.into(), SharedState { seq: attrs.seq });
     OnEventWrapper::on_event_mut(&mut s, SignalExternalMachineEvents::Schedule)
         .expect("Scheduling signal external wf command doesn't fail");
     let cmd_attrs = command::Attributes::SignalExternalWorkflowExecutionCommandAttributes(
         SignalExternalWorkflowExecutionCommandAttributes {
             namespace: workflow_execution.namespace,
             execution: Some(UpstreamWE {
                 workflow_id: workflow_execution.workflow_id,
@@ -179,18 +178,19 @@
             CommandType::SignalExternalWorkflowExecution => {
                 Self::CommandSignalExternalWorkflowExecution
             }
             _ => return Err(()),
         })
     }
 }
-impl TryFrom<HistoryEvent> for SignalExternalMachineEvents {
+impl TryFrom<HistEventData> for SignalExternalMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::ExternalWorkflowExecutionSignaled => Self::ExternalWorkflowExecutionSignaled,
             EventType::SignalExternalWorkflowExecutionInitiated => {
                 Self::SignalExternalWorkflowExecutionInitiated
             }
             EventType::SignalExternalWorkflowExecutionFailed => {
                 if let Some(
@@ -198,23 +198,21 @@
                         attrs,
                     ),
                 ) = e.attributes
                 {
                     Self::SignalExternalWorkflowExecutionFailed(attrs.cause())
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Signal workflow failed attributes were unset: {}",
-                        e
+                        "Signal workflow failed attributes were unset: {e}"
                     )));
                 }
             }
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Signal external WF machine does not handle this event: {}",
-                    e
+                    "Signal external WF machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl WFMachinesAdapter for SignalExternalMachine {
@@ -232,21 +230,24 @@
                 .into()]
             }
             SignalExternalCommand::Failed(f) => {
                 let reason = match f {
                     SignalExternalWorkflowExecutionFailedCause::Unspecified => "unknown",
                     SignalExternalWorkflowExecutionFailedCause::ExternalWorkflowExecutionNotFound
                     | SignalExternalWorkflowExecutionFailedCause::NamespaceNotFound =>
-                        "it was not found"
+                        "it was not found",
+                    SignalExternalWorkflowExecutionFailedCause::SignalCountLimitExceeded => {
+                        "The per-workflow signal limit was exceeded"
+                    }
                 };
                 vec![ResolveSignalExternalWorkflow {
                     seq: self.shared_state.seq,
                     // TODO: Create new failure type upstream for this
                     failure: Some(Failure {
-                        message: format!("Unable to signal external workflow because {}", reason),
+                        message: format!("Unable to signal external workflow because {reason}"),
                         failure_info: Some(FailureInfo::ApplicationFailureInfo(
                             ApplicationFailureInfo {
                                 r#type: f.to_string(),
                                 ..Default::default()
                             },
                         )),
                         ..Default::default()
@@ -293,15 +294,15 @@
         };
         Ok(ret)
     }
 
     fn was_cancelled_before_sent_to_server(&self) -> bool {
         // We are only ever in the cancelled state if cancelled before sent to server, there is no
         // after sent cancellation here.
-        matches!(self.state, SignalExternalMachineState::Cancelled(_))
+        matches!(self.state(), SignalExternalMachineState::Cancelled(_))
     }
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
     use crate::{replay::TestHistoryBuilder, worker::workflow::ManagedWFFunc};
@@ -423,17 +424,14 @@
 
     #[test]
     fn cancels_ignored_terminal() {
         for state in [
             SignalExternalMachineState::Cancelled(Cancelled {}),
             Signaled {}.into(),
         ] {
-            let mut s = SignalExternalMachine {
-                state: state.clone(),
-                shared_state: Default::default(),
-            };
+            let mut s = SignalExternalMachine::from_parts(state.clone(), Default::default());
             let cmds = s.cancel().unwrap();
             assert_eq!(cmds.len(), 0);
-            assert_eq!(discriminant(&state), discriminant(&s.state));
+            assert_eq!(discriminant(&state), discriminant(s.state()));
         }
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/timer_state_machine.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 #![allow(clippy::large_enum_variant)]
 
 use super::{
-    workflow_machines::{MachineResponse, WFMachinesError},
-    Cancellable, EventInfo, NewMachineWithCommand, OnEventWrapper, WFMachinesAdapter,
+    workflow_machines::MachineResponse, Cancellable, EventInfo, NewMachineWithCommand,
+    OnEventWrapper, WFMachinesAdapter,
 };
+use crate::worker::workflow::{machines::HistEventData, WFMachinesError};
 use rustfsm::{fsm, MachineError, StateMachine, TransitionResult};
 use std::convert::TryFrom;
 use temporal_sdk_core_protos::{
     coresdk::{
         workflow_activation::FireTimer,
         workflow_commands::{CancelTimer, StartTimer},
         HistoryEventId,
@@ -79,47 +80,46 @@
             command_type: CommandType::StartTimer as i32,
             attributes: Some(s.shared_state().attrs.clone().into()),
         };
         (s, cmd)
     }
 
     fn new(attribs: StartTimer) -> Self {
-        Self {
-            state: Created {}.into(),
-            shared_state: SharedState {
+        Self::from_parts(
+            Created {}.into(),
+            SharedState {
                 attrs: attribs,
                 cancelled_before_sent: false,
             },
-        }
+        )
     }
 }
 
-impl TryFrom<HistoryEvent> for TimerMachineEvents {
+impl TryFrom<HistEventData> for TimerMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::TimerStarted => Self::TimerStarted(e.event_id),
             EventType::TimerCanceled => Self::TimerCanceled,
             EventType::TimerFired => {
                 if let Some(history_event::Attributes::TimerFiredEventAttributes(attrs)) =
                     e.attributes
                 {
                     Self::TimerFired(attrs)
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Timer fired attribs were unset: {}",
-                        e
+                        "Timer fired attribs were unset: {e}"
                     )));
                 }
             }
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Timer machine does not handle this event: {}",
-                    e
+                    "Timer machine does not handle this event: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for TimerMachineEvents {
@@ -174,48 +174,42 @@
     pub(super) fn on_timer_started(
         self,
         _id: HistoryEventId,
     ) -> TimerMachineTransition<StartCommandRecorded> {
         TransitionResult::default()
     }
 
-    pub(super) fn on_cancel(self, dat: SharedState) -> TimerMachineTransition<Canceled> {
-        TransitionResult::ok_shared(
-            vec![],
-            Canceled::default(),
-            SharedState {
-                cancelled_before_sent: true,
-                ..dat
-            },
-        )
+    pub(super) fn on_cancel(self, dat: &mut SharedState) -> TimerMachineTransition<Canceled> {
+        dat.cancelled_before_sent = true;
+        TransitionResult::default()
     }
 }
 
 #[derive(Default, Clone)]
 pub(super) struct StartCommandRecorded {}
 
 impl StartCommandRecorded {
     pub(super) fn on_timer_fired(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
         attrs: TimerFiredEventAttributes,
     ) -> TimerMachineTransition<Fired> {
         if dat.attrs.seq.to_string() == attrs.timer_id {
             TransitionResult::ok(vec![TimerMachineCommand::Complete], Fired::default())
         } else {
             TransitionResult::Err(WFMachinesError::Fatal(format!(
                 "Timer fired event did not have expected timer id {}, it was {}!",
                 dat.attrs.seq, attrs.timer_id
             )))
         }
     }
 
     pub(super) fn on_cancel(
         self,
-        dat: SharedState,
+        dat: &mut SharedState,
     ) -> TimerMachineTransition<CancelTimerCommandCreated> {
         let cmd = Command {
             command_type: CommandType::CancelTimer as i32,
             attributes: Some(CancelTimer { seq: dat.attrs.seq }.into()),
         };
         TransitionResult::ok(
             vec![TimerMachineCommand::IssueCancelCmd(cmd)],
@@ -252,15 +246,15 @@
     fn cancel(&mut self) -> Result<Vec<MachineResponse>, MachineError<Self::Error>> {
         Ok(
             match OnEventWrapper::on_event_mut(self, TimerMachineEvents::Cancel)?.pop() {
                 Some(TimerMachineCommand::IssueCancelCmd(cmd)) => {
                     vec![MachineResponse::IssueNewCommand(cmd)]
                 }
                 None => vec![],
-                x => panic!("Invalid cancel event response {:?}", x),
+                x => panic!("Invalid cancel event response {x:?}"),
             },
         )
     }
 
     fn was_cancelled_before_sent_to_server(&self) -> bool {
         self.shared_state().cancelled_before_sent
     }
@@ -419,17 +413,14 @@
         assert_eq!(commands.len(), 0);
         wfm.shutdown().await.unwrap();
     }
 
     #[test]
     fn cancels_ignored_terminal() {
         for state in [TimerMachineState::Canceled(Canceled {}), Fired {}.into()] {
-            let mut s = TimerMachine {
-                state: state.clone(),
-                shared_state: Default::default(),
-            };
+            let mut s = TimerMachine::from_parts(state.clone(), Default::default());
             let cmds = s.cancel().unwrap();
             assert_eq!(cmds.len(), 0);
-            assert_eq!(discriminant(&state), discriminant(&s.state));
+            assert_eq!(discriminant(&state), discriminant(s.state()));
         }
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/transition_coverage.rs`

 * *Files 1% similar despite different names*

```diff
@@ -140,15 +140,15 @@
                 m @ "LocalActivityMachine" => cover_transitions(m, &mut la_mach, coverage),
                 m @ "UpsertSearchAttributesMachine" => {
                     cover_transitions(m, &mut upsert_search_attr, coverage)
                 }
                 m @ "ModifyWorkflowPropertiesMachine" => {
                     cover_transitions(m, &mut modify_wf_props, coverage)
                 }
-                m => panic!("Unknown machine {}", m),
+                m => panic!("Unknown machine {m}"),
             }
         }
     }
 
     fn cover_transitions(machine: &str, viz: &mut String, cov: &DashSet<CoveredTransition>) {
         for trans in cov.iter() {
             let find_line = format!(
@@ -164,12 +164,12 @@
             }
         }
 
         // Dump the updated viz to a file
         let mut d = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
         d.push("machine_coverage");
         std::fs::create_dir_all(&d).unwrap();
-        d.push(format!("{}_Coverage.puml", machine));
+        d.push(format!("{machine}_Coverage.puml"));
         let mut file = File::create(d).unwrap();
         file.write_all(viz.as_bytes()).unwrap();
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines/local_acts.rs`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,17 @@
-use super::super::{local_activity_state_machine::ResolveDat, WFMachinesError};
+use super::super::local_activity_state_machine::ResolveDat;
 use crate::{
-    protosext::{HistoryEventExt, ValidScheduleLA},
+    protosext::{CompleteLocalActivityData, ValidScheduleLA},
     worker::{ExecutingLAId, LocalActRequest, NewLocalAct},
 };
 use std::{
     collections::{HashMap, HashSet},
     time::SystemTime,
 };
-use temporal_sdk_core_protos::temporal::api::{
-    common::v1::WorkflowExecution, history::v1::HistoryEvent,
-};
+use temporal_sdk_core_protos::temporal::api::common::v1::WorkflowExecution;
 
 #[derive(Default)]
 pub(super) struct LocalActivityData {
     /// Queued local activity requests which need to be executed
     new_requests: Vec<ValidScheduleLA>,
     /// Queued cancels that need to be dispatched
     cancel_requests: Vec<ExecutingLAId>,
@@ -66,25 +64,16 @@
     }
 
     /// Returns all outstanding local activities, whether executing or requested and in the queue
     pub(super) fn outstanding_la_count(&self) -> usize {
         self.executing.len() + self.new_requests.len()
     }
 
-    pub(super) fn process_peekahead_marker(&mut self, e: &HistoryEvent) -> super::Result<()> {
-        if let Some(la_dat) = e.clone().into_local_activity_marker_details() {
-            self.preresolutions
-                .insert(la_dat.marker_dat.seq, la_dat.into());
-        } else {
-            return Err(WFMachinesError::Fatal(format!(
-                "Local activity marker was unparsable: {:?}",
-                e
-            )));
-        }
-        Ok(())
+    pub(super) fn insert_peeked_marker(&mut self, dat: CompleteLocalActivityData) {
+        self.preresolutions.insert(dat.marker_dat.seq, dat.into());
     }
 
     pub(super) fn take_preresolution(&mut self, seq: u32) -> Option<ResolveDat> {
         self.preresolutions.remove(&seq)
     }
 
     pub(super) fn remove_from_queue(&mut self, seq: u32) -> Option<ValidScheduleLA> {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_machines.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,43 +1,52 @@
 mod local_acts;
 
-pub(crate) use temporal_sdk_core_api::errors::WFMachinesError;
-
 use super::{
-    activity_state_machine::new_activity, cancel_external_state_machine::new_external_cancel,
+    cancel_external_state_machine::new_external_cancel,
     cancel_workflow_state_machine::cancel_workflow,
-    child_workflow_state_machine::new_child_workflow,
     complete_workflow_state_machine::complete_workflow,
     continue_as_new_workflow_state_machine::continue_as_new,
     fail_workflow_state_machine::fail_workflow, local_activity_state_machine::new_local_activity,
     patch_state_machine::has_change, signal_external_state_machine::new_external_signal,
     timer_state_machine::new_timer, upsert_search_attributes_state_machine::upsert_search_attrs,
     workflow_machines::local_acts::LocalActivityData,
     workflow_task_state_machine::WorkflowTaskMachine, Machines, NewMachineWithCommand,
     TemporalStateMachine,
 };
 use crate::{
+    internal_flags::InternalFlags,
     protosext::{HistoryEventExt, ValidScheduleLA},
     telemetry::{metrics::MetricsContext, VecDisplayer},
     worker::{
         workflow::{
-            machines::modify_workflow_properties_state_machine::modify_workflow_properties,
-            CommandID, DrivenWorkflow, HistoryUpdate, LocalResolution, OutgoingJob, WFCommand,
-            WorkflowFetcher, WorkflowStartedInfo,
+            history_update::NextWFT,
+            machines::{
+                activity_state_machine::ActivityMachine,
+                child_workflow_state_machine::ChildWorkflowMachine,
+                modify_workflow_properties_state_machine::modify_workflow_properties,
+                patch_state_machine::VERSION_SEARCH_ATTR_KEY,
+                upsert_search_attributes_state_machine::upsert_search_attrs_internal,
+                HistEventData,
+            },
+            CommandID, DrivenWorkflow, HistoryUpdate, InternalFlagsRef, LocalResolution,
+            OutgoingJob, RunBasics, WFCommand, WFMachinesError, WorkflowFetcher,
+            WorkflowStartedInfo,
         },
         ExecutingLAId, LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
     },
 };
 use siphasher::sip::SipHasher13;
 use slotmap::{SlotMap, SparseSecondaryMap};
 use std::{
     borrow::{Borrow, BorrowMut},
+    cell::RefCell,
     collections::{HashMap, VecDeque},
     convert::TryInto,
     hash::{Hash, Hasher},
+    rc::Rc,
     time::{Duration, Instant, SystemTime},
 };
 use temporal_sdk_core_protos::{
     coresdk::{
         common::NamespacedWorkflowExecution,
         workflow_activation,
         workflow_activation::{
@@ -46,15 +55,16 @@
         workflow_commands::{
             request_cancel_external_workflow_execution as cancel_we, ContinueAsNewWorkflowExecution,
         },
     },
     temporal::api::{
         command::v1::{command::Attributes as ProtoCmdAttrs, Command as ProtoCommand},
         enums::v1::EventType,
-        history::v1::{history_event, HistoryEvent},
+        history::v1::{history_event, history_event::Attributes, HistoryEvent},
+        sdk::v1::WorkflowTaskCompletedMetadata,
     },
 };
 
 type Result<T, E = WFMachinesError> = std::result::Result<T, E>;
 
 slotmap::new_key_type! { struct MachineKey; }
 /// Handles all the logic for driving a workflow. It orchestrates many state machines that together
@@ -91,14 +101,17 @@
     /// a terminal workflow command. If this is `Some`, you know the workflow is ended.
     workflow_end_time: Option<SystemTime>,
     /// The WFT start time if it has been established
     wft_start_time: Option<SystemTime>,
     /// The current workflow time if it has been established. This may differ from the WFT start
     /// time since local activities may advance the clock
     current_wf_time: Option<SystemTime>,
+    /// The internal flags which have been seen so far during this run's execution and thus are
+    /// usable during replay.
+    observed_internal_flags: InternalFlagsRef,
 
     all_machines: SlotMap<MachineKey, Machines>,
     /// If a machine key is in this map, that machine was created internally by core, not as a
     /// command from lang.
     machine_is_core_created: SparseSecondaryMap<MachineKey, ()>,
 
     /// A mapping for accessing machines associated to a particular event, where the key is the id
@@ -129,111 +142,109 @@
     pub have_seen_terminal_event: bool,
 
     /// Metrics context
     pub metrics: MetricsContext,
 }
 
 #[derive(Debug, derive_more::Display)]
-#[display(fmt = "Cmd&Machine({})", "command")]
+#[display(fmt = "Cmd&Machine({command})")]
 struct CommandAndMachine {
     command: MachineAssociatedCommand,
     machine: MachineKey,
 }
 
 #[derive(Debug, derive_more::Display)]
 enum MachineAssociatedCommand {
     Real(Box<ProtoCommand>),
-    #[display(fmt = "FakeLocalActivityMarker({})", "_0")]
+    #[display(fmt = "FakeLocalActivityMarker({_0})")]
     FakeLocalActivityMarker(u32),
 }
 
 #[derive(Debug, Clone, Copy)]
 struct ChangeInfo {
     created_command: bool,
 }
 
 /// Returned by [TemporalStateMachine]s when handling events
 #[derive(Debug, derive_more::Display)]
 #[must_use]
 #[allow(clippy::large_enum_variant)]
 pub(super) enum MachineResponse {
-    #[display(fmt = "PushWFJob({})", "_0")]
+    #[display(fmt = "PushWFJob({_0})")]
     PushWFJob(OutgoingJob),
 
     /// Pushes a new command into the list that will be sent to server once we respond with the
     /// workflow task completion
     IssueNewCommand(ProtoCommand),
     /// The machine requests the creation of another *different* machine. This acts as if lang
     /// had replied to the activation with a command, but we use a special set of IDs to avoid
     /// collisions.
-    #[display(fmt = "NewCoreOriginatedCommand({:?})", "_0")]
+    #[display(fmt = "NewCoreOriginatedCommand({_0:?})")]
     NewCoreOriginatedCommand(ProtoCmdAttrs),
-    #[display(fmt = "IssueFakeLocalActivityMarker({})", "_0")]
+    #[display(fmt = "IssueFakeLocalActivityMarker({_0})")]
     IssueFakeLocalActivityMarker(u32),
     #[display(fmt = "TriggerWFTaskStarted")]
     TriggerWFTaskStarted {
         task_started_event_id: i64,
         time: SystemTime,
     },
-    #[display(fmt = "UpdateRunIdOnWorkflowReset({})", run_id)]
+    #[display(fmt = "UpdateRunIdOnWorkflowReset({run_id})")]
     UpdateRunIdOnWorkflowReset { run_id: String },
 
     /// Queue a local activity to be processed by the worker
     #[display(fmt = "QueueLocalActivity")]
     QueueLocalActivity(ValidScheduleLA),
     /// Request cancellation of an executing local activity
-    #[display(fmt = "RequestCancelLocalActivity({})", "_0")]
+    #[display(fmt = "RequestCancelLocalActivity({_0})")]
     RequestCancelLocalActivity(u32),
     /// Indicates we are abandoning the indicated LA, so we can remove it from "outstanding" LAs
     /// and we will not try to WFT heartbeat because of it.
-    #[display(fmt = "AbandonLocalActivity({:?})", "_0")]
+    #[display(fmt = "AbandonLocalActivity({_0:?})")]
     AbandonLocalActivity(u32),
 
     /// Set the workflow time to the provided time
-    #[display(fmt = "UpdateWFTime({:?})", "_0")]
+    #[display(fmt = "UpdateWFTime({_0:?})")]
     UpdateWFTime(Option<SystemTime>),
 }
 
 impl<T> From<T> for MachineResponse
 where
     T: Into<workflow_activation_job::Variant>,
 {
     fn from(v: T) -> Self {
         Self::PushWFJob(v.into().into())
     }
 }
 
 impl WorkflowMachines {
-    pub(crate) fn new(
-        namespace: String,
-        workflow_id: String,
-        workflow_type: String,
-        run_id: String,
-        history: HistoryUpdate,
-        driven_wf: DrivenWorkflow,
-        metrics: MetricsContext,
-    ) -> Self {
-        let replaying = history.previous_started_event_id > 0;
+    pub(crate) fn new(basics: RunBasics, driven_wf: DrivenWorkflow) -> Self {
+        let replaying = basics.history.previous_wft_started_id > 0;
+        let mut observed_internal_flags = InternalFlags::new(basics.capabilities);
+        // Peek ahead to determine used patches in the first WFT.
+        if let Some(attrs) = basics.history.peek_next_wft_completed(0) {
+            observed_internal_flags.add_from_complete(attrs);
+        };
         Self {
-            last_history_from_server: history,
-            namespace,
-            workflow_id,
-            workflow_type,
-            run_id,
+            last_history_from_server: basics.history,
+            namespace: basics.namespace,
+            workflow_id: basics.workflow_id,
+            workflow_type: basics.workflow_type,
+            run_id: basics.run_id,
             drive_me: driven_wf,
             replaying,
-            metrics,
+            metrics: basics.metrics,
             // In an ideal world one could say ..Default::default() here and it'd still work.
             current_started_event_id: 0,
             next_started_event_id: 0,
             last_processed_event: 0,
             workflow_start_time: None,
             workflow_end_time: None,
             wft_start_time: None,
             current_wf_time: None,
+            observed_internal_flags: Rc::new(RefCell::new(observed_internal_flags)),
             all_machines: Default::default(),
             machine_is_core_created: Default::default(),
             machines_by_event_id: Default::default(),
             id_to_machine: Default::default(),
             commands: Default::default(),
             current_wf_task_commands: Default::default(),
             encountered_change_markers: Default::default(),
@@ -251,18 +262,18 @@
     /// incomplete, or time went backwards.
     pub(crate) fn total_runtime(&self) -> Option<Duration> {
         self.workflow_start_time
             .zip(self.workflow_end_time)
             .and_then(|(st, et)| et.duration_since(st).ok())
     }
 
-    pub(crate) async fn new_history_from_server(&mut self, update: HistoryUpdate) -> Result<()> {
+    pub(crate) fn new_history_from_server(&mut self, update: HistoryUpdate) -> Result<()> {
         self.last_history_from_server = update;
-        self.replaying = self.last_history_from_server.previous_started_event_id > 0;
-        self.apply_next_wft_from_history().await?;
+        self.replaying = self.last_history_from_server.previous_wft_started_id > 0;
+        self.apply_next_wft_from_history()?;
         Ok(())
     }
 
     /// Let this workflow know that something we've been waiting locally on has resolved, like a
     /// local activity or side effect
     ///
     /// Returns true if the resolution did anything. EX: If the activity is already canceled and
@@ -286,17 +297,16 @@
                         lam.try_resolve(result, runtime, attempt, backoff, original_schedule_time)?;
                     if resps.is_empty() {
                         result_important = false;
                     }
                     self.process_machine_responses(mk, resps)?;
                 } else {
                     return Err(WFMachinesError::Nondeterminism(format!(
-                        "Command matching activity with seq num {} existed but was not a \
-                        local activity!",
-                        seq
+                        "Command matching activity with seq num {seq} existed but was not a \
+                        local activity!"
                     )));
                 }
                 self.local_activity_data.done_executing(seq);
             }
         }
         Ok(result_important)
     }
@@ -317,14 +327,19 @@
         self.drive_me.get_started_info()
     }
 
     /// Fetches commands which are ready for processing from the state machines, generally to be
     /// sent off to the server. They are not removed from the internal queue, that happens when
     /// corresponding history events from the server are being handled.
     pub(crate) fn get_commands(&self) -> Vec<ProtoCommand> {
+        // Since we're about to write a WFT, record any internal flags we know about which aren't
+        // already recorded.
+        (*self.observed_internal_flags)
+            .borrow_mut()
+            .write_all_known();
         self.commands
             .iter()
             .filter_map(|c| {
                 if !self.machine(c.machine).is_final_state() {
                     match &c.command {
                         MachineAssociatedCommand::Real(cmd) => Some((**cmd).clone()),
                         MachineAssociatedCommand::FakeLocalActivityMarker(_) => None,
@@ -346,63 +361,112 @@
         let jobs = self.drive_me.drain_jobs();
         WorkflowActivation {
             timestamp: self.current_wf_time.map(Into::into),
             is_replaying: self.replaying,
             run_id: self.run_id.clone(),
             history_length: self.last_processed_event as u32,
             jobs,
+            available_internal_flags: (*self.observed_internal_flags)
+                .borrow()
+                .all_lang()
+                .collect(),
         }
     }
 
     pub(crate) fn has_pending_jobs(&self) -> bool {
         !self.drive_me.peek_pending_jobs().is_empty()
     }
 
     pub(crate) fn has_pending_la_resolutions(&self) -> bool {
         self.drive_me
             .peek_pending_jobs()
             .iter()
             .any(|v| v.is_la_resolution)
     }
 
+    pub(crate) fn get_metadata_for_wft_complete(&self) -> WorkflowTaskCompletedMetadata {
+        (*self.observed_internal_flags)
+            .borrow_mut()
+            .gather_for_wft_complete()
+    }
+
+    pub(crate) fn add_lang_used_flags(&self, flags: Vec<u32>) {
+        (*self.observed_internal_flags)
+            .borrow_mut()
+            .add_lang_used(flags);
+    }
+
     /// Iterate the state machines, which consists of grabbing any pending outgoing commands from
     /// the workflow code, handling them, and preparing them to be sent off to the server.
-    pub(crate) async fn iterate_machines(&mut self) -> Result<()> {
-        let results = self.drive_me.fetch_workflow_iteration_output().await;
+    pub(crate) fn iterate_machines(&mut self) -> Result<()> {
+        let results = self.drive_me.fetch_workflow_iteration_output();
         self.handle_driven_results(results)?;
         self.prepare_commands()?;
         if self.workflow_is_finished() {
             if let Some(rt) = self.total_runtime() {
                 self.metrics.wf_e2e_latency(rt);
             }
         }
         Ok(())
     }
 
+    /// Returns true if machines are ready to apply the next WFT sequence, false if events will need
+    /// to be fetched in order to create a complete update with the entire next WFT sequence.
+    pub(crate) fn ready_to_apply_next_wft(&self) -> bool {
+        self.last_history_from_server
+            .can_take_next_wft_sequence(self.current_started_event_id)
+    }
+
     /// Apply the next (unapplied) entire workflow task from history to these machines. Will replay
-    /// any events that need to be replayed until caught up to the newest WFT. May also fetch
-    /// history from server if needed.
-    pub(crate) async fn apply_next_wft_from_history(&mut self) -> Result<usize> {
+    /// any events that need to be replayed until caught up to the newest WFT.
+    pub(crate) fn apply_next_wft_from_history(&mut self) -> Result<usize> {
         // If we have already seen the terminal event for the entire workflow in a previous WFT,
         // then we don't need to do anything here, and in fact we need to avoid re-applying the
         // final WFT.
         if self.have_seen_terminal_event {
+            // Replay clearly counts as done now, since we return here and never do anything else.
+            self.replaying = false;
             return Ok(0);
         }
 
-        let last_handled_wft_started_id = self.current_started_event_id;
-        let events = {
-            let mut evts = self
+        fn update_internal_flags(me: &mut WorkflowMachines) {
+            // Update observed patches with any that were used in the task
+            if let Some(next_complete) = me
                 .last_history_from_server
-                .take_next_wft_sequence(last_handled_wft_started_id)
-                .await
-                .map_err(WFMachinesError::HistoryFetchingError)?;
-            // Do not re-process events we have already processed
-            evts.retain(|e| e.event_id > self.last_processed_event);
-            evts
+                .peek_next_wft_completed(me.last_processed_event)
+            {
+                (*me.observed_internal_flags)
+                    .borrow_mut()
+                    .add_from_complete(next_complete);
+            }
+        }
+
+        // We update the internal flags before applying the current task (peeking to the completion
+        // of this task), and also at the end (peeking to the completion of the task that lang is
+        // about to generate commands for, and for which we will want those flags active).
+        update_internal_flags(self);
+
+        let last_handled_wft_started_id = self.current_started_event_id;
+        let (events, has_final_event) = match self
+            .last_history_from_server
+            .take_next_wft_sequence(last_handled_wft_started_id)
+        {
+            NextWFT::ReplayOver => (vec![], true),
+            NextWFT::WFT(mut evts, has_final_event) => {
+                // Do not re-process events we have already processed
+                evts.retain(|e| e.event_id > self.last_processed_event);
+                (evts, has_final_event)
+            }
+            NextWFT::NeedFetch => {
+                return Err(WFMachinesError::Fatal(
+                    "Need to fetch history events to continue applying workflow task, but this \
+                     should be prevented ahead of time! This is a Core SDK bug."
+                        .to_string(),
+                ));
+            }
         };
         let num_events_to_process = events.len();
 
         // We're caught up on reply if there are no new events to process
         if events.is_empty() {
             self.replaying = false;
         }
@@ -410,284 +474,341 @@
 
         if let Some(last_event) = events.last() {
             if last_event.event_type == EventType::WorkflowTaskStarted as i32 {
                 self.next_started_event_id = last_event.event_id;
             }
         }
 
+        let mut saw_completed = false;
+        let mut do_handle_event = true;
         let mut history = events.into_iter().peekable();
         while let Some(event) = history.next() {
             if event.event_id != self.last_processed_event + 1 {
                 return Err(WFMachinesError::Fatal(format!(
                     "History is out of order. Last processed event: {}, event id: {}",
                     self.last_processed_event, event.event_id
                 )));
             }
             let next_event = history.peek();
             let eid = event.event_id;
-            let etype = event.event_type();
-            self.handle_event(event, next_event.is_some())?;
-            self.last_processed_event = eid;
-            if etype == EventType::WorkflowTaskStarted && next_event.is_none() {
-                break;
+
+            // This definition of replaying here is that we are no longer replaying as soon as we
+            // see new events that have never been seen or produced by the SDK.
+            //
+            // Specifically, replay ends once we have seen the last command-event which was produced
+            // as a result of the last completed WFT. Thus, replay would be false for things like
+            // signals which were received and after the last completion, and thus generated the
+            // current WFT being handled.
+            if self.replaying && has_final_event && saw_completed && !event.is_command_event() {
+                // Replay is finished
+                self.replaying = false;
+            }
+            if event.event_type() == EventType::WorkflowTaskCompleted {
+                saw_completed = true;
+            }
+
+            if do_handle_event {
+                let eho = self.handle_event(
+                    HistEventData {
+                        event,
+                        replaying: self.replaying,
+                        current_task_is_last_in_history: has_final_event,
+                    },
+                    next_event,
+                )?;
+                if matches!(
+                    eho,
+                    EventHandlingOutcome::SkipEvent {
+                        skip_next_event: true
+                    }
+                ) {
+                    do_handle_event = false;
+                }
+            } else {
+                do_handle_event = true;
             }
+            self.last_processed_event = eid;
         }
 
         // Scan through to the next WFT, searching for any patch / la markers, so that we can
         // pre-resolve them.
-        for e in self.last_history_from_server.peek_next_wft_sequence() {
+        let mut wake_las = vec![];
+        for e in self
+            .last_history_from_server
+            .peek_next_wft_sequence(last_handled_wft_started_id)
+        {
             if let Some((patch_id, _)) = e.get_patch_marker_details() {
                 self.encountered_change_markers.insert(
                     patch_id.clone(),
                     ChangeInfo {
                         created_command: false,
                     },
                 );
                 // Found a patch marker
                 self.drive_me.send_job(
                     workflow_activation_job::Variant::NotifyHasPatch(NotifyHasPatch { patch_id })
                         .into(),
                 );
             } else if e.is_local_activity_marker() {
-                self.local_activity_data.process_peekahead_marker(e)?;
+                if let Some(la_dat) = e.clone().into_local_activity_marker_details() {
+                    if let Ok(mk) =
+                        self.get_machine_key(CommandID::LocalActivity(la_dat.marker_dat.seq))
+                    {
+                        wake_las.push((mk, la_dat));
+                    } else {
+                        self.local_activity_data.insert_peeked_marker(la_dat);
+                    }
+                } else {
+                    return Err(WFMachinesError::Fatal(format!(
+                        "Local activity marker was unparsable: {e:?}"
+                    )));
+                }
+            }
+        }
+        for (mk, la_dat) in wake_las {
+            let mach = self.machine_mut(mk);
+            if let Machines::LocalActivityMachine(ref mut lam) = *mach {
+                if lam.will_accept_resolve_marker() {
+                    let resps = lam.try_resolve_with_dat(la_dat.into())?;
+                    self.process_machine_responses(mk, resps)?;
+                } else {
+                    self.local_activity_data.insert_peeked_marker(la_dat);
+                }
             }
         }
 
+        update_internal_flags(self);
+
         if !self.replaying {
             self.metrics.wf_task_replay_latency(replay_start.elapsed());
         }
 
         Ok(num_events_to_process)
     }
 
-    /// Handle a single event from the workflow history. `has_next_event` should be false if `event`
-    /// is the last event in the history.
+    /// Handle a single event from the workflow history.
     ///
     /// This function will attempt to apply the event to the workflow state machines. If there is
     /// not a matching machine for the event, a nondeterminism error is returned. Otherwise, the
     /// event is applied to the machine, which may also return a nondeterminism error if the machine
     /// does not match the expected type. A fatal error may be returned if the machine is in an
     /// invalid state.
-    #[instrument(skip(self, event), fields(event=%event))]
-    fn handle_event(&mut self, event: HistoryEvent, has_next_event: bool) -> Result<()> {
+    #[instrument(skip(self, event_dat), fields(event=%event_dat))]
+    fn handle_event(
+        &mut self,
+        event_dat: HistEventData,
+        next_event: Option<&HistoryEvent>,
+    ) -> Result<EventHandlingOutcome> {
+        let event = &event_dat.event;
         if event.is_final_wf_execution_event() {
             self.have_seen_terminal_event = true;
         }
         if matches!(
             event.event_type(),
             EventType::WorkflowExecutionTerminated | EventType::WorkflowExecutionTimedOut
         ) {
-            return if has_next_event {
+            let are_more_events =
+                next_event.is_some() || !event_dat.current_task_is_last_in_history;
+            return if are_more_events {
                 Err(WFMachinesError::Fatal(
                     "Machines were fed a history which has an event after workflow execution was \
                      terminated!"
                         .to_string(),
                 ))
             } else {
-                Ok(())
+                Ok(EventHandlingOutcome::Normal)
             };
         }
-        if self.replaying
-            && self.current_started_event_id
-                >= self.last_history_from_server.previous_started_event_id
-            && event.event_type() != EventType::WorkflowTaskCompleted
-        {
-            // Replay is finished
-            self.replaying = false;
-        }
         if event.event_type() == EventType::Unspecified || event.attributes.is_none() {
             return if !event.worker_may_ignore {
                 Err(WFMachinesError::Fatal(format!(
-                    "Event type is unspecified! This history is invalid. Event detail: {:?}",
-                    event
+                    "Event type is unspecified! This history is invalid. Event detail: {event:?}"
                 )))
             } else {
                 debug!("Event is ignorable");
-                Ok(())
+                Ok(EventHandlingOutcome::SkipEvent {
+                    skip_next_event: false,
+                })
             };
         }
 
         if event.is_command_event() {
-            self.handle_command_event(event)?;
-            return Ok(());
+            return self.handle_command_event(event_dat, next_event);
         }
 
         if let Some(initial_cmd_id) = event.get_initial_command_event_id() {
             // We remove the machine while we it handles events, then return it, to avoid
             // borrowing from ourself mutably.
             let maybe_machine = self.machines_by_event_id.remove(&initial_cmd_id);
             match maybe_machine {
                 Some(sm) => {
-                    self.submachine_handle_event(sm, event, has_next_event)?;
+                    self.submachine_handle_event(sm, event_dat)?;
                     // Restore machine if not in it's final state
                     if !self.machine(sm).is_final_state() {
                         self.machines_by_event_id.insert(initial_cmd_id, sm);
                     }
                 }
                 None => {
                     return Err(WFMachinesError::Nondeterminism(format!(
                         "During event handling, this event had an initial command ID but we \
-                            could not find a matching command for it: {:?}",
-                        event
+                            could not find a matching command for it: {event:?}"
                     )));
                 }
             }
         } else {
-            self.handle_non_stateful_event(event, has_next_event)?;
+            self.handle_non_stateful_event(event_dat)?;
         }
 
-        Ok(())
+        Ok(EventHandlingOutcome::Normal)
     }
 
     /// A command event is an event which is generated from a command emitted as a result of
     /// performing a workflow task. Each command has a corresponding event. For example
     /// ScheduleActivityTaskCommand is recorded to the history as ActivityTaskScheduledEvent.
     ///
     /// Command events always follow WorkflowTaskCompletedEvent.
     ///
     /// The handling consists of verifying that the next command in the commands queue is associated
     /// with a state machine, which is then notified about the event and the command is removed from
     /// the commands queue.
-    fn handle_command_event(&mut self, event: HistoryEvent) -> Result<()> {
+    fn handle_command_event(
+        &mut self,
+        event_dat: HistEventData,
+        next_event: Option<&HistoryEvent>,
+    ) -> Result<EventHandlingOutcome> {
+        let event = &event_dat.event;
+
         if event.is_local_activity_marker() {
             let deets = event.extract_local_activity_marker_data().ok_or_else(|| {
-                WFMachinesError::Fatal(format!("Local activity marker was unparsable: {:?}", event))
+                WFMachinesError::Fatal(format!("Local activity marker was unparsable: {event:?}"))
             })?;
             let cmdid = CommandID::LocalActivity(deets.seq);
             let mkey = self.get_machine_key(cmdid)?;
             if let Machines::LocalActivityMachine(lam) = self.machine(mkey) {
                 if lam.marker_should_get_special_handling()? {
-                    self.submachine_handle_event(mkey, event, false)?;
-                    return Ok(());
+                    self.submachine_handle_event(mkey, event_dat)?;
+                    return Ok(EventHandlingOutcome::Normal);
                 }
             } else {
                 return Err(WFMachinesError::Fatal(format!(
                     "Encountered local activity marker but the associated machine was of the \
-                     wrong type! {:?}",
-                    event
+                     wrong type! {event:?}"
                 )));
             }
         }
 
         let event_id = event.event_id;
 
         let consumed_cmd = loop {
             if let Some(peek_machine) = self.commands.front() {
                 let mach = self.machine(peek_machine.machine);
-                match change_marker_handling(&event, mach)? {
-                    ChangeMarkerOutcome::SkipEvent => return Ok(()),
-                    ChangeMarkerOutcome::SkipCommand => {
+                match change_marker_handling(event, mach, next_event)? {
+                    EventHandlingOutcome::SkipCommand => {
                         self.commands.pop_front();
                         continue;
                     }
-                    ChangeMarkerOutcome::Normal => {}
+                    eho @ EventHandlingOutcome::SkipEvent { .. } => return Ok(eho),
+                    EventHandlingOutcome::Normal => {}
                 }
             }
 
             let maybe_command = self.commands.pop_front();
             let command = if let Some(c) = maybe_command {
                 c
             } else {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "No command scheduled for event {}",
-                    event
+                    "No command scheduled for event {event}"
                 )));
             };
 
             let canceled_before_sent = self
                 .machine(command.machine)
                 .was_cancelled_before_sent_to_server();
 
             if !canceled_before_sent {
                 // Feed the machine the event
-                self.submachine_handle_event(command.machine, event, true)?;
+                self.submachine_handle_event(command.machine, event_dat)?;
                 break command;
             }
         };
 
         if !self.machine(consumed_cmd.machine).is_final_state() {
             self.machines_by_event_id
                 .insert(event_id, consumed_cmd.machine);
         }
 
-        Ok(())
+        Ok(EventHandlingOutcome::Normal)
     }
 
-    fn handle_non_stateful_event(
-        &mut self,
-        event: HistoryEvent,
-        has_next_event: bool,
-    ) -> Result<()> {
+    fn handle_non_stateful_event(&mut self, event_dat: HistEventData) -> Result<()> {
         trace!(
-            event = %event,
+            event = %event_dat.event,
             "handling non-stateful event"
         );
-        let event_id = event.event_id;
-        match EventType::from_i32(event.event_type) {
+        let event_id = event_dat.event.event_id;
+        match EventType::from_i32(event_dat.event.event_type) {
             Some(EventType::WorkflowExecutionStarted) => {
                 if let Some(history_event::Attributes::WorkflowExecutionStartedEventAttributes(
                     attrs,
-                )) = event.attributes
+                )) = event_dat.event.attributes
                 {
-                    if let Some(st) = event.event_time.clone() {
+                    if let Some(st) = event_dat.event.event_time.clone() {
                         let as_systime: SystemTime = st.try_into()?;
                         self.workflow_start_time = Some(as_systime);
                         // Set the workflow time to be the event time of the first event, so that
                         // if there is a query issued before first WFT started event, there is some
                         // workflow time set.
                         self.set_current_time(as_systime);
                     }
                     // Notify the lang sdk that it's time to kick off a workflow
                     self.drive_me.start(
                         self.workflow_id.clone(),
                         str_to_randomness_seed(&attrs.original_execution_run_id),
-                        event.event_time.unwrap_or_default(),
+                        event_dat.event.event_time.unwrap_or_default(),
                         attrs,
                     );
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "WorkflowExecutionStarted event did not have appropriate attributes: {}",
-                        event
+                        "WorkflowExecutionStarted event did not have appropriate attributes: {event_dat}"
                     )));
                 }
             }
             Some(EventType::WorkflowTaskScheduled) => {
                 let wf_task_sm = WorkflowTaskMachine::new(self.next_started_event_id);
                 let key = self.all_machines.insert(wf_task_sm.into());
-                self.submachine_handle_event(key, event, has_next_event)?;
+                self.submachine_handle_event(key, event_dat)?;
                 self.machines_by_event_id.insert(event_id, key);
             }
             Some(EventType::WorkflowExecutionSignaled) => {
                 if let Some(history_event::Attributes::WorkflowExecutionSignaledEventAttributes(
                     attrs,
-                )) = event.attributes
+                )) = event_dat.event.attributes
                 {
                     self.drive_me
                         .send_job(workflow_activation::SignalWorkflow::from(attrs).into());
                 } else {
                     // err
                 }
             }
             Some(EventType::WorkflowExecutionCancelRequested) => {
                 if let Some(
                     history_event::Attributes::WorkflowExecutionCancelRequestedEventAttributes(
                         attrs,
                     ),
-                ) = event.attributes
+                ) = event_dat.event.attributes
                 {
                     self.drive_me
                         .send_job(workflow_activation::CancelWorkflow::from(attrs).into());
                 } else {
                     // err
                 }
             }
             _ => {
                 return Err(WFMachinesError::Fatal(format!(
-                    "The event is not a non-stateful event, but we tried to handle it as one: {}",
-                    event
+                    "The event is not a non-stateful event, but we tried to handle it as one: {event_dat}"
                 )));
             }
         }
         Ok(())
     }
 
     fn set_current_time(&mut self, time: SystemTime) -> SystemTime {
@@ -696,21 +817,16 @@
         }
         self.current_wf_time
             .expect("We have just ensured this is populated")
     }
 
     /// Wrapper for calling [TemporalStateMachine::handle_event] which appropriately takes action
     /// on the returned machine responses
-    fn submachine_handle_event(
-        &mut self,
-        sm: MachineKey,
-        event: HistoryEvent,
-        has_next_event: bool,
-    ) -> Result<()> {
-        let machine_responses = self.machine_mut(sm).handle_event(event, has_next_event)?;
+    fn submachine_handle_event(&mut self, sm: MachineKey, event: HistEventData) -> Result<()> {
+        let machine_responses = self.machine_mut(sm).handle_event(event)?;
         self.process_machine_responses(sm, machine_responses)?;
         Ok(())
     }
 
     /// Transfer commands from `current_wf_task_commands` to `commands`, so they may be sent off
     /// to the server. While doing so, [TemporalStateMachine::handle_command] is called on the
     /// machine associated with the command.
@@ -805,18 +921,23 @@
                             run_id: attrs.run_id,
                         };
                         self.add_cmd_to_wf_task(
                             new_external_cancel(0, we, attrs.child_workflow_only, attrs.reason),
                             CommandIdKind::CoreInternal,
                         );
                     }
+                    ProtoCmdAttrs::UpsertWorkflowSearchAttributesCommandAttributes(attrs) => {
+                        self.add_cmd_to_wf_task(
+                            upsert_search_attrs_internal(attrs),
+                            CommandIdKind::NeverResolves,
+                        );
+                    }
                     c => {
                         return Err(WFMachinesError::Fatal(format!(
-                        "A machine requested to create a new command of an unsupported type: {:?}",
-                        c
+                        "A machine requested to create a new command of an unsupported type: {c:?}"
                     )))
                     }
                 },
                 MachineResponse::IssueFakeLocalActivityMarker(seq) => {
                     self.current_wf_task_commands.push_back(CommandAndMachine {
                         command: MachineAssociatedCommand::FakeLocalActivityMarker(seq),
                         machine: smk,
@@ -912,44 +1033,51 @@
             match cmd {
                 WFCommand::AddTimer(attrs) => {
                     let seq = attrs.seq;
                     self.add_cmd_to_wf_task(new_timer(attrs), CommandID::Timer(seq).into());
                 }
                 WFCommand::UpsertSearchAttributes(attrs) => {
                     self.add_cmd_to_wf_task(
-                        upsert_search_attrs(attrs),
+                        upsert_search_attrs(
+                            attrs,
+                            self.observed_internal_flags.clone(),
+                            self.replaying,
+                        ),
                         CommandIdKind::NeverResolves,
                     );
                 }
                 WFCommand::CancelTimer(attrs) => {
                     self.process_cancellation(CommandID::Timer(attrs.seq))?;
                 }
                 WFCommand::AddActivity(attrs) => {
                     let seq = attrs.seq;
-                    self.add_cmd_to_wf_task(new_activity(attrs), CommandID::Activity(seq).into());
+                    self.add_cmd_to_wf_task(
+                        ActivityMachine::new_scheduled(attrs, self.observed_internal_flags.clone()),
+                        CommandID::Activity(seq).into(),
+                    );
                 }
                 WFCommand::AddLocalActivity(attrs) => {
                     let seq = attrs.seq;
                     let attrs: ValidScheduleLA = ValidScheduleLA::from_schedule_la(
                         attrs,
                         self.get_started_info()
                             .as_ref()
                             .and_then(|x| x.workflow_execution_timeout),
                     )
                     .map_err(|e| {
                         WFMachinesError::Fatal(format!(
-                            "Invalid schedule local activity request (seq {}): {}",
-                            seq, e
+                            "Invalid schedule local activity request (seq {seq}): {e}"
                         ))
                     })?;
                     let (la, mach_resp) = new_local_activity(
                         attrs,
                         self.replaying,
                         self.local_activity_data.take_preresolution(seq),
                         self.current_wf_time,
+                        self.observed_internal_flags.clone(),
                     )?;
                     let machkey = self.all_machines.insert(la.into());
                     self.id_to_machine
                         .insert(CommandID::LocalActivity(seq), machkey);
                     self.process_machine_responses(machkey, mach_resp)?;
                 }
                 WFCommand::RequestCancelActivity(attrs) => {
@@ -974,21 +1102,29 @@
                 WFCommand::CancelWorkflow(attrs) => {
                     self.metrics.wf_canceled();
                     self.add_terminal_command(cancel_workflow(attrs));
                 }
                 WFCommand::SetPatchMarker(attrs) => {
                     // Do not create commands for change IDs that we have already created commands
                     // for.
-                    if !matches!(self.encountered_change_markers.get(&attrs.patch_id),
+                    let encountered_entry = self.encountered_change_markers.get(&attrs.patch_id);
+                    if !matches!(encountered_entry,
                                  Some(ChangeInfo {created_command}) if *created_command)
                     {
-                        self.add_cmd_to_wf_task(
-                            has_change(attrs.patch_id.clone(), self.replaying, attrs.deprecated),
-                            CommandIdKind::NeverResolves,
-                        );
+                        let (patch_machine, other_cmds) = has_change(
+                            attrs.patch_id.clone(),
+                            self.replaying,
+                            attrs.deprecated,
+                            encountered_entry.is_some(),
+                            self.encountered_change_markers.keys().map(|s| s.as_str()),
+                            self.observed_internal_flags.clone(),
+                        )?;
+                        let mkey =
+                            self.add_cmd_to_wf_task(patch_machine, CommandIdKind::NeverResolves);
+                        self.process_machine_responses(mkey, other_cmds)?;
 
                         if let Some(ci) = self.encountered_change_markers.get_mut(&attrs.patch_id) {
                             ci.created_command = true;
                         } else {
                             self.encountered_change_markers.insert(
                                 attrs.patch_id,
                                 ChangeInfo {
@@ -997,15 +1133,18 @@
                             );
                         }
                     }
                 }
                 WFCommand::AddChildWorkflow(attrs) => {
                     let seq = attrs.seq;
                     self.add_cmd_to_wf_task(
-                        new_child_workflow(attrs),
+                        ChildWorkflowMachine::new_scheduled(
+                            attrs,
+                            self.observed_internal_flags.clone(),
+                        ),
                         CommandID::ChildWorkflowStart(seq).into(),
                     );
                 }
                 WFCommand::CancelChild(attrs) => self.process_cancellation(
                     CommandID::ChildWorkflowStart(attrs.child_workflow_seq),
                 )?,
                 WFCommand::RequestCancelExternalWorkflow(attrs) => {
@@ -1071,34 +1210,40 @@
         debug!(machine_responses = %machine_resps.display(), cmd_id = ?id,
                "Cancel request responses");
         self.process_machine_resps_impl(m_key, machine_resps)
     }
 
     fn get_machine_key(&self, id: CommandID) -> Result<MachineKey> {
         Ok(*self.id_to_machine.get(&id).ok_or_else(|| {
-            WFMachinesError::Fatal(format!("Missing associated machine for {:?}", id))
+            WFMachinesError::Fatal(format!("Missing associated machine for {id:?}"))
         })?)
     }
 
     fn add_terminal_command(&mut self, machine: NewMachineWithCommand) {
         let cwfm = self.add_new_command_machine(machine);
         self.workflow_end_time = Some(SystemTime::now());
         self.current_wf_task_commands.push_back(cwfm);
     }
 
     /// Add a new command/machines for that command to the current workflow task
-    fn add_cmd_to_wf_task(&mut self, machine: NewMachineWithCommand, id: CommandIdKind) {
+    fn add_cmd_to_wf_task(
+        &mut self,
+        machine: NewMachineWithCommand,
+        id: CommandIdKind,
+    ) -> MachineKey {
         let mach = self.add_new_command_machine(machine);
+        let key = mach.machine;
         if let CommandIdKind::LangIssued(id) = id {
-            self.id_to_machine.insert(id, mach.machine);
+            self.id_to_machine.insert(id, key);
         }
         if matches!(id, CommandIdKind::CoreInternal) {
-            self.machine_is_core_created.insert(mach.machine, ());
+            self.machine_is_core_created.insert(key, ());
         }
         self.current_wf_task_commands.push_back(mach);
+        key
     }
 
     fn add_new_command_machine(&mut self, machine: NewMachineWithCommand) -> CommandAndMachine {
         let k = self.all_machines.insert(machine.machine);
         CommandAndMachine {
             command: MachineAssociatedCommand::Real(Box::new(machine.command)),
             machine: k,
@@ -1150,47 +1295,62 @@
     // This was originally `DefaultHasher` but that is potentially unstable across Rust releases.
     // This must forever be `SipHasher13` now or we risk breaking history compat.
     let mut s = SipHasher13::new();
     run_id.hash(&mut s);
     s.finish()
 }
 
-enum ChangeMarkerOutcome {
-    SkipEvent,
+#[must_use]
+enum EventHandlingOutcome {
+    SkipEvent { skip_next_event: bool },
     SkipCommand,
     Normal,
 }
 
 /// Special handling for patch markers, when handling command events as in
 /// [WorkflowMachines::handle_command_event]
-fn change_marker_handling(event: &HistoryEvent, mach: &Machines) -> Result<ChangeMarkerOutcome> {
+fn change_marker_handling(
+    event: &HistoryEvent,
+    mach: &Machines,
+    next_event: Option<&HistoryEvent>,
+) -> Result<EventHandlingOutcome> {
     if !mach.matches_event(event) {
         // Version markers can be skipped in the event they are deprecated
         if let Some((patch_name, deprecated)) = event.get_patch_marker_details() {
             // Is deprecated. We can simply ignore this event, as deprecated change
             // markers are allowed without matching changed calls.
             if deprecated {
                 debug!("Deprecated patch marker tried against wrong machine, skipping.");
-                return Ok(ChangeMarkerOutcome::SkipEvent);
+
+                // Also ignore the subsequent upsert event if present
+                let mut skip_next_event = false;
+                if let Some(Attributes::UpsertWorkflowSearchAttributesEventAttributes(atts)) =
+                    next_event.and_then(|ne| ne.attributes.as_ref())
+                {
+                    if let Some(ref sa) = atts.search_attributes {
+                        skip_next_event = sa.indexed_fields.contains_key(VERSION_SEARCH_ATTR_KEY);
+                    }
+                }
+
+                return Ok(EventHandlingOutcome::SkipEvent { skip_next_event });
             }
             return Err(WFMachinesError::Nondeterminism(format!(
-                "Non-deprecated patch marker encountered for change {}, \
-                            but there is no corresponding change command!",
-                patch_name
+                "Non-deprecated patch marker encountered for change {patch_name}, \
+                            but there is no corresponding change command!"
             )));
         }
         // Patch machines themselves may also not *have* matching markers, where non-deprecated
         // calls take the old path, and deprecated calls assume history is produced by a new-code
         // worker.
         if matches!(mach, Machines::PatchMachine(_)) {
             debug!("Skipping non-matching event against patch machine");
-            return Ok(ChangeMarkerOutcome::SkipCommand);
+            return Ok(EventHandlingOutcome::SkipCommand);
         }
     }
-    Ok(ChangeMarkerOutcome::Normal)
+    Ok(EventHandlingOutcome::Normal)
 }
 
 #[derive(derive_more::From)]
 enum CommandIdKind {
     /// A normal command, requested by lang
     LangIssued(CommandID),
     /// A command created internally
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/machines/workflow_task_state_machine.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 #![allow(clippy::enum_variant_names)]
 
 use super::{
     workflow_machines::MachineResponse, Cancellable, EventInfo, WFMachinesAdapter, WFMachinesError,
 };
-use rustfsm::{fsm, TransitionResult};
+use crate::worker::workflow::machines::HistEventData;
+use rustfsm::{fsm, StateMachine, TransitionResult};
 use std::{
     convert::{TryFrom, TryInto},
     time::SystemTime,
 };
 use temporal_sdk_core_protos::temporal::api::{
     enums::v1::{CommandType, EventType, WorkflowTaskFailedCause},
     history::v1::{history_event::Attributes::WorkflowTaskFailedEventAttributes, HistoryEvent},
@@ -27,60 +28,58 @@
     Started --(WorkflowTaskCompleted, on_workflow_task_completed) --> Completed;
     Started --(WorkflowTaskFailed(WFTFailedDat), on_workflow_task_failed) --> Failed;
     Started --(WorkflowTaskTimedOut) --> TimedOut;
 }
 
 impl WorkflowTaskMachine {
     pub(super) fn new(wf_task_started_event_id: i64) -> Self {
-        Self {
-            state: Created {}.into(),
-            shared_state: SharedState {
+        Self::from_parts(
+            Created {}.into(),
+            SharedState {
                 wf_task_started_event_id,
             },
-        }
+        )
     }
 }
 
 #[derive(Debug, derive_more::Display)]
 pub(super) enum WFTaskMachineCommand {
     /// Issued to (possibly) trigger the event loop
     #[display(fmt = "WFTaskStartedTrigger")]
     WFTaskStartedTrigger {
         task_started_event_id: i64,
         time: SystemTime,
     },
-    #[display(fmt = "RunIdOnWorkflowResetUpdate({})", run_id)]
+    #[display(fmt = "RunIdOnWorkflowResetUpdate({run_id})")]
     RunIdOnWorkflowResetUpdate { run_id: String },
 }
 
 impl WFMachinesAdapter for WorkflowTaskMachine {
     fn adapt_response(
         &self,
         my_command: WFTaskMachineCommand,
         event_info: Option<EventInfo>,
     ) -> Result<Vec<MachineResponse>, WFMachinesError> {
         match my_command {
             WFTaskMachineCommand::WFTaskStartedTrigger {
                 task_started_event_id,
                 time,
             } => {
-                let (event_id, event_type, has_next_event) = if let Some(ei) = event_info {
-                    (ei.event_id, ei.event_type, ei.has_next_event)
+                let (event_id, event_type) = if let Some(ei) = event_info {
+                    (ei.event_id, ei.event_type)
                 } else {
                     return Err(WFMachinesError::Fatal(
                         "WF Task machine should never issue a task started trigger \
                         command in response to non-history events"
                             .to_string(),
                     ));
                 };
 
                 let cur_event_past_or_at_start = event_id >= task_started_event_id;
-                if event_type == EventType::WorkflowTaskStarted
-                    && (!cur_event_past_or_at_start || has_next_event)
-                {
+                if event_type == EventType::WorkflowTaskStarted && !cur_event_past_or_at_start {
                     return Ok(vec![]);
                 }
                 Ok(vec![MachineResponse::TriggerWFTaskStarted {
                     task_started_event_id,
                     time,
                 }])
             }
@@ -98,18 +97,19 @@
                 | EventType::WorkflowTaskTimedOut
                 | EventType::WorkflowTaskCompleted
                 | EventType::WorkflowTaskFailed
         )
     }
 }
 
-impl TryFrom<HistoryEvent> for WorkflowTaskMachineEvents {
+impl TryFrom<HistEventData> for WorkflowTaskMachineEvents {
     type Error = WFMachinesError;
 
-    fn try_from(e: HistoryEvent) -> Result<Self, Self::Error> {
+    fn try_from(e: HistEventData) -> Result<Self, Self::Error> {
+        let e = e.event;
         Ok(match e.event_type() {
             EventType::WorkflowTaskScheduled => Self::WorkflowTaskScheduled,
             EventType::WorkflowTaskStarted => Self::WorkflowTaskStarted({
                 let time = if let Some(time) = e.event_time.clone() {
                     match time.try_into() {
                         Ok(t) => t,
                         Err(_) => {
@@ -117,16 +117,15 @@
                                 "Workflow task started event timestamp was inconvertible"
                                     .to_string(),
                             ))
                         }
                     }
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Workflow task started event must contain timestamp: {}",
-                        e
+                        "Workflow task started event must contain timestamp: {e}"
                     )));
                 };
                 WFTStartedDat {
                     started_event_id: e.event_id,
                     current_time_millis: time,
                 }
             }),
@@ -146,23 +145,21 @@
                                 }
                             }
                             _ => None,
                         },
                     })
                 } else {
                     return Err(WFMachinesError::Fatal(format!(
-                        "Workflow task failed is missing attributes: {}",
-                        e
+                        "Workflow task failed is missing attributes: {e}"
                     )));
                 }
             }
             _ => {
                 return Err(WFMachinesError::Nondeterminism(format!(
-                    "Event does not apply to a wf task machine: {}",
-                    e
+                    "Event does not apply to a wf task machine: {e}"
                 )))
             }
         })
     }
 }
 
 impl TryFrom<CommandType> for WorkflowTaskMachineEvents {
@@ -200,15 +197,15 @@
 pub(super) struct WFTFailedDat {
     new_run_id: Option<String>,
 }
 
 impl Scheduled {
     pub(super) fn on_workflow_task_started(
         self,
-        shared: SharedState,
+        shared: &mut SharedState,
         WFTStartedDat {
             current_time_millis,
             started_event_id,
         }: WFTStartedDat,
     ) -> WorkflowTaskMachineTransition<Started> {
         TransitionResult::ok(
             vec![WFTaskMachineCommand::WFTaskStartedTrigger {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run/managed_wf_test.rs`

 * *Files 15% similar despite different names*

```diff
@@ -1,18 +1,21 @@
 use super::*;
 use crate::{
     replay::TestHistoryBuilder,
     test_help::TEST_Q,
     worker::{
+        client::mocks::DEFAULT_TEST_CAPABILITIES,
         workflow::{
-            history_update::TestHBExt, machines::WorkflowMachines, WFCommand, WorkflowFetcher,
+            history_update::tests::TestHBExt, machines::WorkflowMachines, WFCommand,
+            WorkflowFetcher,
         },
         LocalActRequest, LocalActivityResolution,
     },
 };
+use crossbeam::channel::bounded;
 use std::{convert::TryInto, time::Duration};
 use temporal_sdk::{WorkflowFunction, WorkflowResult};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::ActivityExecutionResult,
         workflow_activation::{create_evict_activation, remove_from_cache::EvictionReason},
         workflow_completion::{
@@ -23,21 +26,20 @@
 };
 use tokio::{
     sync::mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
     task::JoinHandle,
 };
 
 pub(crate) struct WFFutureDriver {
-    completions_rx: UnboundedReceiver<WorkflowActivationCompletion>,
+    completions_q: crossbeam::channel::Receiver<WorkflowActivationCompletion>,
 }
 
-#[async_trait::async_trait]
 impl WorkflowFetcher for WFFutureDriver {
-    async fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
-        if let Some(completion) = self.completions_rx.recv().await {
+    fn fetch_workflow_iteration_output(&mut self) -> Vec<WFCommand> {
+        if let Ok(completion) = self.completions_q.try_recv() {
             debug!("Managed wf completion: {}", completion);
             completion
                 .status
                 .map(|s| match s {
                     Status::Successful(s) => s
                         .commands
                         .into_iter()
@@ -53,14 +55,16 @@
     }
 }
 
 #[must_use]
 pub struct ManagedWFFunc {
     mgr: WorkflowManager,
     activation_tx: UnboundedSender<WorkflowActivation>,
+    completions_rx: UnboundedReceiver<WorkflowActivationCompletion>,
+    completions_sync_tx: crossbeam::channel::Sender<WorkflowActivationCompletion>,
     future_handle: Option<JoinHandle<WorkflowResult<()>>>,
     was_shutdown: bool,
 }
 
 impl ManagedWFFunc {
     pub fn new(hist: TestHistoryBuilder, func: WorkflowFunction, args: Vec<Payload>) -> Self {
         Self::new_from_update(hist.as_history_update(), func, args)
@@ -75,36 +79,44 @@
         let (wff, activations) = func.start_workflow(
             "testnamespace".to_string(),
             TEST_Q.to_string(),
             args,
             completions_tx,
         );
         let spawned = tokio::spawn(wff);
-        let driver = WFFutureDriver { completions_rx };
+        let (completions_sync_tx, completions_sync_rx) = bounded(1);
+        let driver = WFFutureDriver {
+            completions_q: completions_sync_rx,
+        };
         let state_machines = WorkflowMachines::new(
-            "test_namespace".to_string(),
-            "wfid".to_string(),
-            "wftype".to_string(),
-            "runid".to_string(),
-            hist,
+            RunBasics {
+                namespace: "test_namespace".to_string(),
+                workflow_id: "wfid".to_string(),
+                workflow_type: "wftype".to_string(),
+                run_id: "runid".to_string(),
+                history: hist,
+                metrics: MetricsContext::no_op(),
+                capabilities: DEFAULT_TEST_CAPABILITIES,
+            },
             Box::new(driver).into(),
-            MetricsContext::no_op(),
         );
         let mgr = WorkflowManager::new_from_machines(state_machines);
         Self {
             mgr,
             activation_tx: activations,
+            completions_rx,
+            completions_sync_tx,
             future_handle: Some(spawned),
             was_shutdown: false,
         }
     }
 
     #[instrument(skip(self))]
     pub(crate) async fn get_next_activation(&mut self) -> Result<WorkflowActivation> {
-        let res = self.mgr.get_next_activation().await?;
+        let res = self.mgr.get_next_activation()?;
         debug!("Managed wf next activation: {}", &res);
         self.push_activation_to_wf(&res).await?;
         Ok(res)
     }
 
     /// Return outgoing server commands as of the last iteration
     pub(crate) fn get_server_commands(&mut self) -> OutgoingServerCommands {
@@ -117,15 +129,15 @@
 
     /// Feed new history, as if received a new poll result. Returns new activation
     #[instrument(skip(self, update))]
     pub(crate) async fn new_history(
         &mut self,
         update: HistoryUpdate,
     ) -> Result<WorkflowActivation> {
-        let res = self.mgr.feed_history_from_server(update).await?;
+        let res = self.mgr.feed_history_from_server(update)?;
         self.push_activation_to_wf(&res).await?;
         Ok(res)
     }
 
     /// Say a local activity completed (they always take 1 second in these tests)
     pub(crate) fn complete_local_activity(
         &mut self,
@@ -179,15 +191,19 @@
         if res.jobs.is_empty() {
             // Nothing to do here
             return Ok(());
         }
         self.activation_tx
             .send(res.clone())
             .expect("Workflow should not be dropped if we are still sending activations");
-        self.mgr.machines.iterate_machines().await?;
+        // Move the completion response to the sync workflow bridge
+        self.completions_sync_tx
+            .send(self.completions_rx.recv().await.unwrap())
+            .unwrap();
+        self.mgr.machines.iterate_machines()?;
         Ok(())
     }
 }
 
 impl Drop for ManagedWFFunc {
     fn drop(&mut self) {
         // Double panics cause a SIGILL
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/managed_run.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/workflow_stream.rs`

 * *Files 20% similar despite different names*

```diff
@@ -1,684 +1,738 @@
-#[cfg(test)]
-mod managed_wf_test;
+#[cfg(feature = "save_wf_inputs")]
+mod saved_wf_inputs;
+#[cfg(feature = "save_wf_inputs")]
+mod tonic_status_serde;
+
+#[cfg(feature = "save_wf_inputs")]
+pub use saved_wf_inputs::replay_wf_state_inputs;
 
 use crate::{
-    worker::{
-        workflow::{
-            machines::WorkflowMachines, ActivationAction, ActivationCompleteOutcome, HistoryUpdate,
-            LocalResolution, NewIncomingWFT, OutgoingServerCommands, RequestEvictMsg, RunActions,
-            RunActivationCompletion, RunUpdateResponse, ServerCommandsWithWorkflowInfo, WFCommand,
-            WorkflowBridge,
-        },
-        LocalActRequest,
+    abstractions::dbg_panic,
+    worker::workflow::{
+        managed_run::RunUpdateAct,
+        run_cache::RunCache,
+        wft_extraction::{HistfetchRC, HistoryFetchReq, WFTExtractorOutput},
+        *,
     },
     MetricsContext,
 };
-use futures::{stream, StreamExt};
-use std::{
-    ops::Add,
-    sync::mpsc::Sender,
-    time::{Duration, Instant},
-};
-use temporal_sdk_core_api::errors::WFMachinesError;
-use temporal_sdk_core_protos::coresdk::{
-    workflow_activation::{RemoveFromCache, WorkflowActivation},
-    workflow_commands::QueryResult,
-};
-use tokio::{
-    sync::{
-        mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
-        oneshot,
-    },
-    task,
-    task::JoinHandle,
-};
-use tokio_stream::wrappers::UnboundedReceiverStream;
-use tracing::Span;
-use tracing_futures::Instrument;
-
-use crate::worker::workflow::{
-    ActivationCompleteResult, ActivationOrAuto, FailRunUpdate, FulfillableActivationComplete,
-    GoodRunUpdate, LocalActivityRequestSink, RunAction, RunUpdateResponseKind,
-};
-use temporal_sdk_core_protos::TaskToken;
+use futures::{stream, stream::PollNext, Stream, StreamExt};
+use std::{collections::VecDeque, fmt::Debug, future, sync::Arc};
+use temporal_sdk_core_api::errors::PollWfError;
+use temporal_sdk_core_protos::coresdk::workflow_activation::remove_from_cache::EvictionReason;
+use tokio_util::sync::CancellationToken;
+use tracing::{Level, Span};
+
+/// This struct holds all the state needed for tracking the state of currently cached workflow runs
+/// and directs all actions which affect them. It is ultimately the top-level arbiter of nearly
+/// everything important relating to workflow state.
+///
+/// See [WFStream::build] for more
+pub(super) struct WFStream {
+    runs: RunCache,
+    /// Buffered polls for new runs which need a cache slot to open up before we can handle them
+    buffered_polls_need_cache_slot: VecDeque<PermittedWFT>,
+    /// Is filled with runs that we decided need to have their history fetched during state
+    /// manipulation. Must be drained after handling each input.
+    runs_needing_fetching: VecDeque<HistoryFetchReq>,
+
+    history_fetch_refcounter: Arc<HistfetchRC>,
+    shutdown_token: CancellationToken,
+    ignore_evicts_on_shutdown: bool,
 
-use crate::abstractions::dbg_panic;
-#[cfg(test)]
-pub(crate) use managed_wf_test::ManagedWFFunc;
-
-type Result<T, E = WFMachinesError> = std::result::Result<T, E>;
-/// What percentage of a WFT timeout we are willing to wait before sending a WFT heartbeat when
-/// necessary.
-const WFT_HEARTBEAT_TIMEOUT_FRACTION: f32 = 0.8;
-
-pub(super) struct ManagedRun {
-    wfm: WorkflowManager,
-    update_tx: UnboundedSender<RunUpdateResponse>,
-    local_activity_request_sink: LocalActivityRequestSink,
-    waiting_on_la: Option<WaitingOnLAs>,
-    // Is set to true if the machines encounter an error and the only subsequent thing we should
-    // do is be evicted.
-    am_broken: bool,
-}
-
-/// If an activation completion needed to wait on LA completions (or heartbeat timeout) we use
-/// this struct to store the data we need to finish the completion once that has happened
-struct WaitingOnLAs {
-    wft_timeout: Duration,
-    /// If set, we are waiting for LAs to complete as part of a just-finished workflow activation.
-    /// If unset, we already had a heartbeat timeout and got a new WFT without any new work while
-    /// there are still incomplete LAs.
-    completion_dat: Option<(
-        CompletionDataForWFT,
-        oneshot::Sender<ActivationCompleteResult>,
-    )>,
-    hb_chan: UnboundedSender<Span>,
-    heartbeat_timeout_task: JoinHandle<()>,
-}
+    metrics: MetricsContext,
 
-#[derive(Debug)]
-struct CompletionDataForWFT {
-    task_token: TaskToken,
-    query_responses: Vec<QueryResult>,
-    has_pending_query: bool,
-    activation_was_only_eviction: bool,
+    #[cfg(feature = "save_wf_inputs")]
+    wf_state_inputs: Option<UnboundedSender<Vec<u8>>>,
 }
-
-impl ManagedRun {
-    pub(super) fn new(
-        wfm: WorkflowManager,
-        update_tx: UnboundedSender<RunUpdateResponse>,
-        local_activity_request_sink: LocalActivityRequestSink,
-    ) -> Self {
-        Self {
-            wfm,
-            update_tx,
-            local_activity_request_sink,
-            waiting_on_la: None,
-            am_broken: false,
-        }
+impl WFStream {
+    /// Constructs workflow state management and returns a stream which outputs activations.
+    ///
+    /// * `wft_stream` is a stream of validated poll responses and fetched history pages as returned
+    ///    by a poller (or mock), via [WFTExtractor].
+    /// * `local_rx` is a stream of actions that workflow state needs to see. Things like
+    ///    completions, local activities finishing, etc. See [LocalInputs].
+    /// * `local_activity_request_sink` is used to handle outgoing requests to start or cancel
+    ///    local activities, and may return resolutions that need to be handled immediately.
+    ///
+    /// The stream inputs are combined into a stream of [WFActStreamInput]s. The stream processor
+    /// then takes action on those inputs, mutating the [WFStream] state, and then may yield
+    /// activations.
+    ///
+    /// Importantly, nothing async happens while actually mutating state. This means all changes to
+    /// all workflow state can be represented purely via the stream of inputs, plus the
+    /// calls/retvals from the LA request sink, which is the last unfortunate bit of impurity in
+    /// the design. Eliminating it would be nice, so that all inputs come from the passed-in streams
+    /// and all outputs flow from the return stream, but it's difficult to do so since it would
+    /// require "pausing" in-progress changes to a run while sending & waiting for response from
+    /// local activity management. Likely the best option would be to move the pure state info
+    /// needed to determine immediate responses into LA state machines themselves (out of the LA
+    /// manager), which is a quite substantial change.
+    pub(super) fn build(
+        basics: WorkflowBasics,
+        wft_stream: impl Stream<Item = Result<WFTExtractorOutput, tonic::Status>> + Send + 'static,
+        local_rx: impl Stream<Item = LocalInput> + Send + 'static,
+        local_activity_request_sink: impl LocalActivityRequestSink,
+    ) -> impl Stream<Item = Result<WFStreamOutput, PollWfError>> {
+        let all_inputs = stream::select_with_strategy(
+            local_rx.map(Into::into),
+            wft_stream
+                .map(Into::into)
+                .chain(stream::once(async { ExternalPollerInputs::PollerDead }))
+                .map(Into::into)
+                .boxed(),
+            // Priority always goes to the local stream
+            |_: &mut ()| PollNext::Left,
+        );
+        Self::build_internal(all_inputs, basics, local_activity_request_sink)
     }
 
-    pub(super) async fn run(self, run_actions_rx: UnboundedReceiver<RunAction>) {
-        let (heartbeat_tx, heartbeat_rx) = unbounded_channel();
-        stream::select(
-            UnboundedReceiverStream::new(run_actions_rx),
-            UnboundedReceiverStream::new(heartbeat_rx).map(|trace_span| RunAction {
-                action: RunActions::HeartbeatTimeout,
-                trace_span,
-            }),
-        )
-        .fold((self, heartbeat_tx), |(mut me, heartbeat_tx), action| {
-            let span = action.trace_span;
-            let action = action.action;
-            let mut no_wft = false;
-            async move {
-                let res = match action {
-                    RunActions::NewIncomingWFT(wft) => me
-                        .incoming_wft(wft)
-                        .await
-                        .map(RunActionOutcome::AfterNewWFT),
-                    RunActions::ActivationCompletion(completion) => me
-                        .completion(completion, &heartbeat_tx)
-                        .await
-                        .map(RunActionOutcome::AfterCompletion),
-                    RunActions::CheckMoreWork {
-                        want_to_evict,
-                        has_pending_queries,
-                        has_wft,
-                    } => {
-                        if !has_wft {
-                            no_wft = true;
+    fn build_internal(
+        all_inputs: impl Stream<Item = WFStreamInput>,
+        basics: WorkflowBasics,
+        local_activity_request_sink: impl LocalActivityRequestSink,
+    ) -> impl Stream<Item = Result<WFStreamOutput, PollWfError>> {
+        let mut state = WFStream {
+            buffered_polls_need_cache_slot: Default::default(),
+            runs: RunCache::new(
+                basics.max_cached_workflows,
+                basics.namespace.clone(),
+                basics.server_capabilities.clone(),
+                local_activity_request_sink,
+                basics.metrics.clone(),
+            ),
+            shutdown_token: basics.shutdown_token,
+            ignore_evicts_on_shutdown: basics.ignore_evicts_on_shutdown,
+            metrics: basics.metrics,
+            runs_needing_fetching: Default::default(),
+            history_fetch_refcounter: Arc::new(HistfetchRC {}),
+
+            #[cfg(feature = "save_wf_inputs")]
+            wf_state_inputs: basics.wf_state_inputs,
+        };
+        all_inputs
+            .map(move |action: WFStreamInput| {
+                let span = span!(Level::DEBUG, "new_stream_input", action=?action);
+                let _span_g = span.enter();
+
+                #[cfg(feature = "save_wf_inputs")]
+                let maybe_write = state.prep_input(&action);
+
+                let mut activations = vec![];
+                let maybe_act = match action {
+                    WFStreamInput::NewWft(pwft) => {
+                        debug!(run_id=%pwft.work.execution.run_id, "New WFT");
+                        state.instantiate_or_update(pwft)
+                    }
+                    WFStreamInput::Local(local_input) => {
+                        let _span_g = local_input.span.enter();
+                        if let Some(rid) = local_input.input.run_id() {
+                            if let Some(rh) = state.runs.get_mut(rid) {
+                                rh.record_span_fields(&local_input.span);
+                            }
+                        }
+                        match local_input.input {
+                            LocalInputs::Completion(completion) => {
+                                activations.extend(
+                                    state.process_completion(NewOrFetchedComplete::New(completion)),
+                                );
+                                None // completions can return more than one activation
+                            }
+                            LocalInputs::FetchedPageCompletion { paginator, update } => {
+                                activations.extend(state.process_completion(
+                                    NewOrFetchedComplete::Fetched(update, paginator),
+                                ));
+                                None // completions can return more than one activation
+                            }
+                            LocalInputs::PostActivation(report) => {
+                                state.process_post_activation(report)
+                            }
+                            LocalInputs::LocalResolution(res) => state.local_resolution(res),
+                            LocalInputs::HeartbeatTimeout(hbt) => {
+                                state.process_heartbeat_timeout(hbt)
+                            }
+                            LocalInputs::RequestEviction(evict) => {
+                                state.request_eviction(evict).into_run_update_resp()
+                            }
+                            LocalInputs::GetStateInfo(gsi) => {
+                                let _ = gsi.response_tx.send(WorkflowStateInfo {
+                                    cached_workflows: state.runs.len(),
+                                    outstanding_wft: state.outstanding_wfts(),
+                                });
+                                None
+                            }
                         }
-                        me.check_more_work(want_to_evict, has_pending_queries, has_wft)
-                            .await
-                            .map(RunActionOutcome::AfterCheckWork)
                     }
-                    RunActions::LocalResolution(r) => me
-                        .local_resolution(r)
-                        .await
-                        .map(RunActionOutcome::AfterLocalResolution),
-                    RunActions::HeartbeatTimeout => {
-                        let maybe_act = if me.heartbeat_timeout() {
-                            Some(ActivationOrAuto::Autocomplete {
-                                run_id: me.wfm.machines.run_id.clone(),
-                            })
-                        } else {
-                            None
-                        };
-                        Ok(RunActionOutcome::AfterHeartbeatTimeout(maybe_act))
+                    WFStreamInput::FailedFetch {
+                        run_id,
+                        err,
+                        auto_reply_fail_tt,
+                    } => state
+                        .request_eviction(RequestEvictMsg {
+                            run_id,
+                            message: format!("Fetching history failed: {err:?}"),
+                            reason: EvictionReason::PaginationOrHistoryFetch,
+                            auto_reply_fail_tt,
+                        })
+                        .into_run_update_resp(),
+                    WFStreamInput::PollerDead => {
+                        debug!("WFT poller died, beginning shutdown");
+                        state.shutdown_token.cancel();
+                        None
                     }
-                };
-                match res {
-                    Ok(outcome) => {
-                        me.send_update_response(outcome, no_wft);
+                    WFStreamInput::PollerError(e) => {
+                        warn!("WFT poller errored, shutting down");
+                        return Err(PollWfError::TonicError(e));
                     }
-                    Err(e) => {
-                        error!(error=?e, "Error in run machines");
-                        me.am_broken = true;
-                        me.update_tx
-                            .send(RunUpdateResponse {
-                                kind: RunUpdateResponseKind::Fail(FailRunUpdate {
-                                    run_id: me.wfm.machines.run_id.clone(),
-                                    err: e.source,
-                                    completion_resp: e.complete_resp_chan,
-                                }),
-                                span: Span::current(),
-                            })
-                            .expect("Machine can send update");
+                };
+
+                activations.extend(maybe_act.into_iter());
+                activations.extend(state.reconcile_buffered());
+
+                // Always flush *after* actually handling the input, as this allows LA sink
+                // responses to be recorded before the input, so they can be read and buffered to be
+                // replayed during the handling of the input itself.
+                #[cfg(feature = "save_wf_inputs")]
+                if let Some(write) = maybe_write {
+                    state.flush_write(write);
+                }
+
+                if state.shutdown_done() {
+                    info!("Workflow shutdown is done");
+                    return Err(PollWfError::ShutDown);
+                }
+
+                Ok(WFStreamOutput {
+                    activations: activations.into(),
+                    fetch_histories: std::mem::take(&mut state.runs_needing_fetching),
+                })
+            })
+            .inspect(|o| {
+                if let Some(e) = o.as_ref().err() {
+                    if !matches!(e, PollWfError::ShutDown) {
+                        error!(
+                            "Workflow processing encountered fatal error and must shut down {:?}",
+                            e
+                        );
                     }
                 }
-                (me, heartbeat_tx)
+            })
+            // Stop the stream once we have shut down
+            .take_while(|o| future::ready(!matches!(o, Err(PollWfError::ShutDown))))
+    }
+
+    /// Instantiate or update run machines with a new WFT
+    #[instrument(skip(self, pwft)
+                 fields(run_id=%pwft.work.execution.run_id,
+                        workflow_id=%pwft.work.execution.workflow_id))]
+    fn instantiate_or_update(&mut self, pwft: PermittedWFT) -> RunUpdateAct {
+        match self._instantiate_or_update(pwft) {
+            Err(histfetch) => {
+                self.runs_needing_fetching.push_back(histfetch);
+                Default::default()
             }
-            .instrument(span)
-        })
-        .await;
+            Ok(r) => r,
+        }
     }
 
-    async fn incoming_wft(
+    fn _instantiate_or_update(
         &mut self,
-        wft: NewIncomingWFT,
-    ) -> Result<Option<ActivationOrAuto>, RunUpdateErr> {
-        let activation = if let Some(h) = wft.history_update {
-            self.wfm.feed_history_from_server(h).await?
-        } else {
-            let r = self.wfm.get_next_activation().await?;
-            if r.jobs.is_empty() {
-                return Err(RunUpdateErr {
-                    source: WFMachinesError::Fatal(format!(
-                        "Machines created for {} with no jobs",
-                        self.wfm.machines.run_id
-                    )),
-                    complete_resp_chan: None,
-                });
+        pwft: PermittedWFT,
+    ) -> Result<RunUpdateAct, HistoryFetchReq> {
+        // If the run already exists, possibly buffer the work and return early if we can't handle
+        // it yet.
+        let pwft = if let Some(rh) = self.runs.get_mut(&pwft.work.execution.run_id) {
+            if let Some(w) = rh.buffer_wft_if_outstanding_work(pwft) {
+                w
+            } else {
+                return Ok(None);
             }
-            r
+        } else {
+            pwft
         };
 
-        if activation.jobs.is_empty() {
-            if self.wfm.machines.outstanding_local_activity_count() > 0 {
-                // If the activation has no jobs but there are outstanding LAs, we need to restart the
-                // WFT heartbeat.
-                if let Some(ref mut lawait) = self.waiting_on_la {
-                    if lawait.completion_dat.is_some() {
-                        panic!("Should not have completion dat when getting new wft & empty jobs")
+        let run_id = pwft.work.execution.run_id.clone();
+        // If our cache is full and this WFT is for an unseen run we must first evict a run before
+        // we can deal with this task. So, buffer the task in that case.
+        if !self.runs.has_run(&run_id) && self.runs.is_full() {
+            self.buffer_resp_on_full_cache(pwft);
+            return Ok(None);
+        }
+
+        // This check can't really be lifted up higher since we could EX: See it's in the cache,
+        // not fetch more history, send the task, see cache is full, buffer it, then evict that
+        // run, and now we still have a cache miss.
+        if !self.runs.has_run(&run_id) && pwft.work.is_incremental() {
+            debug!(run_id=?run_id, "Workflow task has partial history, but workflow is not in \
+                   cache. Will fetch history");
+            self.metrics.sticky_cache_miss();
+            return Err(HistoryFetchReq::Full(
+                CacheMissFetchReq { original_wft: pwft },
+                self.history_fetch_refcounter.clone(),
+            ));
+        }
+
+        let rur = self.runs.instantiate_or_update(pwft);
+        Ok(rur)
+    }
+
+    fn process_completion(&mut self, complete: NewOrFetchedComplete) -> Vec<ActivationOrAuto> {
+        let rh = if let Some(rh) = self.runs.get_mut(complete.run_id()) {
+            rh
+        } else {
+            dbg_panic!("Run missing during completion {:?}", complete);
+            return vec![];
+        };
+        let mut acts: Vec<_> = match complete {
+            NewOrFetchedComplete::New(complete) => match complete.completion {
+                ValidatedCompletion::Success {
+                    commands,
+                    used_flags,
+                    ..
+                } => match rh.successful_completion(commands, used_flags, complete.response_tx) {
+                    Ok(acts) => acts,
+                    Err(npr) => {
+                        self.runs_needing_fetching
+                            .push_back(HistoryFetchReq::NextPage(
+                                npr,
+                                self.history_fetch_refcounter.clone(),
+                            ));
+                        None
                     }
-                    lawait.heartbeat_timeout_task.abort();
-                    lawait.heartbeat_timeout_task = start_heartbeat_timeout_task(
-                        lawait.hb_chan.clone(),
-                        wft.start_time,
-                        lawait.wft_timeout,
-                    );
-                    // No activation needs to be sent to lang. We just need to wait for another
-                    // heartbeat timeout or LAs to resolve
-                    return Ok(None);
-                } else {
-                    panic!(
-                        "Got a new WFT while there are outstanding local activities, but there \
-                     was no waiting on LA info."
-                    )
-                }
-            } else {
-                return Ok(Some(ActivationOrAuto::Autocomplete {
-                    run_id: self.wfm.machines.run_id.clone(),
-                }));
+                },
+                ValidatedCompletion::Fail { failure, .. } => rh.failed_completion(
+                    failure.force_cause(),
+                    EvictionReason::LangFail,
+                    failure,
+                    complete.response_tx,
+                ),
+            },
+            NewOrFetchedComplete::Fetched(update, paginator) => {
+                rh.fetched_page_completion(update, paginator)
+            }
+        }
+        .into_iter()
+        .collect();
+        // Always queue evictions after completion when we have a zero-size cache
+        if self.runs.cache_capacity() == 0 {
+            acts.extend(self.request_eviction_of_lru_run().into_run_update_resp())
+        }
+        acts
+    }
+
+    fn process_post_activation(&mut self, report: PostActivationMsg) -> RunUpdateAct {
+        let run_id = &report.run_id;
+        let wft_from_complete = report.wft_from_complete;
+        if let Some((wft, _)) = &wft_from_complete {
+            if &wft.execution.run_id != run_id {
+                dbg_panic!(
+                    "Server returned a WFT on completion for a different run ({}) than the \
+                     one being completed ({}). This is a server bug.",
+                    wft.execution.run_id,
+                    run_id
+                );
             }
         }
 
-        Ok(Some(ActivationOrAuto::LangActivation(activation)))
-    }
+        let mut res = None;
+
+        // If we reported to server, we always want to mark it complete.
+        let maybe_t = self.complete_wft(run_id, report.wft_report_status);
+        // Delete the activation, but only if the report came from lang, or we know the outstanding
+        // activation is expected to be completed internally.
+        if let Some(activation) = self.runs.get_mut(run_id).and_then(|rh| {
+            rh.delete_activation(|act| {
+                !report.is_autocomplete || matches!(act, OutstandingActivation::Autocomplete)
+            })
+        }) {
+            // Evict the run if the activation contained an eviction
+            let mut applied_buffered_poll_for_this_run = false;
+            if activation.has_eviction() {
+                debug!(run_id=%run_id, "Evicting run");
+
+                if let Some(mut rh) = self.runs.remove(run_id) {
+                    if let Some(buff) = rh.take_buffered_wft() {
+                        // Don't try to apply a buffered poll for this run if we just got a new WFT
+                        // from completing, because by definition that buffered poll is now an
+                        // out-of-date WFT.
+                        if wft_from_complete.is_none() {
+                            res = self.instantiate_or_update(buff);
+                            applied_buffered_poll_for_this_run = true;
+                        }
+                    }
+                }
 
-    async fn completion(
-        &mut self,
-        mut completion: RunActivationCompletion,
-        heartbeat_tx: &UnboundedSender<Span>,
-    ) -> Result<Option<FulfillableActivationComplete>, RunUpdateErr> {
-        let resp_chan = completion
-            .resp_chan
-            .take()
-            .expect("Completion response channel must be populated");
-
-        let data = CompletionDataForWFT {
-            task_token: completion.task_token,
-            query_responses: completion.query_responses,
-            has_pending_query: completion.has_pending_query,
-            activation_was_only_eviction: completion.activation_was_only_eviction,
-        };
+                // Attempt to apply a buffered poll for some *other* run, if we didn't have a wft
+                // from complete or a buffered poll for *this* run.
+                if wft_from_complete.is_none() && !applied_buffered_poll_for_this_run {
+                    if let Some(buff) = self.buffered_polls_need_cache_slot.pop_front() {
+                        res = self.instantiate_or_update(buff);
+                    }
+                }
+            };
+        }
 
-        // If this is just bookkeeping after a reply to an only-eviction activation, we can bypass
-        // everything, since there is no reason to continue trying to update machines.
-        if completion.activation_was_only_eviction {
-            return Ok(Some(self.prepare_complete_resp(resp_chan, data, false)));
-        }
-
-        let outcome = async move {
-            // Send commands from lang into the machines then check if the workflow run
-            // needs another activation and mark it if so
-            self.wfm
-                .push_commands_and_iterate(completion.commands)
-                .await?;
-            // Don't bother applying the next task if we're evicting at the end of
-            // this activation
-            if !completion.activation_was_eviction {
-                self.wfm.apply_next_task_if_ready().await?;
+        if let Some((wft, pag)) = wft_from_complete {
+            debug!(run_id=%wft.execution.run_id, "New WFT from completion");
+            if let Some(t) = maybe_t {
+                res = self.instantiate_or_update(PermittedWFT {
+                    work: wft,
+                    permit: t.permit,
+                    paginator: pag,
+                });
             }
-            let new_local_acts = self.wfm.drain_queued_local_activities();
-            self.sink_la_requests(new_local_acts)?;
+        }
 
-            if self.wfm.machines.outstanding_local_activity_count() == 0 {
-                Ok((None, data, self))
-            } else {
-                let wft_timeout: Duration = self
-                    .wfm
-                    .machines
-                    .get_started_info()
-                    .and_then(|attrs| attrs.workflow_task_timeout)
-                    .ok_or_else(|| {
-                        WFMachinesError::Fatal(
-                            "Workflow's start attribs were missing a well formed task timeout"
-                                .to_string(),
-                        )
-                    })?;
-                let heartbeat_tx = heartbeat_tx.clone();
-                Ok((
-                    Some((heartbeat_tx, completion.start_time, wft_timeout)),
-                    data,
-                    self,
-                ))
-            }
-        }
-        .await;
-
-        match outcome {
-            Ok((None, data, me)) => Ok(Some(me.prepare_complete_resp(resp_chan, data, false))),
-            Ok((Some((chan, start_t, wft_timeout)), data, me)) => {
-                if let Some(wola) = me.waiting_on_la.as_mut() {
-                    wola.heartbeat_timeout_task.abort();
-                }
-                me.waiting_on_la = Some(WaitingOnLAs {
-                    wft_timeout,
-                    completion_dat: Some((data, resp_chan)),
-                    hb_chan: chan.clone(),
-                    heartbeat_timeout_task: start_heartbeat_timeout_task(
-                        chan,
-                        start_t,
-                        wft_timeout,
-                    ),
-                });
-                Ok(None)
+        if res.is_none() {
+            if let Some(rh) = self.runs.get_mut(run_id) {
+                // Attempt to produce the next activation if needed
+                res = rh.check_more_activations();
             }
-            Err(e) => Err(RunUpdateErr {
-                source: e,
-                complete_resp_chan: Some(resp_chan),
-            }),
         }
+        res
     }
 
-    async fn check_more_work(
-        &mut self,
-        want_to_evict: Option<RequestEvictMsg>,
-        has_pending_queries: bool,
-        has_wft: bool,
-    ) -> Result<Option<ActivationOrAuto>, RunUpdateErr> {
-        // In the event it's time to evict this run, cancel any outstanding LAs
-        if want_to_evict.is_some() {
-            self.sink_la_requests(vec![LocalActRequest::CancelAllInRun(
-                self.wfm.machines.run_id.clone(),
-            )])?;
+    fn local_resolution(&mut self, msg: LocalResolutionMsg) -> RunUpdateAct {
+        let run_id = msg.run_id;
+        if let Some(rh) = self.runs.get_mut(&run_id) {
+            rh.local_resolution(msg.res)
+        } else {
+            // It isn't an explicit error if the machine is missing when a local activity resolves.
+            // This can happen if an activity reports a timeout after we stopped caring about it.
+            debug!(run_id = %run_id,
+                   "Tried to resolve a local activity for a run we are no longer tracking");
+            None
         }
+    }
 
-        if !has_wft {
-            // It doesn't make sense to do workflow work unless we have a WFT
-            return Ok(None);
+    fn process_heartbeat_timeout(&mut self, run_id: String) -> RunUpdateAct {
+        if let Some(rh) = self.runs.get_mut(&run_id) {
+            rh.heartbeat_timeout()
+        } else {
+            None
         }
+    }
 
-        if self.wfm.machines.has_pending_jobs() && !self.am_broken {
-            Ok(Some(ActivationOrAuto::LangActivation(
-                self.wfm.get_next_activation().await?,
-            )))
+    /// Request a workflow eviction. This will (eventually, after replay is done) queue up an
+    /// activation to evict the workflow from the lang side. Workflow will not *actually* be evicted
+    /// until lang replies to that activation
+    fn request_eviction(&mut self, info: RequestEvictMsg) -> EvictionRequestResult {
+        if let Some(rh) = self.runs.get_mut(&info.run_id) {
+            rh.request_eviction(info)
         } else {
-            if has_pending_queries && !self.am_broken {
-                return Ok(Some(ActivationOrAuto::ReadyForQueries(
-                    self.wfm.machines.get_wf_activation(),
-                )));
-            }
-            if let Some(wte) = want_to_evict {
-                let mut act = self.wfm.machines.get_wf_activation();
-                // No other jobs make any sense to send if we encountered an error.
-                if self.am_broken {
-                    act.jobs = vec![];
-                }
-                act.append_evict_job(RemoveFromCache {
-                    message: wte.message,
-                    reason: wte.reason as i32,
-                });
-                Ok(Some(ActivationOrAuto::LangActivation(act)))
-            } else {
-                Ok(None)
-            }
+            debug!(run_id=%info.run_id, "Eviction requested for unknown run");
+            EvictionRequestResult::NotFound
         }
     }
 
-    fn prepare_complete_resp(
+    fn request_eviction_of_lru_run(&mut self) -> EvictionRequestResult {
+        if let Some(lru_run_id) = self.runs.current_lru_run() {
+            let run_id = lru_run_id.to_string();
+            self.request_eviction(RequestEvictMsg {
+                run_id,
+                message: "Workflow cache full".to_string(),
+                reason: EvictionReason::CacheFull,
+                auto_reply_fail_tt: None,
+            })
+        } else {
+            // This branch shouldn't really be possible
+            EvictionRequestResult::NotFound
+        }
+    }
+
+    fn complete_wft(
         &mut self,
-        resp_chan: oneshot::Sender<ActivationCompleteResult>,
-        data: CompletionDataForWFT,
-        due_to_heartbeat_timeout: bool,
-    ) -> FulfillableActivationComplete {
-        let outgoing_cmds = self.wfm.get_server_commands();
-        if data.activation_was_only_eviction && !outgoing_cmds.commands.is_empty() {
-            dbg_panic!(
-                "There should not be any outgoing commands when preparing a completion response \
-                 if the activation was only an eviction. This is an SDK bug."
-            );
+        run_id: &str,
+        wft_report_status: WFTReportStatus,
+    ) -> Option<OutstandingTask> {
+        // If the WFT completion wasn't sent to the server, but we did see the final event, we still
+        // want to clear the workflow task. This can really only happen in replay testing, where we
+        // will generate poll responses with complete history but no attached query, and such a WFT
+        // would never really exist. The server wouldn't send a workflow task with nothing to do,
+        // but they are very useful for testing complete replay.
+        let saw_final = self
+            .runs
+            .get(run_id)
+            .map(|r| r.have_seen_terminal_event())
+            .unwrap_or_default();
+        if !saw_final && matches!(wft_report_status, WFTReportStatus::NotReported) {
+            return None;
+        }
+
+        if let Some(rh) = self.runs.get_mut(run_id) {
+            // Can't mark the WFT complete if there are pending queries, as doing so would destroy
+            // them.
+            if rh
+                .wft()
+                .map(|wft| !wft.pending_queries.is_empty())
+                .unwrap_or_default()
+            {
+                return None;
+            }
+
+            rh.mark_wft_complete(wft_report_status)
+        } else {
+            None
         }
+    }
 
-        let query_responses = data.query_responses;
-        let has_query_responses = !query_responses.is_empty();
-        let is_query_playback = data.has_pending_query && !has_query_responses;
-        let mut force_new_wft = due_to_heartbeat_timeout;
-
-        // We only actually want to send commands back to the server if there are no more pending
-        // activations and we are caught up on replay. We don't want to complete a wft if we already
-        // saw the final event in the workflow, or if we are playing back for the express purpose of
-        // fulfilling a query. If the activation we sent was *only* an eviction, don't send that
-        // either.
-        let should_respond = !(self.wfm.machines.has_pending_jobs()
-            || outgoing_cmds.replaying
-            || is_query_playback
-            || data.activation_was_only_eviction);
-        // If there are pending LA resolutions, and we're responding to a query here,
-        // we want to make sure to force a new task, as otherwise once we tell lang about
-        // the LA resolution there wouldn't be any task to reply to with the result of iterating
-        // the workflow.
-        if has_query_responses && self.wfm.machines.has_pending_la_resolutions() {
-            force_new_wft = true;
-        }
-
-        let outcome = if should_respond || has_query_responses {
-            ActivationCompleteOutcome::ReportWFTSuccess(ServerCommandsWithWorkflowInfo {
-                task_token: data.task_token,
-                action: ActivationAction::WftComplete {
-                    force_new_wft,
-                    commands: outgoing_cmds.commands,
-                    query_responses,
-                },
-            })
+    fn buffer_resp_on_full_cache(&mut self, work: PermittedWFT) {
+        debug!(run_id=%work.work.execution.run_id, "Buffering WFT because cache is full");
+        // If there's already a buffered poll for the run, replace it.
+        if let Some(rh) = self
+            .buffered_polls_need_cache_slot
+            .iter_mut()
+            .find(|w| w.work.execution.run_id == work.work.execution.run_id)
+        {
+            *rh = work;
         } else {
-            ActivationCompleteOutcome::DoNothing
-        };
-        FulfillableActivationComplete {
-            result: ActivationCompleteResult {
-                most_recently_processed_event: self.wfm.machines.last_processed_event as usize,
-                outcome,
-            },
-            resp_chan,
+            // Otherwise push it to the back
+            self.buffered_polls_need_cache_slot.push_back(work);
         }
     }
 
-    async fn local_resolution(
-        &mut self,
-        res: LocalResolution,
-    ) -> Result<Option<FulfillableActivationComplete>, RunUpdateErr> {
-        debug!(resolution=?res, "Applying local resolution");
-        self.wfm.notify_of_local_result(res)?;
-        if self.wfm.machines.outstanding_local_activity_count() == 0 {
-            if let Some(mut wait_dat) = self.waiting_on_la.take() {
-                // Cancel the heartbeat timeout
-                wait_dat.heartbeat_timeout_task.abort();
-                if let Some((completion_dat, resp_chan)) = wait_dat.completion_dat.take() {
-                    return Ok(Some(self.prepare_complete_resp(
-                        resp_chan,
-                        completion_dat,
-                        false,
-                    )));
-                }
+    /// Makes sure we have enough pending evictions to fulfill the needs of buffered WFTs who are
+    /// waiting on a cache slot
+    fn reconcile_buffered(&mut self) -> Vec<ActivationOrAuto> {
+        // We must ensure that there are at least as many pending evictions as there are tasks
+        // that we might need to un-buffer (skipping runs which already have buffered tasks for
+        // themselves)
+        let num_in_buff = self.buffered_polls_need_cache_slot.len();
+        let mut evict_these = vec![];
+        let num_existing_evictions = self
+            .runs
+            .runs_lru_order()
+            .filter(|(_, h)| h.is_trying_to_evict())
+            .count();
+        let mut num_evicts_needed = num_in_buff.saturating_sub(num_existing_evictions);
+        for (rid, handle) in self.runs.runs_lru_order() {
+            if num_evicts_needed == 0 {
+                break;
             }
+            if !handle.has_buffered_wft() {
+                num_evicts_needed -= 1;
+                evict_these.push(rid.to_string());
+            }
+        }
+        let mut acts = vec![];
+        for run_id in evict_these {
+            acts.extend(
+                self.request_eviction(RequestEvictMsg {
+                    run_id,
+                    message: "Workflow cache full".to_string(),
+                    reason: EvictionReason::CacheFull,
+                    auto_reply_fail_tt: None,
+                })
+                .into_run_update_resp(),
+            );
         }
-        Ok(None)
+        acts
     }
 
-    /// Pump some local activity requests into the sink, applying any immediate results to the
-    /// workflow machines.
-    fn sink_la_requests(
-        &mut self,
-        new_local_acts: Vec<LocalActRequest>,
-    ) -> Result<(), WFMachinesError> {
-        let immediate_resolutions = (self.local_activity_request_sink)(new_local_acts);
-        for resolution in immediate_resolutions {
-            self.wfm
-                .notify_of_local_result(LocalResolution::LocalActivity(resolution))?;
-        }
-        Ok(())
-    }
-
-    /// Returns `true` if autocompletion should be issued, which will actually cause us to end up
-    /// in [completion] again, at which point we'll start a new heartbeat timeout, which will
-    /// immediately trigger and thus finish the completion, forcing a new task as it should.
-    fn heartbeat_timeout(&mut self) -> bool {
-        if let Some(ref mut wait_dat) = self.waiting_on_la {
-            // Cancel the heartbeat timeout
-            wait_dat.heartbeat_timeout_task.abort();
-            if let Some((completion_dat, resp_chan)) = wait_dat.completion_dat.take() {
-                let compl = self.prepare_complete_resp(resp_chan, completion_dat, true);
-                // Immediately fulfill the completion since the run update will already have
-                // been replied to
-                compl.fulfill();
-            } else {
-                // Auto-reply WFT complete
+    fn shutdown_done(&self) -> bool {
+        if self.shutdown_token.is_cancelled() {
+            if Arc::strong_count(&self.history_fetch_refcounter) > 1 {
+                // Don't exit if there are outstanding fetch requests
+                return false;
+            }
+            let all_runs_ready = self
+                .runs
+                .handles()
+                .all(|r| !r.has_any_pending_work(self.ignore_evicts_on_shutdown, false));
+            if all_runs_ready {
                 return true;
             }
-        } else {
-            // If a heartbeat timeout happened, we should always have been waiting on LAs
-            dbg_panic!("WFT heartbeat timeout fired but we were not waiting on any LAs");
         }
         false
     }
 
-    fn send_update_response(&self, outcome: RunActionOutcome, no_wft: bool) {
-        let mut in_response_to_wft = false;
-        let (outgoing_activation, fulfillable_complete) = match outcome {
-            RunActionOutcome::AfterNewWFT(a) => {
-                in_response_to_wft = true;
-                (a, None)
-            }
-            RunActionOutcome::AfterCheckWork(a) => (a, None),
-            RunActionOutcome::AfterLocalResolution(f) => (None, f),
-            RunActionOutcome::AfterCompletion(f) => (None, f),
-            RunActionOutcome::AfterHeartbeatTimeout(a) => (a, None),
-        };
-        let mut more_pending_work = self.wfm.machines.has_pending_jobs();
-        // We don't want to consider there to be more local-only work to be done if there is no
-        // workflow task associated with the run right now. This can happen if, ex, we complete
-        // a local activity while waiting for server to send us the next WFT. Activating lang would
-        // be harmful at this stage, as there might be work returned in that next WFT which should
-        // be part of the next activation.
-        if no_wft {
-            more_pending_work = false;
-        }
-        self.update_tx
-            .send(RunUpdateResponse {
-                kind: RunUpdateResponseKind::Good(GoodRunUpdate {
-                    run_id: self.wfm.machines.run_id.clone(),
-                    outgoing_activation,
-                    fulfillable_complete,
-                    have_seen_terminal_event: self.wfm.machines.have_seen_terminal_event,
-                    more_pending_work,
-                    most_recently_processed_event_number: self.wfm.machines.last_processed_event
-                        as usize,
-                    in_response_to_wft,
-                }),
-                span: Span::current(),
-            })
-            .expect("Machine can send update");
+    fn outstanding_wfts(&self) -> usize {
+        self.runs.handles().filter(|r| r.wft().is_some()).count()
     }
-}
-
-fn start_heartbeat_timeout_task(
-    chan: UnboundedSender<Span>,
-    wft_start_time: Instant,
-    wft_timeout: Duration,
-) -> JoinHandle<()> {
-    // The heartbeat deadline is 80% of the WFT timeout
-    let wft_heartbeat_deadline =
-        wft_start_time.add(wft_timeout.mul_f32(WFT_HEARTBEAT_TIMEOUT_FRACTION));
-    task::spawn(async move {
-        tokio::time::sleep_until(wft_heartbeat_deadline.into()).await;
-        let _ = chan.send(Span::current());
-    })
-}
-
-enum RunActionOutcome {
-    AfterNewWFT(Option<ActivationOrAuto>),
-    AfterCheckWork(Option<ActivationOrAuto>),
-    AfterLocalResolution(Option<FulfillableActivationComplete>),
-    AfterCompletion(Option<FulfillableActivationComplete>),
-    AfterHeartbeatTimeout(Option<ActivationOrAuto>),
-}
 
-#[derive(derive_more::DebugCustom)]
-#[debug(fmt = "RunUpdateErr({:?})", source)]
-struct RunUpdateErr {
-    source: WFMachinesError,
-    complete_resp_chan: Option<oneshot::Sender<ActivationCompleteResult>>,
-}
-
-impl From<WFMachinesError> for RunUpdateErr {
-    fn from(e: WFMachinesError) -> Self {
-        RunUpdateErr {
-            source: e,
-            complete_resp_chan: None,
+    // Useful when debugging
+    #[allow(dead_code)]
+    fn info_dump(&self, run_id: &str) {
+        if let Some(r) = self.runs.peek(run_id) {
+            info!(run_id, wft=?r.wft(), activation=?r.activation(),
+                  buffered_wft=r.has_buffered_wft(),
+                  trying_to_evict=r.is_trying_to_evict(), more_work=r.more_pending_work());
+        } else {
+            info!(run_id, "Run not found");
         }
     }
 }
 
-/// Manages an instance of a [WorkflowMachines], which is not thread-safe, as well as other data
-/// associated with that specific workflow run.
-pub(crate) struct WorkflowManager {
-    machines: WorkflowMachines,
-    /// Is always `Some` in normal operation. Optional to allow for unit testing with the test
-    /// workflow driver, which does not need to complete activations the normal way.
-    command_sink: Option<Sender<Vec<WFCommand>>>,
-}
-
-impl WorkflowManager {
-    /// Create a new workflow manager given workflow history and execution info as would be found
-    /// in [PollWorkflowTaskQueueResponse]
-    pub fn new(
-        history: HistoryUpdate,
-        namespace: String,
-        workflow_id: String,
-        workflow_type: String,
+/// All possible inputs to the [WFStream]
+#[derive(derive_more::From, Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
+enum WFStreamInput {
+    NewWft(PermittedWFT),
+    Local(LocalInput),
+    /// The stream given to us which represents the poller (or a mock) terminated.
+    PollerDead,
+    /// The stream given to us which represents the poller (or a mock) encountered a non-retryable
+    /// error while polling
+    PollerError(
+        #[cfg_attr(
+            feature = "save_wf_inputs",
+            serde(with = "tonic_status_serde::SerdeStatus")
+        )]
+        tonic::Status,
+    ),
+    FailedFetch {
         run_id: String,
-        metrics: MetricsContext,
-    ) -> Self {
-        let (wfb, cmd_sink) = WorkflowBridge::new();
-        let state_machines = WorkflowMachines::new(
-            namespace,
-            workflow_id,
-            workflow_type,
-            run_id,
-            history,
-            Box::new(wfb).into(),
-            metrics,
-        );
-        Self {
-            machines: state_machines,
-            command_sink: Some(cmd_sink),
-        }
-    }
+        #[cfg_attr(
+            feature = "save_wf_inputs",
+            serde(with = "tonic_status_serde::SerdeStatus")
+        )]
+        err: tonic::Status,
+        auto_reply_fail_tt: Option<TaskToken>,
+    },
+}
 
-    #[cfg(test)]
-    pub const fn new_from_machines(workflow_machines: WorkflowMachines) -> Self {
+/// A non-poller-received input to the [WFStream]
+#[derive(derive_more::DebugCustom)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
+#[debug(fmt = "LocalInput {{ {input:?} }}")]
+pub(super) struct LocalInput {
+    pub input: LocalInputs,
+    #[cfg_attr(feature = "save_wf_inputs", serde(skip, default = "Span::current"))]
+    pub span: Span,
+}
+impl From<HeartbeatTimeoutMsg> for LocalInput {
+    fn from(hb: HeartbeatTimeoutMsg) -> Self {
         Self {
-            machines: workflow_machines,
-            command_sink: None,
+            input: LocalInputs::HeartbeatTimeout(hb.run_id),
+            span: hb.span,
         }
     }
-
-    /// Given history that was just obtained from the server, pipe it into this workflow's machines.
-    ///
-    /// Should only be called when a workflow has caught up on replay (or is just beginning). It
-    /// will return a workflow activation if one is needed.
-    async fn feed_history_from_server(
-        &mut self,
+}
+/// Everything that _isn't_ a poll which may affect workflow state. Always higher priority than
+/// new polls.
+#[derive(Debug, derive_more::From)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
+pub(super) enum LocalInputs {
+    Completion(WFActCompleteMsg),
+    FetchedPageCompletion {
+        paginator: HistoryPaginator,
         update: HistoryUpdate,
-    ) -> Result<WorkflowActivation> {
-        self.machines.new_history_from_server(update).await?;
-        self.get_next_activation().await
-    }
-
-    /// Let this workflow know that something we've been waiting locally on has resolved, like a
-    /// local activity or side effect
-    ///
-    /// Returns true if the resolution did anything. EX: If the activity is already canceled and
-    /// used the TryCancel or Abandon modes, the resolution is uninteresting.
-    fn notify_of_local_result(&mut self, resolved: LocalResolution) -> Result<bool> {
-        self.machines.local_resolution(resolved)
-    }
-
-    /// Fetch the next workflow activation for this workflow if one is required. Doing so will apply
-    /// the next unapplied workflow task if such a sequence exists in history we already know about.
-    ///
-    /// Callers may also need to call [get_server_commands] after this to issue any pending commands
-    /// to the server.
-    async fn get_next_activation(&mut self) -> Result<WorkflowActivation> {
-        // First check if there are already some pending jobs, which can be a result of replay.
-        let activation = self.machines.get_wf_activation();
-        if !activation.jobs.is_empty() {
-            return Ok(activation);
-        }
-
-        self.machines.apply_next_wft_from_history().await?;
-        Ok(self.machines.get_wf_activation())
+    },
+    LocalResolution(LocalResolutionMsg),
+    PostActivation(PostActivationMsg),
+    RequestEviction(RequestEvictMsg),
+    HeartbeatTimeout(String),
+    #[cfg_attr(feature = "save_wf_inputs", serde(skip))]
+    GetStateInfo(GetStateInfoMsg),
+}
+impl LocalInputs {
+    fn run_id(&self) -> Option<&str> {
+        Some(match self {
+            LocalInputs::Completion(c) => c.completion.run_id(),
+            LocalInputs::FetchedPageCompletion { paginator, .. } => &paginator.run_id,
+            LocalInputs::LocalResolution(lr) => &lr.run_id,
+            LocalInputs::PostActivation(pa) => &pa.run_id,
+            LocalInputs::RequestEviction(re) => &re.run_id,
+            LocalInputs::HeartbeatTimeout(hb) => hb,
+            LocalInputs::GetStateInfo(_) => return None,
+        })
     }
-
-    /// If there are no pending jobs for the workflow, apply the next workflow task and check
-    /// again if there are any jobs. Importantly, does not *drain* jobs.
-    ///
-    /// Returns true if there are jobs (before or after applying the next WFT).
-    async fn apply_next_task_if_ready(&mut self) -> Result<bool> {
-        if self.machines.has_pending_jobs() {
-            return Ok(true);
-        }
-        loop {
-            let consumed_events = self.machines.apply_next_wft_from_history().await?;
-
-            if consumed_events == 0 || !self.machines.replaying || self.machines.has_pending_jobs()
-            {
-                // Keep applying tasks while there are events, we are still replaying, and there are
-                // no jobs
-                break;
-            }
+}
+#[derive(Debug)]
+#[allow(clippy::large_enum_variant)] // PollerDead only ever gets used once, so not important.
+enum ExternalPollerInputs {
+    NewWft(PermittedWFT),
+    PollerDead,
+    PollerError(tonic::Status),
+    FetchedUpdate(PermittedWFT),
+    NextPage {
+        paginator: HistoryPaginator,
+        update: HistoryUpdate,
+        span: Span,
+    },
+    FailedFetch {
+        run_id: String,
+        err: tonic::Status,
+        auto_reply_fail_tt: Option<TaskToken>,
+    },
+}
+impl From<ExternalPollerInputs> for WFStreamInput {
+    fn from(l: ExternalPollerInputs) -> Self {
+        match l {
+            ExternalPollerInputs::NewWft(v) => WFStreamInput::NewWft(v),
+            ExternalPollerInputs::PollerDead => WFStreamInput::PollerDead,
+            ExternalPollerInputs::PollerError(e) => WFStreamInput::PollerError(e),
+            ExternalPollerInputs::FetchedUpdate(wft) => WFStreamInput::NewWft(wft),
+            ExternalPollerInputs::FailedFetch {
+                run_id,
+                err,
+                auto_reply_fail_tt,
+            } => WFStreamInput::FailedFetch {
+                run_id,
+                err,
+                auto_reply_fail_tt,
+            },
+            ExternalPollerInputs::NextPage {
+                paginator,
+                update,
+                span,
+            } => WFStreamInput::Local(LocalInput {
+                input: LocalInputs::FetchedPageCompletion { paginator, update },
+                span,
+            }),
         }
-        Ok(self.machines.has_pending_jobs())
     }
-
-    /// Typically called after [get_next_activation], use this to retrieve commands to be sent to
-    /// the server which have been generated by the machines. Does *not* drain those commands.
-    /// See [WorkflowMachines::get_commands].
-    fn get_server_commands(&self) -> OutgoingServerCommands {
-        OutgoingServerCommands {
-            commands: self.machines.get_commands(),
-            replaying: self.machines.replaying,
+}
+impl From<Result<WFTExtractorOutput, tonic::Status>> for ExternalPollerInputs {
+    fn from(v: Result<WFTExtractorOutput, tonic::Status>) -> Self {
+        match v {
+            Ok(WFTExtractorOutput::NewWFT(pwft)) => ExternalPollerInputs::NewWft(pwft),
+            Ok(WFTExtractorOutput::FetchResult(updated_wft, _)) => {
+                ExternalPollerInputs::FetchedUpdate(updated_wft)
+            }
+            Ok(WFTExtractorOutput::NextPage {
+                paginator,
+                update,
+                span,
+                rc: _rc,
+            }) => ExternalPollerInputs::NextPage {
+                paginator,
+                update,
+                span,
+            },
+            Ok(WFTExtractorOutput::FailedFetch {
+                run_id,
+                err,
+                auto_reply_fail_tt,
+            }) => ExternalPollerInputs::FailedFetch {
+                run_id,
+                err,
+                auto_reply_fail_tt,
+            },
+            Ok(WFTExtractorOutput::PollerDead) => ExternalPollerInputs::PollerDead,
+            Err(e) => ExternalPollerInputs::PollerError(e),
         }
     }
-
-    /// Remove and return all queued local activities. Once this is called, they need to be
-    /// dispatched for execution.
-    fn drain_queued_local_activities(&mut self) -> Vec<LocalActRequest> {
-        self.machines.drain_queued_local_activities()
-    }
-
-    /// Feed the workflow machines new commands issued by the executing workflow code, and iterate
-    /// the machines.
-    async fn push_commands_and_iterate(&mut self, cmds: Vec<WFCommand>) -> Result<()> {
-        if let Some(cs) = self.command_sink.as_mut() {
-            cs.send(cmds).map_err(|_| {
-                WFMachinesError::Fatal("Internal error buffering workflow commands".to_string())
-            })?;
+}
+#[derive(Debug)]
+enum NewOrFetchedComplete {
+    New(WFActCompleteMsg),
+    Fetched(HistoryUpdate, HistoryPaginator),
+}
+impl NewOrFetchedComplete {
+    fn run_id(&self) -> &str {
+        match self {
+            NewOrFetchedComplete::New(c) => c.completion.run_id(),
+            NewOrFetchedComplete::Fetched(_, p) => &p.run_id,
         }
-        self.machines.iterate_machines().await?;
-        Ok(())
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/mod.rs`

 * *Files 8% similar despite different names*

```diff
@@ -4,48 +4,69 @@
 
 mod bridge;
 mod driven_workflow;
 mod history_update;
 mod machines;
 mod managed_run;
 mod run_cache;
+mod wft_extraction;
 pub(crate) mod wft_poller;
 mod workflow_stream;
 
+#[cfg(feature = "save_wf_inputs")]
+pub use workflow_stream::replay_wf_state_inputs;
+
 pub(crate) use bridge::WorkflowBridge;
 pub(crate) use driven_workflow::{DrivenWorkflow, WorkflowFetcher};
-pub(crate) use history_update::{HistoryPaginator, HistoryUpdate};
-pub(crate) use machines::WFMachinesError;
+pub(crate) use history_update::HistoryUpdate;
 #[cfg(test)]
 pub(crate) use managed_run::ManagedWFFunc;
 
 use crate::{
-    abstractions::OwnedMeteredSemPermit,
-    protosext::{legacy_query_failure, ValidPollWFTQResponse, WorkflowActivationExt},
-    telemetry::VecDisplayer,
+    abstractions::{
+        dbg_panic, stream_when_allowed, take_cell::TakeCell, MeteredSemaphore,
+        TrackedOwnedMeteredSemPermit, UsedMeteredSemPermit,
+    },
+    internal_flags::InternalFlags,
+    protosext::{legacy_query_failure, ValidPollWFTQResponse},
+    telemetry::{
+        metrics::workflow_worker_type, set_trace_subscriber_for_current_thread, TelemetryInstance,
+        VecDisplayer,
+    },
     worker::{
-        activities::{ActivitiesFromWFTsHandle, PermittedTqResp},
+        activities::{ActivitiesFromWFTsHandle, LocalActivityManager, TrackedPermittedTqResp},
         client::{WorkerClient, WorkflowTaskCompletion},
         workflow::{
-            managed_run::{ManagedRun, WorkflowManager},
+            history_update::HistoryPaginator,
+            managed_run::RunUpdateAct,
+            wft_extraction::{HistoryFetchReq, WFTExtractor},
             wft_poller::validate_wft,
             workflow_stream::{LocalInput, LocalInputs, WFStream},
         },
         LocalActRequest, LocalActivityExecutionResult, LocalActivityResolution,
+        PostActivateHookData,
     },
     MetricsContext,
 };
+use anyhow::anyhow;
 use futures::{stream::BoxStream, Stream, StreamExt};
+use futures_util::{future::abortable, stream};
+use prost_types::TimestampError;
 use std::{
-    collections::HashSet,
-    fmt::{Debug, Display, Formatter},
+    cell::RefCell,
+    cmp::Ordering,
+    collections::VecDeque,
+    fmt::Debug,
     future::Future,
+    mem::discriminant,
     ops::DerefMut,
+    rc::Rc,
     result,
-    sync::Arc,
+    sync::{atomic, atomic::AtomicBool, Arc},
+    thread,
     time::{Duration, Instant},
 };
 use temporal_sdk_core_api::errors::{CompleteWfError, PollWfError};
 use temporal_sdk_core_protos::{
     coresdk::{
         workflow_activation::{
             remove_from_cache::EvictionReason, workflow_activation_job, QueryWorkflow,
@@ -55,207 +76,325 @@
         workflow_completion,
         workflow_completion::{
             workflow_activation_completion, Failure, WorkflowActivationCompletion,
         },
     },
     temporal::api::{
         command::v1::{command::Attributes, Command as ProtoCommand, Command},
-        common::v1::{Memo, RetryPolicy, SearchAttributes},
+        common::v1::{Memo, MeteringMetadata, RetryPolicy, SearchAttributes, WorkflowExecution},
         enums::v1::WorkflowTaskFailedCause,
+        query::v1::WorkflowQuery,
+        sdk::v1::WorkflowTaskCompletedMetadata,
         taskqueue::v1::StickyExecutionAttributes,
-        workflowservice::v1::PollActivityTaskQueueResponse,
+        workflowservice::v1::{get_system_info_response, PollActivityTaskQueueResponse},
     },
     TaskToken,
 };
 use tokio::{
     sync::{
-        mpsc::{unbounded_channel, UnboundedSender},
+        mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
         oneshot,
     },
-    task,
-    task::{JoinError, JoinHandle},
+    task::{spawn_blocking, LocalSet},
 };
 use tokio_stream::wrappers::UnboundedReceiverStream;
 use tokio_util::sync::CancellationToken;
 use tracing::Span;
 
 pub(crate) const LEGACY_QUERY_ID: &str = "legacy_query";
+/// What percentage of a WFT timeout we are willing to wait before sending a WFT heartbeat when
+/// necessary.
+const WFT_HEARTBEAT_TIMEOUT_FRACTION: f32 = 0.8;
 const MAX_EAGER_ACTIVITY_RESERVATIONS_PER_WORKFLOW_TASK: usize = 3;
 
 type Result<T, E = WFMachinesError> = result::Result<T, E>;
 type BoxedActivationStream = BoxStream<'static, Result<ActivationOrAuto, PollWfError>>;
+type InternalFlagsRef = Rc<RefCell<InternalFlags>>;
 
 /// Centralizes all state related to workflows and workflow tasks
 pub(crate) struct Workflows {
     task_queue: String,
     local_tx: UnboundedSender<LocalInput>,
-    processing_task: tokio::sync::Mutex<Option<JoinHandle<()>>>,
+    processing_task: TakeCell<thread::JoinHandle<()>>,
     activation_stream: tokio::sync::Mutex<(
         BoxedActivationStream,
         // Used to indicate polling may begin
         Option<oneshot::Sender<()>>,
     )>,
     client: Arc<dyn WorkerClient>,
     /// Will be populated when this worker is using a cache and should complete WFTs with a sticky
     /// queue.
     sticky_attrs: Option<StickyExecutionAttributes>,
     /// If set, can be used to reserve activity task slots for eager-return of new activity tasks.
     activity_tasks_handle: Option<ActivitiesFromWFTsHandle>,
+    /// Ensures we stay at or below this worker's maximum concurrent workflow task limit
+    wft_semaphore: MeteredSemaphore,
+    local_act_mgr: Arc<LocalActivityManager>,
+    ever_polled: AtomicBool,
 }
 
-pub(super) struct WorkflowBasics {
+pub(crate) struct WorkflowBasics {
     pub max_cached_workflows: usize,
     pub max_outstanding_wfts: usize,
     pub shutdown_token: CancellationToken,
     pub metrics: MetricsContext,
     pub namespace: String,
     pub task_queue: String,
     pub ignore_evicts_on_shutdown: bool,
+    pub fetching_concurrency: usize,
+    pub server_capabilities: get_system_info_response::Capabilities,
+    #[cfg(feature = "save_wf_inputs")]
+    pub wf_state_inputs: Option<UnboundedSender<Vec<u8>>>,
+}
+
+pub(crate) struct RunBasics<'a> {
+    pub namespace: String,
+    pub workflow_id: String,
+    pub workflow_type: String,
+    pub run_id: String,
+    pub history: HistoryUpdate,
+    pub metrics: MetricsContext,
+    pub capabilities: &'a get_system_info_response::Capabilities,
 }
 
 impl Workflows {
+    #[allow(clippy::too_many_arguments)] // Not much worth combining here
     pub(super) fn new(
         basics: WorkflowBasics,
         sticky_attrs: Option<StickyExecutionAttributes>,
         client: Arc<dyn WorkerClient>,
         wft_stream: impl Stream<Item = Result<ValidPollWFTQResponse, tonic::Status>> + Send + 'static,
-        local_activity_request_sink: impl Fn(Vec<LocalActRequest>) -> Vec<LocalActivityResolution>
-            + Send
-            + Sync
-            + 'static,
+        local_activity_request_sink: impl LocalActivityRequestSink,
+        local_act_mgr: Arc<LocalActivityManager>,
+        heartbeat_timeout_rx: UnboundedReceiver<HeartbeatTimeoutMsg>,
         activity_tasks_handle: Option<ActivitiesFromWFTsHandle>,
+        telem_instance: Option<&TelemetryInstance>,
     ) -> Self {
         let (local_tx, local_rx) = unbounded_channel();
+        let (fetch_tx, fetch_rx) = unbounded_channel();
         let shutdown_tok = basics.shutdown_token.clone();
         let task_queue = basics.task_queue.clone();
-        let mut stream = WFStream::build(
-            basics,
+        let wft_semaphore = MeteredSemaphore::new(
+            basics.max_outstanding_wfts,
+            basics.metrics.with_new_attrs([workflow_worker_type()]),
+            MetricsContext::available_task_slots,
+        );
+        // Only allow polling of the new WFT stream if there are available task slots
+        let proceeder = stream::unfold(wft_semaphore.clone(), |sem| async move {
+            Some((sem.acquire_owned().await.unwrap(), sem))
+        });
+        let wft_stream = stream_when_allowed(wft_stream, proceeder);
+        let extracted_wft_stream = WFTExtractor::build(
+            client.clone(),
+            basics.fetching_concurrency,
             wft_stream,
+            UnboundedReceiverStream::new(fetch_rx),
+        );
+        let locals_stream = stream::select(
             UnboundedReceiverStream::new(local_rx),
-            client.clone(),
-            local_activity_request_sink,
+            UnboundedReceiverStream::new(heartbeat_timeout_rx).map(Into::into),
         );
         let (activation_tx, activation_rx) = unbounded_channel();
         let (start_polling_tx, start_polling_rx) = oneshot::channel();
         // We must spawn a task to constantly poll the activation stream, because otherwise
         // activation completions would not cause anything to happen until the next poll.
-        let processing_task = task::spawn(async move {
-            // However, we want to avoid plowing ahead until we've been asked to poll at least once.
-            // This supports activity-only workers.
-            let do_poll = tokio::select! {
-                sp = start_polling_rx => {
-                    sp.is_ok()
+        let tracing_sub = telem_instance.map(|ti| ti.trace_subscriber());
+        let processing_task = thread::spawn(move || {
+            if let Some(ts) = tracing_sub {
+                set_trace_subscriber_for_current_thread(ts);
+            }
+            let rt = tokio::runtime::Builder::new_current_thread()
+                .enable_all()
+                .thread_name("workflow-processing")
+                .build()
+                .unwrap();
+            let local = LocalSet::new();
+            local.block_on(&rt, async move {
+                let mut stream = WFStream::build(
+                    basics,
+                    extracted_wft_stream,
+                    locals_stream,
+                    local_activity_request_sink,
+                );
+
+                // However, we want to avoid plowing ahead until we've been asked to poll at least
+                // once. This supports activity-only workers.
+                let do_poll = tokio::select! {
+                    sp = start_polling_rx => {
+                        sp.is_ok()
+                    }
+                    _ = shutdown_tok.cancelled() => {
+                        false
+                    }
+                };
+                if !do_poll {
+                    return;
                 }
-                _ = shutdown_tok.cancelled() => {
-                    false
+                while let Some(output) = stream.next().await {
+                    match output {
+                        Ok(o) => {
+                            for fetchreq in o.fetch_histories {
+                                fetch_tx
+                                    .send(fetchreq)
+                                    .expect("Fetch channel must not be dropped");
+                            }
+                            for act in o.activations {
+                                activation_tx
+                                    .send(Ok(act))
+                                    .expect("Activation processor channel not dropped");
+                            }
+                        }
+                        Err(e) => activation_tx
+                            .send(Err(e))
+                            .expect("Activation processor channel not dropped"),
+                    }
                 }
-            };
-            if !do_poll {
-                return;
-            }
-            while let Some(act) = stream.next().await {
-                activation_tx
-                    .send(act)
-                    .expect("Activation processor channel not dropped");
-            }
+            });
         });
         Self {
             task_queue,
             local_tx,
-            processing_task: tokio::sync::Mutex::new(Some(processing_task)),
+            processing_task: TakeCell::new(processing_task),
             activation_stream: tokio::sync::Mutex::new((
                 UnboundedReceiverStream::new(activation_rx).boxed(),
                 Some(start_polling_tx),
             )),
             client,
             sticky_attrs,
             activity_tasks_handle,
+            wft_semaphore,
+            local_act_mgr,
+            ever_polled: AtomicBool::new(false),
         }
     }
 
-    pub async fn next_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
+    pub(super) async fn next_workflow_activation(&self) -> Result<WorkflowActivation, PollWfError> {
+        self.ever_polled.store(true, atomic::Ordering::Release);
         loop {
-            let r = {
+            let al = {
                 let mut lock = self.activation_stream.lock().await;
                 let (ref mut stream, ref mut beginner) = lock.deref_mut();
                 if let Some(beginner) = beginner.take() {
                     let _ = beginner.send(());
                 }
                 stream.next().await.unwrap_or(Err(PollWfError::ShutDown))?
             };
-            Span::current().record("run_id", r.run_id());
-            match r {
-                ActivationOrAuto::LangActivation(act) | ActivationOrAuto::ReadyForQueries(act) => {
+            Span::current().record("run_id", al.run_id());
+            match al {
+                ActivationOrAuto::LangActivation(mut act)
+                | ActivationOrAuto::ReadyForQueries(mut act) => {
+                    sort_act_jobs(&mut act);
                     debug!(activation=%act, "Sending activation to lang");
                     break Ok(act);
                 }
                 ActivationOrAuto::Autocomplete { run_id } => {
-                    self.activation_completed(WorkflowActivationCompletion {
-                        run_id,
-                        status: Some(workflow_completion::Success::from_variants(vec![]).into()),
-                    })
+                    self.activation_completed(
+                        WorkflowActivationCompletion {
+                            run_id,
+                            status: Some(
+                                workflow_completion::Success::from_variants(vec![]).into(),
+                            ),
+                        },
+                        true,
+                        // We need to say a type, but the type is irrelevant, so imagine some
+                        // boxed function we'll never call.
+                        Option::<Box<dyn Fn(PostActivateHookData) + Send>>::None,
+                    )
+                    .await?;
+                }
+                ActivationOrAuto::AutoFail {
+                    run_id,
+                    machines_err,
+                } => {
+                    self.activation_completed(
+                        WorkflowActivationCompletion {
+                            run_id,
+                            status: Some(auto_fail_to_complete_status(machines_err)),
+                        },
+                        true,
+                        Option::<Box<dyn Fn(PostActivateHookData) + Send>>::None,
+                    )
                     .await?;
                 }
             }
         }
     }
 
     /// Queue an activation completion for processing, returning a future that will resolve with
     /// the outcome of that completion. See [ActivationCompletedOutcome].
     ///
-    /// Returns the most-recently-processed event number for the run
-    pub async fn activation_completed(
+    /// Returns the most-recently-processed event number for the run.
+    pub(super) async fn activation_completed(
         &self,
         completion: WorkflowActivationCompletion,
-    ) -> Result<usize, CompleteWfError> {
+        is_autocomplete: bool,
+        post_activate_hook: Option<impl Fn(PostActivateHookData)>,
+    ) -> Result<(), CompleteWfError> {
         let is_empty_completion = completion.is_empty();
         let completion = validate_completion(completion)?;
         let run_id = completion.run_id().to_string();
         let (tx, rx) = oneshot::channel();
         let was_sent = self.send_local(WFActCompleteMsg {
             completion,
-            response_tx: tx,
+            response_tx: Some(tx),
         });
         if !was_sent {
             if is_empty_completion {
                 // Empty complete which is likely an evict reply, we can just ignore.
-                return Ok(0);
+                return Ok(());
             }
             panic!(
                 "A non-empty completion was not processed. Workflow processing may have \
                  terminated unexpectedly. This is a bug."
             );
         }
 
-        let completion_outcome = rx
-            .await
-            .expect("Send half of activation complete response not dropped");
+        let completion_outcome = if let Ok(c) = rx.await {
+            c
+        } else {
+            dbg_panic!("Send half of activation complete response channel went missing");
+            self.request_eviction(
+                run_id,
+                "Send half of activation complete response channel went missing",
+                EvictionReason::Fatal,
+            );
+            return Ok(());
+        };
+
         let mut wft_from_complete = None;
         let wft_report_status = match completion_outcome.outcome {
             ActivationCompleteOutcome::ReportWFTSuccess(report) => match report {
                 ServerCommandsWithWorkflowInfo {
                     task_token,
                     action:
                         ActivationAction::WftComplete {
                             mut commands,
                             query_responses,
                             force_new_wft,
+                            sdk_metadata,
                         },
                 } => {
                     let reserved_act_permits =
                         self.reserve_activity_slots_for_outgoing_commands(commands.as_mut_slice());
                     debug!(commands=%commands.display(), query_responses=%query_responses.display(),
                            force_new_wft, "Sending responses to server");
                     let mut completion = WorkflowTaskCompletion {
                         task_token,
                         commands,
                         query_responses,
                         sticky_attributes: None,
                         return_new_workflow_task: true,
                         force_create_new_workflow_task: force_new_wft,
+                        sdk_metadata,
+                        metering_metadata: MeteringMetadata {
+                            nonfirst_local_activity_execution_attempts: self
+                                .local_act_mgr
+                                .get_nonfirst_attempt_count(&run_id)
+                                as u32,
+                        },
                     };
                     let sticky_attrs = self.sticky_attrs.clone();
                     // Do not return new WFT if we would not cache, because returned new WFTs are
                     // always partial.
                     if sticky_attrs.is_none() {
                         completion.return_new_workflow_task = false;
                     }
@@ -301,62 +440,112 @@
                     WFTReportStatus::Reported
                 }
             },
             ActivationCompleteOutcome::WFTFailedDontReport => WFTReportStatus::DropWft,
             ActivationCompleteOutcome::DoNothing => WFTReportStatus::NotReported,
         };
 
+        let maybe_pwft = if let Some(wft) = wft_from_complete {
+            match HistoryPaginator::from_poll(wft, self.client.clone()).await {
+                Ok((paginator, pwft)) => Some((pwft, paginator)),
+                Err(e) => {
+                    self.request_eviction(
+                        &run_id,
+                        format!("Failed to paginate workflow task from completion: {e:?}"),
+                        EvictionReason::Fatal,
+                    );
+                    None
+                }
+            }
+        } else {
+            None
+        };
+
+        if let Some(h) = post_activate_hook {
+            h(PostActivateHookData {
+                run_id: &run_id,
+                most_recent_event: completion_outcome.most_recently_processed_event,
+                replaying: completion_outcome.replaying,
+            });
+        }
+
         self.post_activation(PostActivationMsg {
             run_id,
             wft_report_status,
-            wft_from_complete,
+            wft_from_complete: maybe_pwft,
+            is_autocomplete,
         });
 
-        Ok(completion_outcome.most_recently_processed_event)
+        Ok(())
     }
 
     /// Tell workflow that a local activity has finished with the provided result
-    pub fn notify_of_local_result(&self, run_id: impl Into<String>, resolved: LocalResolution) {
+    pub(super) fn notify_of_local_result(
+        &self,
+        run_id: impl Into<String>,
+        resolved: LocalResolution,
+    ) {
         self.send_local(LocalResolutionMsg {
             run_id: run_id.into(),
             res: resolved,
         });
     }
 
     /// Request eviction of a workflow
-    pub fn request_eviction(
+    pub(super) fn request_eviction(
         &self,
         run_id: impl Into<String>,
         message: impl Into<String>,
         reason: EvictionReason,
     ) {
         self.send_local(RequestEvictMsg {
             run_id: run_id.into(),
             message: message.into(),
             reason,
+            auto_reply_fail_tt: None,
         });
     }
 
     /// Query the state of workflow management. Can return `None` if workflow state is shut down.
-    pub fn get_state_info(&self) -> impl Future<Output = Option<WorkflowStateInfo>> {
+    pub(super) fn get_state_info(&self) -> impl Future<Output = Option<WorkflowStateInfo>> {
         let (tx, rx) = oneshot::channel();
         self.send_local(GetStateInfoMsg { response_tx: tx });
         async move { rx.await.ok() }
     }
 
-    pub async fn shutdown(&self) -> Result<(), JoinError> {
-        let maybe_jh = self.processing_task.lock().await.take();
-        if let Some(jh) = maybe_jh {
-            // This acts as a final wake up in case the stream is still alive and wouldn't otherwise
-            // receive another message. It allows it to shut itself down.
-            let _ = self.get_state_info();
-            jh.await
-        } else {
-            Ok(())
+    pub(super) fn available_wft_permits(&self) -> usize {
+        self.wft_semaphore.available_permits()
+    }
+
+    pub(super) async fn shutdown(&self) -> Result<(), anyhow::Error> {
+        if let Some(jh) = self.processing_task.take_once() {
+            // This serves to drive the stream if it is still alive and wouldn't otherwise receive
+            // another message. It allows it to shut itself down.
+            let (waker, stop_waker) = abortable(async {
+                let mut interval = tokio::time::interval(Duration::from_millis(10));
+                loop {
+                    interval.tick().await;
+                    let _ = self.get_state_info().await;
+                }
+            });
+            let (_, jh_res) = tokio::join!(
+                waker,
+                spawn_blocking(move || {
+                    let r = jh.join();
+                    stop_waker.abort();
+                    r
+                })
+            );
+            jh_res?.map_err(|e| anyhow!("Error joining workflow processing thread: {e:?}"))?;
         }
+        Ok(())
+    }
+
+    pub(super) fn ever_polled(&self) -> bool {
+        self.ever_polled.load(atomic::Ordering::Acquire)
     }
 
     /// Must be called after every activation completion has finished
     fn post_activation(&self, msg: PostActivationMsg) {
         self.send_local(msg);
     }
 
@@ -415,15 +604,15 @@
             true
         }
     }
 
     /// Process eagerly returned activities from WFT completion
     fn handle_eager_activities(
         &self,
-        reserved_act_permits: Vec<OwnedMeteredSemPermit>,
+        reserved_act_permits: Vec<TrackedOwnedMeteredSemPermit>,
         eager_acts: Vec<PollActivityTaskQueueResponse>,
     ) {
         if let Some(at_handle) = self.activity_tasks_handle.as_ref() {
             let excess_reserved = reserved_act_permits.len().saturating_sub(eager_acts.len());
             if excess_reserved > 0 {
                 debug!(
                     "Server returned {excess_reserved} fewer activities for \
@@ -436,15 +625,15 @@
                     "Server sent more activities for eager execution than we requested! They will \
                      be dropped and eventually time out. Please report this, as it is a server bug."
                 )
             }
             let with_permits = reserved_act_permits
                 .into_iter()
                 .zip(eager_acts.into_iter())
-                .map(|(permit, resp)| PermittedTqResp { permit, resp });
+                .map(|(permit, resp)| TrackedPermittedTqResp { permit, resp });
             if with_permits.len() > 0 {
                 debug!(
                     "Adding {} activity tasks received from WFT complete",
                     with_permits.len()
                 );
                 at_handle.add_tasks(with_permits);
             }
@@ -459,15 +648,15 @@
     /// Attempt to reserve activity slots for activities we could eagerly execute on
     /// this worker.
     ///
     /// Returns the number of activity slots that were reserved
     fn reserve_activity_slots_for_outgoing_commands(
         &self,
         commands: &mut [Command],
-    ) -> Vec<OwnedMeteredSemPermit> {
+    ) -> Vec<TrackedOwnedMeteredSemPermit> {
         let mut reserved = vec![];
         for cmd in commands {
             if let Some(Attributes::ScheduleActivityTaskCommandAttributes(attrs)) =
                 cmd.attributes.as_mut()
             {
                 // If request_eager_execution was already false, that means lang explicitly
                 // told us it didn't want to eagerly execute for some reason. So, we only
@@ -510,233 +699,121 @@
             Err(e) => {
                 warn!(error= %e, "Network error while responding to legacy query");
             }
         }
     }
 }
 
-/// Manages access to a specific workflow run, and contains various bookkeeping information that the
-/// [WFStream] may need to access quickly.
-#[derive(derive_more::DebugCustom)]
-#[debug(
-    fmt = "ManagedRunHandle {{ wft: {:?}, activation: {:?}, buffered_resp: {:?} \
-           have_seen_terminal_event: {}, most_recently_processed_event: {}, more_pending_work: {}, \
-           trying_to_evict: {}, last_action_acked: {} }}",
-    wft,
-    activation,
-    buffered_resp,
-    have_seen_terminal_event,
-    most_recently_processed_event_number,
-    more_pending_work,
-    "trying_to_evict.is_some()",
-    last_action_acked
+/// Returned when a cache miss happens and we need to fetch history from the beginning to
+/// replay a run
+#[derive(Debug, derive_more::Display)]
+#[display(
+    fmt = "CacheMissFetchReq(run_id: {})",
+    "original_wft.work.execution.run_id"
 )]
-struct ManagedRunHandle {
-    /// If set, the WFT this run is currently/will be processing.
-    wft: Option<OutstandingTask>,
-    /// An outstanding activation to lang
-    activation: Option<OutstandingActivation>,
-    /// If set, it indicates there is a buffered poll response from the server that applies to this
-    /// run. This can happen when lang takes too long to complete a task and the task times out, for
-    /// example. Upon next completion, the buffered response will be removed and can be made ready
-    /// to be returned from polling
-    buffered_resp: Option<PermittedWFT>,
-    /// True if this machine has seen an event which ends the execution
-    have_seen_terminal_event: bool,
-    /// The most recently processed event id this machine has seen. 0 means it has seen nothing.
-    most_recently_processed_event_number: usize,
-    /// Is set true when the machines indicate that there is additional known work to be processed
-    more_pending_work: bool,
-    /// Is set if an eviction has been requested for this run
-    trying_to_evict: Option<RequestEvictMsg>,
-    /// Set to true if the last action we tried to take to this run has been processed (ie: the
-    /// [RunUpdateResponse] for it has been seen.
-    last_action_acked: bool,
-    /// For sending work to the machines
-    run_actions_tx: UnboundedSender<RunAction>,
-    /// Handle to the task where the actual machines live
-    handle: JoinHandle<()>,
-
-    /// We track if we have recorded useful debugging values onto a certain span yet, to overcome
-    /// duplicating field values. Remove this once https://github.com/tokio-rs/tracing/issues/2334
-    /// is fixed.
-    recorded_span_ids: HashSet<tracing::Id>,
-    metrics: MetricsContext,
-}
-impl ManagedRunHandle {
-    fn new(
-        wfm: WorkflowManager,
-        activations_tx: UnboundedSender<RunUpdateResponse>,
-        local_activity_request_sink: LocalActivityRequestSink,
-        metrics: MetricsContext,
-    ) -> Self {
-        let (run_actions_tx, run_actions_rx) = unbounded_channel();
-        let managed = ManagedRun::new(wfm, activations_tx, local_activity_request_sink);
-        let handle = tokio::task::spawn(managed.run(run_actions_rx));
-        Self {
-            wft: None,
-            activation: None,
-            buffered_resp: None,
-            have_seen_terminal_event: false,
-            most_recently_processed_event_number: 0,
-            more_pending_work: false,
-            trying_to_evict: None,
-            last_action_acked: true,
-            run_actions_tx,
-            handle,
-            recorded_span_ids: Default::default(),
-            metrics,
-        }
-    }
-
-    fn incoming_wft(&mut self, wft: NewIncomingWFT) {
-        if self.wft.is_some() {
-            error!("Trying to send a new WFT for a run which already has one!");
-        }
-        self.send_run_action(RunActions::NewIncomingWFT(wft));
-    }
-    fn check_more_activations(&mut self) {
-        // No point in checking for more activations if we have not acked the last update, or
-        // if there's already an outstanding activation.
-        if self.last_action_acked && self.activation.is_none() {
-            self.send_run_action(RunActions::CheckMoreWork {
-                want_to_evict: self.trying_to_evict.clone(),
-                has_pending_queries: self
-                    .wft
-                    .as_ref()
-                    .map(|wft| !wft.pending_queries.is_empty())
-                    .unwrap_or_default(),
-                has_wft: self.wft.is_some(),
-            });
-        }
-    }
-    fn send_completion(&mut self, c: RunActivationCompletion) {
-        self.send_run_action(RunActions::ActivationCompletion(c));
-    }
-    fn send_local_resolution(&mut self, r: LocalResolution) {
-        self.send_run_action(RunActions::LocalResolution(r));
-    }
-
-    fn insert_outstanding_activation(&mut self, act: &ActivationOrAuto) {
-        let act_type = match &act {
-            ActivationOrAuto::LangActivation(act) | ActivationOrAuto::ReadyForQueries(act) => {
-                if act.is_legacy_query() {
-                    OutstandingActivation::LegacyQuery
-                } else {
-                    OutstandingActivation::Normal {
-                        contains_eviction: act.eviction_index().is_some(),
-                        num_jobs: act.jobs.len(),
-                    }
-                }
-            }
-            ActivationOrAuto::Autocomplete { .. } => OutstandingActivation::Autocomplete,
-        };
-        if let Some(old_act) = self.activation {
-            // This is a panic because we have screwed up core logic if this is violated. It must be
-            // upheld.
-            panic!(
-                "Attempted to insert a new outstanding activation {:?}, but there already was \
-                 one outstanding: {:?}",
-                act, old_act
-            );
-        }
-        self.activation = Some(act_type);
-    }
-
-    fn send_run_action(&mut self, action: RunActions) {
-        self.last_action_acked = false;
-        self.run_actions_tx
-            .send(RunAction {
-                action,
-                trace_span: Span::current(),
-            })
-            .expect("Receive half of run actions not dropped");
-    }
+#[must_use]
+struct CacheMissFetchReq {
+    original_wft: PermittedWFT,
+}
+/// Bubbled up from inside workflow state if we're trying to apply the next workflow task but it
+/// isn't in memory
+#[derive(Debug)]
+#[must_use]
+struct NextPageReq {
+    paginator: HistoryPaginator,
+    span: Span,
+}
 
-    /// Returns true if the managed run has any form of pending work
-    /// If `ignore_evicts` is true, pending evictions do not count as pending work.
-    /// If `ignore_buffered` is true, buffered workflow tasks do not count as pending work.
-    fn has_any_pending_work(&self, ignore_evicts: bool, ignore_buffered: bool) -> bool {
-        let evict_work = if ignore_evicts {
-            false
-        } else {
-            self.trying_to_evict.is_some()
-        };
-        let act_work = if ignore_evicts {
-            if let Some(ref act) = self.activation {
-                !act.has_only_eviction()
-            } else {
-                false
-            }
-        } else {
-            self.activation.is_some()
-        };
-        let buffered = if ignore_buffered {
-            false
-        } else {
-            self.buffered_resp.is_some()
-        };
-        self.wft.is_some()
-            || buffered
-            || !self.last_action_acked
-            || self.more_pending_work
-            || act_work
-            || evict_work
-    }
-
-    /// Returns true if the handle is currently processing a WFT which contains a legacy query.
-    fn pending_work_is_legacy_query(&self) -> bool {
-        // Either we know because there is a pending legacy query, or it's already been drained and
-        // sent as an activation.
-        matches!(self.activation, Some(OutstandingActivation::LegacyQuery))
-            || self
-                .wft
-                .as_ref()
-                .map(|t| t.has_pending_legacy_query())
-                .unwrap_or_default()
-    }
+#[derive(Debug)]
+struct WFStreamOutput {
+    activations: VecDeque<ActivationOrAuto>,
+    fetch_histories: VecDeque<HistoryFetchReq>,
 }
 
 #[derive(Debug, derive_more::Display)]
 enum ActivationOrAuto {
     LangActivation(WorkflowActivation),
     /// This type should only be filled with an empty activation which is ready to have queries
     /// inserted into the joblist
     ReadyForQueries(WorkflowActivation),
+    #[display(fmt = "Autocomplete(run_id={run_id})")]
     Autocomplete {
         run_id: String,
     },
+    #[display(fmt = "AutoFail(run_id={run_id})")]
+    AutoFail {
+        run_id: String,
+        machines_err: WFMachinesError,
+    },
 }
 impl ActivationOrAuto {
     pub fn run_id(&self) -> &str {
         match self {
             ActivationOrAuto::LangActivation(act) => &act.run_id,
             ActivationOrAuto::Autocomplete { run_id, .. } => run_id,
             ActivationOrAuto::ReadyForQueries(act) => &act.run_id,
+            ActivationOrAuto::AutoFail { run_id, .. } => run_id,
         }
     }
 }
 
+/// A processed WFT which has been validated and had a history update extracted from it
 #[derive(derive_more::DebugCustom)]
-#[debug(fmt = "PermittedWft {{ {:?} }}", wft)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
+#[debug(fmt = "PermittedWft({work:?})")]
 pub(crate) struct PermittedWFT {
-    wft: ValidPollWFTQResponse,
-    permit: OwnedMeteredSemPermit,
+    work: PreparedWFT,
+    #[cfg_attr(
+        feature = "save_wf_inputs",
+        serde(skip, default = "UsedMeteredSemPermit::fake_deserialized")
+    )]
+    permit: UsedMeteredSemPermit,
+    #[cfg_attr(
+        feature = "save_wf_inputs",
+        serde(skip, default = "HistoryPaginator::fake_deserialized")
+    )]
+    paginator: HistoryPaginator,
+}
+#[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
+struct PreparedWFT {
+    task_token: TaskToken,
+    attempt: u32,
+    execution: WorkflowExecution,
+    workflow_type: String,
+    legacy_query: Option<WorkflowQuery>,
+    query_requests: Vec<QueryWorkflow>,
+    update: HistoryUpdate,
+}
+impl PreparedWFT {
+    /// Returns true if the contained history update is incremental (IE: expects to hit a cached
+    /// workflow)
+    pub fn is_incremental(&self) -> bool {
+        let start_event_id = self.update.first_event_id();
+        let poll_resp_is_incremental = start_event_id.map(|eid| eid > 1).unwrap_or_default();
+        poll_resp_is_incremental || start_event_id.is_none()
+    }
 }
 
 #[derive(Debug)]
 pub(crate) struct OutstandingTask {
     pub info: WorkflowTaskInfo,
     pub hit_cache: bool,
     /// Set if the outstanding task has quer(ies) which must be fulfilled upon finishing replay
     pub pending_queries: Vec<QueryWorkflow>,
     pub start_time: Instant,
     /// The WFT permit owned by this task, ensures we don't exceed max concurrent WFT, and makes
     /// sure the permit is automatically freed when we delete the task.
-    pub permit: OwnedMeteredSemPermit,
+    pub permit: UsedMeteredSemPermit,
 }
 
 impl OutstandingTask {
     pub fn has_pending_legacy_query(&self) -> bool {
         self.pending_queries
             .iter()
             .any(|q| q.query_id == LEGACY_QUERY_ID)
@@ -807,65 +884,102 @@
 #[derive(Debug)]
 pub(crate) enum ActivationAction {
     /// We should respond that the workflow task is complete
     WftComplete {
         commands: Vec<ProtoCommand>,
         query_responses: Vec<QueryResult>,
         force_new_wft: bool,
+        sdk_metadata: WorkflowTaskCompletedMetadata,
     },
     /// We should respond to a legacy query request
     RespondLegacyQuery { result: Box<QueryResult> },
 }
 
-#[derive(Debug, Eq, PartialEq, Hash)]
-pub(crate) enum EvictionRequestResult {
-    EvictionRequested(Option<u32>),
+#[derive(Debug)]
+enum EvictionRequestResult {
+    EvictionRequested(Option<u32>, RunUpdateAct),
     NotFound,
     EvictionAlreadyRequested(Option<u32>),
 }
+impl EvictionRequestResult {
+    fn into_run_update_resp(self) -> RunUpdateAct {
+        match self {
+            EvictionRequestResult::EvictionRequested(_, resp) => resp,
+            EvictionRequestResult::NotFound
+            | EvictionRequestResult::EvictionAlreadyRequested(_) => None,
+        }
+    }
+}
 
 #[derive(Debug)]
 #[allow(dead_code)] // Not always used in non-test
 pub(crate) struct WorkflowStateInfo {
     pub cached_workflows: usize,
     pub outstanding_wft: usize,
-    pub available_wft_permits: usize,
 }
 
 #[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 struct WFActCompleteMsg {
     completion: ValidatedCompletion,
-    response_tx: oneshot::Sender<ActivationCompleteResult>,
+    #[cfg_attr(feature = "save_wf_inputs", serde(skip))]
+    response_tx: Option<oneshot::Sender<ActivationCompleteResult>>,
 }
 #[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 struct LocalResolutionMsg {
     run_id: String,
     res: LocalResolution,
 }
 #[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 struct PostActivationMsg {
     run_id: String,
     wft_report_status: WFTReportStatus,
-    wft_from_complete: Option<ValidPollWFTQResponse>,
+    wft_from_complete: Option<(PreparedWFT, HistoryPaginator)>,
+    is_autocomplete: bool,
 }
 #[derive(Debug, Clone)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 struct RequestEvictMsg {
     run_id: String,
     message: String,
     reason: EvictionReason,
+    /// If set, we requested eviction because something went wrong processing a brand new poll task,
+    /// which means we won't have stored the WFT and we need to track the task token separately so
+    /// we can reply with a failure to server after the evict goes through.
+    auto_reply_fail_tt: Option<TaskToken>,
+}
+#[derive(Debug)]
+pub(crate) struct HeartbeatTimeoutMsg {
+    pub(crate) run_id: String,
+    pub(crate) span: Span,
 }
 #[derive(Debug)]
 struct GetStateInfoMsg {
     response_tx: oneshot::Sender<WorkflowStateInfo>,
 }
 
 /// Each activation completion produces one of these
 #[derive(Debug)]
 struct ActivationCompleteResult {
     most_recently_processed_event: usize,
+    replaying: bool,
     outcome: ActivationCompleteOutcome,
 }
 /// What needs to be done after calling [Workflows::activation_completed]
 #[derive(Debug)]
 #[allow(clippy::large_enum_variant)]
 enum ActivationCompleteOutcome {
     /// The WFT must be reported as successful to the server using the contained information.
@@ -875,42 +989,36 @@
     /// There's nothing to do right now. EX: The workflow needs to keep replaying.
     DoNothing,
     /// The workflow task failed, but we shouldn't report it. EX: We have failed 2 or more attempts
     /// in a row.
     WFTFailedDontReport,
 }
 /// Did we report, or not, completion of a WFT to server?
-#[derive(Debug)]
+#[derive(Debug, Copy, Clone)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 enum WFTReportStatus {
     Reported,
     /// The WFT completion was not reported when finishing the activation, because there's still
     /// work to be done. EX: Running LAs.
     NotReported,
     /// We didn't report, but we want to clear the outstanding workflow task anyway. See
     /// [ActivationCompleteOutcome::WFTFailedDontReport]
     DropWft,
 }
-#[derive(Debug)]
-struct FulfillableActivationComplete {
-    result: ActivationCompleteResult,
-    resp_chan: oneshot::Sender<ActivationCompleteResult>,
-}
-impl FulfillableActivationComplete {
-    fn fulfill(self) {
-        let _ = self.resp_chan.send(self.result);
-    }
-}
 
 fn validate_completion(
     completion: WorkflowActivationCompletion,
 ) -> Result<ValidatedCompletion, CompleteWfError> {
     match completion.status {
         Some(workflow_activation_completion::Status::Successful(success)) => {
             // Convert to wf commands
-            let commands = success
+            let mut commands = success
                 .commands
                 .into_iter()
                 .map(|c| c.try_into())
                 .collect::<Result<Vec<_>, EmptyWorkflowCommandErr>>()
                 .map_err(|_| CompleteWfError::MalformedWorkflowCompletion {
                     reason: "At least one workflow command in the completion contained \
                                  an empty variant"
@@ -923,24 +1031,34 @@
                     |c| matches!(c, WFCommand::QueryResponse(q) if q.query_id == LEGACY_QUERY_ID),
                 )
             {
                 return Err(CompleteWfError::MalformedWorkflowCompletion {
                     reason: format!(
                         "Workflow completion had a legacy query response along with other \
                          commands. This is not allowed and constitutes an error in the \
-                         lang SDK. Commands: {:?}",
-                        commands
+                         lang SDK. Commands: {commands:?}"
                     ),
                     run_id: completion.run_id,
                 });
             }
 
+            // Any non-query-response commands after a terminal command should be ignored
+            if let Some(term_cmd_pos) = commands.iter().position(|c| c.is_terminal()) {
+                // Query responses are just fine, so keep them.
+                let queries = commands
+                    .split_off(term_cmd_pos + 1)
+                    .into_iter()
+                    .filter(|c| matches!(c, WFCommand::QueryResponse(_)));
+                commands.extend(queries);
+            }
+
             Ok(ValidatedCompletion::Success {
                 run_id: completion.run_id,
                 commands,
+                used_flags: success.used_internal_flags,
             })
         }
         Some(workflow_activation_completion::Status::Failed(failure)) => {
             Ok(ValidatedCompletion::Fail {
                 run_id: completion.run_id,
                 failure,
             })
@@ -949,19 +1067,24 @@
             reason: "Workflow completion had empty status field".to_owned(),
             run_id: completion.run_id,
         }),
     }
 }
 
 #[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 #[allow(clippy::large_enum_variant)]
 enum ValidatedCompletion {
     Success {
         run_id: String,
         commands: Vec<WFCommand>,
+        used_flags: Vec<u32>,
     },
     Fail {
         run_id: String,
         failure: Failure,
     },
 }
 
@@ -970,127 +1093,25 @@
         match self {
             ValidatedCompletion::Success { run_id, .. } => run_id,
             ValidatedCompletion::Fail { run_id, .. } => run_id,
         }
     }
 }
 
-/// Input to run tasks, sent to [ManagedRun]s via [ManagedRunHandle]s
-#[derive(Debug)]
-struct RunAction {
-    action: RunActions,
-    trace_span: Span,
-}
-#[derive(Debug)]
-#[allow(clippy::large_enum_variant)]
-enum RunActions {
-    NewIncomingWFT(NewIncomingWFT),
-    ActivationCompletion(RunActivationCompletion),
-    CheckMoreWork {
-        want_to_evict: Option<RequestEvictMsg>,
-        has_pending_queries: bool,
-        has_wft: bool,
-    },
-    LocalResolution(LocalResolution),
-    HeartbeatTimeout,
-}
-#[derive(Debug)]
-struct NewIncomingWFT {
-    /// This field is only populated if the machines already exist. Otherwise the machines
-    /// are instantiated with the workflow history.
-    history_update: Option<HistoryUpdate>,
-    /// Wft start time
-    start_time: Instant,
-}
-#[derive(Debug)]
-struct RunActivationCompletion {
-    task_token: TaskToken,
-    start_time: Instant,
-    commands: Vec<WFCommand>,
-    activation_was_eviction: bool,
-    activation_was_only_eviction: bool,
-    has_pending_query: bool,
-    query_responses: Vec<QueryResult>,
-    /// Used to notify the worker when the completion is done processing and the completion can
-    /// unblock. Must always be `Some` when initialized.
-    resp_chan: Option<oneshot::Sender<ActivationCompleteResult>>,
-}
-
-/// A response from a [ManagedRun] held by a [ManagedRunHandle]
-#[derive(Debug)]
-struct RunUpdateResponse {
-    kind: RunUpdateResponseKind,
-    span: Span,
-}
-#[derive(Debug, derive_more::Display)]
-#[allow(clippy::large_enum_variant)]
-enum RunUpdateResponseKind {
-    Good(GoodRunUpdate),
-    Fail(FailRunUpdate),
-}
-impl RunUpdateResponseKind {
-    pub(crate) fn run_id(&self) -> &str {
-        match self {
-            RunUpdateResponseKind::Good(g) => &g.run_id,
-            RunUpdateResponseKind::Fail(f) => &f.run_id,
-        }
-    }
-}
-
-#[derive(Debug)]
-struct GoodRunUpdate {
-    run_id: String,
-    outgoing_activation: Option<ActivationOrAuto>,
-    fulfillable_complete: Option<FulfillableActivationComplete>,
-    have_seen_terminal_event: bool,
-    /// Is true if there are more jobs that need to be sent to lang
-    more_pending_work: bool,
-    most_recently_processed_event_number: usize,
-    /// Is true if this update was in response to a new WFT
-    in_response_to_wft: bool,
-}
-impl Display for GoodRunUpdate {
-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        write!(
-            f,
-            "GoodRunUpdate(run_id: {}, outgoing_activation: {}, more_pending_work: {})",
-            self.run_id,
-            if let Some(og) = self.outgoing_activation.as_ref() {
-                format!("{}", og)
-            } else {
-                "None".to_string()
-            },
-            self.more_pending_work
-        )
-    }
-}
-#[derive(Debug)]
-pub(crate) struct FailRunUpdate {
-    run_id: String,
-    err: WFMachinesError,
-    /// This is populated if the run update failed while processing a completion - and thus we
-    /// must respond down it when handling the failure.
-    completion_resp: Option<oneshot::Sender<ActivationCompleteResult>>,
-}
-impl Display for FailRunUpdate {
-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-        write!(
-            f,
-            "FailRunUpdate(run_id: {}, error: {:?})",
-            self.run_id, self.err
-        )
-    }
-}
 #[derive(Debug)]
 pub struct OutgoingServerCommands {
     pub commands: Vec<ProtoCommand>,
     pub replaying: bool,
 }
 
 #[derive(Debug)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 pub(crate) enum LocalResolution {
     LocalActivity(LocalActivityResolution),
 }
 impl LocalResolution {
     pub fn is_la_cancel_confirmation(&self) -> bool {
         match self {
             LocalResolution::LocalActivity(lar) => {
@@ -1103,14 +1124,18 @@
 #[derive(thiserror::Error, Debug, derive_more::From)]
 #[error("Lang provided workflow command with empty variant")]
 pub struct EmptyWorkflowCommandErr;
 
 /// [DrivenWorkflow]s respond with these when called, to indicate what they want to do next.
 /// EX: Create a new timer, complete the workflow, etc.
 #[derive(Debug, derive_more::From, derive_more::Display)]
+#[cfg_attr(
+    feature = "save_wf_inputs",
+    derive(serde::Serialize, serde::Deserialize)
+)]
 #[allow(clippy::large_enum_variant)]
 pub enum WFCommand {
     /// Returned when we need to wait for the lang sdk to send us something
     NoCommandsFromLang,
     AddActivity(ScheduleActivity),
     AddLocalActivity(ScheduleLocalActivity),
     RequestCancelActivity(RequestCancelActivity),
@@ -1174,14 +1199,31 @@
             workflow_command::Variant::ModifyWorkflowProperties(s) => {
                 Ok(Self::ModifyWorkflowProperties(s))
             }
         }
     }
 }
 
+impl WFCommand {
+    /// Returns true if the command is one which ends the workflow:
+    /// * Completed
+    /// * Failed
+    /// * Cancelled
+    /// * Continue-as-new
+    pub fn is_terminal(&self) -> bool {
+        matches!(
+            self,
+            WFCommand::CompleteWorkflow(_)
+                | WFCommand::FailWorkflow(_)
+                | WFCommand::CancelWorkflow(_)
+                | WFCommand::ContinueAsNew(_)
+        )
+    }
+}
+
 #[derive(Debug, PartialEq, Eq, Hash, Clone, Copy)]
 enum CommandID {
     Timer(u32),
     Activity(u32),
     LocalActivity(u32),
     ChildWorkflowStart(u32),
     SignalExternal(u32),
@@ -1195,20 +1237,17 @@
     workflow_task_timeout: Option<Duration>,
     workflow_execution_timeout: Option<Duration>,
     memo: Option<Memo>,
     search_attrs: Option<SearchAttributes>,
     retry_policy: Option<RetryPolicy>,
 }
 
-type LocalActivityRequestSink =
-    Arc<dyn Fn(Vec<LocalActRequest>) -> Vec<LocalActivityResolution> + Send + Sync>;
-
 /// Wraps outgoing activation job protos with some internal details core might care about
 #[derive(Debug, derive_more::Display)]
-#[display(fmt = "{}", variant)]
+#[display(fmt = "{variant}")]
 struct OutgoingJob {
     variant: workflow_activation_job::Variant,
     /// Since LA resolutions are not distinguished from non-LA resolutions as far as lang is
     /// concerned, but core cares about that sometimes, attach that info here.
     is_la_resolution: bool,
 }
 impl<WA: Into<workflow_activation_job::Variant>> From<WA> for OutgoingJob {
@@ -1222,7 +1261,162 @@
 impl From<OutgoingJob> for WorkflowActivationJob {
     fn from(og: OutgoingJob) -> Self {
         Self {
             variant: Some(og.variant),
         }
     }
 }
+
+/// Errors thrown inside of workflow machines
+#[derive(thiserror::Error, Debug)]
+pub(crate) enum WFMachinesError {
+    #[error("Nondeterminism error: {0}")]
+    Nondeterminism(String),
+    #[error("Fatal error in workflow machines: {0}")]
+    Fatal(String),
+}
+
+impl WFMachinesError {
+    pub fn evict_reason(&self) -> EvictionReason {
+        match self {
+            WFMachinesError::Nondeterminism(_) => EvictionReason::Nondeterminism,
+            WFMachinesError::Fatal(_) => EvictionReason::Fatal,
+        }
+    }
+}
+
+impl From<TimestampError> for WFMachinesError {
+    fn from(_: TimestampError) -> Self {
+        Self::Fatal("Could not decode timestamp".to_string())
+    }
+}
+
+impl From<anyhow::Error> for WFMachinesError {
+    fn from(value: anyhow::Error) -> Self {
+        WFMachinesError::Fatal(value.to_string())
+    }
+}
+
+fn auto_fail_to_complete_status(err: WFMachinesError) -> workflow_activation_completion::Status {
+    workflow_activation_completion::Status::Failed(Failure {
+        failure: Some(
+            temporal_sdk_core_protos::temporal::api::failure::v1::Failure {
+                message: "Error while processing workflow task".to_string(),
+                source: err.to_string(),
+                stack_trace: "".to_string(),
+                encoded_attributes: None,
+                cause: None,
+                failure_info: None,
+            },
+        ),
+        force_cause: WorkflowTaskFailedCause::from(err.evict_reason()) as i32,
+    })
+}
+
+pub(crate) trait LocalActivityRequestSink: Send + Sync + 'static {
+    fn sink_reqs(&self, reqs: Vec<LocalActRequest>) -> Vec<LocalActivityResolution>;
+}
+
+#[derive(derive_more::Constructor)]
+pub(super) struct LAReqSink {
+    lam: Arc<LocalActivityManager>,
+    /// If we're recording WF inputs, we also need to store immediate resolutions so they're
+    /// available on replay.
+    #[allow(dead_code)] // sometimes appears unused due to feature flagging
+    recorder: Option<UnboundedSender<Vec<u8>>>,
+}
+
+impl LocalActivityRequestSink for LAReqSink {
+    fn sink_reqs(&self, reqs: Vec<LocalActRequest>) -> Vec<LocalActivityResolution> {
+        if reqs.is_empty() {
+            return vec![];
+        }
+
+        #[allow(clippy::let_and_return)] // When feature is off clippy doesn't like this
+        let res = self.lam.enqueue(reqs);
+
+        // We always save when there are any reqs, even if the response might be empty, so that
+        // calls/responses are 1:1
+        #[cfg(feature = "save_wf_inputs")]
+        self.write_req(&res);
+
+        res
+    }
+}
+
+/// Sorts jobs in an activation to be in the order lang expects:
+/// `patches -> signals -> other -> queries`
+fn sort_act_jobs(wfa: &mut WorkflowActivation) {
+    wfa.jobs.sort_by(|j1, j2| {
+        // Unwrapping is fine here since we'll never issue empty variants
+        let j1v = j1.variant.as_ref().unwrap();
+        let j2v = j2.variant.as_ref().unwrap();
+        if discriminant(j1v) == discriminant(j2v) {
+            return Ordering::Equal;
+        }
+        fn variant_ordinal(v: &workflow_activation_job::Variant) -> u8 {
+            match v {
+                workflow_activation_job::Variant::NotifyHasPatch(_) => 1,
+                workflow_activation_job::Variant::SignalWorkflow(_) => 2,
+                workflow_activation_job::Variant::QueryWorkflow(_) => 4,
+                _ => 3,
+            }
+        }
+        variant_ordinal(j1v).cmp(&variant_ordinal(j2v))
+    })
+}
+
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use itertools::Itertools;
+
+    #[test]
+    fn jobs_sort() {
+        let mut act = WorkflowActivation {
+            jobs: vec![
+                WorkflowActivationJob {
+                    variant: Some(workflow_activation_job::Variant::SignalWorkflow(
+                        Default::default(),
+                    )),
+                },
+                WorkflowActivationJob {
+                    variant: Some(workflow_activation_job::Variant::NotifyHasPatch(
+                        Default::default(),
+                    )),
+                },
+                WorkflowActivationJob {
+                    variant: Some(workflow_activation_job::Variant::QueryWorkflow(
+                        Default::default(),
+                    )),
+                },
+                WorkflowActivationJob {
+                    variant: Some(workflow_activation_job::Variant::FireTimer(
+                        Default::default(),
+                    )),
+                },
+                WorkflowActivationJob {
+                    variant: Some(workflow_activation_job::Variant::ResolveActivity(
+                        Default::default(),
+                    )),
+                },
+            ],
+            ..Default::default()
+        };
+        sort_act_jobs(&mut act);
+        let variants = act
+            .jobs
+            .into_iter()
+            .map(|j| j.variant.unwrap())
+            .collect_vec();
+        assert_matches!(
+            variants.as_slice(),
+            &[
+                workflow_activation_job::Variant::NotifyHasPatch(_),
+                workflow_activation_job::Variant::SignalWorkflow(_),
+                workflow_activation_job::Variant::FireTimer(_),
+                workflow_activation_job::Variant::ResolveActivity(_),
+                workflow_activation_job::Variant::QueryWorkflow(_)
+            ]
+        )
+    }
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/run_cache.rs`

 * *Files 14% similar despite different names*

```diff
@@ -1,140 +1,123 @@
 use crate::{
     telemetry::metrics::workflow_type,
     worker::workflow::{
-        managed_run::WorkflowManager, HistoryUpdate, LocalActivityRequestSink, ManagedRunHandle,
-        NewIncomingWFT, RunUpdateResponse,
+        managed_run::{ManagedRun, RunUpdateAct},
+        HistoryUpdate, LocalActivityRequestSink, PermittedWFT, RunBasics,
     },
     MetricsContext,
 };
 use lru::LruCache;
-use std::{num::NonZeroUsize, time::Instant};
-use tokio::sync::mpsc::UnboundedSender;
+use std::{mem, num::NonZeroUsize, rc::Rc};
+use temporal_sdk_core_protos::temporal::api::workflowservice::v1::get_system_info_response;
 
 pub(super) struct RunCache {
     max: usize,
     namespace: String,
-    run_update_tx: UnboundedSender<RunUpdateResponse>,
+    server_capabilities: get_system_info_response::Capabilities,
     /// Run id -> Data
-    runs: LruCache<String, ManagedRunHandle>,
-    local_activity_request_sink: LocalActivityRequestSink,
+    runs: LruCache<String, ManagedRun>,
+    local_activity_request_sink: Rc<dyn LocalActivityRequestSink>,
 
     metrics: MetricsContext,
 }
 
 impl RunCache {
     pub fn new(
         max_cache_size: usize,
         namespace: String,
-        run_update_tx: UnboundedSender<RunUpdateResponse>,
-        local_activity_request_sink: LocalActivityRequestSink,
+        server_capabilities: get_system_info_response::Capabilities,
+        local_activity_request_sink: impl LocalActivityRequestSink,
         metrics: MetricsContext,
     ) -> Self {
         // The cache needs room for at least one run, otherwise we couldn't do anything. In
         // "0" size mode, the run is evicted once the workflow task is complete.
         let lru_size = if max_cache_size > 0 {
             max_cache_size
         } else {
             1
         };
         Self {
             max: max_cache_size,
             namespace,
-            run_update_tx,
+            server_capabilities,
             runs: LruCache::new(
                 NonZeroUsize::new(lru_size).expect("LRU size is guaranteed positive"),
             ),
-            local_activity_request_sink,
+            local_activity_request_sink: Rc::new(local_activity_request_sink),
             metrics,
         }
     }
 
-    pub fn instantiate_or_update(
-        &mut self,
-        run_id: &str,
-        workflow_id: &str,
-        wf_type: &str,
-        history_update: HistoryUpdate,
-        start_time: Instant,
-    ) -> &mut ManagedRunHandle {
+    pub fn instantiate_or_update(&mut self, mut pwft: PermittedWFT) -> RunUpdateAct {
         let cur_num_cached_runs = self.runs.len();
+        let run_id = &pwft.work.execution.run_id;
 
-        if self.runs.contains(run_id) {
-            // For some weird reason, maybe a NLL bug, there are double-mutable-borrow errors if I
-            // use get_mut above instead of in here (even though we always return from this branch).
-            // So, forced to do this.
-            let run_handle = self.runs.get_mut(run_id).unwrap();
-
-            run_handle.metrics.sticky_cache_hit();
-            run_handle.incoming_wft(NewIncomingWFT {
-                history_update: Some(history_update),
-                start_time,
-            });
+        if let Some(run_handle) = self.runs.get_mut(run_id) {
+            let rur = run_handle.incoming_wft(pwft);
             self.metrics.cache_size(cur_num_cached_runs as u64);
-            return run_handle;
+            return rur;
         }
 
         // Create a new workflow machines instance for this workflow, initialize it, and
         // track it.
         let metrics = self
             .metrics
-            .with_new_attrs([workflow_type(wf_type.to_string())]);
-        let wfm = WorkflowManager::new(
-            history_update,
-            self.namespace.clone(),
-            workflow_id.to_string(),
-            wf_type.to_string(),
-            run_id.to_string(),
-            metrics.clone(),
-        );
-        let mut mrh = ManagedRunHandle::new(
-            wfm,
-            self.run_update_tx.clone(),
+            .with_new_attrs([workflow_type(pwft.work.workflow_type.clone())]);
+        // Replace the update in the wft with a dummy one, since we must instantiate the machines
+        // with the update.
+        let history_update = mem::replace(&mut pwft.work.update, HistoryUpdate::dummy());
+        let mut mrh = ManagedRun::new(
+            RunBasics {
+                namespace: self.namespace.clone(),
+                workflow_id: pwft.work.execution.workflow_id.clone(),
+                workflow_type: pwft.work.workflow_type.clone(),
+                run_id: pwft.work.execution.run_id.clone(),
+                history: history_update,
+                metrics,
+                capabilities: &self.server_capabilities,
+            },
             self.local_activity_request_sink.clone(),
-            metrics,
         );
-        mrh.incoming_wft(NewIncomingWFT {
-            history_update: None,
-            start_time,
-        });
-        if self.runs.push(run_id.to_string(), mrh).is_some() {
+        let run_id = run_id.to_string();
+        let rur = mrh.incoming_wft(pwft);
+        if self.runs.push(run_id, mrh).is_some() {
             panic!("Overflowed run cache! Cache owner is expected to avoid this!");
         }
         self.metrics.cache_size(cur_num_cached_runs as u64 + 1);
-        // This is safe, we just inserted.
-        self.runs.get_mut(run_id).unwrap()
+        rur
     }
-    pub fn remove(&mut self, k: &str) -> Option<ManagedRunHandle> {
+    pub fn remove(&mut self, k: &str) -> Option<ManagedRun> {
         let r = self.runs.pop(k);
         self.metrics.cache_size(self.len() as u64);
         r
     }
 
-    pub fn get_mut(&mut self, k: &str) -> Option<&mut ManagedRunHandle> {
+    pub fn get_mut(&mut self, k: &str) -> Option<&mut ManagedRun> {
         self.runs.get_mut(k)
     }
-    pub fn get(&mut self, k: &str) -> Option<&ManagedRunHandle> {
+    pub fn get(&mut self, k: &str) -> Option<&ManagedRun> {
         self.runs.get(k)
     }
 
     /// Returns the current least-recently-used run. Returns `None` when cache empty.
     pub fn current_lru_run(&self) -> Option<&str> {
         self.runs.peek_lru().map(|(run_id, _)| run_id.as_str())
     }
     /// Returns an iterator yielding cached runs in LRU order
-    pub fn runs_lru_order(&self) -> impl Iterator<Item = (&str, &ManagedRunHandle)> {
+    pub fn runs_lru_order(&self) -> impl Iterator<Item = (&str, &ManagedRun)> {
         self.runs.iter().rev().map(|(k, v)| (k.as_str(), v))
     }
-    pub fn peek(&self, k: &str) -> Option<&ManagedRunHandle> {
+    pub fn peek(&self, k: &str) -> Option<&ManagedRun> {
         self.runs.peek(k)
     }
     pub fn has_run(&self, k: &str) -> bool {
         self.runs.contains(k)
     }
-    pub fn handles(&self) -> impl Iterator<Item = &ManagedRunHandle> {
+    pub fn handles(&self) -> impl Iterator<Item = &ManagedRun> {
         self.runs.iter().map(|(_, v)| v)
     }
     pub fn is_full(&self) -> bool {
         self.runs.cap().get() == self.runs.len()
     }
     pub fn len(&self) -> usize {
         self.runs.len()
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/workflow/wft_poller.rs`

 * *Files 4% similar despite different names*

```diff
@@ -43,18 +43,15 @@
 
 pub(crate) fn validate_wft(
     wft: PollWorkflowTaskQueueResponse,
 ) -> Result<ValidPollWFTQResponse, tonic::Status> {
     wft.try_into().map_err(|resp| {
         tonic::Status::new(
             tonic::Code::DataLoss,
-            format!(
-                "Server returned a poll WFT response we couldn't interpret: {:?}",
-                resp
-            ),
+            format!("Server returned a poll WFT response we couldn't interpret: {resp:?}"),
         )
     })
 }
 
 #[cfg(test)]
 mod tests {
     use super::*;
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/Cargo.toml`

 * *Files 11% similar despite different names*

```diff
@@ -11,18 +11,19 @@
 categories = ["development-tools"]
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 async-trait = "0.1"
 derive_builder = "0.12"
-opentelemetry = "0.18"
 prost-types = "0.11"
+serde = { version = "1.0", default_features = false, features = ["derive"] }
 serde_json = "1.0"
 thiserror = "1.0"
+tokio = "1.24"
 tonic = "0.8"
 tracing-core = "0.1"
 url = "2.3"
 
 [dependencies.temporal-sdk-core-protos]
 path = "../sdk-core-protos"
 version = "0.1"
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/errors.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/errors.rs`

 * *Files 20% similar despite different names*

```diff
@@ -1,14 +1,10 @@
 //! Error types exposed by public APIs
 
-use prost_types::TimestampError;
-use temporal_sdk_core_protos::coresdk::{
-    activity_result::ActivityExecutionResult,
-    workflow_activation::remove_from_cache::EvictionReason,
-};
+use temporal_sdk_core_protos::coresdk::activity_result::ActivityExecutionResult;
 
 /// Errors thrown by [crate::Worker::poll_workflow_activation]
 #[derive(thiserror::Error, Debug)]
 pub enum PollWfError {
     /// [crate::Worker::shutdown] was called, and there are no more replay tasks to be handled. Lang
     /// must call [crate::Worker::complete_workflow_activation] for any remaining tasks, and then may
     /// exit.
@@ -60,36 +56,7 @@
     MalformedActivityCompletion {
         /// Reason the completion was malformed
         reason: String,
         /// The completion, which may not be included to avoid unnecessary copies.
         completion: Option<ActivityExecutionResult>,
     },
 }
-
-/// Errors thrown inside of workflow machines
-#[derive(thiserror::Error, Debug)]
-pub enum WFMachinesError {
-    #[error("Nondeterminism error: {0}")]
-    Nondeterminism(String),
-    #[error("Fatal error in workflow machines: {0}")]
-    Fatal(String),
-
-    #[error("Unrecoverable network error while fetching history: {0}")]
-    HistoryFetchingError(tonic::Status),
-}
-
-impl WFMachinesError {
-    pub fn evict_reason(&self) -> EvictionReason {
-        match self {
-            WFMachinesError::Nondeterminism(_) => EvictionReason::Nondeterminism,
-            WFMachinesError::Fatal(_) | WFMachinesError::HistoryFetchingError(_) => {
-                EvictionReason::Fatal
-            }
-        }
-    }
-}
-
-impl From<TimestampError> for WFMachinesError {
-    fn from(_: TimestampError) -> Self {
-        Self::Fatal("Could not decode timestamp".to_string())
-    }
-}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/lib.rs`

 * *Files 6% similar despite different names*

```diff
@@ -41,21 +41,25 @@
     /// The returned activation is guaranteed to be for the same task queue / worker which was
     /// provided as the `task_queue` argument.
     ///
     /// It is rarely a good idea to call poll concurrently. It handles polling the server
     /// concurrently internally.
     async fn poll_activity_task(&self) -> Result<ActivityTask, PollActivityError>;
 
-    /// Tell the worker that a workflow activation has completed. May be freely called concurrently.
+    /// Tell the worker that a workflow activation has completed. May (and should) be freely called
+    /// concurrently. The future may take some time to resolve, as fetching more events might be
+    /// necessary for completion to... complete - thus SDK implementers should make sure they do
+    /// not serialize completions.
     async fn complete_workflow_activation(
         &self,
         completion: WorkflowActivationCompletion,
     ) -> Result<(), CompleteWfError>;
 
-    /// Tell the worker that an activity has finished executing. May be freely called concurrently.
+    /// Tell the worker that an activity has finished executing. May (and should) be freely called
+    /// concurrently.
     async fn complete_activity_task(
         &self,
         completion: ActivityTaskCompletion,
     ) -> Result<(), CompleteActivityError>;
 
     /// Notify the Temporal service that an activity is still alive. Long running activities that
     /// take longer than `activity_heartbeat_timeout` to finish must call this function in order to
@@ -89,21 +93,27 @@
     fn get_config(&self) -> &WorkerConfig;
 
     /// Initiate shutdown. See [Worker::shutdown], this is just a sync version that starts the
     /// process. You can then wait on `shutdown` or [Worker::finalize_shutdown].
     fn initiate_shutdown(&self);
 
     /// Initiates async shutdown procedure, eventually ceases all polling of the server and shuts
-    /// down this worker. [Worker::poll_workflow_activation] should be called until it
-    /// returns [PollWfError::ShutDown] to ensure that any workflows which are still undergoing
-    /// replay have an opportunity to finish. This means that the lang sdk will need to call
-    /// [Worker::complete_workflow_activation] for those workflows until they are done. At that point,
-    /// the lang SDK can end the process, or drop the [Worker] instance, which will close the
-    /// connection.
+    /// down this worker. [Worker::poll_workflow_activation] and [Worker::poll_activity_task] should
+    /// be called until both return a `ShutDown` error to ensure that all outstanding work is
+    /// complete. This means that the lang sdk will need to call
+    /// [Worker::complete_workflow_activation] and [Worker::complete_activity_task] for those
+    /// workflows & activities until they are done. At that point, the lang SDK can end the process,
+    /// or drop the [Worker] instance via [Worker::finalize_shutdown], which will close the
+    /// connection and free resources. If you have set [WorkerConfig::no_remote_activities], you may
+    /// skip calling [Worker::poll_activity_task].
+    ///
+    /// Lang implementations should use [Worker::initiate_shutdown] followed by
+    /// [Worker::finalize_shutdown].
     async fn shutdown(&self);
 
     /// Completes shutdown and frees all resources. You should avoid simply dropping workers, as
     /// this does not allow async tasks to report any panics that may have occurred cleanly.
     ///
-    /// This should be called only after [Worker::shutdown] has resolved.
+    /// This should be called only after [Worker::shutdown] has resolved and/or both polling
+    /// functions have returned `ShutDown` errors.
     async fn finalize_shutdown(self);
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/telemetry.rs`

 * *Files 5% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-use opentelemetry::metrics::Meter;
 use std::{
     collections::HashMap,
     net::SocketAddr,
     time::{Duration, SystemTime, UNIX_EPOCH},
 };
 use tracing_core::Level;
 use url::Url;
@@ -14,19 +13,14 @@
     /// with the user's desired logging library. Use this function to grab the most recent buffered
     /// logs since the last time it was called. A fixed number of such logs are retained at maximum,
     /// with the oldest being dropped when full.
     ///
     /// Returns the list of logs from oldest to newest. Returns an empty vec if the feature is not
     /// configured.
     fn fetch_buffered_logs(&self) -> Vec<CoreLog>;
-
-    /// If metrics gathering is enabled, returns the OTel meter for core telemetry, which can be
-    /// used to create metrics instruments, or passed to things that create/record metrics (ex:
-    /// clients).
-    fn get_metric_meter(&self) -> Option<&Meter>;
 }
 
 /// Telemetry configuration options. Construct with [TelemetryOptionsBuilder]
 #[derive(Debug, Clone, derive_builder::Builder)]
 #[non_exhaustive]
 pub struct TelemetryOptions {
     /// Optional trace exporter - set as None to disable.
@@ -43,14 +37,18 @@
     /// the prefix is consistent with other SDKs.
     #[builder(default)]
     pub no_temporal_prefix_for_metrics: bool,
 
     /// Specifies the aggregation temporality for metric export. Defaults to cumulative.
     #[builder(default = "MetricTemporality::Cumulative")]
     pub metric_temporality: MetricTemporality,
+
+    // A map of tags to be applied to all metrics
+    #[builder(default)]
+    pub global_tags: HashMap<String, String>,
 }
 
 /// Options for exporting to an OpenTelemetry Collector
 #[derive(Debug, Clone)]
 pub struct OtelCollectorOptions {
     /// The url of the OTel collector to export telemetry and metrics to. Lang SDK should also
     /// export to this same collector.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/core-api/src/worker.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core-api/src/worker.rs`

 * *Files 6% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 use std::time::Duration;
+use tokio::sync::mpsc::UnboundedSender;
 
 /// Defines per-worker configuration options
-#[derive(Debug, Clone, derive_builder::Builder)]
+#[derive(Debug, Clone, derive_builder::Builder, serde::Serialize, serde::Deserialize)]
 #[builder(setter(into), build_fn(validate = "Self::validate"))]
 #[non_exhaustive]
 pub struct WorkerConfig {
     /// The Temporal service namespace this worker is bound to
     pub namespace: String,
     /// What task queue will this worker poll from? This task queue name will be used for both
     /// workflow and activity polling.
@@ -101,14 +102,31 @@
     /// remaining work is pending evictions.
     ///
     /// This flag is useful during tests to avoid needing to deal with lots of uninteresting
     /// evictions during shutdown. Alternatively, if a lang implementation finds it easy to clean
     /// up during shutdown, setting this true saves some back-and-forth.
     #[builder(default = "false")]
     pub ignore_evicts_on_shutdown: bool,
+
+    /// Maximum number of next page (or initial) history event listing requests we'll make
+    /// concurrently. I don't this it's worth exposing this to users until we encounter a reason.
+    #[builder(default = "5")]
+    pub fetching_concurrency: usize,
+
+    /// If set, and the `save_wf_inputs` feature is enabled in core, will be sent a serialized
+    /// instance of every input to workflow state in order. This is for testing purposes, SDK
+    /// implementations never need to care about it.
+    #[builder(default)]
+    #[serde(skip)]
+    pub wf_state_inputs: Option<UnboundedSender<Vec<u8>>>,
+
+    /// If set, core will issue cancels for all outstanding activities after shutdown has been
+    /// initiated and this amount of time has elapsed.
+    #[builder(default)]
+    pub graceful_shutdown_period: Option<Duration>,
 }
 
 impl WorkerConfig {
     pub fn max_nonsticky_polls(&self) -> usize {
         ((self.max_concurrent_wft_polls as f32 * self.nonsticky_to_sticky_poll_ratio) as usize)
             .max(1)
     }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/etc/deps.svg` & `temporalio-1.2.0/temporalio/bridge/sdk-core/etc/deps.svg`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/etc/otel-collector-config.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/Cargo.toml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/src/lib.rs`

 * *Files 5% similar despite different names*

```diff
@@ -60,29 +60,29 @@
 /// impl DoorOpen {
 ///     fn on_door_closed(&self) -> CardReaderTransition<Locked> {
 ///         TransitionResult::ok(vec![], Locked {})
 ///     }
 /// }
 ///
 /// impl Locked {
-///     fn on_card_readable(&self, shared_dat: SharedState, data: CardData)
+///     fn on_card_readable(&self, shared_dat: &mut SharedState, data: CardData)
 ///       -> CardReaderTransition<ReadingCardOrLocked> {
-///         match shared_dat.last_id {
+///         match &shared_dat.last_id {
 ///             // Arbitrarily deny the same person entering twice in a row
-///             Some(d) if d == data => TransitionResult::ok(vec![], Locked {}.into()),
+///             Some(d) if d == &data => TransitionResult::ok(vec![], Locked {}.into()),
 ///             _ => {
 ///                 // Otherwise issue a processing command. This illustrates using the same handler
 ///                 // for different destinations
-///                 TransitionResult::ok_shared(
+///                 shared_dat.last_id = Some(data.clone());
+///                 TransitionResult::ok(
 ///                     vec![
 ///                         Commands::ProcessData(data.clone()),
 ///                         Commands::StartBlinkingLight,
 ///                     ],
-///                     ReadingCard { card_data: data.clone() }.into(),
-///                     SharedState { last_id: Some(data) }
+///                     ReadingCard { card_data: data }.into(),
 ///                 )
 ///             }
 ///         }
 ///     }
 /// }
 ///
 /// impl ReadingCard {
@@ -92,27 +92,27 @@
 ///     fn on_card_rejected(&self) -> CardReaderTransition<Locked> {
 ///         TransitionResult::ok(vec![Commands::StopBlinkingLight], Locked {})
 ///     }
 /// }
 ///
 /// # fn main() -> Result<(), Box<dyn std::error::Error>> {
 /// let crs = CardReaderState::Locked(Locked {});
-/// let mut cr = CardReader { state: crs, shared_state: SharedState { last_id: None } };
-/// let cmds = cr.on_event_mut(CardReaderEvents::CardReadable("badguy".to_string()))?;
+/// let mut cr = CardReader::from_parts(crs, SharedState { last_id: None });
+/// let cmds = cr.on_event(CardReaderEvents::CardReadable("badguy".to_string()))?;
 /// assert_eq!(cmds[0], Commands::ProcessData("badguy".to_string()));
 /// assert_eq!(cmds[1], Commands::StartBlinkingLight);
 ///
-/// let cmds = cr.on_event_mut(CardReaderEvents::CardRejected)?;
+/// let cmds = cr.on_event(CardReaderEvents::CardRejected)?;
 /// assert_eq!(cmds[0], Commands::StopBlinkingLight);
 ///
-/// let cmds = cr.on_event_mut(CardReaderEvents::CardReadable("goodguy".to_string()))?;
+/// let cmds = cr.on_event(CardReaderEvents::CardReadable("goodguy".to_string()))?;
 /// assert_eq!(cmds[0], Commands::ProcessData("goodguy".to_string()));
 /// assert_eq!(cmds[1], Commands::StartBlinkingLight);
 ///
-/// let cmds = cr.on_event_mut(CardReaderEvents::CardAccepted)?;
+/// let cmds = cr.on_event(CardReaderEvents::CardAccepted)?;
 /// assert_eq!(cmds[0], Commands::StopBlinkingLight);
 /// # Ok(())
 /// # }
 /// ```
 ///
 /// In the above example the first word is the name of the state machine, then after the comma the
 /// type (which you must define separately) of commands produced by the machine.
@@ -128,45 +128,48 @@
 /// The first transition can be interpreted as "If the machine is in the locked state, when a
 /// `CardReadable` event is seen, call `on_card_readable` (passing in `CardData`) and transition to
 /// the `ReadingCard` state.
 ///
 /// The macro will generate a few things:
 /// * A struct for the overall state machine, named with the provided name. Here:
 ///   ```text
-///   struct CardMachine {
-///       state: CardMachineState,
-///       shared_state: CardId,
+///   struct CardReader {
+///       state: CardReaderState,
+///       shared_state: SharedState,
 ///   }
 ///   ```
 /// * An enum with a variant for each state, named with the provided name + "State".
 ///   ```text
-///   enum CardMachineState {
+///   enum CardReaderState {
 ///       Locked(Locked),
 ///       ReadingCard(ReadingCard),
-///       Unlocked(Unlocked),
+///       DoorOpen(DoorOpen),
 ///   }
 ///   ```
 ///
 ///   You are expected to define a type for each state, to contain that state's data. If there is
 ///   no data, you can simply: `type StateName = ()`
 /// * For any instance of transitions with the same event/handler which transition to different
 ///   destination states (dynamic destinations), an enum named like `DestAOrDestBOrDestC` is
 ///   generated. This enum must be used as the destination "state" from those handlers.
 /// * An enum with a variant for each event. You are expected to define the type (if any) contained
 ///   in the event variant.
 ///   ```text
-///   enum CardMachineEvents {
-///     CardReadable(CardData)
+///   enum CardReaderEvents {
+///     DoorClosed,
+///     CardAccepted,
+///     CardRejected,
+///     CardReadable(CardData),
 ///   }
 ///   ```
 /// * An implementation of the [StateMachine](trait.StateMachine.html) trait for the generated state
-///   machine enum (in this case, `CardMachine`)
+///   machine enum (in this case, `CardReader`)
 /// * A type alias for a [TransitionResult](enum.TransitionResult.html) with the appropriate generic
 ///   parameters set for your machine. It is named as your machine with `Transition` appended. In
-///   this case, `CardMachineTransition`.
+///   this case, `CardReaderTransition`.
 #[proc_macro]
 pub fn fsm(input: TokenStream) -> TokenStream {
     let def: StateMachineDefinition = parse_macro_input!(input as StateMachineDefinition);
     def.codegen()
 }
 
 mod kw {
@@ -213,15 +216,15 @@
             input.parse_terminated(Transition::parse)?;
         let transitions: Vec<_> = transitions.into_iter().collect();
         // Check for and whine about any identical transitions. We do this here because preserving
         // the order transitions were defined in is important, so simply collecting to a set is
         // not ideal.
         let trans_set: HashSet<_> = transitions.iter().collect();
         if trans_set.len() != transitions.len() {
-            return Err(syn::Error::new(
+            return Err(Error::new(
                 input.span(),
                 "Duplicate transitions are not allowed!",
             ));
         }
         Ok(Self {
             visibility,
             name,
@@ -342,29 +345,29 @@
                 #[display(fmt=#statestr)]
                 #s(#s)
             }
         });
         let name = &self.name;
         let name_str = &self.name.to_string();
 
-        let transition_result_name = Ident::new(&format!("{}Transition", name), name.span());
+        let transition_result_name = Ident::new(&format!("{name}Transition"), name.span());
         let transition_type_alias = quote! {
             type #transition_result_name<Ds, Sm = #name> = TransitionResult<Sm, Ds>;
         };
 
-        let state_enum_name = Ident::new(&format!("{}State", name), name.span());
+        let state_enum_name = Ident::new(&format!("{name}State"), name.span());
         // If user has not defined any shared state, use the unit type.
         let shared_state_type = self
             .shared_state_type
             .clone()
             .unwrap_or_else(|| syn::parse_str("()").unwrap());
         let machine_struct = quote! {
             #[derive(Clone)]
             #visibility struct #name {
-                state: #state_enum_name,
+                state: ::core::option::Option<#state_enum_name>,
                 shared_state: #shared_state_type
             }
         };
         let states_enum = quote! {
             #[derive(::derive_more::From, Clone, ::derive_more::Display)]
             #visibility enum #state_enum_name {
                 #(#state_variants),*
@@ -386,15 +389,15 @@
                     }
                 }
             }
         };
 
         // Build the events enum
         let events: HashSet<Variant> = self.transitions.iter().map(|t| t.event.clone()).collect();
-        let events_enum_name = Ident::new(&format!("{}Events", name), name.span());
+        let events_enum_name = Ident::new(&format!("{name}Events"), name.span());
         let events: Vec<_> = events
             .into_iter()
             .map(|v| {
                 let vname = v.ident.to_string();
                 quote! {
                     #[display(fmt=#vname)]
                     #v
@@ -420,16 +423,26 @@
         }
         // Add any states without any transitions to the map
         for s in &states {
             if !statemap.contains_key(s) {
                 statemap.insert(s.clone(), vec![]);
             }
         }
+        let transition_result_transform = quote! {
+            match res.into_cmd_result() {
+                Ok((cmds, state)) => {
+                    self.state = Some(state);
+                    Ok(cmds)
+                }
+                Err(e) => Err(e)
+            }
+        };
         let mut multi_dest_enums = vec![];
         let state_branches: Vec<_> = statemap.into_iter().map(|(from, transitions)| {
+            let occupied_current_state = quote! { Some(#state_enum_name::#from(state_data)) };
             // Merge transition dest states with the same handler
             let transitions = merge_transition_dests(transitions);
             let event_branches = transitions
                 .into_iter()
                 .map(|ts| {
                     let ev_variant = &ts.event.ident;
                     if let Some(ts_fn) = ts.handler.clone() {
@@ -463,78 +476,88 @@
                                     #transition_result_name<#enum_ident>
                                 }
                             }
                         };
                         match ts.event.fields {
                             Fields::Unnamed(_) => {
                                 let arglist = if ts.mutates_shared {
-                                    quote! {self.shared_state, val}
+                                    quote! {&mut self.shared_state, val}
                                 } else {
                                     quote! {val}
                                 };
-                                quote_spanned! {span=>
+                                quote_spanned! { span =>
                                     #events_enum_name::#ev_variant(val) => {
                                         let res: #trans_type = state_data.#ts_fn(#arglist);
-                                        res.into_general()
+                                        #transition_result_transform
                                     }
                                 }
                             }
                             Fields::Unit => {
                                 let arglist = if ts.mutates_shared {
-                                    quote! {self.shared_state}
+                                    quote! {&mut self.shared_state}
                                 } else {
                                     quote! {}
                                 };
-                                quote_spanned! {span=>
+                                quote_spanned! { span =>
                                     #events_enum_name::#ev_variant => {
                                         let res: #trans_type = state_data.#ts_fn(#arglist);
-                                        res.into_general()
+                                        #transition_result_transform
                                     }
                                 }
                             }
                             Fields::Named(_) => unreachable!(),
                         }
                     } else {
                         // If events do not have a handler, attempt to construct the next state
                         // using `Default`.
                         if let [new_state] = ts.to.as_slice() {
                             let span = new_state.span();
-                            let default_trans = quote_spanned! {span=>
-                            TransitionResult::<_, #new_state>::from::<#from>(state_data).into_general()
-                        };
+                            let default_trans = quote_spanned! { span =>
+                            let res = TransitionResult::<Self, #new_state>::from::<#from>(state_data);
+                                #transition_result_transform
+                            };
                             let span = ts.event.span();
                             match ts.event.fields {
-                                Fields::Unnamed(_) => quote_spanned! {span=>
-                                #events_enum_name::#ev_variant(_val) => {
-                                    #default_trans
-                                }
-                            },
-                                Fields::Unit => quote_spanned! {span=>
-                                #events_enum_name::#ev_variant => {
-                                    #default_trans
-                                }
-                            },
+                                Fields::Unnamed(_) => quote_spanned! { span =>
+                                    #events_enum_name::#ev_variant(_val) => {
+                                        #default_trans
+                                    }
+                                },
+                                Fields::Unit => quote_spanned! { span =>
+                                    #events_enum_name::#ev_variant => {
+                                        #default_trans
+                                    }
+                                },
                                 Fields::Named(_) => unreachable!(),
                             }
-
                         } else {
-                            unreachable!("It should be impossible to have more than one dest state in no-handler transitions")
+                            unreachable!("It should be impossible to have more than one dest state \
+                                          in no-handler transitions")
                         }
                     }
                 })
-                // Since most states won't handle every possible event, return an error to that effect
+                // Since most states won't handle every possible event, return an error to that
+                // effect
                 .chain(std::iter::once(
-                    quote! { _ => { return TransitionResult::InvalidTransition } },
+                    quote! { _ => {
+                        // Restore state in event the transition doesn't match
+                        self.state = #occupied_current_state;
+                        return Err(::rustfsm::MachineError::InvalidTransition)
+                    } },
                 ));
             quote! {
-                #state_enum_name::#from(state_data) => match event {
+                #occupied_current_state => match event {
                     #(#event_branches),*
                 }
             }
-        }).collect();
+        }).chain(std::iter::once(
+            quote! {
+                None => Err(::rustfsm::MachineError::InvalidTransition)
+            }
+        )).collect();
 
         let viz_str = self.visualize();
 
         let trait_impl = quote! {
             impl ::rustfsm::StateMachine for #name {
                 type Error = #err_type;
                 type State = #state_enum_name;
@@ -542,39 +565,41 @@
                 type Event = #events_enum_name;
                 type Command = #cmd_type;
 
                 fn name(&self) -> &str {
                   #name_str
                 }
 
-                fn on_event(self, event: #events_enum_name)
-                  -> ::rustfsm::TransitionResult<Self, Self::State> {
-                    match self.state {
+                fn on_event(&mut self, event: #events_enum_name)
+                  -> ::core::result::Result<::std::vec::Vec<Self::Command>,
+                                            ::rustfsm::MachineError<Self::Error>> {
+                    let taken_state = self.state.take();
+                    match taken_state {
                         #(#state_branches),*
                     }
                 }
 
                 fn state(&self) -> &Self::State {
-                    &self.state
+                    self.state.as_ref().unwrap()
                 }
 
                 fn set_state(&mut self, new: Self::State) {
-                    self.state = new
+                    self.state = Some(new)
                 }
 
                 fn shared_state(&self) -> &Self::SharedState{
                     &self.shared_state
                 }
 
                 fn has_reached_final_state(&self) -> bool {
-                    self.state.is_final()
+                    self.state.as_ref().unwrap().is_final()
                 }
 
-                fn from_parts(shared: Self::SharedState, state: Self::State) -> Self {
-                    Self { shared_state: shared, state }
+                fn from_parts(state: Self::State, shared: Self::SharedState) -> Self {
+                    Self { shared_state: shared, state: Some(state) }
                 }
 
                 fn visualizer() -> &'static str {
                     #viz_str
                 }
             }
         };
@@ -612,19 +637,19 @@
                     .map(move |d| format!("{} --> {}: {}", t.from, d, t.event.ident))
             })
             // Add all final state transitions
             .chain(
                 self.all_states()
                     .iter()
                     .filter(|s| self.is_final_state(s))
-                    .map(|s| format!("{} --> [*]", s)),
+                    .map(|s| format!("{s} --> [*]")),
             )
             .collect();
         let transitions = transitions.join("\n");
-        format!("@startuml\n{}\n@enduml", transitions)
+        format!("@startuml\n{transitions}\n@enduml")
     }
 }
 
 /// Merge transition's dest state lists for those with the same from state & handler
 fn merge_transition_dests(transitions: Vec<Transition>) -> Vec<Transition> {
     let mut map = HashMap::<_, Transition>::new();
     for t in transitions {
@@ -639,9 +664,9 @@
                 e.get_mut().to.extend(t.to.into_iter());
             }
             Entry::Vacant(v) => {
                 v.insert(t);
             }
         }
     }
-    map.into_iter().map(|(_, v)| v).collect()
+    map.into_values().collect()
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/dynamic_dest_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_arg_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/handler_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/medium_complex_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/no_handle_conversions_require_into_fail.stderr`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_procmacro/tests/trybuild/simple_pass.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/fsm/rustfsm_trait/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin` & `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-23_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin` & `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/evict_while_la_running_no_interference-85_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin` & `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/fail_wf_task.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin` & `temporalio-1.2.0/temporalio/bridge/sdk-core/histories/timer_workflow_history.bin`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/.github/workflows/trigger-api-go-update.yml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/LICENSE`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/Makefile`

 * *Files 6% similar despite different names*

```diff
@@ -25,23 +25,23 @@
 PROTO_OUT := .gen
 PROTO_IMPORTS = -I=$(PROTO_ROOT) -I=$(shell go list -modfile build/go.mod -m -f '{{.Dir}}' github.com/temporalio/gogo-protobuf)/protobuf
 
 $(PROTO_OUT):
 	mkdir $(PROTO_OUT)
 
 ##### Compile proto files for go #####
-grpc: buf-lint api-linter buf-breaking gogo-grpc fix-path
+grpc: buf-lint api-linter gogo-grpc fix-path
 
 go-grpc: clean $(PROTO_OUT)
 	printf $(COLOR) "Compile for go-gRPC..."
 	$(foreach PROTO_DIR,$(PROTO_DIRS),protoc --fatal_warnings $(PROTO_IMPORTS) --go_out=plugins=grpc,paths=source_relative:$(PROTO_OUT) $(PROTO_DIR)*.proto;)
 
 gogo-grpc: clean $(PROTO_OUT)
 	printf $(COLOR) "Compile for gogo-gRPC..."
-	$(foreach PROTO_DIR,$(PROTO_DIRS),protoc --fatal_warnings $(PROTO_IMPORTS) --gogoslick_out=Mgoogle/protobuf/wrappers.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/duration.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/descriptor.proto=github.com/golang/protobuf/protoc-gen-go/descriptor,Mgoogle/protobuf/timestamp.proto=github.com/gogo/protobuf/types,plugins=grpc,paths=source_relative:$(PROTO_OUT) $(PROTO_DIR)*.proto;)
+	$(foreach PROTO_DIR,$(PROTO_DIRS),protoc --fatal_warnings $(PROTO_IMPORTS) --gogoslick_out=Mgoogle/protobuf/any.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/wrappers.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/duration.proto=github.com/gogo/protobuf/types,Mgoogle/protobuf/descriptor.proto=github.com/golang/protobuf/protoc-gen-go/descriptor,Mgoogle/protobuf/timestamp.proto=github.com/gogo/protobuf/types,plugins=grpc,paths=source_relative:$(PROTO_OUT) $(PROTO_DIR)*.proto;)
 
 fix-path:
 	mv -f $(PROTO_OUT)/temporal/api/* $(PROTO_OUT) && rm -rf $(PROTO_OUT)/temporal
 
 ##### Plugins & tools #####
 grpc-install: gogo-protobuf-install
 	printf $(COLOR) "Install/update gRPC plugins..."
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/api-linter.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/build/tools.go`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/dependencies/gogoproto/gogo.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/batch/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/command/v1/message.proto`

 * *Files 4% similar despite different names*

```diff
@@ -35,15 +35,14 @@
 
 import "dependencies/gogoproto/gogo.proto";
 
 import "temporal/api/enums/v1/workflow.proto";
 import "temporal/api/enums/v1/command_type.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/failure/v1/message.proto";
-import "temporal/api/interaction/v1/message.proto";
 import "temporal/api/taskqueue/v1/message.proto";
 
 message ScheduleActivityTaskCommandAttributes {
     string activity_id = 1;
     temporal.api.common.v1.ActivityType activity_type = 2;
     // This used to be a `namespace` field which allowed to schedule activity in another namespace.
     reserved 3;
@@ -217,27 +216,17 @@
     // Establish a cron schedule for the child workflow.
     string cron_schedule = 13;
     temporal.api.common.v1.Header header = 14;
     temporal.api.common.v1.Memo memo = 15;
     temporal.api.common.v1.SearchAttributes search_attributes = 16;
 }
 
-message AcceptWorkflowUpdateCommandAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.interaction.v1.Input input = 2;
-}
-
-message CompleteWorkflowUpdateCommandAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.interaction.v1.Output output = 2;
-}
-
-message RejectWorkflowUpdateCommandAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.failure.v1.Failure failure = 2;
+message ProtocolMessageCommandAttributes {
+    // The message ID of the message to which this command is a pointer.
+    string message_id = 1;
 }
 
 message Command {
     temporal.api.enums.v1.CommandType command_type = 1;
     oneof attributes {
         ScheduleActivityTaskCommandAttributes schedule_activity_task_command_attributes = 2;
         StartTimerCommandAttributes start_timer_command_attributes = 3;
@@ -248,13 +237,12 @@
         CancelWorkflowExecutionCommandAttributes cancel_workflow_execution_command_attributes = 8;
         RequestCancelExternalWorkflowExecutionCommandAttributes request_cancel_external_workflow_execution_command_attributes = 9;
         RecordMarkerCommandAttributes record_marker_command_attributes = 10;
         ContinueAsNewWorkflowExecutionCommandAttributes continue_as_new_workflow_execution_command_attributes = 11;
         StartChildWorkflowExecutionCommandAttributes start_child_workflow_execution_command_attributes = 12;
         SignalExternalWorkflowExecutionCommandAttributes signal_external_workflow_execution_command_attributes = 13;
         UpsertWorkflowSearchAttributesCommandAttributes upsert_workflow_search_attributes_command_attributes = 14;
-        AcceptWorkflowUpdateCommandAttributes accept_workflow_update_command_attributes = 15;
-        CompleteWorkflowUpdateCommandAttributes complete_workflow_update_command_attributes = 16;
+        ProtocolMessageCommandAttributes protocol_message_command_attributes = 15;
+        // 16 is available for use - it was used as part of a prototype that never made it into a release
         ModifyWorkflowPropertiesCommandAttributes modify_workflow_properties_command_attributes = 17;
-        RejectWorkflowUpdateCommandAttributes reject_workflow_update_command_attributes = 18;
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/common/v1/message.proto`

 * *Files 20% similar despite different names*

```diff
@@ -106,7 +106,35 @@
     // Maximum number of attempts. When exceeded the retries stop even if not expired yet.
     // 1 disables retries. 0 means unlimited (up to the timeouts)
     int32 maximum_attempts = 4;
     // Non-Retryable errors types. Will stop retrying if the error type matches this list. Note that
     // this is not a substring match, the error *type* (not message) must match exactly.
     repeated string non_retryable_error_types = 5;
 }
+
+// Metadata relevant for metering purposes
+message MeteringMetadata {
+    // Count of local activities which have begun an execution attempt during this workflow task,
+    // and whose first attempt occurred in some previous task. This is used for metering
+    // purposes, and does not affect workflow state.
+    //
+    // (-- api-linter: core::0141::forbidden-types=disabled
+    //     aip.dev/not-precedent: Negative values make no sense to represent. --)
+    uint32 nonfirst_local_activity_execution_attempts = 13;
+}
+
+// Identifies the version(s) of a worker that processed a task
+message WorkerVersionStamp {
+    // An opaque whole-worker identifier
+    string build_id = 1;
+    // Set if the worker used a dynamically loadable bundle to process
+    // the task. The bundle could be a WASM blob, JS bundle, etc.
+    string bundle_id = 2;
+}
+
+// Identifies the version(s) that a worker is compatible with when polling or identifying itself
+message WorkerVersionCapabilities {
+    // An opaque whole-worker identifier
+    string build_id = 1;
+
+    // Later, may include info like "I can process WASM and/or JS bundles"
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/batch_operation.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/command_type.proto`

 * *Files 13% similar despite different names*

```diff
@@ -43,15 +43,10 @@
     COMMAND_TYPE_CANCEL_WORKFLOW_EXECUTION = 7;
     COMMAND_TYPE_REQUEST_CANCEL_EXTERNAL_WORKFLOW_EXECUTION = 8;
     COMMAND_TYPE_RECORD_MARKER = 9;
     COMMAND_TYPE_CONTINUE_AS_NEW_WORKFLOW_EXECUTION = 10;
     COMMAND_TYPE_START_CHILD_WORKFLOW_EXECUTION = 11;
     COMMAND_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION = 12;
     COMMAND_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES = 13;
-    // Indicates that an update has been accepted for processing workflow code
-    COMMAND_TYPE_ACCEPT_WORKFLOW_UPDATE = 14;
-    // Indicates that an update has completed and carries either the success or
-    // failure outcome of said update.
-    COMMAND_TYPE_COMPLETE_WORKFLOW_UPDATE = 15;
+    COMMAND_TYPE_PROTOCOL_MESSAGE = 14;
     COMMAND_TYPE_MODIFY_WORKFLOW_PROPERTIES = 16;
-    COMMAND_TYPE_REJECT_WORKFLOW_UPDATE = 17;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/common.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/event_type.proto`

 * *Files 4% similar despite different names*

```diff
@@ -147,20 +147,20 @@
     // Temporal Server cannot Signal the targeted Workflow
     // Usually because the Workflow could not be found
     EVENT_TYPE_SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED = 38;
     // Temporal Server has successfully Signaled the targeted Workflow
     EVENT_TYPE_EXTERNAL_WORKFLOW_EXECUTION_SIGNALED = 39;
     // Workflow search attributes should be updated and synchronized with the visibility store
     EVENT_TYPE_UPSERT_WORKFLOW_SEARCH_ATTRIBUTES = 40;
-    // Workflow update request has been received
-    EVENT_TYPE_WORKFLOW_UPDATE_REJECTED = 41;
-    // Workflow update request has been accepted by user workflow code
-    EVENT_TYPE_WORKFLOW_UPDATE_ACCEPTED = 42;
-    // Workflow update has been completed
-    EVENT_TYPE_WORKFLOW_UPDATE_COMPLETED = 43;
+    // An update was accepted (i.e. validated)
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_ACCEPTED = 41;
+    // An update was rejected (i.e. failed validation)
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_REJECTED = 42;
+    // An update completed
+    EVENT_TYPE_WORKFLOW_EXECUTION_UPDATE_COMPLETED = 43;
     // Some property or properties of the workflow as a whole have changed by non-workflow code.
     // The distinction of external vs. command-based modification is important so the SDK can
     // maintain determinism when using the command-based approach.
     EVENT_TYPE_WORKFLOW_PROPERTIES_MODIFIED_EXTERNALLY = 44;
     // Some property or properties of an already-scheduled activity have changed by non-workflow code.
     // The distinction of external vs. command-based modification is important so the SDK can
     // maintain determinism when using the command-based approach.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/failed_cause.proto`

 * *Files 7% similar despite different names*

```diff
@@ -81,14 +81,19 @@
     WORKFLOW_TASK_FAILED_CAUSE_PENDING_ACTIVITIES_LIMIT_EXCEEDED = 27;
     // A workflow has a buffer of signals that have not yet reached their destination. We return this
     // error when sending a new signal would exceed the capacity of this buffer.
     WORKFLOW_TASK_FAILED_CAUSE_PENDING_SIGNALS_LIMIT_EXCEEDED = 28;
     // Similarly, we have a buffer of pending requests to cancel other workflows. We return this error
     // when our capacity for pending cancel requests is already reached.
     WORKFLOW_TASK_FAILED_CAUSE_PENDING_REQUEST_CANCEL_LIMIT_EXCEEDED = 29;
+    // Workflow execution update message (update.Acceptance, update.Rejection, or update.Response)
+    // has wrong format, or missing required fields.
+    WORKFLOW_TASK_FAILED_CAUSE_BAD_UPDATE_WORKFLOW_EXECUTION_MESSAGE = 30;
+    // Similar to WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_COMMAND, but for updates.
+    WORKFLOW_TASK_FAILED_CAUSE_UNHANDLED_UPDATE = 31;
 }
 
 enum StartChildWorkflowExecutionFailedCause {
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0;
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS = 1;
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2;
 }
@@ -99,14 +104,16 @@
     CANCEL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2;
 }
 
 enum SignalExternalWorkflowExecutionFailedCause {
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0;
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_EXTERNAL_WORKFLOW_EXECUTION_NOT_FOUND = 1;
     SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_NAMESPACE_NOT_FOUND = 2;
+    // Signal count limit is per workflow and controlled by server dynamic config "history.maximumSignalsPerExecution"
+    SIGNAL_EXTERNAL_WORKFLOW_EXECUTION_FAILED_CAUSE_SIGNAL_COUNT_LIMIT_EXCEEDED = 3;
 }
 
 enum ResourceExhaustedCause {
     RESOURCE_EXHAUSTED_CAUSE_UNSPECIFIED = 0;
     // Caller exceeds request per second limit.
     RESOURCE_EXHAUSTED_CAUSE_RPS_LIMIT = 1;
     // Caller exceeds max concurrent request limit.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/interaction_type.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto`

 * *Files 22% similar despite different names*

```diff
@@ -18,22 +18,42 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.enums.v1;
+package temporal.api.version.v1;
 
-option go_package = "go.temporal.io/api/enums/v1;enums";
-option java_package = "io.temporal.api.enums.v1";
+option go_package = "go.temporal.io/api/version/v1;version";
+option java_package = "io.temporal.api.version.v1";
 option java_multiple_files = true;
-option java_outer_classname = "InteractionTypeProto";
-option ruby_package = "Temporalio::Api::Enums::V1";
-option csharp_namespace = "Temporalio.Api.Enums.V1";
-
-enum InteractionType {
-   INTERACTION_TYPE_UNSPECIFIED = 0;
-   INTERACTION_TYPE_WORKFLOW_QUERY = 1;
-   INTERACTION_TYPE_WORKFLOW_UPDATE = 2;
-   INTERACTION_TYPE_WORKFLOW_SIGNAL = 3;
+option java_outer_classname = "MessageProto";
+option ruby_package = "Temporalio::Api::Version::V1";
+option csharp_namespace = "Temporalio.Api.Version.V1";
+
+import "google/protobuf/timestamp.proto";
+import "dependencies/gogoproto/gogo.proto";
+import "temporal/api/enums/v1/common.proto";
+
+// ReleaseInfo contains information about specific version of temporal.
+message ReleaseInfo {
+    string version = 1;
+    google.protobuf.Timestamp release_time = 2 [(gogoproto.stdtime) = true];
+    string notes = 3;
+}
+
+// Alert contains notification and severity.
+message Alert {
+    string message = 1;
+    temporal.api.enums.v1.Severity severity = 2;
 }
+
+// VersionInfo contains details about current and recommended release versions as well as alerts and upgrade instructions.
+message VersionInfo {
+    ReleaseInfo current = 1;
+    ReleaseInfo recommended = 2;
+    string instructions = 3;
+    repeated Alert alerts = 4;
+    google.protobuf.Timestamp last_update_time = 5 [(gogoproto.stdtime) = true];
+}
+
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/namespace.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/query.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/reset.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/schedule.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/task_queue.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/update.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt`

 * *Files 18% similar despite different names*

```diff
@@ -1,40 +1,23 @@
-// The MIT License
-//
-// Copyright (c) 2020 Temporal Technologies Inc.  All rights reserved.
-//
-// Permission is hereby granted, free of charge, to any person obtaining a copy
-// of this software and associated documentation files (the "Software"), to deal
-// in the Software without restriction, including without limitation the rights
-// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-// copies of the Software, and to permit persons to whom the Software is
-// furnished to do so, subject to the following conditions:
-//
-// The above copyright notice and this permission notice shall be included in
-// all copies or substantial portions of the Software.
-//
-// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-// THE SOFTWARE.
+Temporal Core SDK
 
-syntax = "proto3";
+The MIT License
 
-package temporal.api.enums.v1;
+Copyright (c) 2021 Temporal Technologies, Inc. All Rights Reserved
 
-option go_package = "go.temporal.io/api/enums/v1;enums";
-option java_package = "io.temporal.api.enums.v1";
-option java_multiple_files = true;
-option java_outer_classname = "UpdateProto";
-option ruby_package = "Temporalio::Api::Enums::V1";
-option csharp_namespace = "Temporalio.Api.Enums.V1";
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
 
-enum WorkflowUpdateResultAccessStyle {
-    WORKFLOW_UPDATE_RESULT_ACCESS_STYLE_UNSPECIFIED = 0;
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
 
-    // Indicates that the update response _must_ be included as part of the gRPC
-    // response body
-    WORKFLOW_UPDATE_RESULT_ACCESS_STYLE_REQUIRE_INLINE = 1;
-}
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/enums/v1/workflow.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/errordetails/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/failure/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/filter/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/history/v1/message.proto`

 * *Files 3% similar despite different names*

```diff
@@ -37,17 +37,18 @@
 import "dependencies/gogoproto/gogo.proto";
 
 import "temporal/api/enums/v1/event_type.proto";
 import "temporal/api/enums/v1/failed_cause.proto";
 import "temporal/api/enums/v1/workflow.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/failure/v1/message.proto";
-import "temporal/api/interaction/v1/message.proto";
 import "temporal/api/taskqueue/v1/message.proto";
+import "temporal/api/update/v1/message.proto";
 import "temporal/api/workflow/v1/message.proto";
+import "temporal/api/sdk/v1/task_complete_metadata.proto";
 
 // Always the first event in workflow history
 message WorkflowExecutionStartedEventAttributes {
     temporal.api.common.v1.WorkflowType workflow_type = 1;
     // If this workflow is a child, the namespace our parent lives in.
     // SDKs and UI tools should use `parent_workflow_namespace` field but server must use `parent_workflow_namespace_id` only.
     string parent_workflow_namespace = 2;
@@ -188,17 +189,23 @@
     int64 scheduled_event_id = 1;
     // The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to
     int64 started_event_id = 2;
     // Identity of the worker who completed this task
     string identity = 3;
     // Binary ID of the worker who completed this task
     string binary_checksum = 4;
-    // ID of the worker who picked up this workflow task, or missing if worker
-    // is not using versioning.
-    temporal.api.taskqueue.v1.VersionId worker_versioning_id = 5;
+    // Version info of the worker who processed this workflow task, or missing if worker is not
+    // using versioning. If present, the `build_id` field within is also used as `binary_checksum`,
+    // which may be omitted in that case (it may also be populated to preserve compatibility).
+    temporal.api.common.v1.WorkerVersionStamp worker_version = 5;
+    // Data the SDK wishes to record for itself, but server need not interpret, and does not
+    // directly impact workflow state.
+    temporal.api.sdk.v1.WorkflowTaskCompletedMetadata sdk_metadata = 6;
+    // Local usage data sent during workflow task completion and recorded here for posterity
+    temporal.api.common.v1.MeteringMetadata metering_metadata = 13;
 }
 
 message WorkflowTaskTimedOutEventAttributes {
     // The id of the `WORKFLOW_TASK_SCHEDULED` event this task corresponds to
     int64 scheduled_event_id = 1;
     // The id of the `WORKFLOW_TASK_STARTED` event this task corresponds to
     int64 started_event_id = 2;
@@ -399,14 +406,16 @@
     // Will be deserialized and provided as argument(s) to the signal handler
     temporal.api.common.v1.Payloads input = 2;
     // id of the worker/client who sent this signal
     string identity = 3;
     // Headers that were passed by the sender of the signal and copied by temporal 
     // server into the workflow task.
     temporal.api.common.v1.Header header = 4;
+    // Indicates the signal did not generate a new workflow task when received.
+    bool skip_generate_workflow_task = 5;
 }
 
 message WorkflowExecutionTerminatedEventAttributes {
     // User/client provided reason for termination
     string reason = 1;
     temporal.api.common.v1.Payloads details = 2;
     // id of the client who requested termination
@@ -643,29 +652,14 @@
     temporal.api.common.v1.WorkflowType workflow_type = 3;
     // Id of the `START_CHILD_WORKFLOW_EXECUTION_INITIATED` event which this event corresponds to
     int64 initiated_event_id = 4;
     // Id of the `CHILD_WORKFLOW_EXECUTION_STARTED` event which this event corresponds to
     int64 started_event_id = 5;
 }
 
-message WorkflowUpdateAcceptedEventAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.interaction.v1.Input input = 2;
-}
-
-message WorkflowUpdateCompletedEventAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.interaction.v1.Output output = 2;
-}
-
-message WorkflowUpdateRejectedEventAttributes {
-    temporal.api.interaction.v1.Meta meta = 1;
-    temporal.api.failure.v1.Failure failure = 2;
-}
-
 message WorkflowPropertiesModifiedExternallyEventAttributes {
     // If set to a nonempty string, future workflow tasks for this workflow shall be dispatched on
     // the provided queue.
     string new_task_queue = 1;
     // If set, update the workflow task timeout to this value.
     google.protobuf.Duration new_workflow_task_timeout = 2 [(gogoproto.stdduration) = true];
     // If set, update the workflow run timeout to this value. May be set to 0 for no timeout.
@@ -682,14 +676,52 @@
     // The id of the `ACTIVITY_TASK_SCHEDULED` event this modification corresponds to.
     int64 scheduled_event_id = 1;
     // If set, update the retry policy of the activity, replacing it with the specified one.
     // The number of attempts at the activity is preserved.
     temporal.api.common.v1.RetryPolicy new_retry_policy = 2;
 }
 
+message WorkflowExecutionUpdateAcceptedEventAttributes {
+    // The instance ID of the update protocol that generated this event.
+    string protocol_instance_id = 1;
+    // The message ID of the original request message that initiated this
+    // update. Needed so that the worker can recreate and deliver that same
+    // message as part of replay.
+    string accepted_request_message_id = 2;
+    // The event ID used to sequence the original request message.
+    int64 accepted_request_sequencing_event_id = 3;
+    // The message payload of the original request message that initiated this
+    // update.
+    temporal.api.update.v1.Request accepted_request = 4;
+}
+
+message WorkflowExecutionUpdateCompletedEventAttributes {
+    // The metadata about this update.
+    temporal.api.update.v1.Meta meta = 1;
+    // The outcome of executing the workflow update function.
+    temporal.api.update.v1.Outcome outcome = 2;
+}
+
+message WorkflowExecutionUpdateRejectedEventAttributes {
+    // The instance ID of the update protocol that generated this event.
+    string protocol_instance_id = 1;
+    // The message ID of the original request message that initiated this
+    // update. Needed so that the worker can recreate and deliver that same
+    // message as part of replay.
+    string rejected_request_message_id = 2;
+    // The event ID used to sequence the original request message.
+    int64 rejected_request_sequencing_event_id = 3;
+    // The message payload of the original request message that initiated this
+    // update.
+    temporal.api.update.v1.Request rejected_request = 4;
+    // The cause of rejection.
+    temporal.api.failure.v1.Failure failure = 5;
+}
+
+
 // History events are the method by which Temporal SDKs advance (or recreate) workflow state.
 // See the `EventType` enum for more info about what each event is for.
 message HistoryEvent {
     // Monotonically increasing event number, starts at 1.
     int64 event_id = 1;
     google.protobuf.Timestamp event_time = 2 [(gogoproto.stdtime) = true];
     temporal.api.enums.v1.EventType event_type = 3;
@@ -740,17 +772,17 @@
         ChildWorkflowExecutionCanceledEventAttributes child_workflow_execution_canceled_event_attributes = 39;
         ChildWorkflowExecutionTimedOutEventAttributes child_workflow_execution_timed_out_event_attributes = 40;
         ChildWorkflowExecutionTerminatedEventAttributes child_workflow_execution_terminated_event_attributes = 41;
         SignalExternalWorkflowExecutionInitiatedEventAttributes signal_external_workflow_execution_initiated_event_attributes = 42;
         SignalExternalWorkflowExecutionFailedEventAttributes signal_external_workflow_execution_failed_event_attributes = 43;
         ExternalWorkflowExecutionSignaledEventAttributes external_workflow_execution_signaled_event_attributes = 44;
         UpsertWorkflowSearchAttributesEventAttributes upsert_workflow_search_attributes_event_attributes = 45;
-        WorkflowUpdateRejectedEventAttributes workflow_update_rejected_event_attributes = 46;
-        WorkflowUpdateAcceptedEventAttributes workflow_update_accepted_event_attributes = 47;
-        WorkflowUpdateCompletedEventAttributes workflow_update_completed_event_attributes = 48;
+        WorkflowExecutionUpdateAcceptedEventAttributes workflow_execution_update_accepted_event_attributes = 46;
+        WorkflowExecutionUpdateRejectedEventAttributes workflow_execution_update_rejected_event_attributes = 47;
+        WorkflowExecutionUpdateCompletedEventAttributes workflow_execution_update_completed_event_attributes = 48;
         WorkflowPropertiesModifiedExternallyEventAttributes workflow_properties_modified_externally_event_attributes = 49;
         ActivityPropertiesModifiedExternallyEventAttributes activity_properties_modified_externally_event_attributes = 50;
         WorkflowPropertiesModifiedEventAttributes workflow_properties_modified_event_attributes = 51;
     }
 }
 
 message History {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/interaction/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto`

 * *Files 18% similar despite different names*

```diff
@@ -18,70 +18,44 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.interaction.v1;
+package temporal.api.query.v1;
 
-option go_package = "go.temporal.io/api/interaction/v1;interaction";
-option java_package = "io.temporal.api.interaction.v1";
+option go_package = "go.temporal.io/api/query/v1;query";
+option java_package = "io.temporal.api.query.v1";
 option java_multiple_files = true;
 option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Interaction::V1";
-option csharp_namespace = "Temporalio.Api.Interaction.V1";
+option ruby_package = "Temporalio::Api::Query::V1";
+option csharp_namespace = "Temporalio.Api.Query.V1";
 
+import "temporal/api/enums/v1/query.proto";
+import "temporal/api/enums/v1/workflow.proto";
 import "temporal/api/common/v1/message.proto";
-import "temporal/api/failure/v1/message.proto";
-import "temporal/api/enums/v1/interaction_type.proto";
 
-// Meta carries metadata about an interaction for use by the system (i.e. not
-// generall user-visible)
-message Meta {
-    // An ID with workflow-scoped uniqueness for this interaction
-    string id = 1;
-
-    // The event ID after which this interaction can execute. The effects of
-    // history up to and including this event ID should be visible to the
-    // interaction when it executes.
-    int64 event_id = 2;
-
-    // The type of this interaction.
-    temporal.api.enums.v1.InteractionType interaction_type = 3;
-
-    // A string identifying the agent that requested this interaction.
-    string identity = 4;
-
-    string request_id = 5;
-}
-
-// Input carries interaction input that comes from the caller.
-message Input {
-    // Headers that are passed with the interaction to and from the processing workflow.
-    // These can include things like auth or tracing tokens.
-    temporal.api.common.v1.Header header = 1;
-
-    // The name of the input handler to invoke on the target workflow
-    string name = 2;
-
-    // The arguments to pass to the named handler.
-    temporal.api.common.v1.Payloads args = 3;
+// See https://docs.temporal.io/docs/concepts/queries/
+message WorkflowQuery {
+    // The workflow-author-defined identifier of the query. Typically a function name.
+    string query_type = 1;
+    // Serialized arguments that will be provided to the query handler.
+    temporal.api.common.v1.Payloads query_args = 2;
+    // Headers that were passed by the caller of the query and copied by temporal 
+    // server into the workflow task.
+    temporal.api.common.v1.Header header = 3;
 }
 
-
-// Output carries the output data from an interaction.
-message Output {
-    // Headers that are passed with the interaction to and from the processing workflow.
-    // These can include things like auth or tracing tokens.
-    temporal.api.common.v1.Header header = 1;
-
-    oneof result {
-        temporal.api.common.v1.Payloads success = 2;
-        temporal.api.failure.v1.Failure failure = 3;
-    }
+// Answer to a `WorkflowQuery`
+message WorkflowQueryResult {
+    // Did the query succeed or fail?
+    temporal.api.enums.v1.QueryResultType result_type = 1;
+    // Set when the query succeeds with the results
+    temporal.api.common.v1.Payloads answer = 2;
+    // Mutually exclusive with `answer`. Set when the query fails.
+    string error_message = 3;
 }
 
-message Invocation {
-    Meta meta = 1;
-    Input input = 2;
+message QueryRejected {
+    temporal.api.enums.v1.WorkflowExecutionStatus status = 1;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/namespace/v1/message.proto`

 * *Files 2% similar despite different names*

```diff
@@ -58,14 +58,16 @@
     BadBinaries bad_binaries = 2;
     // If unspecified (ARCHIVAL_STATE_UNSPECIFIED) then default server configuration is used.
     temporal.api.enums.v1.ArchivalState history_archival_state = 3;
     string history_archival_uri = 4;
     // If unspecified (ARCHIVAL_STATE_UNSPECIFIED) then default server configuration is used.
     temporal.api.enums.v1.ArchivalState visibility_archival_state = 5;
     string visibility_archival_uri = 6;
+    // Map from field name to alias.
+    map<string, string> custom_search_attribute_aliases = 7;
 }
 
 message BadBinaries {
     map<string, BadBinaryInfo> binaries = 1;
 }
 
 message BadBinaryInfo {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/request_response.proto`

 * *Files 8% similar despite different names*

```diff
@@ -34,28 +34,31 @@
 import "temporal/api/enums/v1/common.proto";
 
 // (-- Search Attribute --)
 
 message AddSearchAttributesRequest {
     // Mapping between search attribute name and its IndexedValueType.
     map<string, temporal.api.enums.v1.IndexedValueType> search_attributes = 1;
+    string namespace = 2;
 }
 
 message AddSearchAttributesResponse {
 }
 
 message RemoveSearchAttributesRequest {
     // Search attribute names to delete.
     repeated string search_attributes = 1;
+    string namespace = 2;
 }
 
 message RemoveSearchAttributesResponse {
 }
 
 message ListSearchAttributesRequest {
+    string namespace = 1;
 }
 
 message ListSearchAttributesResponse {
     // Mapping between custom (user-registered) search attribute name to its IndexedValueType.
     map<string, temporal.api.enums.v1.IndexedValueType> custom_attributes = 1;
     // Mapping between system (predefined) search attribute name to its IndexedValueType.
     map<string, temporal.api.enums.v1.IndexedValueType> system_attributes = 2;
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/service.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/query/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto`

 * *Files 22% similar despite different names*

```diff
@@ -18,44 +18,38 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.query.v1;
+package temporal.api.replication.v1;
 
-option go_package = "go.temporal.io/api/query/v1;query";
-option java_package = "io.temporal.api.query.v1";
+option go_package = "go.temporal.io/api/replication/v1;replication";
+option java_package = "io.temporal.api.replication.v1";
 option java_multiple_files = true;
 option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Query::V1";
-option csharp_namespace = "Temporalio.Api.Query.V1";
+option ruby_package = "Temporalio::Api::Replication::V1";
+option csharp_namespace = "Temporalio.Api.Replication.V1";
 
-import "temporal/api/enums/v1/query.proto";
-import "temporal/api/enums/v1/workflow.proto";
-import "temporal/api/common/v1/message.proto";
-
-// See https://docs.temporal.io/docs/concepts/queries/
-message WorkflowQuery {
-    // The workflow-author-defined identifier of the query. Typically a function name.
-    string query_type = 1;
-    // Serialized arguments that will be provided to the query handler.
-    temporal.api.common.v1.Payloads query_args = 2;
-    // Headers that were passed by the caller of the query and copied by temporal 
-    // server into the workflow task.
-    temporal.api.common.v1.Header header = 3;
+import "google/protobuf/timestamp.proto";
+
+import "dependencies/gogoproto/gogo.proto";
+
+import "temporal/api/enums/v1/namespace.proto";
+
+message ClusterReplicationConfig {
+    string cluster_name = 1;
 }
 
-// Answer to a `WorkflowQuery`
-message WorkflowQueryResult {
-    // Did the query succeed or fail?
-    temporal.api.enums.v1.QueryResultType result_type = 1;
-    // Set when the query succeeds with the results
-    temporal.api.common.v1.Payloads answer = 2;
-    // Mutually exclusive with `answer`. Set when the query fails.
-    string error_message = 3;
+message NamespaceReplicationConfig {
+    string active_cluster_name = 1;
+    repeated ClusterReplicationConfig clusters = 2;
+    temporal.api.enums.v1.ReplicationState state = 3;
 }
 
-message QueryRejected {
-    temporal.api.enums.v1.WorkflowExecutionStatus status = 1;
+// Represents a historical replication status of a Namespace
+message FailoverStatus {
+    // Timestamp when the Cluster switched to the following failover_version
+    google.protobuf.Timestamp failover_time = 1 [(gogoproto.stdtime) = true];
+    int64 failover_version = 2;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/replication/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/request_response.proto`

 * *Files 23% similar despite different names*

```diff
@@ -18,38 +18,46 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.replication.v1;
+package temporal.api.testservice.v1;
 
-option go_package = "go.temporal.io/api/replication/v1;replication";
-option java_package = "io.temporal.api.replication.v1";
+option go_package = "go.temporal.io/api/testservice/v1;testservice";
+option java_package = "io.temporal.api.testservice.v1";
 option java_multiple_files = true;
-option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Replication::V1";
-option csharp_namespace = "Temporalio.Api.Replication.V1";
+option java_outer_classname = "RequestResponseProto";
+option ruby_package = "Temporalio::Api::TestService::V1";
+option csharp_namespace = "Temporalio.Api.TestService.V1";
 
+import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
-
 import "dependencies/gogoproto/gogo.proto";
 
-import "temporal/api/enums/v1/namespace.proto";
+message LockTimeSkippingRequest {
+}
 
-message ClusterReplicationConfig {
-    string cluster_name = 1;
+message LockTimeSkippingResponse {
 }
 
-message NamespaceReplicationConfig {
-    string active_cluster_name = 1;
-    repeated ClusterReplicationConfig clusters = 2;
-    temporal.api.enums.v1.ReplicationState state = 3;
+message UnlockTimeSkippingRequest {
 }
 
-// Represents a historical replication status of a Namespace
-message FailoverStatus {
-    // Timestamp when the Cluster switched to the following failover_version
-    google.protobuf.Timestamp failover_time = 1 [(gogoproto.stdtime) = true];
-    int64 failover_version = 2;
+message UnlockTimeSkippingResponse {
 }
+
+message SleepUntilRequest {
+    google.protobuf.Timestamp timestamp = 1 [(gogoproto.stdtime) = true];
+}
+
+message SleepRequest {
+    google.protobuf.Duration duration = 1 [(gogoproto.stdduration) = true];
+}
+
+message SleepResponse {
+}
+
+message GetCurrentTimeResponse {
+    google.protobuf.Timestamp time = 1 [(gogoproto.stdtime) = true];
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/schedule/v1/message.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/message.proto`

 * *Files 11% similar despite different names*

```diff
@@ -34,14 +34,15 @@
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 import "google/protobuf/wrappers.proto";
 
 import "dependencies/gogoproto/gogo.proto";
 
 import "temporal/api/enums/v1/task_queue.proto";
+import "temporal/api/common/v1/message.proto";
 
 // See https://docs.temporal.io/docs/concepts/task-queues/
 message TaskQueue {
     string name = 1;
     // Default: TASK_QUEUE_KIND_NORMAL.
     temporal.api.enums.v1.TaskQueueKind kind = 2;
 }
@@ -67,42 +68,31 @@
 
 message TaskQueuePartitionMetadata {
     string key = 1;
     string owner_host_name = 2;
 }
 
 message PollerInfo {
-    // Unix Nano
     google.protobuf.Timestamp last_access_time = 1 [(gogoproto.stdtime) = true];
     string identity = 2;
     double rate_per_second = 3;
-    // If a worker has specified an ID for use with the worker versioning feature while polling,
-    // that id must appear here.
-    VersionId worker_versioning_id = 4;
+    // If a worker has opted into the worker versioning feature while polling, its capabilities will
+    // appear here.
+    temporal.api.common.v1.WorkerVersionCapabilities worker_version_capabilities = 4;
 }
 
 message StickyExecutionAttributes {
     TaskQueue worker_task_queue = 1;
     // (-- api-linter: core::0140::prepositions=disabled
     //     aip.dev/not-precedent: "to" is used to indicate interval. --)
     google.protobuf.Duration schedule_to_start_timeout = 2 [(gogoproto.stdduration) = true];
 }
 
-// Used by the worker versioning APIs, represents a node in the version graph for a particular
-// task queue
-message VersionIdNode {
-    VersionId version = 1;
-    // A pointer to the previous version this version is considered to be compatible with
-    VersionIdNode previous_compatible = 2;
-    // A pointer to the last incompatible version (previous major version)
-    VersionIdNode previous_incompatible = 3;
-}
-
-// Used by the worker versioning APIs, represents a specific version of something
-// Currently, that's just a whole-worker id. In the future, if we support
-// WASM workflow bundle based versioning, for example, then the inside of this
-// message may become a oneof of different version types.
-message VersionId {
-    // An opaque whole-worker identifier
-    string worker_build_id = 1;
+// Used by the worker versioning APIs, represents an ordering of one or more versions which are
+// considered to be compatible with each other. Currently the versions are always worker build ids.
+message CompatibleVersionSet {
+    // A unique identifier for this version set. Users don't need to understand or care about this
+    // value, but it has value for debugging purposes.
+    string version_set_id = 1;
+    // All the compatible versions, ordered from oldest to newest
+    repeated string build_ids = 2;
 }
-
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/version/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/protocol/v1/message.proto`

 * *Files 19% similar despite different names*

```diff
@@ -18,42 +18,40 @@
 // AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 // LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 // OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 // THE SOFTWARE.
 
 syntax = "proto3";
 
-package temporal.api.version.v1;
+package temporal.api.protocol.v1;
 
-option go_package = "go.temporal.io/api/version/v1;version";
-option java_package = "io.temporal.api.version.v1";
+option go_package = "go.temporal.io/api/protocol/v1;protocol";
+option java_package = "io.temporal.api.protocol.v1";
 option java_multiple_files = true;
 option java_outer_classname = "MessageProto";
-option ruby_package = "Temporalio::Api::Version::V1";
-option csharp_namespace = "Temporalio.Api.Version.V1";
+option ruby_package = "Temporalio::Api::Protocol::V1";
+option csharp_namespace = "Temporalio.Api.Protocol.V1";
 
-import "google/protobuf/timestamp.proto";
-import "dependencies/gogoproto/gogo.proto";
-import "temporal/api/enums/v1/common.proto";
-
-// ReleaseInfo contains information about specific version of temporal.
-message ReleaseInfo {
-    string version = 1;
-    google.protobuf.Timestamp release_time = 2 [(gogoproto.stdtime) = true];
-    string notes = 3;
-}
-
-// Alert contains notification and severity.
-message Alert {
-    string message = 1;
-    temporal.api.enums.v1.Severity severity = 2;
-}
+import "google/protobuf/any.proto";
 
-// VersionInfo contains details about current and recommended release versions as well as alerts and upgrade instructions.
-message VersionInfo {
-    ReleaseInfo current = 1;
-    ReleaseInfo recommended = 2;
-    string instructions = 3;
-    repeated Alert alerts = 4;
-    google.protobuf.Timestamp last_update_time = 5 [(gogoproto.stdtime) = true];
+// (-- api-linter: core::0146::any=disabled
+//     aip.dev/not-precedent: We want runtime extensibility for the body field --)
+message Message {
+    // An ID for this specific message.
+    string id = 1;
+
+    // Identifies the specific instance of a protocol to which this message
+    // belongs.
+    string protocol_instance_id = 2;
+
+    // The event ID or command ID after which this message can be delivered. The
+    // effects of history up to and including this event ID should be visible to
+    // the code that handles this message. Omit to opt out of sequencing.
+    oneof sequencing_id {
+        int64 event_id = 3;
+        int64 command_index = 4;
+    };
+    
+    // The opaque data carried by this message. The protocol type can be
+    // extracted from the package name of the message carried inside the Any.
+    google.protobuf.Any body = 5;
 }
-
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflow/v1/message.proto`

 * *Files 2% similar despite different names*

```diff
@@ -53,14 +53,16 @@
     google.protobuf.Timestamp execution_time = 9 [(gogoproto.stdtime) = true];
     temporal.api.common.v1.Memo memo = 10;
     temporal.api.common.v1.SearchAttributes search_attributes = 11;
     ResetPoints auto_reset_points = 12;
     string task_queue = 13;
     int64 state_transition_count = 14;
     int64 history_size_bytes = 15;
+    // If set, the most recent worker version stamp that appeared in a workflow task completion
+    temporal.api.common.v1.WorkerVersionStamp most_recent_worker_version_stamp = 16;
 }
 
 message WorkflowExecutionConfig {
     temporal.api.taskqueue.v1.TaskQueue task_queue = 1;
     google.protobuf.Duration workflow_execution_timeout = 2 [(gogoproto.stdduration) = true];
     google.protobuf.Duration workflow_run_timeout = 3 [(gogoproto.stdduration) = true];
     google.protobuf.Duration default_workflow_task_timeout = 4 [(gogoproto.stdduration) = true];
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/request_response.proto`

 * *Files 10% similar despite different names*

```diff
@@ -35,29 +35,30 @@
 import "temporal/api/enums/v1/workflow.proto";
 import "temporal/api/enums/v1/namespace.proto";
 import "temporal/api/enums/v1/failed_cause.proto";
 import "temporal/api/enums/v1/common.proto";
 import "temporal/api/enums/v1/query.proto";
 import "temporal/api/enums/v1/reset.proto";
 import "temporal/api/enums/v1/task_queue.proto";
-import "temporal/api/enums/v1/update.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/history/v1/message.proto";
-import "temporal/api/interaction/v1/message.proto";
 import "temporal/api/workflow/v1/message.proto";
 import "temporal/api/command/v1/message.proto";
 import "temporal/api/failure/v1/message.proto";
 import "temporal/api/filter/v1/message.proto";
+import "temporal/api/protocol/v1/message.proto";
 import "temporal/api/namespace/v1/message.proto";
 import "temporal/api/query/v1/message.proto";
 import "temporal/api/replication/v1/message.proto";
 import "temporal/api/schedule/v1/message.proto";
 import "temporal/api/taskqueue/v1/message.proto";
+import "temporal/api/update/v1/message.proto";
 import "temporal/api/version/v1/message.proto";
 import "temporal/api/batch/v1/message.proto";
+import "temporal/api/sdk/v1/task_complete_metadata.proto";
 
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 
 import "dependencies/gogoproto/gogo.proto";
 
 message RegisterNamespaceRequest {
@@ -164,18 +165,37 @@
     // The retry policy for the workflow. Will never exceed `workflow_execution_timeout`.
     temporal.api.common.v1.RetryPolicy retry_policy = 12;
     // See https://docs.temporal.io/docs/content/what-is-a-temporal-cron-job/
     string cron_schedule = 13;
     temporal.api.common.v1.Memo memo = 14;
     temporal.api.common.v1.SearchAttributes search_attributes = 15;
     temporal.api.common.v1.Header header = 16;
+    // Request to get the first workflow task inline in the response bypassing matching service and worker polling.
+    // If set to `true` the caller is expected to have a worker available and capable of processing the task.
+    // The returned task will be marked as started and is expected to be completed by the specified
+    // `workflow_task_timeout`.
+    bool request_eager_execution = 17;
+    // These values will be available as ContinuedFailure and LastCompletionResult in the
+    // WorkflowExecutionStarted event and through SDKs. The are currently only used by the
+    // server itself (for the schedules feature) and are not intended to be exposed in
+    // StartWorkflowExecution.
+    temporal.api.failure.v1.Failure continued_failure = 18;
+    temporal.api.common.v1.Payloads last_completion_result = 19;
+    // Time to wait before dispatching the first workflow task. Cannot be used with `cron_schedule`.
+    // If the workflow gets a signal before the delay, a workflow task will be dispatched and the rest
+    // of the delay will be ignored.
+    google.protobuf.Duration workflow_start_delay = 20 [(gogoproto.stdduration) = true];
 }
 
 message StartWorkflowExecutionResponse {
     string run_id = 1;
+    // When `request_eager_execution` is set on the `StartWorkflowExecutionRequest`, the server - if supported - will
+    // return the first workflow task to be eagerly executed.
+    // The caller is expected to have a worker available to process the task.
+    PollWorkflowTaskQueueResponse eager_workflow_task = 2;
 }
 
 message GetWorkflowExecutionHistoryRequest {
     string namespace = 1;
     temporal.api.common.v1.WorkflowExecution execution = 2;
     int32 maximum_page_size = 3;
     // If a `GetWorkflowExecutionHistoryResponse` or a `PollWorkflowTaskQueueResponse` had one of
@@ -217,20 +237,20 @@
     string namespace = 1;
     temporal.api.taskqueue.v1.TaskQueue task_queue = 2;
     // The identity of the worker/client who is polling this task queue
     string identity = 3;
     // Each worker process should provide an ID unique to the specific set of code it is running
     // "checksum" in this field name isn't very accurate, it should be though of as an id.
     string binary_checksum = 4;
-    // If set, the worker is opting in to build-id based versioning and wishes to only
-    // receive tasks that are considered compatible with the version provided.
-    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdOrdering` API.
-    // When `worker_versioning_id` has a `worker_build_id`, and `binary_checksum` is not
+    // If set, the worker is opting in to versioning and wishes to only
+    // receive tasks that are considered compatible with the version capabilities provided.
+    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
+    // When this field has a `worker_build_id`, and `binary_checksum` is not
     // set, that value should also be considered as the `binary_checksum`.
-    temporal.api.taskqueue.v1.VersionId worker_versioning_id = 5;
+    temporal.api.common.v1.WorkerVersionCapabilities worker_version_capabilities = 5;
 }
 
 message PollWorkflowTaskQueueResponse {
     // A unique identifier for this task
     bytes task_token = 1;
     temporal.api.common.v1.WorkflowExecution workflow_execution = 2;
     temporal.api.common.v1.WorkflowType workflow_type = 3;
@@ -263,16 +283,16 @@
     // When this task was scheduled by the server
     google.protobuf.Timestamp scheduled_time = 12 [(gogoproto.stdtime) = true];
     // When the current workflow task started event was generated, meaning the current attempt.
     google.protobuf.Timestamp started_time = 13 [(gogoproto.stdtime) = true];
     // Queries that should be executed after applying the history in this task. Responses should be
     // attached to `RespondWorkflowTaskCompletedRequest::query_results`
     map<string, temporal.api.query.v1.WorkflowQuery> queries = 14;
-
-    repeated temporal.api.interaction.v1.Invocation interactions = 15;
+    // Protocol messages piggybacking on a WFT as a transport
+    repeated temporal.api.protocol.v1.Message messages = 15;
 }
 
 message RespondWorkflowTaskCompletedRequest {
     // The task token as received in `PollWorkflowTaskQueueResponse`
     bytes task_token = 1;
     // A list of commands generated when driving the workflow code in response to the new task
     repeated temporal.api.command.v1.Command commands = 2;
@@ -290,19 +310,27 @@
     // which run for longer than the task timeout being the prime example.
     bool force_create_new_workflow_task = 6;
     // Worker process' unique binary id
     string binary_checksum = 7;
     // Responses to the `queries` field in the task being responded to
     map<string, temporal.api.query.v1.WorkflowQueryResult> query_results = 8;
     string namespace = 9;
-    // If using versioning, worker should send the same id here that it used to
-    // poll for the workflow task.
-    // When `worker_versioning_id` has a `worker_build_id`, and `binary_checksum` is not
-    // set, that value should also be considered as the `binary_checksum`.
-    temporal.api.taskqueue.v1.VersionId worker_versioning_id = 10;
+    // If using versioning, the worker uses this field to indicate what version(s) it used to
+    // process the task. When this field has a `worker_build_id`, and `binary_checksum` is not set,
+    // that value should also be considered as the `binary_checksum`. Leaving this field empty when
+    // replying to a task has had this field previously populated in history in an error, and such
+    // a completion will be rejected.
+    temporal.api.common.v1.WorkerVersionStamp worker_version_stamp = 10;
+    // Protocol messages piggybacking on a WFT as a transport
+    repeated temporal.api.protocol.v1.Message messages = 11;
+    // Data the SDK wishes to record for itself, but server need not interpret, and does not
+    // directly impact workflow state.
+    temporal.api.sdk.v1.WorkflowTaskCompletedMetadata sdk_metadata = 12;
+    // Local usage data collected for metering
+    temporal.api.common.v1.MeteringMetadata metering_metadata = 13;
 }
 
 message RespondWorkflowTaskCompletedResponse {
     // See `RespondWorkflowTaskCompletedResponse::return_new_workflow_task`
     PollWorkflowTaskQueueResponse workflow_task = 1;
     // See `ScheduleActivityTaskCommandAttributes::request_start`
     repeated PollActivityTaskQueueResponse activity_tasks = 2;
@@ -319,29 +347,31 @@
     // Failure details
     temporal.api.failure.v1.Failure failure = 3;
     // The identity of the worker/client
     string identity = 4;
     // Worker process' unique binary id
     string binary_checksum = 5;
     string namespace = 6;
+    // Protocol messages piggybacking on a WFT as a transport
+    repeated temporal.api.protocol.v1.Message messages = 7;
 }
 
 message RespondWorkflowTaskFailedResponse {
 }
 
 message PollActivityTaskQueueRequest {
     string namespace = 1;
     temporal.api.taskqueue.v1.TaskQueue task_queue = 2;
     // The identity of the worker/client
     string identity = 3;
     temporal.api.taskqueue.v1.TaskQueueMetadata task_queue_metadata = 4;
-    // If set, the worker is opting in to build-id based versioning and wishes to only
-    // receive tasks that are considered compatible with the version provided.
-    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdOrdering` API.
-    temporal.api.taskqueue.v1.VersionId worker_versioning_id = 5;
+    // If set, the worker is opting in to versioning and wishes to only
+    // receive tasks that are considered compatible with the capabilities provided.
+    // Doing so only makes sense in conjunction with the `UpdateWorkerBuildIdCompatibility` API.
+    temporal.api.common.v1.WorkerVersionCapabilities worker_version_capabilities = 5;
 }
 
 message PollActivityTaskQueueResponse {
     // A unique identifier for this task
     bytes task_token = 1;
     // The namespace the workflow which requested this activity lives in
     string workflow_namespace = 2;
@@ -558,14 +588,16 @@
     // Used to de-dupe sent signals
     string request_id = 6;
     // Deprecated
     string control = 7;
     // Headers that are passed with the signal to the processing workflow.
     // These can include things like auth or tracing tokens.
     temporal.api.common.v1.Header header = 8;
+    // Indicates that a new workflow task should not be generated when this signal is received.
+    bool skip_generate_workflow_task = 9;
 }
 
 message SignalWorkflowExecutionResponse {
 }
 
 message SignalWithStartWorkflowExecutionRequest {
     string namespace = 1;
@@ -595,14 +627,23 @@
     // Retry policy for the workflow Default: WORKFLOW_ID_REUSE_POLICY_ALLOW_DUPLICATE.
     temporal.api.common.v1.RetryPolicy retry_policy = 15;
     // See https://docs.temporal.io/docs/content/what-is-a-temporal-cron-job/
     string cron_schedule = 16;
     temporal.api.common.v1.Memo memo = 17;
     temporal.api.common.v1.SearchAttributes search_attributes = 18;
     temporal.api.common.v1.Header header = 19;
+    // Time to wait before dispatching the first workflow task. Cannot be used with `cron_schedule`.
+    // Note that the signal will be delivered with the first workflow task. If the workflow gets
+    // another SignalWithStartWorkflow before the delay and `skip_generate_workflow_task` is false
+    // or not set, a workflow task will be dispatched immediately and the rest of the delay period
+    // will be ignored, even if that request also had a delay. Signal via SignalWorkflowExecution
+    // will not unblock the workflow.
+    google.protobuf.Duration workflow_start_delay = 20 [(gogoproto.stdduration) = true];
+    // Indicates that a new workflow task should not be generated when this signal is received.
+    bool skip_generate_workflow_task = 21;
 }
 
 message SignalWithStartWorkflowExecutionResponse {
     string run_id = 1;
 }
 
 message ResetWorkflowExecutionRequest {
@@ -847,14 +888,21 @@
         // True if server supports dispatching Workflow and Activity tasks based on a worker's build_id
         // (see:
         // https://github.com/temporalio/proposals/blob/a123af3b559f43db16ea6dd31870bfb754c4dc5e/versioning/worker-versions.md)
         bool build_id_based_versioning = 6;
 
         // True if server supports upserting workflow memo
         bool upsert_memo = 7;
+
+        // True if server supports eager workflow task dispatching for the StartWorkflowExecution API
+        bool eager_workflow_start = 8;
+
+        // True if the server knows about the sdk metadata field on WFT completions and will record
+        // it in history
+        bool sdk_metadata = 9;
     }
 }
 
 message ListTaskQueuePartitionsRequest {
     string namespace = 1;
     temporal.api.taskqueue.v1.TaskQueue task_queue = 2;
 }
@@ -1002,104 +1050,162 @@
 
 message ListSchedulesResponse {
     repeated temporal.api.schedule.v1.ScheduleListEntry schedules = 1;
     bytes next_page_token = 2;
 }
 
 // (-- api-linter: core::0134::request-mask-required=disabled
-//     aip.dev/not-precedent: UpdateWorkerBuildIdOrderingRequest doesn't follow Google API format --)
+//     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibilityRequest doesn't follow Google API format --)
 // (-- api-linter: core::0134::request-resource-required=disabled
-//     aip.dev/not-precedent: UpdateWorkerBuildIdOrderingRequest RPC doesn't follow Google API format. --)
-message UpdateWorkerBuildIdOrderingRequest {
+//     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibilityRequest RPC doesn't follow Google API format. --)
+message UpdateWorkerBuildIdCompatibilityRequest {
+    message AddNewCompatibleVersion {
+        // A new id to be added to an existing compatible set.
+        string new_build_id = 1;
+        // A build id which must already exist in the version sets known by the task queue. The new
+        // id will be stored in the set containing this id, marking it as compatible with
+        // the versions within.
+        string existing_compatible_build_id = 2;
+        // When set, establishes the compatible set being targeted as the overall default for the
+        // queue. If a different set was the current default, the targeted set will replace it as
+        // the new default.
+        bool make_set_default = 3;
+    }
+
     string namespace = 1;
-    // Must be set, the task queue to apply changes to. Because all workers on
-    // a given task queue must have the same set of workflow & activity
-    // implementations, there is no reason to specify a task queue type here.
+    // Must be set, the task queue to apply changes to. Because all workers on a given task queue
+    // must have the same set of workflow & activity implementations, there is no reason to specify
+    // a task queue type here.
     string task_queue = 2;
-    // The version id we are targeting.
-    temporal.api.taskqueue.v1.VersionId version_id = 3;
-    // When set, indicates that the `version_id` in this message is compatible
-    // with the one specified in this field. Because compatability should form
-    // a DAG, any build id can only be the "next compatible" version for one
-    // other ID of a certain type at a time, and any setting which would create a cycle is invalid.
-    temporal.api.taskqueue.v1.VersionId previous_compatible = 4;
-    // When set, establishes the specified `version_id` as the default of it's type
-    // for the queue. Workers matching it will begin processing new workflow executions.
-    // The existing default will be marked as a previous incompatible version
-    // to this one, assuming it is not also in `is_compatible_with`.
-    bool become_default = 5;
+    oneof operation {
+        // A new build id. This operation will create a new set which will be the new overall
+        // default version for the queue, with this id as its only member. This new set is
+        // incompatible with all previous sets/versions.
+        //
+        // (-- api-linter: core::0140::prepositions=disabled
+        //     aip.dev/not-precedent: In makes perfect sense here. --)
+        string add_new_build_id_in_new_default_set = 3;
+        // Adds a new id to an existing compatible set, see sub-message definition for more.
+        AddNewCompatibleVersion add_new_compatible_build_id = 4;
+        // Promote an existing set to be the current default (if it isn't already) by targeting
+        // an existing build id within it. This field's value is the extant build id.
+        //
+        // (-- api-linter: core::0140::prepositions=disabled
+        //     aip.dev/not-precedent: Names are hard. --)
+        string promote_set_by_build_id = 5;
+        // Promote an existing build id within some set to be the current default for that set.
+        //
+        // (-- api-linter: core::0140::prepositions=disabled
+        //     aip.dev/not-precedent: Within makes perfect sense here. --)
+        string promote_build_id_within_set = 6;
+    }
+}
+message UpdateWorkerBuildIdCompatibilityResponse {
+    // The id of the compatible set that the updated version was added to, or exists in. Users don't
+    // need to understand or care about this value, but it has value for debugging purposes.
+    string version_set_id = 1;
 }
-message UpdateWorkerBuildIdOrderingResponse {}
 
 // (-- api-linter: core::0134::request-resource-required=disabled
-//     aip.dev/not-precedent: GetWorkerBuildIdOrderingRequest RPC doesn't follow Google API format. --)
-message GetWorkerBuildIdOrderingRequest {
+//     aip.dev/not-precedent: GetWorkerBuildIdCompatibilityRequest RPC doesn't follow Google API format. --)
+message GetWorkerBuildIdCompatibilityRequest {
     string namespace = 1;
-    // Must be set, the task queue to interrogate about worker id ordering
+    // Must be set, the task queue to interrogate about worker id compatibility.
     string task_queue = 2;
-    // Limits how deep the returned DAG will go. 1 will return only the
-    // default build id. A default/0 value will return the entire graph.
-    int32 max_depth = 3;
-}
-message GetWorkerBuildIdOrderingResponse {
-    // The currently established default version
-    temporal.api.taskqueue.v1.VersionIdNode current_default = 1;
-    // Other current latest-compatible versions who are not the overall default. These are the
-    // versions that will be used when generating new tasks by following the graph from the
-    // version of the last task out to a leaf.
-    repeated temporal.api.taskqueue.v1.VersionIdNode compatible_leaves = 2;
+    // Limits how many compatible sets will be returned. Specify 1 to only return the current
+    // default major version set. 0 returns all sets.
+    int32 max_sets = 3;
+    // If set, the response will include information about worker versions which are ready to be
+    // retired.
+    bool include_retirement_candidates = 4;
+    // If set, the response will include information about which versions have open workflows, and
+    // whether or not there are currently polling workers who are compatible with those versions.
+    bool include_poller_compatibility = 5;
+}
+message GetWorkerBuildIdCompatibilityResponse {
+    // Major version sets, in order from oldest to newest. The last element of the list will always
+    // be the current default major version. IE: New workflows will target the most recent version
+    // in that version set.
+    //
+    // There may be fewer sets returned than exist, if the request chose to limit this response.
+    repeated temporal.api.taskqueue.v1.CompatibleVersionSet major_version_sets = 1;
+
+    message RetirementCandidate {
+        // The worker build id which is ready for retirement
+        string build_id = 1;
+        // If true, there are no open *or* closed workflows, meaning there is no reason at all
+        // to keep the worker alive, not even to service queries on closed workflows. If not true,
+        // then there are no open workflows, but some closed ones.
+        bool all_workflows_are_archived = 2;
+        // Currently polling workers who match the build id ready for retirement
+        repeated temporal.api.taskqueue.v1.PollerInfo pollers = 3;
+    }
+
+    // A list of workers who are still live and polling the task queue, but may no longer be needed
+    // to make progress on open workflows.
+    repeated RetirementCandidate retirement_candidates = 2;
+
+    message VersionsWithCompatiblePollers {
+        // The latest build id which completed a workflow task on some open workflow
+        string most_recent_build_id = 1;
+        // Currently polling workers who are compatible with `most_recent_build_id`.
+        repeated temporal.api.taskqueue.v1.PollerInfo pollers = 2;
+    }
+
+    // A list of versions and pollers who are capable of processing tasks at that version (if any)
+    // for which there are currently open workflows.
+    repeated VersionsWithCompatiblePollers active_versions_and_pollers = 3;
 }
 
 // (-- api-linter: core::0134=disabled
 //     aip.dev/not-precedent: Update RPCs don't follow Google API format. --)
-message UpdateWorkflowRequest {
-    // A unique ID for this logical request
-    string request_id = 1;
-
-    // The manner in which the update result will be accessed.
-    // This field requires a non-default value; the default value of the enum
-    // will result in an error.
-    temporal.api.enums.v1.WorkflowUpdateResultAccessStyle result_access_style = 2;
-
+message UpdateWorkflowExecutionRequest {
     // The namespace name of the target workflow
-    string namespace = 3;
+    string namespace = 1;
     // The target workflow id and (optionally) a specific run thereof
     // (-- api-linter: core::0203::optional=disabled
     //     aip.dev/not-precedent: false positive triggered by the word "optional" --)
-    temporal.api.common.v1.WorkflowExecution workflow_execution = 4;
+    temporal.api.common.v1.WorkflowExecution workflow_execution = 2;
     // If set, this call will error if the most recent (if no run id is set on
     // `workflow_execution`), or specified (if it is) workflow execution is not
     // part of the same execution chain as this id.
-    string first_execution_run_id = 5;
+    string first_execution_run_id = 3;
 
-    // A string identifying the agent that requested this interaction.
-    string identity = 6;
+    // Describes when this request should return - basically whether the
+    // update is synchronous, asynchronous, or somewhere in between.
+    temporal.api.update.v1.WaitPolicy wait_policy = 4;
 
-    // The name under which the workflow update function is registered and the
-    // arguments to pass to said function.
-    temporal.api.interaction.v1.Input input = 7;
+    // The request information that will be delivered all the way down to the
+    // workflow execution.
+    temporal.api.update.v1.Request request = 5;
 }
 
-message UpdateWorkflowResponse {
-    // An opaque token that can be used to retrieve the update result via
-    // polling if it is not returned as part of the gRPC response
-    bytes update_token = 1;
-    // The success or failure status of the update
-    temporal.api.interaction.v1.Output output = 2;
+message UpdateWorkflowExecutionResponse {
+    // Enough information for subsequent poll calls if needed. Never null.
+    temporal.api.update.v1.UpdateRef update_ref = 1;
+
+    // The outcome of the update if and only if the workflow execution update
+    // has completed. If this response is being returned before the update has
+    // completed then this field will not be set.
+    temporal.api.update.v1.Outcome outcome = 2;
 }
 
 message StartBatchOperationRequest {
     // Namespace that contains the batch operation
     string namespace = 1;
-    // Visibility query defines the the group of workflow to do batch operation
+    // Visibility query defines the the group of workflow to apply the batch operation
+    // This field and Executions are mutually exclusive
     string visibility_query = 2;
     // Job ID defines the unique ID for the batch job
     string job_id = 3;
     // Reason to perform the batch operation
     string reason = 4;
+    // Executions to apply the batch operation
+    // This field and VisibilityQuery are mutually exclusive
+    repeated temporal.api.common.v1.WorkflowExecution executions = 5;
     // Operation input
     oneof operation {
         temporal.api.batch.v1.BatchOperationTermination termination_operation = 10;
         temporal.api.batch.v1.BatchOperationSignal signal_operation = 11;
         temporal.api.batch.v1.BatchOperationCancellation cancellation_operation = 12;
         temporal.api.batch.v1.BatchOperationDeletion deletion_operation = 13;
     }
@@ -1162,7 +1268,29 @@
 }
 
 message ListBatchOperationsResponse {
     // BatchOperationInfo contains the basic info about batch operation
     repeated temporal.api.batch.v1.BatchOperationInfo operation_info = 1;
     bytes next_page_token = 2;
 }
+
+message PollWorkflowExecutionUpdateRequest {
+    // The namespace of the workflow execution to which the update was
+    // originally issued.
+    string namespace = 1;
+    // The update reference returned in the initial
+    // UpdateWorkflowExecutionResponse
+    temporal.api.update.v1.UpdateRef update_ref = 2;
+    // The identity of the worker/client who is polling this update outcome
+    string identity = 3;
+    // Describes when this poll request should return a response
+    temporal.api.update.v1.WaitPolicy wait_policy = 4;
+}
+
+message PollWorkflowExecutionUpdateResponse {
+    // The outcome of the update if and only if the update has completed. If
+    // this response is being returned before the update has completed (e.g. due
+    // to the specification of a wait policy that only waits on
+    // UPDATE_WORKFLOW_EXECUTION_LIFECYCLE_STAGE_ACCEPTED) then this field will
+    // not be set.
+    temporal.api.update.v1.Outcome outcome = 1;
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/service.proto`

 * *Files 4% similar despite different names*

```diff
@@ -376,29 +376,40 @@
     rpc DeleteSchedule (DeleteScheduleRequest) returns (DeleteScheduleResponse) {
     }
 
     // List all schedules in a namespace.
     rpc ListSchedules (ListSchedulesRequest) returns (ListSchedulesResponse) {
     }
 
-    // Allows users to specify a graph of worker build id based versions on a
-    // per task queue basis. Versions are ordered, and may be either compatible
-    // with some extant version, or a new incompatible version.
+    // Allows users to specify sets of worker build id versions on a per task queue basis. Versions
+    // are ordered, and may be either compatible with some extant version, or a new incompatible
+    // version, forming sets of ids which are incompatible with each other, but whose contained
+    // members are compatible with one another.
+    //
     // (-- api-linter: core::0134::response-message-name=disabled
-    //     aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
+    //     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
     // (-- api-linter: core::0134::method-signature=disabled
-    //     aip.dev/not-precedent: UpdateWorkerBuildIdOrdering RPC doesn't follow Google API format. --)
-    rpc UpdateWorkerBuildIdOrdering (UpdateWorkerBuildIdOrderingRequest) returns (UpdateWorkerBuildIdOrderingResponse) {}
-    // Fetches the worker build id versioning graph for some task queue.
-    rpc GetWorkerBuildIdOrdering (GetWorkerBuildIdOrderingRequest) returns (GetWorkerBuildIdOrderingResponse) {}
+    //     aip.dev/not-precedent: UpdateWorkerBuildIdCompatibility RPC doesn't follow Google API format. --)
+    rpc UpdateWorkerBuildIdCompatibility (UpdateWorkerBuildIdCompatibilityRequest) returns (UpdateWorkerBuildIdCompatibilityResponse) {}
+    // Fetches the worker build id versioning sets for some task queue and related metadata.
+    rpc GetWorkerBuildIdCompatibility (GetWorkerBuildIdCompatibilityRequest) returns (GetWorkerBuildIdCompatibilityResponse) {}
 
     // Invokes the specified update function on user workflow code.
     // (-- api-linter: core::0134=disabled
-    //     aip.dev/not-precedent: UpdateWorkflow doesn't follow Google API format --)
-    rpc UpdateWorkflow(UpdateWorkflowRequest) returns (UpdateWorkflowResponse) {
+    //     aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
+    rpc UpdateWorkflowExecution(UpdateWorkflowExecutionRequest) returns (UpdateWorkflowExecutionResponse) {
+    }
+
+    // Polls a workflow execution for the outcome of a workflow execution update
+    // previously issued through the UpdateWorkflowExecution RPC. The effective
+    // timeout on this call will be shorter of the the caller-supplied gRPC
+    // timeout and the server's configured long-poll timeout.
+    // (-- api-linter: core::0134=disabled
+    //     aip.dev/not-precedent: UpdateWorkflowExecution doesn't follow Google API format --)
+    rpc PollWorkflowExecutionUpdate(PollWorkflowExecutionUpdateRequest) returns (PollWorkflowExecutionUpdateResponse){
     }
 
     // StartBatchOperation starts a new batch operation
     rpc StartBatchOperation(StartBatchOperationRequest) returns (StartBatchOperationResponse) {
     }
 
     // StopBatchOperation stops a batch operation
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/grpc/health/v1/health.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_result/activity_result.proto`

 * *Files 7% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 syntax = "proto3";
 
 package coresdk.activity_result;
+option ruby_package = "Temporalio::Bridge::Api::ActivityResult";
 
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/failure/v1/message.proto";
 
-/**
- * Used to report activity completions to core
- */
+// Used to report activity completions to core
 message ActivityExecutionResult {
     oneof status {
         Success completed = 1;
         Failure failed = 2;
         Cancellation cancelled = 3;
         WillCompleteAsync will_complete_async = 4;
     }
@@ -26,42 +25,42 @@
         Success completed = 1;
         Failure failed = 2;
         Cancellation cancelled = 3;
         DoBackoff backoff = 4;
     }
 }
 
-/** Used to report successful completion either when executing or resolving */
+// Used to report successful completion either when executing or resolving
 message Success {
     temporal.api.common.v1.Payload result = 1;
 }
 
-/** Used to report activity failure either when executing or resolving */
+// Used to report activity failure either when executing or resolving
 message Failure {
     temporal.api.failure.v1.Failure failure = 1;
 }
 
-/**
+/*
  * Used to report cancellation from both Core and Lang.
  * When Lang reports a cancelled activity, it must put a CancelledFailure in the failure field.
  * When Core reports a cancelled activity, it must put an ActivityFailure with CancelledFailure
  * as the cause in the failure field.
  */
 message Cancellation {
     temporal.api.failure.v1.Failure failure = 1;
 }
 
-/**
+/*
  * Used in ActivityExecutionResult to notify Core that this Activity will complete asynchronously.
  * Core will forget about this Activity and free up resources used to track this Activity.
  */
 message WillCompleteAsync {
 }
 
-/**
+/*
  * Issued when a local activity needs to retry but also wants to back off more than would be
  * reasonable to WFT heartbeat for. Lang is expected to schedule a timer for the duration
  * and then start a local activity of the same type & same inputs with the provided attempt number
  * after the timer has elapsed.
  *
  * This exists because Core does not have a concept of starting commands by itself, they originate
  * from lang. So expecting lang to start the timer / next pass of the activity fits more smoothly.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/activity_task/activity_task.proto`

 * *Files 12% similar despite different names*

```diff
@@ -1,26 +1,27 @@
 syntax = "proto3";
 
 /**
  * Definitions of the different activity tasks returned from [crate::Core::poll_task].
  */
 package coresdk.activity_task;
+option ruby_package = "Temporalio::Bridge::Api::ActivityTask";
 
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/sdk/core/common/common.proto";
 
 message ActivityTask {
-    /// A unique identifier for this task
+    // A unique identifier for this task
     bytes task_token = 1;
     oneof variant {
-        /// Start activity execution.
+        // Start activity execution.
         Start start = 3;
-        /// Attempt to cancel activity execution.
+        // Attempt to cancel activity execution.
         Cancel cancel = 4;
     }
 }
 
 // Begin executing an activity
 message Start {
     // The namespace the workflow lives in
@@ -58,22 +59,24 @@
     temporal.api.common.v1.RetryPolicy retry_policy = 16;
 
     // Set to true if this is a local activity. Note that heartbeating does not apply to local
     // activities.
     bool is_local = 17;
 }
 
-/// Attempt to cancel a running activity
+// Attempt to cancel a running activity
 message Cancel {
     ActivityCancelReason reason = 1;
 }
 
 enum ActivityCancelReason {
-    /// The activity no longer exists according to server (may be already completed)
+    // The activity no longer exists according to server (may be already completed)
     NOT_FOUND = 0;
-    /// Activity was explicitly cancelled
+    // Activity was explicitly cancelled
     CANCELLED = 1;
-    /// Activity timed out
+    // Activity timed out
     TIMED_OUT = 2;
+    // Core is shutting down and the graceful timeout has elapsed
+    WORKER_SHUTDOWN = 3;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/child_workflow/child_workflow.proto`

 * *Files 13% similar despite different names*

```diff
@@ -1,77 +1,66 @@
 syntax = "proto3";
 
 package coresdk.child_workflow;
+option ruby_package = "Temporalio::Bridge::Api::ChildWorkflow";
 
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/failure/v1/message.proto";
 import "temporal/sdk/core/common/common.proto";
 
-/**
- * Used by core to resolve child workflow executions.
- */
+// Used by core to resolve child workflow executions.
 message ChildWorkflowResult {
     oneof status {
         Success completed = 1;
         Failure failed = 2;
         Cancellation cancelled = 3;
     }
 }
 
-/**
- * Used in ChildWorkflowResult to report successful completion.
- */
+// Used in ChildWorkflowResult to report successful completion.
 message Success {
     temporal.api.common.v1.Payload result = 1;
 }
 
-/**
- * Used in ChildWorkflowResult to report non successful outcomes such as
- * application failures, timeouts, terminations, and cancellations.
- */
+// Used in ChildWorkflowResult to report non successful outcomes such as
+// application failures, timeouts, terminations, and cancellations.
 message Failure {
     temporal.api.failure.v1.Failure failure = 1;
 }
 
-/**
- * Used in ChildWorkflowResult to report cancellation.
- * Failure should be ChildWorkflowFailure with a CanceledFailure cause.
- */
+// Used in ChildWorkflowResult to report cancellation.
+// Failure should be ChildWorkflowFailure with a CanceledFailure cause.
 message Cancellation {
     temporal.api.failure.v1.Failure failure = 1;
 }
 
-/**
- * Used by the service to determine the fate of a child workflow
- * in case its parent is closed.
- */
+// Used by the service to determine the fate of a child workflow
+// in case its parent is closed.
 enum ParentClosePolicy {
-    /** Let's the server set the default. */
+    // Let's the server set the default.
     PARENT_CLOSE_POLICY_UNSPECIFIED = 0;
-    /** Terminate means terminating the child workflow. */
+    // Terminate means terminating the child workflow.
     PARENT_CLOSE_POLICY_TERMINATE = 1;
-    /** Abandon means not doing anything on the child workflow. */
+    // Abandon means not doing anything on the child workflow.
     PARENT_CLOSE_POLICY_ABANDON = 2;
-    /** Cancel means requesting cancellation on the child workflow. */
+    // Cancel means requesting cancellation on the child workflow.
     PARENT_CLOSE_POLICY_REQUEST_CANCEL = 3;
 }
 
-/** Possible causes of failure to start a child workflow */
+// Possible causes of failure to start a child workflow
 enum StartChildWorkflowExecutionFailedCause {
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_UNSPECIFIED = 0;
     START_CHILD_WORKFLOW_EXECUTION_FAILED_CAUSE_WORKFLOW_ALREADY_EXISTS = 1;
 }
 
-/**
- * Controls at which point to report back to lang when a child workflow is cancelled
- */
+// Controls at which point to report back to lang when a child workflow is cancelled
 enum ChildWorkflowCancellationType {
-    /** Do not request cancellation of the child workflow if already scheduled */
+    // Do not request cancellation of the child workflow if already scheduled
     ABANDON = 0;
-    /** Initiate a cancellation request and immediately report cancellation to the parent. */
+    // Initiate a cancellation request and immediately report cancellation to the parent.
     TRY_CANCEL = 1;
-    /** Wait for child cancellation completion. */
+    // Wait for child cancellation completion.
     WAIT_CANCELLATION_COMPLETED = 2;
-    /** Request cancellation of the child and wait for confirmation that the request was received. */
+    // Request cancellation of the child and wait for confirmation that the request was received.
     WAIT_CANCELLATION_REQUESTED = 3;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/core_interface.proto`

 * *Files 13% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 syntax = "proto3";
 
 package coresdk;
+option ruby_package = "Temporalio::Bridge::Api::CoreInterface";
 
 // Note: Intellij will think the Google imports don't work because of the slightly odd nature of
 // the include paths. You can make it work by going to the "Protobuf Support" settings section
 // and adding the "api_upstream" subdir as an include path.
 import "google/protobuf/duration.proto";
 import "google/protobuf/empty.proto";
 import "google/protobuf/timestamp.proto";
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/external_data/external_data.proto`

 * *Files 9% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 syntax = "proto3";
 
 package coresdk.external_data;
+option ruby_package = "Temporalio::Bridge::Api::ExternalData";
 
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 
 // This file defines data that Core might write externally. The first motivating case being
 // storing data in markers in event history. Defining such data as protos provides an easy way
 // for consumers which would like to just depend on the proto package to make sense of marker data.
@@ -23,8 +24,15 @@
   // If set, this local activity conceptually is retrying after the specified backoff.
   // Implementation wise, they are really two different LA machines, but with the same type & input.
   // The retry starts with an attempt number > 1.
   google.protobuf.Duration backoff = 6;
   // The time the LA was originally scheduled (wall clock time). This is used to track
   // schedule-to-close timeouts when timer-based backoffs are used
   google.protobuf.Timestamp original_schedule_time = 7;
+}
+
+message PatchedMarkerData {
+  // The patch id
+  string id = 1;
+  // Whether or not the patch is marked deprecated.
+  bool deprecated = 2;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_activation/workflow_activation.proto`

 * *Files 7% similar despite different names*

```diff
@@ -1,74 +1,79 @@
 syntax = "proto3";
 
 /**
  * Definitions of the different workflow activation jobs returned from [crate::Core::poll_task]. The
  * lang SDK applies these activation jobs to drive workflows.
  */
 package coresdk.workflow_activation;
+option ruby_package = "Temporalio::Bridge::Api::WorkflowActivation";
 
 import "google/protobuf/timestamp.proto";
 import "google/protobuf/duration.proto";
 import "temporal/api/failure/v1/message.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/enums/v1/workflow.proto";
 import "temporal/sdk/core/activity_result/activity_result.proto";
 import "temporal/sdk/core/child_workflow/child_workflow.proto";
 import "temporal/sdk/core/common/common.proto";
 
-/// An instruction to the lang sdk to run some workflow code, whether for the first time or from
-/// a cached state.
+// An instruction to the lang sdk to run some workflow code, whether for the first time or from
+// a cached state.
 message WorkflowActivation {
-    /// The id of the currently active run of the workflow. Also used as a cache key. There may
-    /// only ever be one active workflow task (and hence activation) of a run at one time.
+    // The id of the currently active run of the workflow. Also used as a cache key. There may
+    // only ever be one active workflow task (and hence activation) of a run at one time.
     string run_id = 1;
-    /// The current time as understood by the workflow, which is set by workflow task started events
+    // The current time as understood by the workflow, which is set by workflow task started events
     google.protobuf.Timestamp timestamp = 2;
-    /// Whether or not the activation is replaying past events
+    // Whether or not the activation is replaying past events
     bool is_replaying = 3;
-    /// Current history length as determined by the event id of the most recently processed event.
-    /// This ensures that the number is always deterministic
+    // Current history length as determined by the event id of the most recently processed event.
+    // This ensures that the number is always deterministic
     uint32 history_length = 4;
-    /// The things to do upon activating the workflow
+    // The things to do upon activating the workflow
     repeated WorkflowActivationJob jobs = 5;
+    // Internal flags which are available for use by lang. If `is_replaying` is false, all
+    // internal flags may be used. This is not a delta - all previously used flags always
+    // appear since this representation is cheap.
+    repeated uint32 available_internal_flags = 6;
 }
 
 message WorkflowActivationJob {
     oneof variant {
-        /// Begin a workflow for the first time
+        // Begin a workflow for the first time
         StartWorkflow start_workflow = 1;
-        /// A timer has fired, allowing whatever was waiting on it (if anything) to proceed
+        // A timer has fired, allowing whatever was waiting on it (if anything) to proceed
         FireTimer fire_timer = 2;
-        /// Workflow was reset. The randomness seed must be updated.
+        // Workflow was reset. The randomness seed must be updated.
         UpdateRandomSeed update_random_seed = 4;
-        /// A request to query the workflow was received.
+        // A request to query the workflow was received.
         QueryWorkflow query_workflow = 5;
-        /// A request to cancel the workflow was received.
+        // A request to cancel the workflow was received.
         CancelWorkflow cancel_workflow = 6;
-        /// A request to signal the workflow was received.
+        // A request to signal the workflow was received.
         SignalWorkflow signal_workflow = 7;
-        /// An activity was resolved, result could be completed, failed or cancelled
+        // An activity was resolved, result could be completed, failed or cancelled
         ResolveActivity resolve_activity = 8;
-        /// A patch marker has been detected and lang is being told that change exists. This
-        /// job is strange in that it is sent pre-emptively to lang without any corresponding
-        /// command being sent first.
+        // A patch marker has been detected and lang is being told that change exists. This
+        // job is strange in that it is sent pre-emptively to lang without any corresponding
+        // command being sent first.
         NotifyHasPatch notify_has_patch = 9;
-        /// A child workflow execution has started or failed to start
+        // A child workflow execution has started or failed to start
         ResolveChildWorkflowExecutionStart resolve_child_workflow_execution_start = 10;
-        /// A child workflow was resolved, result could be completed or failed
+        // A child workflow was resolved, result could be completed or failed
         ResolveChildWorkflowExecution resolve_child_workflow_execution = 11;
-        /// An attempt to signal an external workflow resolved
+        // An attempt to signal an external workflow resolved
         ResolveSignalExternalWorkflow resolve_signal_external_workflow = 12;
-        /// An attempt to cancel an external workflow resolved
+        // An attempt to cancel an external workflow resolved
         ResolveRequestCancelExternalWorkflow resolve_request_cancel_external_workflow = 13;
-        /// Remove the workflow identified by the [WorkflowActivation] containing this job from the cache
-        /// after performing the activation.
-        ///
-        /// If other job variant are present in the list, this variant will be the last job in the
-        /// job list. The string value is a reason for eviction.
+        // Remove the workflow identified by the [WorkflowActivation] containing this job from the cache
+        // after performing the activation.
+        //
+        // If other job variant are present in the list, this variant will be the last job in the
+        // job list. The string value is a reason for eviction.
         RemoveFromCache remove_from_cache = 50;
     }
 }
 
 // Start a new workflow
 message StartWorkflow {
     // The identifier the lang-specific sdk uses to execute workflow code
@@ -119,87 +124,87 @@
     temporal.api.common.v1.Memo memo = 21;
     // Search attributes created/updated when this workflow was started
     temporal.api.common.v1.SearchAttributes search_attributes = 22;
     // When the workflow execution started event was first written
     google.protobuf.Timestamp start_time = 23;
 }
 
-/// Notify a workflow that a timer has fired
+// Notify a workflow that a timer has fired
 message FireTimer {
-    /// Sequence number as provided by lang in the corresponding StartTimer command
+    // Sequence number as provided by lang in the corresponding StartTimer command
     uint32 seq = 1;
 }
 
-/// Notify a workflow that an activity has been resolved
+// Notify a workflow that an activity has been resolved
 message ResolveActivity {
-    /// Sequence number as provided by lang in the corresponding ScheduleActivity command
+    // Sequence number as provided by lang in the corresponding ScheduleActivity command
     uint32 seq = 1;
     activity_result.ActivityResolution result = 2;
 }
 
-/// Notify a workflow that a start child workflow execution request has succeeded, failed or was
-/// cancelled.
+// Notify a workflow that a start child workflow execution request has succeeded, failed or was
+// cancelled.
 message ResolveChildWorkflowExecutionStart {
-    /// Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command
+    // Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command
     uint32 seq = 1;
     oneof status {
         ResolveChildWorkflowExecutionStartSuccess succeeded = 2;
         ResolveChildWorkflowExecutionStartFailure failed = 3;
         ResolveChildWorkflowExecutionStartCancelled cancelled = 4;
     }
 }
 
-/// Simply pass the run_id to lang
+// Simply pass the run_id to lang
 message ResolveChildWorkflowExecutionStartSuccess {
     string run_id = 1;
 }
 
-/// Provide lang the cause of failure
+// Provide lang the cause of failure
 message ResolveChildWorkflowExecutionStartFailure {
-    /// Lang should have this information but it's more convenient to pass it back
-    /// for error construction on the lang side.
+    // Lang should have this information but it's more convenient to pass it back
+    // for error construction on the lang side.
     string workflow_id = 1;
     string workflow_type = 2;
     child_workflow.StartChildWorkflowExecutionFailedCause cause = 3;
 }
 
-/// `failure` should be ChildWorkflowFailure with cause set to CancelledFailure.
-/// The failure is constructed in core for lang's convenience.
+// `failure` should be ChildWorkflowFailure with cause set to CancelledFailure.
+// The failure is constructed in core for lang's convenience.
 message ResolveChildWorkflowExecutionStartCancelled {
   temporal.api.failure.v1.Failure failure = 1;
 }
 
-/// Notify a workflow that a child workflow execution has been resolved
+// Notify a workflow that a child workflow execution has been resolved
 message ResolveChildWorkflowExecution {
-    /// Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command
+    // Sequence number as provided by lang in the corresponding StartChildWorkflowExecution command
     uint32 seq = 1;
     child_workflow.ChildWorkflowResult result = 2;
 }
 
-/// Update the workflow's random seed
+// Update the workflow's random seed
 message UpdateRandomSeed {
     uint64 randomness_seed = 1;
 }
 
-/// Query a workflow
+// Query a workflow
 message QueryWorkflow {
-    /// For PollWFTResp `query` field, this will be set to the special value `legacy`. For the
-    /// `queries` field, the server provides a unique identifier. If it is a `legacy` query,
-    /// lang cannot issue any commands in response other than to answer the query.
+    // For PollWFTResp `query` field, this will be set to the special value `legacy`. For the
+    // `queries` field, the server provides a unique identifier. If it is a `legacy` query,
+    // lang cannot issue any commands in response other than to answer the query.
     string query_id = 1;
-    /// The query's function/method/etc name
+    // The query's function/method/etc name
     string query_type = 2;
     repeated temporal.api.common.v1.Payload arguments = 3;
-    /// Headers attached to the query
+    // Headers attached to the query
     map<string, temporal.api.common.v1.Payload> headers = 5;
 }
 
-/// Cancel a running workflow
+// Cancel a running workflow
 message CancelWorkflow {
-    /// Information from the cancellation request
+    // Information from the cancellation request
     repeated temporal.api.common.v1.Payload details = 1;
 }
 
 // Send a signal to a workflow
 message SignalWorkflow {
     string signal_name = 1;
     repeated temporal.api.common.v1.Payload input = 2;
@@ -212,28 +217,28 @@
 // Inform lang what the result of a call to `patched` or similar API should be -- this is always
 // sent pre-emptively, so any time it is sent the change is present
 message NotifyHasPatch {
     string patch_id = 1;
 }
 
 message ResolveSignalExternalWorkflow {
-    /// Sequence number as provided by lang in the corresponding SignalExternalWorkflowExecution
-    /// command
+    // Sequence number as provided by lang in the corresponding SignalExternalWorkflowExecution
+    // command
     uint32 seq = 1;
-    /// If populated, this signal either failed to be sent or was cancelled depending on failure
-    /// type / info.
+    // If populated, this signal either failed to be sent or was cancelled depending on failure
+    // type / info.
     temporal.api.failure.v1.Failure failure = 2;
 }
 
 message ResolveRequestCancelExternalWorkflow {
-    /// Sequence number as provided by lang in the corresponding
-    /// RequestCancelExternalWorkflowExecution command
+    // Sequence number as provided by lang in the corresponding
+    // RequestCancelExternalWorkflowExecution command
     uint32 seq = 1;
-    /// If populated, this signal either failed to be sent or was cancelled depending on failure
-    /// type / info.
+    // If populated, this signal either failed to be sent or was cancelled depending on failure
+    // type / info.
     temporal.api.failure.v1.Failure failure = 2;
 }
 
 message RemoveFromCache {
     string message = 1;
 
     enum EvictionReason {
@@ -254,10 +259,12 @@
         TASK_NOT_FOUND = 6;
         // There was new work that must be handled while we attempted to complete the WFT. Ex:
         // a new signal came in while trying to complete the workflow.
         UNHANDLED_COMMAND = 7;
         // There was some fatal error processing the workflow, typically an internal error, but
         // can also happen if then network drops out while paginating. Check message string.
         FATAL = 8;
+        // Something went wrong attempting to fetch more history events.
+        PAGINATION_OR_HISTORY_FETCH = 9;
     }
     EvictionReason reason = 2;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_commands/workflow_commands.proto`

 * *Files 4% similar despite different names*

```diff
@@ -1,15 +1,16 @@
 syntax = "proto3";
 
-/**
+/*
  * Definitions for commands from a workflow in lang SDK to core. While a workflow processes a batch
  * of activation jobs, it accumulates these commands to be sent back to core to conclude that
  * activation.
  */
 package coresdk.workflow_commands;
+option ruby_package = "Temporalio::Bridge::Api::WorkflowCommands";
 
 import "google/protobuf/duration.proto";
 import "google/protobuf/timestamp.proto";
 import "temporal/api/common/v1/message.proto";
 import "temporal/api/enums/v1/workflow.proto";
 import "temporal/api/failure/v1/message.proto";
 import "temporal/sdk/core/child_workflow/child_workflow.proto";
@@ -36,143 +37,143 @@
         RequestCancelLocalActivity request_cancel_local_activity = 17;
         UpsertWorkflowSearchAttributes upsert_workflow_search_attributes = 18;
         ModifyWorkflowProperties modify_workflow_properties = 19;
     }
 }
 
 message StartTimer {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     google.protobuf.Duration start_to_fire_timeout = 2;
 }
 
 message CancelTimer {
-    /// Lang's incremental sequence number as passed to `StartTimer`
+    // Lang's incremental sequence number as passed to `StartTimer`
     uint32 seq = 1;
 }
 
 message ScheduleActivity {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     string activity_id = 2;
     string activity_type = 3;
     // The name of the task queue to place this activity request in
     string task_queue = 5;
     map<string, temporal.api.common.v1.Payload> headers = 6;
-    /// Arguments/input to the activity. Called "input" upstream.
+    // Arguments/input to the activity. Called "input" upstream.
     repeated temporal.api.common.v1.Payload arguments = 7;
-    /// Indicates how long the caller is willing to wait for an activity completion. Limits how long
-    /// retries will be attempted. Either this or start_to_close_timeout_seconds must be specified.
-    /// When not specified defaults to the workflow execution timeout.
+    // Indicates how long the caller is willing to wait for an activity completion. Limits how long
+    // retries will be attempted. Either this or start_to_close_timeout_seconds must be specified.
+    // When not specified defaults to the workflow execution timeout.
     google.protobuf.Duration schedule_to_close_timeout = 8;
-    /// Limits time an activity task can stay in a task queue before a worker picks it up. This
-    /// timeout is always non retryable as all a retry would achieve is to put it back into the same
-    /// queue. Defaults to schedule_to_close_timeout or workflow execution timeout if not specified.
+    // Limits time an activity task can stay in a task queue before a worker picks it up. This
+    // timeout is always non retryable as all a retry would achieve is to put it back into the same
+    // queue. Defaults to schedule_to_close_timeout or workflow execution timeout if not specified.
     google.protobuf.Duration schedule_to_start_timeout = 9;
-    /// Maximum time an activity is allowed to execute after a pick up by a worker. This timeout is
-    /// always retryable. Either this or schedule_to_close_timeout must be specified.
+    // Maximum time an activity is allowed to execute after a pick up by a worker. This timeout is
+    // always retryable. Either this or schedule_to_close_timeout must be specified.
     google.protobuf.Duration start_to_close_timeout = 10;
-    /// Maximum time allowed between successful worker heartbeats.
+    // Maximum time allowed between successful worker heartbeats.
     google.protobuf.Duration heartbeat_timeout = 11;
-    /// Activities are provided by a default retry policy controlled through the service dynamic
-    /// configuration. Retries are happening up to schedule_to_close_timeout. To disable retries set
-    /// retry_policy.maximum_attempts to 1.
+    // Activities are provided by a default retry policy controlled through the service dynamic
+    // configuration. Retries are happening up to schedule_to_close_timeout. To disable retries set
+    // retry_policy.maximum_attempts to 1.
     temporal.api.common.v1.RetryPolicy retry_policy = 12;
-    /// Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed
+    // Defines how the workflow will wait (or not) for cancellation of the activity to be confirmed
     ActivityCancellationType cancellation_type = 13;
-    /// If set, the worker will not tell the service that it can immediately start executing this
-    /// activity. When unset/default, workers will always attempt to do so if activity execution
-    /// slots are available.
+    // If set, the worker will not tell the service that it can immediately start executing this
+    // activity. When unset/default, workers will always attempt to do so if activity execution
+    // slots are available.
     bool do_not_eagerly_execute = 14;
 }
 
 message ScheduleLocalActivity {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     string activity_id = 2;
     string activity_type = 3;
-    /// Local activities can start with a non-1 attempt, if lang has been told to backoff using
-    /// a timer before retrying. It should pass the attempt number from a `DoBackoff` activity
-    /// resolution.
+    // Local activities can start with a non-1 attempt, if lang has been told to backoff using
+    // a timer before retrying. It should pass the attempt number from a `DoBackoff` activity
+    // resolution.
     uint32 attempt = 4;
-    /// If this local activity is a retry (as per the attempt field) this needs to be the original
-    /// scheduling time (as provided in `DoBackoff`)
+    // If this local activity is a retry (as per the attempt field) this needs to be the original
+    // scheduling time (as provided in `DoBackoff`)
     google.protobuf.Timestamp original_schedule_time = 5;
     map<string, temporal.api.common.v1.Payload> headers = 6;
-    /// Arguments/input to the activity.
+    // Arguments/input to the activity.
     repeated temporal.api.common.v1.Payload arguments = 7;
-    /// Indicates how long the caller is willing to wait for local activity completion. Limits how
-    /// long retries will be attempted. When not specified defaults to the workflow execution
-    /// timeout (which may be unset).
+    // Indicates how long the caller is willing to wait for local activity completion. Limits how
+    // long retries will be attempted. When not specified defaults to the workflow execution
+    // timeout (which may be unset).
     google.protobuf.Duration schedule_to_close_timeout = 8;
-    /// Limits time the local activity can idle internally before being executed. That can happen if
-    /// the worker is currently at max concurrent local activity executions. This timeout is always
-    /// non retryable as all a retry would achieve is to put it back into the same queue. Defaults
-    /// to `schedule_to_close_timeout` if not specified and that is set. Must be <=
-    /// `schedule_to_close_timeout` when set, otherwise, it will be clamped down.
+    // Limits time the local activity can idle internally before being executed. That can happen if
+    // the worker is currently at max concurrent local activity executions. This timeout is always
+    // non retryable as all a retry would achieve is to put it back into the same queue. Defaults
+    // to `schedule_to_close_timeout` if not specified and that is set. Must be <=
+    // `schedule_to_close_timeout` when set, otherwise, it will be clamped down.
     google.protobuf.Duration schedule_to_start_timeout = 9;
-    /// Maximum time the local activity is allowed to execute after the task is dispatched. This
-    /// timeout is always retryable. Either or both of `schedule_to_close_timeout` and this must be
-    /// specified. If set, this must be <= `schedule_to_close_timeout`, otherwise, it will be
-    /// clamped down.
+    // Maximum time the local activity is allowed to execute after the task is dispatched. This
+    // timeout is always retryable. Either or both of `schedule_to_close_timeout` and this must be
+    // specified. If set, this must be <= `schedule_to_close_timeout`, otherwise, it will be
+    // clamped down.
     google.protobuf.Duration start_to_close_timeout = 10;
-    /// Specify a retry policy for the local activity. By default local activities will be retried
-    /// indefinitely.
+    // Specify a retry policy for the local activity. By default local activities will be retried
+    // indefinitely.
     temporal.api.common.v1.RetryPolicy retry_policy = 11;
-    /// If the activity is retrying and backoff would exceed this value, lang will be told to
-    /// schedule a timer and retry the activity after. Otherwise, backoff will happen internally in
-    /// core. Defaults to 1 minute.
+    // If the activity is retrying and backoff would exceed this value, lang will be told to
+    // schedule a timer and retry the activity after. Otherwise, backoff will happen internally in
+    // core. Defaults to 1 minute.
     google.protobuf.Duration local_retry_threshold = 12;
-    /// Defines how the workflow will wait (or not) for cancellation of the activity to be
-    /// confirmed. Lang should default this to `WAIT_CANCELLATION_COMPLETED`, even though proto
-    /// will default to `TRY_CANCEL` automatically.
+    // Defines how the workflow will wait (or not) for cancellation of the activity to be
+    // confirmed. Lang should default this to `WAIT_CANCELLATION_COMPLETED`, even though proto
+    // will default to `TRY_CANCEL` automatically.
     ActivityCancellationType cancellation_type = 13;
 }
 
 enum ActivityCancellationType {
-    /// Initiate a cancellation request and immediately report cancellation to the workflow.
+    // Initiate a cancellation request and immediately report cancellation to the workflow.
     TRY_CANCEL = 0;
-    /// Wait for activity cancellation completion. Note that activity must heartbeat to receive a
-    /// cancellation notification. This can block the cancellation for a long time if activity
-    /// doesn't heartbeat or chooses to ignore the cancellation request.
+    // Wait for activity cancellation completion. Note that activity must heartbeat to receive a
+    // cancellation notification. This can block the cancellation for a long time if activity
+    // doesn't heartbeat or chooses to ignore the cancellation request.
     WAIT_CANCELLATION_COMPLETED = 1;
-    /// Do not request cancellation of the activity and immediately report cancellation to the
-    /// workflow
+    // Do not request cancellation of the activity and immediately report cancellation to the
+    // workflow
     ABANDON = 2;
 }
 
 message RequestCancelActivity {
-    /// Lang's incremental sequence number as passed to `ScheduleActivity`
+    // Lang's incremental sequence number as passed to `ScheduleActivity`
     uint32 seq = 1;
 }
 
 message RequestCancelLocalActivity {
-    /// Lang's incremental sequence number as passed to `ScheduleLocalActivity`
+    // Lang's incremental sequence number as passed to `ScheduleLocalActivity`
     uint32 seq = 1;
 }
 
 message QueryResult {
-    /// Corresponds to the id provided in the activation job
+    // Corresponds to the id provided in the activation job
     string query_id = 1;
     oneof variant {
         QuerySuccess succeeded = 2;
         temporal.api.failure.v1.Failure failed = 3;
     }
 }
 
 message QuerySuccess {
     temporal.api.common.v1.Payload response = 1;
 }
 
-/// Issued when the workflow completes successfully
+// Issued when the workflow completes successfully
 message CompleteWorkflowExecution {
     temporal.api.common.v1.Payload result = 1;
 }
 
-/// Issued when the workflow errors out
+// Issued when the workflow errors out
 message FailWorkflowExecution {
     temporal.api.failure.v1.Failure failure = 1;
 }
 
 // Continue the workflow as a new execution
 message ContinueAsNewWorkflowExecution {
     // The identifier the lang-specific sdk uses to execute workflow code
@@ -195,108 +196,108 @@
     // workflow's search attributes.
     map<string, temporal.api.common.v1.Payload> search_attributes = 8;
     // If set, the new workflow will have this retry policy. If unset, re-uses the current
     // workflow's retry policy.
     temporal.api.common.v1.RetryPolicy retry_policy = 9;
 }
 
-/// Indicate a workflow has completed as cancelled. Generally sent as a response to an activation
-/// containing a cancellation job.
+// Indicate a workflow has completed as cancelled. Generally sent as a response to an activation
+// containing a cancellation job.
 message CancelWorkflowExecution {}
 
-/// A request to set/check if a certain patch is present or not
+// A request to set/check if a certain patch is present or not
 message SetPatchMarker {
     // A user-chosen identifier for this patch. If the same identifier is used in multiple places in
     // the code, those places are considered to be versioned as one unit. IE: The check call will
     // return the same result for all of them
     string patch_id = 1;
     // Can be set to true to indicate that branches using this change are being removed, and all
     // future worker deployments will only have the "with change" code in them.
     bool deprecated = 2;
 }
 
-/// Start a child workflow execution
+// Start a child workflow execution
 message StartChildWorkflowExecution {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     string namespace = 2;
     string workflow_id = 3;
     string workflow_type = 4;
     string task_queue = 5;
     repeated temporal.api.common.v1.Payload input = 6;
-    /// Total workflow execution timeout including retries and continue as new.
+    // Total workflow execution timeout including retries and continue as new.
     google.protobuf.Duration workflow_execution_timeout = 7;
-    /// Timeout of a single workflow run.
+    // Timeout of a single workflow run.
     google.protobuf.Duration workflow_run_timeout = 8;
-    /// Timeout of a single workflow task.
+    // Timeout of a single workflow task.
     google.protobuf.Duration workflow_task_timeout = 9;
-    /// Default: PARENT_CLOSE_POLICY_TERMINATE.
+    // Default: PARENT_CLOSE_POLICY_TERMINATE.
     child_workflow.ParentClosePolicy parent_close_policy = 10;
     // string control = 11; (unused from StartChildWorkflowExecutionCommandAttributes)
     // Default: WORKFLOW_ID_REUSE_POLICY_ALLOW_DUPLICATE.
     temporal.api.enums.v1.WorkflowIdReusePolicy workflow_id_reuse_policy = 12;
     temporal.api.common.v1.RetryPolicy retry_policy = 13;
     string cron_schedule = 14;
-    /// Header fields
+    // Header fields
     map<string, temporal.api.common.v1.Payload> headers = 15;
-    /// Memo fields
+    // Memo fields
     map<string, temporal.api.common.v1.Payload> memo = 16;
-    /// Search attributes
+    // Search attributes
     map<string, temporal.api.common.v1.Payload> search_attributes = 17;
-    /// Defines behaviour of the underlying workflow when child workflow cancellation has been requested.
+    // Defines behaviour of the underlying workflow when child workflow cancellation has been requested.
     child_workflow.ChildWorkflowCancellationType cancellation_type = 18;
 }
 
-/// Cancel a child workflow
+// Cancel a child workflow
 message CancelChildWorkflowExecution {
     // Sequence number as given to the `StartChildWorkflowExecution` command
     uint32 child_workflow_seq = 1;
 }
 
-/// Request cancellation of an external workflow execution (which may be a started child)
+// Request cancellation of an external workflow execution (which may be a started child)
 message RequestCancelExternalWorkflowExecution {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     // What workflow is being targeted
     oneof target {
         // A specific workflow instance
         common.NamespacedWorkflowExecution workflow_execution = 2;
         // The desired target must be a child of the issuing workflow, and this is its workflow id
         string child_workflow_id = 3;
     }
 }
 
-/// Send a signal to an external or child workflow
+// Send a signal to an external or child workflow
 message SignalExternalWorkflowExecution {
-    /// Lang's incremental sequence number, used as the operation identifier
+    // Lang's incremental sequence number, used as the operation identifier
     uint32 seq = 1;
     // What workflow is being targeted
     oneof target {
         // A specific workflow instance
         common.NamespacedWorkflowExecution workflow_execution = 2;
         // The desired target must be a child of the issuing workflow, and this is its workflow id
         string child_workflow_id = 3;
     }
-    /// Name of the signal handler
+    // Name of the signal handler
     string signal_name = 4;
-    /// Arguments for the handler
+    // Arguments for the handler
     repeated temporal.api.common.v1.Payload args = 5;
-    /// Headers to attach to the signal
+    // Headers to attach to the signal
     map<string, temporal.api.common.v1.Payload> headers = 6;
 }
 
-/// Can be used to cancel not-already-sent `SignalExternalWorkflowExecution` commands
+// Can be used to cancel not-already-sent `SignalExternalWorkflowExecution` commands
 message CancelSignalWorkflow {
-    /// Lang's incremental sequence number as passed to `SignalExternalWorkflowExecution`
+    // Lang's incremental sequence number as passed to `SignalExternalWorkflowExecution`
     uint32 seq = 1;
 }
 
 message UpsertWorkflowSearchAttributes {
-    /// SearchAttributes fields - equivalent to indexed_fields on api. Key = search index, Value =
-    /// value?
+    // SearchAttributes fields - equivalent to indexed_fields on api. Key = search index, Value =
+    // value?
     map<string, temporal.api.common.v1.Payload> search_attributes = 1;
 }
 
 message ModifyWorkflowProperties {
     // If set, update the workflow memo with the provided values. The values will be merged with
     // the existing memo. If the user wants to delete values, a default/empty Payload should be
     // used as the value for the key being deleted.
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/local/temporal/sdk/core/workflow_completion/workflow_completion.proto`

 * *Files 19% similar despite different names*

```diff
@@ -1,29 +1,35 @@
 syntax = "proto3";
 
 package coresdk.workflow_completion;
+option ruby_package = "Temporalio::Bridge::Api::WorkflowCompletion";
 
 import "temporal/api/failure/v1/message.proto";
+import "temporal/api/enums/v1/failed_cause.proto";
 import "temporal/sdk/core/common/common.proto";
 import "temporal/sdk/core/workflow_commands/workflow_commands.proto";
 
-/// Result of a single workflow activation, reported from lang to core
+// Result of a single workflow activation, reported from lang to core
 message WorkflowActivationCompletion {
     // The run id from the workflow activation you are completing
     string run_id = 1;
     oneof status {
         Success successful = 2;
         Failure failed = 3;
     }
 }
 
-/// Successful workflow activation with a list of commands generated by the workflow execution
+// Successful workflow activation with a list of commands generated by the workflow execution
 message Success {
     // A list of commands to send back to the temporal server
     repeated workflow_commands.WorkflowCommand commands = 1;
+    // Any internal flags which the lang SDK used in the processing of this activation
+    repeated uint32 used_internal_flags = 6;
 }
 
-/// Failure to activate or execute a workflow
+// Failure to activate or execute a workflow
 message Failure {
     temporal.api.failure.v1.Failure failure = 1;
+    // Forces overriding the WFT failure cause
+    temporal.api.enums.v1.WorkflowTaskFailedCause force_cause = 2;
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/Makefile`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/api-linter.yaml`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/dependencies/gogoproto/gogo.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto` & `temporalio-1.2.0/temporalio/bridge/sdk-core/protos/testsrv_upstream/temporal/api/testservice/v1/service.proto`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/Cargo.toml`

 * *Files 13% similar despite different names*

```diff
@@ -12,24 +12,24 @@
 
 # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html
 
 [dependencies]
 async-trait = "0.1"
 thiserror = "1.0"
 anyhow = "1.0"
-base64 = "0.20"
+base64 = "0.21"
 crossbeam = "0.8"
 derive_more = "0.99"
 futures = "0.3"
 once_cell = "1.10"
 parking_lot = { version = "0.12", features = ["send_guard"] }
-prost-types = "0.11"
+prost-types = { version = "0.4", package = "prost-wkt-types" }
 sha2 = "0.10"
 serde = "1.0"
-tokio = { version = "1.1", features = ["rt", "rt-multi-thread", "parking_lot", "time", "fs"] }
+tokio = { version = "1.26", features = ["rt", "rt-multi-thread", "parking_lot", "time", "fs"] }
 tokio-util = { version = "0.7" }
 tokio-stream = "0.1"
 tonic = "0.8"
 tracing = "0.1"
 
 [dependencies.temporal-sdk-core]
 path = "../core"
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/LICENSE.txt` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/LICENSE.txt`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/activity_context.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/app_data.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/interceptors.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/lib.rs`

 * *Files 2% similar despite different names*

```diff
@@ -84,15 +84,15 @@
     coresdk::{
         activity_result::{ActivityExecutionResult, ActivityResolution},
         activity_task::{activity_task, ActivityTask},
         child_workflow::ChildWorkflowResult,
         common::NamespacedWorkflowExecution,
         workflow_activation::{
             resolve_child_workflow_execution_start::Status as ChildWorkflowStartStatus,
-            workflow_activation_job::Variant, WorkflowActivation, WorkflowActivationJob,
+            workflow_activation_job::Variant, WorkflowActivation,
         },
         workflow_commands::{workflow_command, ContinueAsNewWorkflowExecution},
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion, AsJsonPayloadExt, FromJsonPayloadExt,
     },
     temporal::api::{common::v1::Payload, failure::v1::Failure},
     TaskToken,
@@ -387,18 +387,18 @@
         anyhow::Error,
     > {
         let mut res = None;
         let run_id = activation.run_id.clone();
 
         // If the activation is to start a workflow, create a new workflow driver for it,
         // using the function associated with that workflow id
-        if let Some(WorkflowActivationJob {
-            variant: Some(Variant::StartWorkflow(sw)),
-        }) = activation.jobs.get(0)
-        {
+        if let Some(sw) = activation.jobs.iter().find_map(|j| match j.variant {
+            Some(Variant::StartWorkflow(ref sw)) => Some(sw),
+            _ => None,
+        }) {
             let workflow_type = &sw.workflow_type;
             let wf_fns_borrow = self.workflow_fns.borrow();
             let wf_function = wf_fns_borrow
                 .get(workflow_type)
                 .ok_or_else(|| anyhow!("Workflow type {workflow_type} not found"))?;
 
             let (wff, activations) = wf_function.start_workflow(
@@ -406,15 +406,15 @@
                 common.task_queue.clone(),
                 // NOTE: Don't clone args if this gets ported to be a non-test rust worker
                 sw.arguments.clone(),
                 completions_tx.clone(),
             );
             let jh = tokio::spawn(async move {
                 tokio::select! {
-                    r = wff => r,
+                    r = wff.fuse() => r,
                     // TODO: This probably shouldn't abort early, as it could cause an in-progress
                     //  complete to abort. Send synthetic remove activation
                     _ = shutdown_token.cancelled() => {
                         Ok(WfExitValue::Evicted)
                     }
                 }
             });
@@ -545,19 +545,21 @@
     /// The timer was cancelled
     Cancelled,
     /// The timer elapsed and fired
     Fired,
 }
 
 /// Successful result of sending a signal to an external workflow
+#[derive(Debug)]
 pub struct SignalExternalOk;
 /// Result of awaiting on sending a signal to an external workflow
 pub type SignalExternalWfResult = Result<SignalExternalOk, Failure>;
 
 /// Successful result of sending a cancel request to an external workflow
+#[derive(Debug)]
 pub struct CancelExternalOk;
 /// Result of awaiting on sending a cancel request to an external workflow
 pub type CancelExternalWfResult = Result<CancelExternalOk, Failure>;
 
 trait Unblockable {
     type OtherDat;
 
@@ -652,14 +654,28 @@
         /// Identifying information about the workflow to be cancelled
         execution: NamespacedWorkflowExecution,
         /// Set to true if this workflow is a child of the issuing workflow
         only_child: bool,
     },
 }
 
+impl CancellableID {
+    /// Returns the type-specific sequence number used for this command
+    pub fn seq_num(&self) -> u32 {
+        match self {
+            CancellableID::Timer(seq) => *seq,
+            CancellableID::Activity(seq) => *seq,
+            CancellableID::LocalActivity(seq) => *seq,
+            CancellableID::ChildWorkflow(seq) => *seq,
+            CancellableID::SignalExternalWorkflow(seq) => *seq,
+            CancellableID::ExternalWorkflow { seqnum, .. } => *seqnum,
+        }
+    }
+}
+
 #[derive(derive_more::From)]
 #[allow(clippy::large_enum_variant)]
 enum RustWfCmd {
     #[from(ignore)]
     Cancel(CancellableID),
     ForceWFTFailure(anyhow::Error),
     NewCmd(CommandCreateRequest),
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/payload_converter.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context/options.rs`

 * *Files 4% similar despite different names*

```diff
@@ -5,15 +5,18 @@
     coresdk::{
         child_workflow::ChildWorkflowCancellationType,
         workflow_commands::{
             ActivityCancellationType, ScheduleActivity, ScheduleLocalActivity,
             StartChildWorkflowExecution,
         },
     },
-    temporal::api::common::v1::{Payload, RetryPolicy},
+    temporal::api::{
+        common::v1::{Payload, RetryPolicy},
+        enums::v1::ParentClosePolicy,
+    },
 };
 
 // TODO: Before release, probably best to avoid using proto types entirely here. They're awkward.
 
 pub trait IntoWorkflowCommand {
     type WFCommandType;
 
@@ -176,14 +179,16 @@
     pub workflow_type: String,
     /// Input to send the child Workflow
     pub input: Vec<Payload>,
     /// Cancellation strategy for the child workflow
     pub cancel_type: ChildWorkflowCancellationType,
     /// Common options
     pub options: WorkflowOptions,
+    /// How to respond to parent workflow ending
+    pub parent_close_policy: ParentClosePolicy,
 }
 
 impl IntoWorkflowCommand for ChildWorkflowOptions {
     type WFCommandType = StartChildWorkflowExecution;
     fn into_command(self, seq: u32) -> StartChildWorkflowExecution {
         StartChildWorkflowExecution {
             seq,
@@ -199,14 +204,15 @@
             workflow_run_timeout: self
                 .options
                 .execution_timeout
                 .and_then(|d| d.try_into().ok()),
             workflow_task_timeout: self.options.task_timeout.and_then(|d| d.try_into().ok()),
             search_attributes: self.options.search_attributes.unwrap_or_default(),
             cron_schedule: self.options.cron_schedule.unwrap_or_default(),
+            parent_close_policy: self.parent_close_policy as i32,
             ..Default::default()
         }
     }
 }
 
 /// Options for sending a signal to an external workflow
 pub struct SignalWorkflowOptions {
@@ -262,15 +268,15 @@
             signal_name: name.into(),
             data: SignalData::new(input),
         }
     }
 }
 
 /// Data contained within a signal
-#[derive(Default)]
+#[derive(Default, Debug)]
 pub struct SignalData {
     /// The arguments the signal will receive
     pub input: Vec<Payload>,
     /// Metadata attached to the signal
     pub headers: HashMap<String, Payload>,
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_context.rs`

 * *Files 5% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 use crate::{
     workflow_context::options::IntoWorkflowCommand, CancelExternalWfResult, CancellableID,
     CommandCreateRequest, CommandSubscribeChildWorkflowCompletion, RustWfCmd,
     SignalExternalWfResult, TimerResult, UnblockEvent, Unblockable,
 };
 use crossbeam::channel::{Receiver, Sender};
-use futures::{task::Context, FutureExt, Stream};
+use futures::{task::Context, FutureExt, Stream, StreamExt};
 use parking_lot::RwLock;
 use std::{
     collections::HashMap,
     future::Future,
     marker::PhantomData,
     pin::Pin,
     sync::{
@@ -30,15 +30,16 @@
         activity_result::{activity_resolution, ActivityResolution},
         child_workflow::ChildWorkflowResult,
         common::NamespacedWorkflowExecution,
         workflow_activation::resolve_child_workflow_execution_start::Status as ChildWorkflowStartStatus,
         workflow_commands::{
             request_cancel_external_workflow_execution as cancel_we,
             signal_external_workflow_execution as sig_we, workflow_command,
-            ModifyWorkflowProperties, RequestCancelExternalWorkflowExecution, SetPatchMarker,
+            CancelChildWorkflowExecution, ModifyWorkflowProperties,
+            RequestCancelExternalWorkflowExecution, SetPatchMarker,
             SignalExternalWorkflowExecution, StartTimer, UpsertWorkflowSearchAttributes,
         },
     },
     temporal::api::common::v1::{Memo, Payload},
 };
 use tokio::sync::{mpsc, oneshot, watch};
 use tokio_stream::wrappers::UnboundedReceiverStream;
@@ -94,14 +95,15 @@
 
 #[derive(Clone, Debug, Default)]
 pub struct WfContextSharedData {
     /// Maps change ids -> resolved status
     pub changes: HashMap<String, bool>,
     pub is_replaying: bool,
     pub wf_time: Option<SystemTime>,
+    pub history_length: u32,
 }
 
 // TODO: Dataconverter type interface to replace Payloads here. Possibly just use serde
 //    traits.
 impl WfContext {
     /// Create a new wf context, returning the context itself and a receiver which outputs commands
     /// sent from the workflow.
@@ -144,14 +146,19 @@
     }
 
     /// Return the current time according to the workflow (which is not wall-clock time).
     pub fn workflow_time(&self) -> Option<SystemTime> {
         self.shared.read().wf_time
     }
 
+    /// Return the length of history so far at this point in the workflow
+    pub fn history_length(&self) -> u32 {
+        self.shared.read().history_length
+    }
+
     pub(crate) fn get_shared_data(&self) -> Arc<RwLock<WfContextSharedData>> {
         self.shared.clone()
     }
 
     /// A future that resolves if/when the workflow is cancelled
     pub async fn cancelled(&mut self) {
         if *self.am_cancelled.borrow() {
@@ -387,14 +394,22 @@
         let mut receiver = self.0.into_inner();
         let mut signals = vec![];
         while let Ok(s) = receiver.try_recv() {
             signals.push(s);
         }
         signals
     }
+
+    pub fn drain_ready(&mut self) -> Vec<SignalData> {
+        let mut signals = vec![];
+        while let Some(s) = self.0.next().now_or_never().flatten() {
+            signals.push(s);
+        }
+        signals
+    }
 }
 
 impl Stream for DrainableSignalStream {
     type Item = SignalData;
 
     fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
         Pin::new(&mut self.0).poll_next(cx)
@@ -546,24 +561,24 @@
                     }
                 }
                 Poll::Pending => Poll::Pending,
             };
         }
         let poll_res = self.current_fut.poll_unpin(cx);
         if let Poll::Ready(ref r) = poll_res {
-            // If we've already said we want to cancel, don't schedule the backoff timer. Just
-            // return cancel status. This can happen if cancel comes after the LA says it wants to
-            // back off but before we have scheduled the timer.
-            if self.did_cancel.load(Ordering::Acquire) {
-                return Poll::Ready(ActivityResolution {
-                    status: Some(activity_resolution::Status::Cancelled(Default::default())),
-                });
-            }
-
             if let Some(activity_resolution::Status::Backoff(b)) = r.status.as_ref() {
+                // If we've already said we want to cancel, don't schedule the backoff timer. Just
+                // return cancel status. This can happen if cancel comes after the LA says it wants
+                // to back off but before we have scheduled the timer.
+                if self.did_cancel.load(Ordering::Acquire) {
+                    return Poll::Ready(ActivityResolution {
+                        status: Some(activity_resolution::Status::Cancelled(Default::default())),
+                    });
+                }
+
                 let timer_f = self.ctx.timer(
                     b.backoff_duration
                         .clone()
                         .expect("Duration is set")
                         .try_into()
                         .expect("duration converts ok"),
                 );
@@ -669,21 +684,21 @@
     /// Consumes self and returns a future that will wait until completion of this child workflow
     /// execution
     pub fn result(self) -> impl CancellableFuture<ChildWorkflowResult> {
         self.common.result_future
     }
 
     /// Cancel the child workflow
-    pub fn cancel(&self, cx: &WfContext) -> impl Future<Output = CancelExternalWfResult> {
-        let target = NamespacedWorkflowExecution {
-            namespace: cx.namespace().to_string(),
-            workflow_id: self.common.workflow_id.clone(),
-            ..Default::default()
-        };
-        cx.cancel_external(target)
+    pub fn cancel(&self, cx: &WfContext) {
+        cx.send(RustWfCmd::NewNonblockingCmd(
+            CancelChildWorkflowExecution {
+                child_workflow_seq: self.common.result_future.cancellable_id.seq_num(),
+            }
+            .into(),
+        ));
     }
 
     /// Signal the child workflow
     pub fn signal(
         &self,
         cx: &WfContext,
         data: impl Into<Signal>,
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk/src/workflow_future.rs`

 * *Files 5% similar despite different names*

```diff
@@ -58,15 +58,17 @@
         let (tx, incoming_activations) = unbounded_channel();
         (
             WorkflowFuture {
                 ctx_shared: wf_context.get_shared_data(),
                 // We need to mark the workflow future as unconstrained, otherwise Tokio will impose
                 // an artificial limit on how many commands we can unblock in one poll round.
                 // TODO: Now we *need* deadlock detection or we could hose the whole system
-                inner: tokio::task::unconstrained((self.wf_func)(wf_context)).boxed(),
+                inner: tokio::task::unconstrained((self.wf_func)(wf_context))
+                    .fuse()
+                    .boxed(),
                 incoming_commands: cmd_receiver,
                 outgoing_completions,
                 incoming_activations,
                 command_status: Default::default(),
                 cancel_sender: cancel_tx,
                 child_workflow_starts: Default::default(),
                 sig_chans: Default::default(),
@@ -175,16 +177,19 @@
                     seq,
                     result,
                 }) => self.unblock(UnblockEvent::WorkflowComplete(
                     seq,
                     Box::new(result.context("Child Workflow execution must have a result")?),
                 ))?,
                 Variant::UpdateRandomSeed(_) => (),
-                Variant::QueryWorkflow(_) => {
-                    todo!()
+                Variant::QueryWorkflow(q) => {
+                    error!(
+                        "Queries are not implemented in the Rust SDK. Got query '{}'",
+                        q.query_id
+                    );
                 }
                 Variant::CancelWorkflow(_) => {
                     // TODO: Cancel pending futures, etc
                     self.cancel_sender
                         .send(true)
                         .expect("Cancel rx not dropped");
                 }
@@ -210,14 +215,17 @@
                     self.unblock(UnblockEvent::SignalExternal(attrs.seq, attrs.failure))?;
                 }
                 Variant::ResolveRequestCancelExternalWorkflow(attrs) => {
                     self.unblock(UnblockEvent::CancelExternal(attrs.seq, attrs.failure))?;
                 }
 
                 Variant::RemoveFromCache(_) => {
+                    // TODO: Need to abort any spawned tasks, etc. See also cancel WF.
+                    //   How best to do this in executor agnostic way? Is that possible?
+                    //  -- tokio JoinSet does this in a nice way.
                     return Ok(true);
                 }
             }
         } else {
             bail!("Empty activation job variant");
         }
 
@@ -245,14 +253,15 @@
 
             let is_only_eviction = activation.is_only_eviction();
             let run_id = activation.run_id;
             {
                 let mut wlock = self.ctx_shared.write();
                 wlock.is_replaying = activation.is_replaying;
                 wlock.wf_time = activation.timestamp.try_into_or_none();
+                wlock.history_length = activation.history_length;
             }
 
             let mut die_of_eviction_when_done = false;
             for WorkflowActivationJob { variant } in activation.jobs {
                 match self.handle_job(variant) {
                     Ok(true) => {
                         die_of_eviction_when_done = true;
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/Cargo.toml`

 * *Files 10% similar despite different names*

```diff
@@ -8,23 +8,26 @@
 homepage = "https://temporal.io/"
 repository = "https://github.com/temporalio/sdk-core"
 keywords = ["temporal", "workflow"]
 categories = ["development-tools"]
 
 [features]
 history_builders = ["uuid", "rand"]
+serde_serialize = []
 
 [dependencies]
 anyhow = "1.0"
-base64 = "0.20"
+base64 = "0.21"
 derive_more = "0.99"
 prost = "0.11"
-prost-types = "0.11"
+prost-wkt = "0.4"
+prost-wkt-types = "0.4"
 rand = { version = "0.8", optional = true }
 serde = { version = "1.0", features = ["derive"] }
 serde_json = "1.0"
 thiserror = "1.0"
 tonic = "0.8"
 uuid = { version = "1.1", features = ["v4"], optional = true }
 
 [build-dependencies]
 tonic-build = "0.8"
+prost-wkt-build = "0.4"
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/build.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,9 +1,13 @@
+use std::{env, path::PathBuf};
+
 fn main() -> Result<(), Box<dyn std::error::Error>> {
     println!("cargo:rerun-if-changed=../protos");
+    let out = PathBuf::from(env::var("OUT_DIR").unwrap());
+    let descriptor_file = out.join("descriptors.bin");
     tonic_build::configure()
         // We don't actually want to build the grpc definitions - we don't need them (for now).
         // Just build the message structs.
         .build_server(false)
         .build_client(true)
         // Make conversions easier for some types
         .type_attribute(
@@ -70,28 +74,49 @@
             "coresdk.activity_task.ActivityCancelReason",
             "#[derive(::derive_more::Display)]",
         )
         .type_attribute("coresdk.Task.variant", "#[derive(::derive_more::From)]")
         // All external data is useful to be able to JSON serialize, so it can render in web UI
         .type_attribute(
             ".coresdk.external_data",
-            "#[derive(::serde::Serialize, ::serde::Deserialize)]",
+            "#[cfg_attr(not(feature = \"serde_serialize\"), derive(::serde::Serialize, ::serde::Deserialize))]",
+        )
+        .type_attribute(
+            ".",
+            "#[cfg_attr(feature = \"serde_serialize\", derive(::serde::Serialize, ::serde::Deserialize))]",
         )
         .field_attribute(
             "coresdk.external_data.LocalActivityMarkerData.complete_time",
             "#[serde(with = \"opt_timestamp\")]",
         )
         .field_attribute(
             "coresdk.external_data.LocalActivityMarkerData.original_schedule_time",
             "#[serde(with = \"opt_timestamp\")]",
         )
         .field_attribute(
             "coresdk.external_data.LocalActivityMarkerData.backoff",
             "#[serde(with = \"opt_duration\")]",
         )
+        .extern_path(
+            ".google.protobuf.Any",
+            "::prost_wkt_types::Any"
+        )
+        .extern_path(
+            ".google.protobuf.Timestamp",
+            "::prost_wkt_types::Timestamp"
+        )
+        .extern_path(
+            ".google.protobuf.Duration",
+            "::prost_wkt_types::Duration"
+        )
+        .extern_path(
+            ".google.protobuf.Value",
+            "::prost_wkt_types::Value"
+        )
+        .file_descriptor_set_path(#[allow(clippy::needless_borrow)] &descriptor_file)
         .compile(
             &[
                 "../protos/local/temporal/sdk/core/core_interface.proto",
                 "../protos/api_upstream/temporal/api/workflowservice/v1/service.proto",
                 "../protos/api_upstream/temporal/api/operatorservice/v1/service.proto",
                 "../protos/testsrv_upstream/temporal/api/testservice/v1/service.proto",
                 "../protos/grpc/health/v1/health.proto",
@@ -99,9 +124,19 @@
             &[
                 "../protos/api_upstream",
                 "../protos/local",
                 "../protos/testsrv_upstream",
                 "../protos/grpc",
             ],
         )?;
+
+    #[cfg(feature = "serde_serialize")]
+    {
+        use prost_wkt_build::{FileDescriptorSet, Message};
+
+        let descriptor_bytes = std::fs::read(descriptor_file)?;
+        let descriptor = FileDescriptorSet::decode(&descriptor_bytes[..])?;
+        prost_wkt_build::add_serde(out, descriptor);
+    }
+
     Ok(())
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_builder.rs`

 * *Files 10% similar despite different names*

```diff
@@ -2,31 +2,38 @@
     constants::{LOCAL_ACTIVITY_MARKER_NAME, PATCH_MARKER_NAME},
     coresdk::{
         common::{
             build_has_change_marker_details, build_local_activity_marker_details,
             NamespacedWorkflowExecution,
         },
         external_data::LocalActivityMarkerData,
-        IntoPayloadsExt,
+        workflow_commands::ScheduleActivity,
+        AsJsonPayloadExt, IntoPayloadsExt,
     },
     temporal::api::{
-        common::v1::{Payload, Payloads, WorkflowExecution, WorkflowType},
+        common::v1::{
+            ActivityType, Payload, Payloads, SearchAttributes, WorkflowExecution, WorkflowType,
+        },
         enums::v1::{EventType, TaskQueueKind, WorkflowTaskFailedCause},
         failure::v1::{failure, CanceledFailureInfo, Failure},
         history::v1::{history_event::Attributes, *},
         taskqueue::v1::TaskQueue,
     },
     HistoryInfo,
 };
 use anyhow::bail;
-use prost_types::Timestamp;
-use std::time::{Duration, SystemTime};
+use prost_wkt_types::Timestamp;
+use std::{
+    collections::HashMap,
+    time::{Duration, SystemTime},
+};
 use uuid::Uuid;
 
 pub static DEFAULT_WORKFLOW_TYPE: &str = "default_wf_type";
+pub static DEFAULT_ACTIVITY_TYPE: &str = "default_act_type";
 
 type Result<T, E = anyhow::Error> = std::result::Result<T, E>;
 
 #[derive(Default, Clone, Debug)]
 pub struct TestHistoryBuilder {
     events: Vec<HistoryEvent>,
     /// Is incremented every time a new event is added, and that *new* value is used as that event's
@@ -57,34 +64,27 @@
                 .expect("Run id must be discoverable")
                 .to_string(),
             events,
         }
     }
 
     /// Add an event by type with attributes. Bundles both into a [HistoryEvent] with an id that is
-    /// incremented on each call to add.
-    pub fn add(&mut self, event_type: EventType, attribs: Attributes) {
-        self.build_and_push_event(event_type, attribs);
+    /// incremented on each call to add. Returns the id of the new event.
+    pub fn add(&mut self, attribs: impl Into<Attributes>) -> i64 {
+        let attribs: Attributes = attribs.into();
+        self.build_and_push_event(attribs.event_type(), attribs);
+        self.current_event_id
     }
 
-    /// Adds an event to the history by type, with default attributes.
-    pub fn add_by_type(&mut self, event_type: EventType) {
+    /// Adds an event to the history by type, with default attributes. Returns the id of the new
+    /// event.
+    pub fn add_by_type(&mut self, event_type: EventType) -> i64 {
         let attribs =
             default_attribs(event_type).expect("Couldn't make default attributes in test builder");
-        self.build_and_push_event(event_type, attribs);
-    }
-
-    /// Adds an event, returning the ID that was assigned to it
-    pub fn add_get_event_id(&mut self, event_type: EventType, attrs: Option<Attributes>) -> i64 {
-        if let Some(a) = attrs {
-            self.build_and_push_event(event_type, a);
-        } else {
-            self.add_by_type(event_type);
-        }
-        self.current_event_id
+        self.add(attribs)
     }
 
     /// Adds the following events:
     /// ```text
     /// EVENT_TYPE_WORKFLOW_TASK_SCHEDULED
     /// EVENT_TYPE_WORKFLOW_TASK_STARTED
     /// EVENT_TYPE_WORKFLOW_TASK_COMPLETED
@@ -96,33 +96,29 @@
 
     pub fn add_workflow_task_scheduled_and_started(&mut self) {
         self.add_workflow_task_scheduled();
         self.add_workflow_task_started();
     }
 
     pub fn add_workflow_task_scheduled(&mut self) {
-        self.workflow_task_scheduled_event_id =
-            self.add_get_event_id(EventType::WorkflowTaskScheduled, None);
+        self.workflow_task_scheduled_event_id = self.add_by_type(EventType::WorkflowTaskScheduled);
     }
 
     pub fn add_workflow_task_started(&mut self) {
-        let attrs = WorkflowTaskStartedEventAttributes {
+        self.final_workflow_task_started_event_id = self.add(WorkflowTaskStartedEventAttributes {
             scheduled_event_id: self.workflow_task_scheduled_event_id,
             ..Default::default()
-        };
-        self.final_workflow_task_started_event_id =
-            self.add_get_event_id(EventType::WorkflowTaskStarted, Some(attrs.into()));
+        });
     }
 
     pub fn add_workflow_task_completed(&mut self) {
-        let attrs = WorkflowTaskCompletedEventAttributes {
+        let id = self.add(WorkflowTaskCompletedEventAttributes {
             scheduled_event_id: self.workflow_task_scheduled_event_id,
             ..Default::default()
-        };
-        let id = self.add_get_event_id(EventType::WorkflowTaskCompleted, Some(attrs.into()));
+        });
         self.previous_task_completed_id = id;
     }
 
     pub fn add_workflow_task_timed_out(&mut self) {
         let attrs = WorkflowTaskTimedOutEventAttributes {
             scheduled_event_id: self.workflow_task_scheduled_event_id,
             ..Default::default()
@@ -172,57 +168,44 @@
 
     pub fn add_cancelled(&mut self) {
         let attrs = WorkflowExecutionCanceledEventAttributes::default();
         self.build_and_push_event(EventType::WorkflowExecutionCanceled, attrs.into());
     }
 
     pub fn add_activity_task_scheduled(&mut self, activity_id: impl Into<String>) -> i64 {
-        self.add_get_event_id(
-            EventType::ActivityTaskScheduled,
-            Some(
-                history_event::Attributes::ActivityTaskScheduledEventAttributes(
-                    ActivityTaskScheduledEventAttributes {
-                        activity_id: activity_id.into(),
-                        ..Default::default()
-                    },
-                ),
-            ),
-        )
+        self.add(ActivityTaskScheduledEventAttributes {
+            activity_id: activity_id.into(),
+            activity_type: Some(ActivityType {
+                name: DEFAULT_ACTIVITY_TYPE.to_string(),
+            }),
+            ..Default::default()
+        })
     }
+
     pub fn add_activity_task_started(&mut self, scheduled_event_id: i64) -> i64 {
-        self.add_get_event_id(
-            EventType::ActivityTaskStarted,
-            Some(
-                history_event::Attributes::ActivityTaskStartedEventAttributes(
-                    ActivityTaskStartedEventAttributes {
-                        scheduled_event_id,
-                        ..Default::default()
-                    },
-                ),
-            ),
-        )
+        self.add(Attributes::ActivityTaskStartedEventAttributes(
+            ActivityTaskStartedEventAttributes {
+                scheduled_event_id,
+                ..Default::default()
+            },
+        ))
     }
 
     pub fn add_activity_task_completed(
         &mut self,
         scheduled_event_id: i64,
         started_event_id: i64,
         payload: Payload,
     ) {
-        self.add(
-            EventType::ActivityTaskCompleted,
-            history_event::Attributes::ActivityTaskCompletedEventAttributes(
-                ActivityTaskCompletedEventAttributes {
-                    scheduled_event_id,
-                    started_event_id,
-                    result: vec![payload].into_payloads(),
-                    ..Default::default()
-                },
-            ),
-        );
+        self.add(ActivityTaskCompletedEventAttributes {
+            scheduled_event_id,
+            started_event_id,
+            result: vec![payload].into_payloads(),
+            ..Default::default()
+        });
     }
 
     pub fn add_activity_task_cancel_requested(&mut self, scheduled_event_id: i64) {
         let attrs = ActivityTaskCancelRequestedEventAttributes {
             scheduled_event_id,
             workflow_task_completed_event_id: self.previous_task_completed_id,
         };
@@ -254,36 +237,33 @@
             new_run_id: new_run_id.into(),
             ..Default::default()
         };
         self.build_and_push_event(EventType::WorkflowTaskFailed, attrs.into());
     }
 
     pub fn add_timer_fired(&mut self, timer_started_evt_id: i64, timer_id: String) {
-        self.add(
-            EventType::TimerFired,
-            history_event::Attributes::TimerFiredEventAttributes(TimerFiredEventAttributes {
-                started_event_id: timer_started_evt_id,
-                timer_id,
-            }),
-        );
+        self.add(TimerFiredEventAttributes {
+            started_event_id: timer_started_evt_id,
+            timer_id,
+        });
     }
 
     pub fn add_we_signaled(&mut self, signal_name: &str, payloads: Vec<Payload>) {
         let attrs = WorkflowExecutionSignaledEventAttributes {
             signal_name: signal_name.to_string(),
             input: Some(Payloads { payloads }),
             ..Default::default()
         };
         self.build_and_push_event(EventType::WorkflowExecutionSignaled, attrs.into());
     }
 
     pub fn add_has_change_marker(&mut self, patch_id: &str, deprecated: bool) {
         let attrs = MarkerRecordedEventAttributes {
             marker_name: PATCH_MARKER_NAME.to_string(),
-            details: build_has_change_marker_details(patch_id, deprecated),
+            details: build_has_change_marker_details(patch_id, deprecated).unwrap(),
             workflow_task_completed_event_id: self.previous_task_completed_id,
             ..Default::default()
         };
         self.build_and_push_event(EventType::MarkerRecorded, attrs.into());
     }
 
     pub fn add_local_activity_marker(
@@ -294,15 +274,15 @@
         failure: Option<Failure>,
         detail_mutator: impl FnOnce(&mut LocalActivityMarkerData),
     ) {
         let mut lamd = LocalActivityMarkerData {
             seq,
             attempt: 1,
             activity_id: activity_id.to_string(),
-            activity_type: "some_act_type".to_string(),
+            activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
             complete_time: None,
             backoff: None,
             original_schedule_time: None,
         };
         detail_mutator(&mut lamd);
         let attrs = MarkerRecordedEventAttributes {
             marker_name: LOCAL_ACTIVITY_MARKER_NAME.to_string(),
@@ -365,28 +345,24 @@
 
     pub fn add_signal_wf(
         &mut self,
         signal_name: impl Into<String>,
         workflow_id: impl Into<String>,
         run_id: impl Into<String>,
     ) -> i64 {
-        let attrs = SignalExternalWorkflowExecutionInitiatedEventAttributes {
+        self.add(SignalExternalWorkflowExecutionInitiatedEventAttributes {
             workflow_task_completed_event_id: self.previous_task_completed_id,
             workflow_execution: Some(WorkflowExecution {
                 workflow_id: workflow_id.into(),
                 run_id: run_id.into(),
             }),
             signal_name: signal_name.into(),
             control: "".to_string(),
             ..Default::default()
-        };
-        self.add_get_event_id(
-            EventType::SignalExternalWorkflowExecutionInitiated,
-            Some(attrs.into()),
-        )
+        })
     }
 
     pub fn add_external_signal_completed(&mut self, initiated_id: i64) {
         let attrs = ExternalWorkflowExecutionSignaledEventAttributes {
             initiated_event_id: initiated_id,
             ..Default::default()
         };
@@ -401,26 +377,24 @@
         self.build_and_push_event(
             EventType::SignalExternalWorkflowExecutionFailed,
             attrs.into(),
         );
     }
 
     pub fn add_cancel_external_wf(&mut self, execution: NamespacedWorkflowExecution) -> i64 {
-        let attrs = RequestCancelExternalWorkflowExecutionInitiatedEventAttributes {
-            workflow_task_completed_event_id: self.previous_task_completed_id,
-            namespace: execution.namespace,
-            workflow_execution: Some(WorkflowExecution {
-                workflow_id: execution.workflow_id,
-                run_id: execution.run_id,
-            }),
-            ..Default::default()
-        };
-        self.add_get_event_id(
-            EventType::RequestCancelExternalWorkflowExecutionInitiated,
-            Some(attrs.into()),
+        self.add(
+            RequestCancelExternalWorkflowExecutionInitiatedEventAttributes {
+                workflow_task_completed_event_id: self.previous_task_completed_id,
+                namespace: execution.namespace,
+                workflow_execution: Some(WorkflowExecution {
+                    workflow_id: execution.workflow_id,
+                    run_id: execution.run_id,
+                }),
+                ..Default::default()
+            },
         )
     }
 
     pub fn add_cancel_external_wf_completed(&mut self, initiated_id: i64) {
         let attrs = ExternalWorkflowExecutionCancelRequestedEventAttributes {
             initiated_event_id: initiated_id,
             ..Default::default()
@@ -441,15 +415,28 @@
             attrs.into(),
         );
     }
 
     pub fn add_wfe_started_with_wft_timeout(&mut self, dur: Duration) {
         let mut wesattrs = default_wes_attribs();
         wesattrs.workflow_task_timeout = Some(dur.try_into().unwrap());
-        self.add(EventType::WorkflowExecutionStarted, wesattrs.into());
+        self.add(wesattrs);
+    }
+
+    pub fn add_upsert_search_attrs_for_patch(&mut self, attribs: &[String]) {
+        let mut indexed_fields = HashMap::new();
+        indexed_fields.insert(
+            "TemporalChangeVersion".to_string(),
+            attribs.as_json_payload().unwrap(),
+        );
+        let attrs = UpsertWorkflowSearchAttributesEventAttributes {
+            workflow_task_completed_event_id: self.previous_task_completed_id,
+            search_attributes: Some(SearchAttributes { indexed_fields }),
+        };
+        self.build_and_push_event(EventType::UpsertWorkflowSearchAttributes, attrs.into())
     }
 
     pub fn get_orig_run_id(&self) -> &str {
         &self.original_run_id
     }
 
     /// Iterates over the events in this builder to return a [HistoryInfo] including events up to
@@ -495,14 +482,45 @@
         let he = self
             .events
             .get_mut((event_id - 1) as usize)
             .expect("Event must be present");
         modifier(he);
     }
 
+    /// Sets internal patches which should appear in the first WFT complete event
+    pub fn set_flags_first_wft(&mut self, core: &[u32], lang: &[u32]) {
+        Self::set_flags(self.events.iter_mut(), core, lang)
+    }
+
+    /// Sets internal patches which should appear in the most recent complete event
+    pub fn set_flags_last_wft(&mut self, core: &[u32], lang: &[u32]) {
+        Self::set_flags(self.events.iter_mut().rev(), core, lang)
+    }
+
+    fn set_flags<'a>(
+        mut events: impl Iterator<Item = &'a mut HistoryEvent>,
+        core: &[u32],
+        lang: &[u32],
+    ) {
+        if let Some(first_attrs) = events.find_map(|e| {
+            if let Some(Attributes::WorkflowTaskCompletedEventAttributes(a)) = e.attributes.as_mut()
+            {
+                Some(a)
+            } else {
+                None
+            }
+        }) {
+            let sdk_dat = first_attrs
+                .sdk_metadata
+                .get_or_insert_with(Default::default);
+            sdk_dat.core_used_flags = core.to_vec();
+            sdk_dat.lang_used_flags = lang.to_vec();
+        }
+    }
+
     fn build_and_push_event(&mut self, event_type: EventType, attribs: Attributes) {
         self.current_event_id += 1;
         let evt = HistoryEvent {
             event_type: event_type as i32,
             event_id: self.current_event_id,
             event_time: Some(SystemTime::now().into()),
             attributes: Some(attribs),
@@ -544,7 +562,14 @@
         task_queue: Some(TaskQueue {
             name: "q".to_string(),
             kind: TaskQueueKind::Normal as i32,
         }),
         ..Default::default()
     }
 }
+
+pub fn default_act_sched() -> ScheduleActivity {
+    ScheduleActivity {
+        activity_type: DEFAULT_ACTIVITY_TYPE.to_string(),
+        ..Default::default()
+    }
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/history_info.rs`

 * *Files 7% similar despite different names*

```diff
@@ -132,14 +132,18 @@
         self.events.drain(0..last_complete_ix);
     }
 
     pub fn events(&self) -> &[HistoryEvent] {
         &self.events
     }
 
+    pub fn into_events(self) -> Vec<HistoryEvent> {
+        self.events
+    }
+
     /// Extract run id from the workflow execution started attributes.
     pub fn orig_run_id(&self) -> &str {
         &self.wf_exe_started_attrs.original_execution_run_id
     }
 
     /// Return total workflow task count in this history
     pub const fn wf_task_count(&self) -> usize {
@@ -175,14 +179,19 @@
         }
     }
 
     /// Returns the last workflow task started event id
     pub fn previous_started_event_id(&self) -> i64 {
         self.previous_started_event_id
     }
+
+    /// Returns the current workflow task started event id
+    pub fn workflow_task_started_event_id(&self) -> i64 {
+        self.workflow_task_started_event_id
+    }
 }
 
 impl From<HistoryInfo> for History {
     fn from(i: HistoryInfo) -> Self {
         Self { events: i.events }
     }
 }
@@ -200,15 +209,15 @@
 mod tests {
     use crate::{temporal::api::enums::v1::EventType, TestHistoryBuilder};
 
     fn single_timer(timer_id: &str) -> TestHistoryBuilder {
         let mut t = TestHistoryBuilder::default();
         t.add_by_type(EventType::WorkflowExecutionStarted);
         t.add_full_wf_task();
-        let timer_started_event_id = t.add_get_event_id(EventType::TimerStarted, None);
+        let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
         t.add_timer_fired(timer_started_event_id, timer_id.to_string());
         t.add_workflow_task_scheduled_and_started();
         t
     }
 
     #[test]
     fn history_info_constructs_properly() {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/lib.rs`

 * *Files 10% similar despite different names*

```diff
@@ -8,31 +8,42 @@
 #[cfg(feature = "history_builders")]
 mod history_builder;
 #[cfg(feature = "history_builders")]
 mod history_info;
 mod task_token;
 
 #[cfg(feature = "history_builders")]
-pub use history_builder::{default_wes_attribs, TestHistoryBuilder, DEFAULT_WORKFLOW_TYPE};
+pub use history_builder::{
+    default_act_sched, default_wes_attribs, TestHistoryBuilder, DEFAULT_ACTIVITY_TYPE,
+    DEFAULT_WORKFLOW_TYPE,
+};
 #[cfg(feature = "history_builders")]
 pub use history_info::HistoryInfo;
 pub use task_token::TaskToken;
 
+pub static ENCODING_PAYLOAD_KEY: &str = "encoding";
+pub static JSON_ENCODING_VAL: &str = "json/plain";
+pub static PATCHED_MARKER_DETAILS_KEY: &str = "patch-data";
+
 #[allow(clippy::large_enum_variant, clippy::derive_partial_eq_without_eq)]
 // I'd prefer not to do this, but there are some generated things that just don't need it.
 #[allow(missing_docs)]
 pub mod coresdk {
     //! Contains all protobufs relating to communication between core and lang-specific SDKs
 
     tonic::include_proto!("coresdk");
 
-    use crate::temporal::api::{
-        common::v1::{ActivityType, Payload, Payloads, WorkflowExecution},
-        failure::v1::{failure::FailureInfo, ApplicationFailureInfo, Failure},
-        workflowservice::v1::PollActivityTaskQueueResponse,
+    use crate::{
+        temporal::api::{
+            common::v1::{Payload, Payloads, WorkflowExecution},
+            enums::v1::WorkflowTaskFailedCause,
+            failure::v1::{failure::FailureInfo, ApplicationFailureInfo, Failure},
+            workflowservice::v1::PollActivityTaskQueueResponse,
+        },
+        ENCODING_PAYLOAD_KEY, JSON_ENCODING_VAL,
     };
     use activity_task::ActivityTask;
     use serde::{Deserialize, Serialize};
     use std::{
         collections::HashMap,
         convert::TryFrom,
         fmt::{Display, Formatter},
@@ -63,30 +74,33 @@
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(
                     f,
                     "ActivityTaskCompletion(token: {}",
                     fmt_tt(&self.task_token),
                 )?;
                 if let Some(r) = self.result.as_ref().and_then(|r| r.status.as_ref()) {
-                    write!(f, ", {}", r)?;
+                    write!(f, ", {r}")?;
                 } else {
                     write!(f, ", missing result")?;
                 }
                 write!(f, ")")
             }
         }
     }
     #[allow(clippy::module_inception)]
     pub mod activity_result {
         tonic::include_proto!("coresdk.activity_result");
         use super::super::temporal::api::{
             common::v1::Payload,
             failure::v1::{failure, CanceledFailureInfo, Failure as APIFailure},
         };
-        use crate::temporal::api::{enums::v1::TimeoutType, failure::v1::TimeoutFailureInfo};
+        use crate::{
+            coresdk::activity_result::activity_resolution::Status,
+            temporal::api::enums::v1::TimeoutType,
+        };
         use activity_execution_result as aer;
         use std::fmt::{Display, Formatter};
 
         impl ActivityExecutionResult {
             pub const fn ok(result: Payload) -> Self {
                 Self {
                     status: Some(aer::Status::Completed(Success {
@@ -121,54 +135,54 @@
         }
 
         impl Display for aer::Status {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "ActivityExecutionResult(")?;
                 match self {
                     aer::Status::Completed(v) => {
-                        write!(f, "{})", v)
+                        write!(f, "{v})")
                     }
                     aer::Status::Failed(v) => {
-                        write!(f, "{})", v)
+                        write!(f, "{v})")
                     }
                     aer::Status::Cancelled(v) => {
-                        write!(f, "{})", v)
+                        write!(f, "{v})")
                     }
                     aer::Status::WillCompleteAsync(_) => {
                         write!(f, "Will complete async)")
                     }
                 }
             }
         }
 
         impl Display for Success {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "Success(")?;
                 if let Some(ref v) = self.result {
-                    write!(f, "{}", v)?;
+                    write!(f, "{v}")?;
                 }
                 write!(f, ")")
             }
         }
 
         impl Display for Failure {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "Failure(")?;
                 if let Some(ref v) = self.failure {
-                    write!(f, "{}", v)?;
+                    write!(f, "{v}")?;
                 }
                 write!(f, ")")
             }
         }
 
         impl Display for Cancellation {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "Cancellation(")?;
                 if let Some(ref v) = self.failure {
-                    write!(f, "{}", v)?;
+                    write!(f, "{v}")?;
                 }
                 write!(f, ")")
             }
         }
 
         impl From<Result<Payload, APIFailure>> for ActivityExecutionResult {
             fn from(r: Result<Payload, APIFailure>) -> Self {
@@ -181,102 +195,112 @@
             }
         }
 
         impl ActivityResolution {
             pub fn unwrap_ok_payload(self) -> Payload {
                 match self.status.unwrap() {
                     activity_resolution::Status::Completed(c) => c.result.unwrap(),
-                    _ => panic!("Activity was not successful"),
+                    e => panic!("Activity was not successful: {e:?}"),
                 }
             }
 
             pub fn completed_ok(&self) -> bool {
                 matches!(self.status, Some(activity_resolution::Status::Completed(_)))
             }
 
             pub fn failed(&self) -> bool {
                 matches!(self.status, Some(activity_resolution::Status::Failed(_)))
             }
 
-            pub fn timed_out(&self) -> Option<crate::temporal::api::enums::v1::TimeoutType> {
+            pub fn timed_out(&self) -> Option<TimeoutType> {
                 match self.status {
                     Some(activity_resolution::Status::Failed(Failure {
                         failure: Some(ref f),
                     })) => f
                         .is_timeout()
                         .or_else(|| f.cause.as_ref().and_then(|c| c.is_timeout())),
                     _ => None,
                 }
             }
 
             pub fn cancelled(&self) -> bool {
                 matches!(self.status, Some(activity_resolution::Status::Cancelled(_)))
             }
+
+            /// If this resolution is any kind of failure, return the inner failure details. Panics
+            /// if the activity succeeded, is in backoff, or this resolution is malformed.
+            pub fn unwrap_failure(self) -> APIFailure {
+                match self.status.unwrap() {
+                    Status::Failed(f) => f.failure.unwrap(),
+                    Status::Cancelled(c) => c.failure.unwrap(),
+                    _ => panic!("Actvity did not fail"),
+                }
+            }
         }
 
         impl Cancellation {
-            pub fn from_details(payload: Option<Payload>) -> Self {
+            /// Create a cancellation result from some payload. This is to be used when telling Core
+            /// that an activity completed as cancelled.
+            pub fn from_details(details: Option<Payload>) -> Self {
                 Cancellation {
                     failure: Some(APIFailure {
                         message: "Activity cancelled".to_string(),
                         failure_info: Some(failure::FailureInfo::CanceledFailureInfo(
                             CanceledFailureInfo {
-                                details: payload.map(Into::into),
-                            },
-                        )),
-                        ..Default::default()
-                    }),
-                }
-            }
-        }
-
-        impl Failure {
-            pub fn timeout(timeout_type: TimeoutType) -> Self {
-                Failure {
-                    failure: Some(APIFailure {
-                        message: "Activity timed out".to_string(),
-                        failure_info: Some(failure::FailureInfo::TimeoutFailureInfo(
-                            TimeoutFailureInfo {
-                                timeout_type: timeout_type as i32,
-                                last_heartbeat_details: None,
+                                details: details.map(Into::into),
                             },
                         )),
                         ..Default::default()
                     }),
                 }
             }
         }
     }
 
     pub mod common {
         tonic::include_proto!("coresdk.common");
         use super::external_data::LocalActivityMarkerData;
         use crate::{
-            coresdk::{AsJsonPayloadExt, IntoPayloadsExt},
+            coresdk::{
+                external_data::PatchedMarkerData, AsJsonPayloadExt, FromJsonPayloadExt,
+                IntoPayloadsExt,
+            },
             temporal::api::common::v1::{Payload, Payloads},
+            PATCHED_MARKER_DETAILS_KEY,
         };
         use std::collections::HashMap;
 
         pub fn build_has_change_marker_details(
-            patch_id: &str,
+            patch_id: impl Into<String>,
             deprecated: bool,
-        ) -> HashMap<String, Payloads> {
+        ) -> anyhow::Result<HashMap<String, Payloads>> {
             let mut hm = HashMap::new();
-            hm.insert("patch_id".to_string(), patch_id.as_bytes().into());
-            let deprecated = deprecated as u8;
-            hm.insert("deprecated".to_string(), (&[deprecated]).into());
-            hm
+            let encoded = PatchedMarkerData {
+                id: patch_id.into(),
+                deprecated,
+            }
+            .as_json_payload()?;
+            hm.insert(PATCHED_MARKER_DETAILS_KEY.to_string(), encoded.into());
+            Ok(hm)
         }
 
         pub fn decode_change_marker_details(
             details: &HashMap<String, Payloads>,
         ) -> Option<(String, bool)> {
-            let name =
-                std::str::from_utf8(&details.get("patch_id")?.payloads.first()?.data).ok()?;
-            let deprecated = *details.get("deprecated")?.payloads.first()?.data.first()? != 0;
+            // We used to write change markers with plain bytes, so try to decode if they are
+            // json first, then fall back to that.
+            if let Some(cd) = details.get(PATCHED_MARKER_DETAILS_KEY) {
+                let decoded = PatchedMarkerData::from_json_payload(cd.payloads.first()?).ok()?;
+                return Some((decoded.id, decoded.deprecated));
+            }
+
+            let id_entry = details.get("patch_id")?.payloads.first()?;
+            let deprecated_entry = details.get("deprecated")?.payloads.first()?;
+            let name = std::str::from_utf8(&id_entry.data).ok()?;
+            let deprecated = *deprecated_entry.data.first()? != 0;
             Some((name.to_string(), deprecated))
         }
 
         pub fn build_local_activity_marker_details(
             metadata: LocalActivityMarkerData,
             result: Option<Payload>,
         ) -> HashMap<String, Payloads> {
@@ -313,15 +337,15 @@
             let data = extract_local_activity_marker_data(details);
             let result = details.remove("result").and_then(|mut p| p.payloads.pop());
             (data, result)
         }
     }
 
     pub mod external_data {
-        use prost_types::{Duration, Timestamp};
+        use prost_wkt_types::{Duration, Timestamp};
         use serde::{Deserialize, Deserializer, Serialize, Serializer};
         tonic::include_proto!("coresdk.external_data");
 
         // Buncha hullaballoo because prost types aren't serde compat.
         // See https://github.com/tokio-rs/prost/issues/75 which hilariously Chad opened ages ago
 
         #[derive(Serialize, Deserialize)]
@@ -392,23 +416,24 @@
         use crate::{
             coresdk::{
                 common::NamespacedWorkflowExecution,
                 workflow_activation::remove_from_cache::EvictionReason, FromPayloadsExt,
             },
             temporal::api::{
                 common::v1::Header,
+                enums::v1::WorkflowTaskFailedCause,
                 history::v1::{
                     WorkflowExecutionCancelRequestedEventAttributes,
                     WorkflowExecutionSignaledEventAttributes,
                     WorkflowExecutionStartedEventAttributes,
                 },
                 query::v1::WorkflowQuery,
             },
         };
-        use prost_types::Timestamp;
+        use prost_wkt_types::Timestamp;
         use std::{
             collections::HashMap,
             fmt::{Display, Formatter},
         };
 
         tonic::include_proto!("coresdk.workflow_activation");
 
@@ -424,14 +449,15 @@
                 history_length: 0,
                 jobs: vec![WorkflowActivationJob::from(
                     workflow_activation_job::Variant::RemoveFromCache(RemoveFromCache {
                         message,
                         reason: reason as i32,
                     }),
                 )],
+                available_internal_flags: vec![],
             }
         }
 
         pub fn query_to_job(id: String, q: WorkflowQuery) -> QueryWorkflow {
             QueryWorkflow {
                 query_id: id,
                 query_type: q.query_type,
@@ -487,15 +513,26 @@
                 );
                 self.jobs.push(evict_job);
             }
         }
 
         impl Display for EvictionReason {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
-                write!(f, "{:?}", self)
+                write!(f, "{self:?}")
+            }
+        }
+
+        impl From<EvictionReason> for WorkflowTaskFailedCause {
+            fn from(value: EvictionReason) -> Self {
+                match value {
+                    EvictionReason::Nondeterminism => {
+                        WorkflowTaskFailedCause::NonDeterministicError
+                    }
+                    _ => WorkflowTaskFailedCause::Unspecified,
+                }
             }
         }
 
         impl Display for WorkflowActivation {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "WorkflowActivation(")?;
                 write!(f, "run_id: {}, ", self.run_id)?;
@@ -513,15 +550,15 @@
             }
         }
 
         impl Display for WorkflowActivationJob {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 match &self.variant {
                     None => write!(f, "empty"),
-                    Some(v) => write!(f, "{}", v),
+                    Some(v) => write!(f, "{v}"),
                 }
             }
         }
 
         impl Display for workflow_activation_job::Variant {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 match self {
@@ -636,29 +673,32 @@
                 search_attributes: attrs.search_attributes,
                 start_time: Some(start_time),
             }
         }
     }
 
     pub mod workflow_completion {
-        use crate::temporal::api::failure;
+        use crate::temporal::api::{enums::v1::WorkflowTaskFailedCause, failure};
         tonic::include_proto!("coresdk.workflow_completion");
 
         impl workflow_activation_completion::Status {
             pub const fn is_success(&self) -> bool {
                 match &self {
                     Self::Successful(_) => true,
                     Self::Failed(_) => false,
                 }
             }
         }
 
         impl From<failure::v1::Failure> for Failure {
             fn from(f: failure::v1::Failure) -> Self {
-                Failure { failure: Some(f) }
+                Failure {
+                    failure: Some(f),
+                    force_cause: WorkflowTaskFailedCause::Unspecified as i32,
+                }
             }
         }
     }
 
     pub mod child_workflow {
         tonic::include_proto!("coresdk.child_workflow");
     }
@@ -669,15 +709,15 @@
         use crate::temporal::api::{common::v1::Payloads, enums::v1::QueryResultType};
         use std::fmt::{Display, Formatter};
 
         impl Display for WorkflowCommand {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 match &self.variant {
                     None => write!(f, "Empty"),
-                    Some(v) => write!(f, "{}", v),
+                    Some(v) => write!(f, "{v}"),
                 }
             }
         }
 
         impl Display for StartTimer {
             fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                 write!(f, "StartTimer({})", self.seq)
@@ -849,15 +889,18 @@
         fn from(a: workflow_activation_job::Variant) -> Self {
             Self { variant: Some(a) }
         }
     }
 
     impl From<Vec<WorkflowCommand>> for workflow_completion::Success {
         fn from(v: Vec<WorkflowCommand>) -> Self {
-            Self { commands: v }
+            Self {
+                commands: v,
+                used_internal_flags: vec![],
+            }
         }
     }
 
     impl From<workflow_command::Variant> for WorkflowCommand {
         fn from(v: workflow_command::Variant) -> Self {
             Self { variant: Some(v) }
         }
@@ -903,14 +946,15 @@
 
         pub fn fail(run_id: impl Into<String>, failure: Failure) -> Self {
             Self {
                 run_id: run_id.into(),
                 status: Some(workflow_activation_completion::Status::Failed(
                     workflow_completion::Failure {
                         failure: Some(failure),
+                        force_cause: WorkflowTaskFailedCause::Unspecified as i32,
                     },
                 )),
             }
         }
 
         /// Returns true if the activation has either a fail, continue, cancel, or complete workflow
         /// execution command in it.
@@ -986,14 +1030,20 @@
         /// Returns true if the activation completion is a success with no commands
         pub fn is_empty(&self) -> bool {
             if let Some(workflow_activation_completion::Status::Successful(s)) = &self.status {
                 return s.commands.is_empty();
             }
             false
         }
+
+        pub fn add_internal_flags(&mut self, patch: u32) {
+            if let Some(workflow_activation_completion::Status::Successful(s)) = &mut self.status {
+                s.used_internal_flags.push(patch);
+            }
+        }
     }
 
     /// Makes converting outgoing lang commands into [WorkflowActivationCompletion]s easier
     pub trait IntoCompletion {
         /// The conversion function
         fn into_completion(self, run_id: String) -> WorkflowActivationCompletion;
     }
@@ -1023,30 +1073,30 @@
             write!(
                 f,
                 "WorkflowActivationCompletion(run_id: {}, status: ",
                 &self.run_id
             )?;
             match &self.status {
                 None => write!(f, "empty")?,
-                Some(s) => write!(f, "{}", s)?,
+                Some(s) => write!(f, "{s}")?,
             };
             write!(f, ")")
         }
     }
 
     impl Display for workflow_activation_completion::Status {
         fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
             match self {
                 workflow_activation_completion::Status::Successful(
-                    workflow_completion::Success { commands },
+                    workflow_completion::Success { commands, .. },
                 ) => {
                     write!(f, "Success(")?;
                     let mut written = 0;
                     for c in commands {
-                        write!(f, "{} ", c)?;
+                        write!(f, "{c} ")?;
                         written += 1;
                         if written >= 10 && written < commands.len() {
                             write!(f, "... {} more", commands.len() - written)?;
                             break;
                         }
                     }
                     write!(f, ")")
@@ -1090,26 +1140,14 @@
                         is_local: false,
                     },
                 )),
             }
         }
     }
 
-    impl From<String> for ActivityType {
-        fn from(name: String) -> Self {
-            Self { name }
-        }
-    }
-
-    impl From<ActivityType> for String {
-        fn from(at: ActivityType) -> Self {
-            at.name
-        }
-    }
-
     impl Failure {
         pub fn is_timeout(&self) -> Option<crate::temporal::api::enums::v1::TimeoutType> {
             match &self.failure_info {
                 Some(FailureInfo::TimeoutFailureInfo(ti)) => Some(ti.timeout_type()),
                 _ => None,
             }
         }
@@ -1290,15 +1328,18 @@
     impl<T> AsJsonPayloadExt for T
     where
         T: Serialize,
     {
         fn as_json_payload(&self) -> anyhow::Result<Payload> {
             let as_json = serde_json::to_string(self)?;
             let mut metadata = HashMap::new();
-            metadata.insert("encoding".to_string(), b"json/plain".to_vec());
+            metadata.insert(
+                ENCODING_PAYLOAD_KEY.to_string(),
+                JSON_ENCODING_VAL.as_bytes().to_vec(),
+            );
             Ok(Payload {
                 metadata,
                 data: as_json.into_bytes(),
             })
         }
     }
 
@@ -1306,18 +1347,15 @@
         fn from_json_payload(payload: &Payload) -> Result<Self, PayloadDeserializeErr>;
     }
     impl<T> FromJsonPayloadExt for T
     where
         T: for<'de> Deserialize<'de>,
     {
         fn from_json_payload(payload: &Payload) -> Result<Self, PayloadDeserializeErr> {
-            if !matches!(
-                payload.metadata.get("encoding").map(|v| v.as_slice()),
-                Some(b"json/plain")
-            ) {
+            if !payload.is_json_payload() {
                 return Err(PayloadDeserializeErr::DeserializerDoesNotHandle);
             }
             let payload_str = std::str::from_utf8(&payload.data).map_err(anyhow::Error::from)?;
             Ok(serde_json::from_str(payload_str).map_err(anyhow::Error::from)?)
         }
     }
 
@@ -1569,55 +1607,64 @@
                         )
                     }
                 }
             }
         }
         pub mod common {
             pub mod v1 {
+                use crate::{ENCODING_PAYLOAD_KEY, JSON_ENCODING_VAL};
+                use base64::{prelude::BASE64_STANDARD, Engine};
                 use std::{
                     collections::HashMap,
                     fmt::{Display, Formatter},
                 };
                 tonic::include_proto!("temporal.api.common.v1");
 
                 impl<T> From<T> for Payload
                 where
                     T: AsRef<[u8]>,
                 {
                     fn from(v: T) -> Self {
                         // TODO: Set better encodings, whole data converter deal. Setting anything
                         //  for now at least makes it show up in the web UI.
                         let mut metadata = HashMap::new();
-                        metadata.insert("encoding".to_string(), b"binary/plain".to_vec());
+                        metadata.insert(ENCODING_PAYLOAD_KEY.to_string(), b"binary/plain".to_vec());
                         Self {
                             metadata,
                             data: v.as_ref().to_vec(),
                         }
                     }
                 }
 
                 impl Payload {
                     // Is its own function b/c asref causes implementation conflicts
                     pub fn as_slice(&self) -> &[u8] {
                         self.data.as_slice()
                     }
+
+                    pub fn is_json_payload(&self) -> bool {
+                        self.metadata
+                            .get(ENCODING_PAYLOAD_KEY)
+                            .map(|v| v.as_slice() == JSON_ENCODING_VAL.as_bytes())
+                            .unwrap_or_default()
+                    }
                 }
 
                 impl Display for Payload {
                     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                         if self.data.len() > 64 {
                             let mut windows = self.data.as_slice().windows(32);
                             write!(
                                 f,
                                 "[{}..{}]",
-                                base64::encode(windows.next().unwrap_or_default()),
-                                base64::encode(windows.next_back().unwrap_or_default())
+                                BASE64_STANDARD.encode(windows.next().unwrap_or_default()),
+                                BASE64_STANDARD.encode(windows.next_back().unwrap_or_default())
                             )
                         } else {
-                            write!(f, "[{}]", base64::encode(&self.data))
+                            write!(f, "[{}]", BASE64_STANDARD.encode(&self.data))
                         }
                     }
                 }
 
                 impl Display for Header {
                     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                         write!(f, "Header(")?;
@@ -1653,14 +1700,34 @@
                 impl From<HashMap<String, Payload>> for SearchAttributes {
                     fn from(h: HashMap<String, Payload>) -> Self {
                         Self {
                             indexed_fields: h.into_iter().map(|(k, v)| (k, v.into())).collect(),
                         }
                     }
                 }
+
+                impl From<String> for ActivityType {
+                    fn from(name: String) -> Self {
+                        Self { name }
+                    }
+                }
+
+                impl From<&str> for ActivityType {
+                    fn from(name: &str) -> Self {
+                        Self {
+                            name: name.to_string(),
+                        }
+                    }
+                }
+
+                impl From<ActivityType> for String {
+                    fn from(at: ActivityType) -> Self {
+                        at.name
+                    }
+                }
             }
         }
         pub mod enums {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.enums.v1");
             }
         }
@@ -1718,14 +1785,15 @@
                             | EventType::MarkerRecorded
                             | EventType::RequestCancelExternalWorkflowExecutionInitiated
                             | EventType::SignalExternalWorkflowExecutionInitiated
                             | EventType::StartChildWorkflowExecutionInitiated
                             | EventType::TimerCanceled
                             | EventType::TimerStarted
                             | EventType::UpsertWorkflowSearchAttributes
+                            | EventType::WorkflowPropertiesModified
                             | EventType::WorkflowExecutionCanceled
                             | EventType::WorkflowExecutionCompleted
                             | EventType::WorkflowExecutionContinuedAsNew
                             | EventType::WorkflowExecutionFailed => true,
                             _ => false,
                         })
                     }
@@ -1776,58 +1844,127 @@
                             EventType::WorkflowExecutionFailed => true,
                             EventType::WorkflowExecutionTimedOut => true,
                             EventType::WorkflowExecutionContinuedAsNew => true,
                             EventType::WorkflowExecutionTerminated => true,
                             _ => false,
                         }
                     }
+
+                    pub fn is_wft_closed_event(&self) -> bool {
+                        match self.event_type() {
+                            EventType::WorkflowTaskCompleted => true,
+                            EventType::WorkflowTaskFailed => true,
+                            EventType::WorkflowTaskTimedOut => true,
+                            _ => false,
+                        }
+                    }
                 }
 
                 impl Display for HistoryEvent {
                     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
                         write!(
                             f,
                             "HistoryEvent(id: {}, {:?})",
                             self.event_id,
                             EventType::from_i32(self.event_type)
                         )
                     }
                 }
-            }
-        }
-        pub mod interaction {
-            pub mod v1 {
-                tonic::include_proto!("temporal.api.interaction.v1");
+
+                impl Attributes {
+                    pub fn event_type(&self) -> EventType {
+                        // I just absolutely _love_ this
+                        match self {
+                            Attributes::WorkflowExecutionStartedEventAttributes(_) => {EventType::WorkflowExecutionStarted}
+                            Attributes::WorkflowExecutionCompletedEventAttributes(_) => {EventType::WorkflowExecutionCompleted}
+                            Attributes::WorkflowExecutionFailedEventAttributes(_) => {EventType::WorkflowExecutionFailed}
+                            Attributes::WorkflowExecutionTimedOutEventAttributes(_) => {EventType::WorkflowExecutionTimedOut}
+                            Attributes::WorkflowTaskScheduledEventAttributes(_) => {EventType::WorkflowTaskScheduled}
+                            Attributes::WorkflowTaskStartedEventAttributes(_) => {EventType::WorkflowTaskStarted}
+                            Attributes::WorkflowTaskCompletedEventAttributes(_) => {EventType::WorkflowTaskCompleted}
+                            Attributes::WorkflowTaskTimedOutEventAttributes(_) => {EventType::WorkflowTaskTimedOut}
+                            Attributes::WorkflowTaskFailedEventAttributes(_) => {EventType::WorkflowTaskFailed}
+                            Attributes::ActivityTaskScheduledEventAttributes(_) => {EventType::ActivityTaskScheduled}
+                            Attributes::ActivityTaskStartedEventAttributes(_) => {EventType::ActivityTaskStarted}
+                            Attributes::ActivityTaskCompletedEventAttributes(_) => {EventType::ActivityTaskCompleted}
+                            Attributes::ActivityTaskFailedEventAttributes(_) => {EventType::ActivityTaskFailed}
+                            Attributes::ActivityTaskTimedOutEventAttributes(_) => {EventType::ActivityTaskTimedOut}
+                            Attributes::TimerStartedEventAttributes(_) => {EventType::TimerStarted}
+                            Attributes::TimerFiredEventAttributes(_) => {EventType::TimerFired}
+                            Attributes::ActivityTaskCancelRequestedEventAttributes(_) => {EventType::ActivityTaskCancelRequested}
+                            Attributes::ActivityTaskCanceledEventAttributes(_) => {EventType::ActivityTaskCanceled}
+                            Attributes::TimerCanceledEventAttributes(_) => {EventType::TimerCanceled}
+                            Attributes::MarkerRecordedEventAttributes(_) => {EventType::MarkerRecorded}
+                            Attributes::WorkflowExecutionSignaledEventAttributes(_) => {EventType::WorkflowExecutionSignaled}
+                            Attributes::WorkflowExecutionTerminatedEventAttributes(_) => {EventType::WorkflowExecutionTerminated}
+                            Attributes::WorkflowExecutionCancelRequestedEventAttributes(_) => {EventType::WorkflowExecutionCancelRequested}
+                            Attributes::WorkflowExecutionCanceledEventAttributes(_) => {EventType::WorkflowExecutionCanceled}
+                            Attributes::RequestCancelExternalWorkflowExecutionInitiatedEventAttributes(_) => {EventType::RequestCancelExternalWorkflowExecutionInitiated}
+                            Attributes::RequestCancelExternalWorkflowExecutionFailedEventAttributes(_) => {EventType::RequestCancelExternalWorkflowExecutionFailed}
+                            Attributes::ExternalWorkflowExecutionCancelRequestedEventAttributes(_) => {EventType::ExternalWorkflowExecutionCancelRequested}
+                            Attributes::WorkflowExecutionContinuedAsNewEventAttributes(_) => {EventType::WorkflowExecutionContinuedAsNew}
+                            Attributes::StartChildWorkflowExecutionInitiatedEventAttributes(_) => {EventType::StartChildWorkflowExecutionInitiated}
+                            Attributes::StartChildWorkflowExecutionFailedEventAttributes(_) => {EventType::StartChildWorkflowExecutionFailed}
+                            Attributes::ChildWorkflowExecutionStartedEventAttributes(_) => {EventType::ChildWorkflowExecutionStarted}
+                            Attributes::ChildWorkflowExecutionCompletedEventAttributes(_) => {EventType::ChildWorkflowExecutionCompleted}
+                            Attributes::ChildWorkflowExecutionFailedEventAttributes(_) => {EventType::ChildWorkflowExecutionFailed}
+                            Attributes::ChildWorkflowExecutionCanceledEventAttributes(_) => {EventType::ChildWorkflowExecutionCanceled}
+                            Attributes::ChildWorkflowExecutionTimedOutEventAttributes(_) => {EventType::ChildWorkflowExecutionTimedOut}
+                            Attributes::ChildWorkflowExecutionTerminatedEventAttributes(_) => {EventType::ChildWorkflowExecutionTerminated}
+                            Attributes::SignalExternalWorkflowExecutionInitiatedEventAttributes(_) => {EventType::SignalExternalWorkflowExecutionInitiated}
+                            Attributes::SignalExternalWorkflowExecutionFailedEventAttributes(_) => {EventType::SignalExternalWorkflowExecutionFailed}
+                            Attributes::ExternalWorkflowExecutionSignaledEventAttributes(_) => {EventType::ExternalWorkflowExecutionSignaled}
+                            Attributes::UpsertWorkflowSearchAttributesEventAttributes(_) => {EventType::UpsertWorkflowSearchAttributes}
+                            Attributes::WorkflowExecutionUpdateRejectedEventAttributes(_) => {EventType::WorkflowExecutionUpdateRejected}
+                            Attributes::WorkflowExecutionUpdateAcceptedEventAttributes(_) => {EventType::WorkflowExecutionUpdateAccepted}
+                            Attributes::WorkflowExecutionUpdateCompletedEventAttributes(_) => {EventType::WorkflowExecutionUpdateCompleted}
+                            Attributes::WorkflowPropertiesModifiedExternallyEventAttributes(_) => {EventType::WorkflowPropertiesModifiedExternally}
+                            Attributes::ActivityPropertiesModifiedExternallyEventAttributes(_) => {EventType::ActivityPropertiesModifiedExternally}
+                            Attributes::WorkflowPropertiesModifiedEventAttributes(_) => {EventType::WorkflowPropertiesModified}
+                        }
+                    }
+                }
             }
         }
         pub mod namespace {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.namespace.v1");
             }
         }
         pub mod operatorservice {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.operatorservice.v1");
             }
         }
+        pub mod protocol {
+            pub mod v1 {
+                tonic::include_proto!("temporal.api.protocol.v1");
+            }
+        }
         pub mod query {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.query.v1");
             }
         }
         pub mod replication {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.replication.v1");
             }
         }
         pub mod schedule {
+            #[allow(rustdoc::invalid_html_tags)]
             pub mod v1 {
                 tonic::include_proto!("temporal.api.schedule.v1");
             }
         }
+        pub mod sdk {
+            pub mod v1 {
+                tonic::include_proto!("temporal.api.sdk.v1");
+            }
+        }
         pub mod taskqueue {
             pub mod v1 {
                 use crate::temporal::api::enums::v1::TaskQueueKind;
                 tonic::include_proto!("temporal.api.taskqueue.v1");
 
                 impl From<String> for TaskQueue {
                     fn from(name: String) -> Self {
@@ -1840,14 +1977,19 @@
             }
         }
         pub mod testservice {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.testservice.v1");
             }
         }
+        pub mod update {
+            pub mod v1 {
+                tonic::include_proto!("temporal.api.update.v1");
+            }
+        }
         pub mod version {
             pub mod v1 {
                 tonic::include_proto!("temporal.api.version.v1");
             }
         }
         pub mod workflow {
             pub mod v1 {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/sdk-core-protos/src/task_token.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,22 @@
+use base64::{prelude::BASE64_STANDARD, Engine};
 use std::fmt::{Debug, Display, Formatter};
 
 static LOCAL_ACT_TASK_TOKEN_PREFIX: &[u8] = b"local_act_";
 
-#[derive(Hash, Eq, PartialEq, Clone, derive_more::From, derive_more::Into)]
+#[derive(
+    Hash,
+    Eq,
+    PartialEq,
+    Clone,
+    derive_more::From,
+    derive_more::Into,
+    serde::Serialize,
+    serde::Deserialize,
+)]
 /// Type-safe wrapper for task token bytes
 pub struct TaskToken(pub Vec<u8>);
 
 impl TaskToken {
     /// Task tokens for local activities are always prefixed with a special sigil so they can
     /// be identified easily
     pub fn new_local_activity_token(unique_data: impl IntoIterator<Item = u8>) -> Self {
@@ -30,9 +40,9 @@
 impl Debug for TaskToken {
     fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {
         f.write_str(&format!("TaskToken({})", fmt_tt(&self.0)))
     }
 }
 
 pub fn fmt_tt(tt: &[u8]) -> String {
-    base64::encode(tt)
+    BASE64_STANDARD.encode(tt)
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml` & `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/Cargo.toml`

 * *Files 7% similar despite different names*

```diff
@@ -7,22 +7,24 @@
 [[bin]]
 name = "histfetch"
 path = "src/histfetch.rs"
 
 [dependencies]
 anyhow = "1.0"
 async-trait = "0.1"
-base64 = "0.20"
+base64 = "0.21"
+bytes = "1.3"
 futures = "0.3"
 log = "0.4"
 once_cell = "1.16"
 parking_lot = "0.12"
 prost = "0.11"
 prost-types = "0.11"
 rand = "0.8"
+rmp-serde = "1.1"
 serde_json = "1.0"
 temporal-client = { path = "../client" }
 temporal-sdk = { path = "../sdk" }
 temporal-sdk-core = { path = "../core" }
 temporal-sdk-core-api = { path = "../core-api" }
 thiserror = "1.0"
 tokio = "1.1"
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/test-utils/src/histfetch.rs`

 * *Files 2% similar despite different names*

```diff
@@ -19,10 +19,10 @@
     let hist = client
         .get_workflow_execution_history(wf_id.clone(), run_id, vec![])
         .await?
         .history
         .expect("history field must be populated");
     // Serialize history to file
     let byteified = hist.encode_to_vec();
-    tokio::fs::write(format!("{}_history.bin", wf_id), &byteified).await?;
+    tokio::fs::write(format!("{wf_id}_history.bin"), &byteified).await?;
     Ok(())
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/test-utils/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,651 +1,667 @@
-//! This crate contains testing functionality that can be useful when building SDKs against Core,
-//! or even when testing workflows written in SDKs that use Core.
-
-#[macro_use]
-extern crate tracing;
-
-pub mod canned_histories;
-
-use crate::stream::{Stream, TryStreamExt};
-use futures::{future, stream, stream::FuturesUnordered, StreamExt};
-use parking_lot::Mutex;
-use prost::Message;
-use rand::{distributions::Standard, Rng};
+use crate::integ_tests::activity_functions::echo;
+use anyhow::anyhow;
+use futures::future::join_all;
 use std::{
-    convert::TryFrom, env, future::Future, net::SocketAddr, path::PathBuf, sync::Arc,
+    sync::atomic::{AtomicU8, Ordering},
     time::Duration,
 };
-use temporal_client::{
-    Client, RetryClient, WorkflowClientTrait, WorkflowExecutionInfo, WorkflowOptions,
-};
+use temporal_client::WorkflowOptions;
 use temporal_sdk::{
-    interceptors::{FailOnNondeterminismInterceptor, WorkerInterceptor},
-    IntoActivityFunc, Worker, WorkflowFunction,
-};
-use temporal_sdk_core::{
-    ephemeral_server::{EphemeralExe, EphemeralExeVersion},
-    init_replay_worker, init_worker,
-    replay::HistoryForReplay,
-    ClientOptions, ClientOptionsBuilder, CoreRuntime, WorkerConfig, WorkerConfigBuilder,
-};
-use temporal_sdk_core_api::{
-    telemetry::{
-        Logger, MetricsExporter, OtelCollectorOptions, TelemetryOptions, TelemetryOptionsBuilder,
-        TraceExportConfig, TraceExporter,
-    },
-    Worker as CoreWorker,
+    interceptors::WorkerInterceptor, ActContext, ActivityCancelledError, CancellableFuture,
+    LocalActivityOptions, WfContext, WorkflowResult,
 };
+use temporal_sdk_core::replay::HistoryForReplay;
 use temporal_sdk_core_protos::{
     coresdk::{
-        workflow_commands::{
-            workflow_command, ActivityCancellationType, CompleteWorkflowExecution,
-            ScheduleActivity, ScheduleLocalActivity, StartTimer,
-        },
-        workflow_completion::WorkflowActivationCompletion,
+        workflow_commands::{workflow_command::Variant, ActivityCancellationType},
+        workflow_completion,
+        workflow_completion::{workflow_activation_completion, WorkflowActivationCompletion},
+        AsJsonPayloadExt,
     },
-    temporal::api::{common::v1::Payload, history::v1::History},
+    temporal::api::{common::v1::RetryPolicy, enums::v1::TimeoutType},
+    TestHistoryBuilder,
+};
+use temporal_sdk_core_test_utils::{
+    history_from_proto_binary, init_integ_telem, replay_sdk_worker, workflows::la_problem_workflow,
+    CoreWfStarter,
 };
-use tokio::sync::OnceCell;
-use url::Url;
+use tokio_util::sync::CancellationToken;
 
-pub const NAMESPACE: &str = "default";
-pub const TEST_Q: &str = "q";
-/// The env var used to specify where the integ tests should point
-pub const INTEG_SERVER_TARGET_ENV_VAR: &str = "TEMPORAL_SERVICE_ADDRESS";
-/// This env var is set (to any value) if temporalite is in use
-pub const INTEG_TEMPORALITE_USED_ENV_VAR: &str = "INTEG_TEMPORALITE_ON";
-/// This env var is set (to any value) if the test server is in use
-pub const INTEG_TEST_SERVER_USED_ENV_VAR: &str = "INTEG_TEST_SERVER_ON";
-
-/// If set, turn export traces and metrics to the OTel collector at the given URL
-const OTEL_URL_ENV_VAR: &str = "TEMPORAL_INTEG_OTEL_URL";
-/// If set, enable direct scraping of prom metrics on the specified port
-const PROM_ENABLE_ENV_VAR: &str = "TEMPORAL_INTEG_PROM_PORT";
-/// Create a worker instance which will use the provided test name to base the task queue and wf id
-/// upon. Returns the instance and the task queue name (which is also the workflow id).
-pub async fn init_core_and_create_wf(test_name: &str) -> CoreWfStarter {
-    let mut starter = CoreWfStarter::new(test_name);
-    let _ = starter.get_worker().await;
-    starter.start_wf().await;
-    starter
-}
+pub async fn one_local_activity_wf(ctx: WfContext) -> WorkflowResult<()> {
+    let initial_workflow_time = ctx.workflow_time().expect("Workflow time should be set");
+    ctx.local_activity(LocalActivityOptions {
+        activity_type: "echo_activity".to_string(),
+        input: "hi!".as_json_payload().expect("serializes fine"),
+        ..Default::default()
+    })
+    .await;
+    // Verify LA execution advances the clock
+    assert!(initial_workflow_time < ctx.workflow_time().unwrap());
+    Ok(().into())
+}
+
+#[tokio::test]
+async fn one_local_activity() {
+    let wf_name = "one_local_activity";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), one_local_activity_wf);
+    worker.register_activity("echo_activity", echo);
+
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+}
+
+pub async fn local_act_concurrent_with_timer_wf(ctx: WfContext) -> WorkflowResult<()> {
+    let la = ctx.local_activity(LocalActivityOptions {
+        activity_type: "echo_activity".to_string(),
+        input: "hi!".as_json_payload().expect("serializes fine"),
+        ..Default::default()
+    });
+    let timer = ctx.timer(Duration::from_secs(1));
+    tokio::join!(la, timer);
+    Ok(().into())
+}
+
+#[tokio::test]
+async fn local_act_concurrent_with_timer() {
+    let wf_name = "local_act_concurrent_with_timer";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), local_act_concurrent_with_timer_wf);
+    worker.register_activity("echo_activity", echo);
+
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+}
+
+pub async fn local_act_then_timer_then_wait(ctx: WfContext) -> WorkflowResult<()> {
+    let la = ctx.local_activity(LocalActivityOptions {
+        activity_type: "echo_activity".to_string(),
+        input: "hi!".as_json_payload().expect("serializes fine"),
+        ..Default::default()
+    });
+    ctx.timer(Duration::from_secs(1)).await;
+    let res = la.await;
+    assert!(res.completed_ok());
+    Ok(().into())
+}
+
+#[tokio::test]
+async fn local_act_then_timer_then_wait_result() {
+    let wf_name = "local_act_then_timer_then_wait_result";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
+    worker.register_activity("echo_activity", echo);
+
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+}
+
+#[tokio::test]
+async fn long_running_local_act_with_timer() {
+    let wf_name = "long_running_local_act_with_timer";
+    let mut starter = CoreWfStarter::new(wf_name);
+    starter.workflow_options.task_timeout = Some(Duration::from_secs(1));
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
+    worker.register_activity("echo_activity", |_ctx: ActContext, str: String| async {
+        tokio::time::sleep(Duration::from_secs(4)).await;
+        Ok(str)
+    });
 
-/// Create a worker replay instance preloaded with provided histories. Returns the worker impl.
-pub fn init_core_replay_preloaded<I>(test_name: &str, histories: I) -> Arc<dyn CoreWorker>
-where
-    I: IntoIterator<Item = HistoryForReplay> + 'static,
-    <I as IntoIterator>::IntoIter: Send,
-{
-    init_core_replay_stream(test_name, stream::iter(histories))
-}
-pub fn init_core_replay_stream<I>(test_name: &str, histories: I) -> Arc<dyn CoreWorker>
-where
-    I: Stream<Item = HistoryForReplay> + Send + 'static,
-{
-    init_integ_telem();
-    let worker_cfg = WorkerConfigBuilder::default()
-        .namespace(NAMESPACE)
-        .task_queue(test_name)
-        .worker_build_id("test_bin_id")
-        .build()
-        .expect("Configuration options construct properly");
-    let worker =
-        init_replay_worker(worker_cfg, histories).expect("Replay worker must init properly");
-    Arc::new(worker)
-}
-pub fn replay_sdk_worker<I>(histories: I) -> Worker
-where
-    I: IntoIterator<Item = HistoryForReplay> + 'static,
-    <I as IntoIterator>::IntoIter: Send,
-{
-    replay_sdk_worker_stream(stream::iter(histories))
-}
-pub fn replay_sdk_worker_stream<I>(histories: I) -> Worker
-where
-    I: Stream<Item = HistoryForReplay> + Send + 'static,
-{
-    let core = init_core_replay_stream("replay_worker_test", histories);
-    let mut worker = Worker::new_from_core(core, "replay_q".to_string());
-    worker.set_worker_interceptor(Box::new(FailOnNondeterminismInterceptor {}));
-    worker
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
 }
 
-/// Load history from a file containing the protobuf serialization of it
-pub async fn history_from_proto_binary(path_from_root: &str) -> Result<History, anyhow::Error> {
-    let mut path = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
-    path.push("..");
-    path.push(path_from_root);
-    let bytes = tokio::fs::read(path).await?;
-    Ok(History::decode(&*bytes)?)
-}
-
-static INTEG_TESTS_RT: once_cell::sync::OnceCell<CoreRuntime> = once_cell::sync::OnceCell::new();
-pub fn init_integ_telem() {
-    INTEG_TESTS_RT.get_or_init(|| {
-        let telemetry_options = get_integ_telem_options();
-        let rt =
-            CoreRuntime::new_assume_tokio(telemetry_options).expect("Core runtime inits cleanly");
-        let _ = tracing::subscriber::set_global_default(rt.trace_subscriber());
-        rt
+pub async fn local_act_fanout_wf(ctx: WfContext) -> WorkflowResult<()> {
+    let las: Vec<_> = (1..=50)
+        .map(|i| {
+            ctx.local_activity(LocalActivityOptions {
+                activity_type: "echo_activity".to_string(),
+                input: format!("Hi {i}")
+                    .as_json_payload()
+                    .expect("serializes fine"),
+                ..Default::default()
+            })
+        })
+        .collect();
+    ctx.timer(Duration::from_secs(1)).await;
+    join_all(las).await;
+    Ok(().into())
+}
+
+#[tokio::test]
+async fn local_act_fanout() {
+    let wf_name = "local_act_fanout";
+    let mut starter = CoreWfStarter::new(wf_name);
+    starter.max_local_at(1);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), local_act_fanout_wf);
+    worker.register_activity("echo_activity", echo);
+
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+}
+
+#[tokio::test]
+async fn local_act_retry_timer_backoff() {
+    let wf_name = "local_act_retry_timer_backoff";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        let res = ctx
+            .local_activity(LocalActivityOptions {
+                activity_type: "echo".to_string(),
+                input: "hi".as_json_payload().expect("serializes fine"),
+                retry_policy: RetryPolicy {
+                    initial_interval: Some(prost_dur!(from_micros(15))),
+                    // We want two local backoffs that are short. Third backoff will use timer
+                    backoff_coefficient: 1_000.,
+                    maximum_interval: Some(prost_dur!(from_millis(1500))),
+                    maximum_attempts: 4,
+                    non_retryable_error_types: vec![],
+                },
+                timer_backoff_threshold: Some(Duration::from_secs(1)),
+                ..Default::default()
+            })
+            .await;
+        assert!(res.failed());
+        Ok(().into())
+    });
+    worker.register_activity("echo", |_: ActContext, _: String| async {
+        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
     });
-}
-
-/// Implements a builder pattern to help integ tests initialize core and create workflows
-pub struct CoreWfStarter {
-    /// Used for both the task queue and workflow id
-    task_queue_name: String,
-    pub worker_config: WorkerConfig,
-    wft_timeout: Option<Duration>,
-    initted_worker: OnceCell<InitializedWorker>,
-}
-struct InitializedWorker {
-    worker: Arc<dyn CoreWorker>,
-    client: Arc<RetryClient<Client>>,
-}
-
-impl CoreWfStarter {
-    pub fn new(test_name: &str) -> Self {
-        let rand_bytes: Vec<u8> = rand::thread_rng().sample_iter(&Standard).take(6).collect();
-        let task_q_salt = base64::encode(rand_bytes);
-        let task_queue = format!("{}_{}", test_name, task_q_salt);
-        Self::new_tq_name(&task_queue)
-    }
-
-    pub fn new_tq_name(task_queue: &str) -> Self {
-        init_integ_telem();
-        Self {
-            task_queue_name: task_queue.to_owned(),
-            worker_config: WorkerConfigBuilder::default()
-                .namespace(NAMESPACE)
-                .task_queue(task_queue)
-                .worker_build_id("test_build_id")
-                .max_cached_workflows(1000_usize)
-                .build()
-                .unwrap(),
-            wft_timeout: None,
-            initted_worker: OnceCell::new(),
-        }
-    }
-
-    pub async fn worker(&mut self) -> TestWorker {
-        let mut w = TestWorker::new(
-            self.get_worker().await,
-            self.worker_config.task_queue.clone(),
-        );
-        w.client = Some(self.get_client().await);
-
-        w
-    }
-
-    pub async fn shutdown(&mut self) {
-        self.get_worker().await.shutdown().await;
-    }
-
-    pub async fn get_worker(&mut self) -> Arc<dyn CoreWorker> {
-        self.get_or_init().await.worker.clone()
-    }
-
-    pub async fn get_client(&mut self) -> Arc<RetryClient<Client>> {
-        self.get_or_init().await.client.clone()
-    }
-
-    /// Start the workflow defined by the builder and return run id
-    pub async fn start_wf(&self) -> String {
-        self.start_wf_with_id(self.task_queue_name.clone(), WorkflowOptions::default())
-            .await
-    }
-
-    pub async fn start_wf_with_id(&self, workflow_id: String, mut opts: WorkflowOptions) -> String {
-        opts.task_timeout = opts.task_timeout.or(self.wft_timeout);
-        self.initted_worker
-            .get()
-            .expect(
-                "Worker must be initted before starting a workflow.\
-                             Tests must call `get_worker` first.",
-            )
-            .client
-            .start_workflow(
-                vec![],
-                self.worker_config.task_queue.clone(),
-                workflow_id,
-                self.task_queue_name.clone(),
-                None,
-                opts,
-            )
-            .await
-            .unwrap()
-            .run_id
-    }
-
-    /// Fetch the history for the indicated workflow and replay it using the provided worker.
-    /// Can be used after completing workflows normally to ensure replay works as well.
-    pub async fn fetch_history_and_replay(
-        &mut self,
-        wf_id: impl Into<String>,
-        run_id: impl Into<String>,
-        worker: &mut Worker,
-    ) -> Result<(), anyhow::Error> {
-        let wf_id = wf_id.into();
-        // Fetch history and replay it
-        let history = self
-            .get_client()
-            .await
-            .get_workflow_execution_history(wf_id.clone(), Some(run_id.into()), vec![])
-            .await?
-            .history
-            .expect("history field must be populated");
-        let with_id = HistoryForReplay::new(history, wf_id);
-        let replay_worker = init_core_replay_preloaded(worker.task_queue(), [with_id]);
-        worker.with_new_core_worker(replay_worker);
-        worker.set_worker_interceptor(Box::new(FailOnNondeterminismInterceptor {}));
-        worker.run().await.unwrap();
-        Ok(())
-    }
-
-    pub fn get_task_queue(&self) -> &str {
-        &self.worker_config.task_queue
-    }
-
-    pub fn get_wf_id(&self) -> &str {
-        &self.task_queue_name
-    }
-
-    pub fn max_cached_workflows(&mut self, num: usize) -> &mut Self {
-        self.worker_config.max_cached_workflows = num;
-        self
-    }
-
-    pub fn max_wft(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_workflow_tasks = max;
-        self
-    }
-
-    pub fn max_at(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_activities = max;
-        self
-    }
-
-    pub fn max_local_at(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_outstanding_local_activities = max;
-        self
-    }
-
-    pub fn max_at_polls(&mut self, max: usize) -> &mut Self {
-        self.worker_config.max_concurrent_at_polls = max;
-        self
-    }
-
-    pub fn wft_timeout(&mut self, timeout: Duration) -> &mut Self {
-        self.wft_timeout = Some(timeout);
-        self
-    }
 
-    async fn get_or_init(&mut self) -> &InitializedWorker {
-        self.initted_worker
-            .get_or_init(|| async {
-                let client = Arc::new(
-                    get_integ_server_options()
-                        .connect(self.worker_config.namespace.clone(), None, None)
-                        .await
-                        .expect("Must connect"),
-                );
-                let worker = init_worker(
-                    INTEG_TESTS_RT.get().unwrap(),
-                    self.worker_config.clone(),
-                    client.clone(),
-                )
-                .expect("Worker inits cleanly");
-                InitializedWorker {
-                    worker: Arc::new(worker),
-                    client,
-                }
-            })
-            .await
-    }
+    let run_id = worker
+        .submit_wf(
+            wf_name.to_owned(),
+            wf_name.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
+        .await
+        .unwrap();
+    worker.run_until_done().await.unwrap();
+    starter
+        .fetch_history_and_replay(wf_name, run_id, worker.inner_mut())
+        .await
+        .unwrap();
 }
 
-/// Provides conveniences for running integ tests with the SDK (against real server or mocks)
-pub struct TestWorker {
-    inner: Worker,
-    pub core_worker: Arc<dyn CoreWorker>,
-    client: Option<Arc<RetryClient<Client>>>,
-    pub started_workflows: Mutex<Vec<WorkflowExecutionInfo>>,
-    /// If set true (default), and a client is available, we will fetch workflow results to
-    /// determine when they have all completed.
-    pub fetch_results: bool,
-    iceptor: Option<TestWorkerCompletionIceptor>,
-}
-impl TestWorker {
-    /// Create a new test worker
-    pub fn new(core_worker: Arc<dyn CoreWorker>, task_queue: impl Into<String>) -> Self {
-        let inner = Worker::new_from_core(core_worker.clone(), task_queue);
-        let iceptor = TestWorkerCompletionIceptor::new(
-            TestWorkerShutdownCond::NoAutoShutdown,
-            Arc::new(inner.shutdown_handle()),
-        );
-        Self {
-            inner,
-            core_worker,
-            client: None,
-            started_workflows: Mutex::new(vec![]),
-            fetch_results: true,
-            iceptor: Some(iceptor),
-        }
-    }
-
-    pub fn inner_mut(&mut self) -> &mut Worker {
-        &mut self.inner
-    }
-
-    // TODO: Maybe trait-ify?
-    pub fn register_wf<F: Into<WorkflowFunction>>(
-        &mut self,
-        workflow_type: impl Into<String>,
-        wf_function: F,
-    ) {
-        self.inner.register_wf(workflow_type, wf_function)
-    }
-
-    pub fn register_activity<A, R, O>(
-        &mut self,
-        activity_type: impl Into<String>,
-        act_function: impl IntoActivityFunc<A, R, O>,
-    ) {
-        self.inner.register_activity(activity_type, act_function)
-    }
-
-    /// Create a workflow, asking the server to start it with the provided workflow ID and using the
-    /// provided workflow function.
-    ///
-    /// Increments the expected Workflow run count.
-    ///
-    /// Returns the run id of the started workflow
-    pub async fn submit_wf(
-        &self,
-        workflow_id: impl Into<String>,
-        workflow_type: impl Into<String>,
-        input: Vec<Payload>,
-        options: WorkflowOptions,
-    ) -> Result<String, anyhow::Error> {
-        if let Some(c) = self.client.as_ref() {
-            let wfid = workflow_id.into();
-            let res = c
-                .start_workflow(
-                    input,
-                    self.inner.task_queue().to_string(),
-                    wfid.clone(),
-                    workflow_type.into(),
-                    None,
-                    options,
-                )
-                .await?;
-            self.started_workflows.lock().push(WorkflowExecutionInfo {
-                namespace: c.namespace().to_string(),
-                workflow_id: wfid,
-                run_id: Some(res.run_id.clone()),
-            });
-            Ok(res.run_id)
-        } else {
-            Ok("fake_run_id".to_string())
-        }
-    }
-
-    /// Runs until all expected workflows have completed
-    pub async fn run_until_done(&mut self) -> Result<(), anyhow::Error> {
-        self.run_until_done_intercepted(Option::<TestWorkerCompletionIceptor>::None)
-            .await
-    }
+#[rstest::rstest]
+#[case::wait(ActivityCancellationType::WaitCancellationCompleted)]
+#[case::try_cancel(ActivityCancellationType::TryCancel)]
+#[case::abandon(ActivityCancellationType::Abandon)]
+#[tokio::test]
+async fn cancel_immediate(#[case] cancel_type: ActivityCancellationType) {
+    let wf_name = format!("cancel_immediate_{cancel_type:?}");
+    let mut starter = CoreWfStarter::new(&wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(&wf_name, move |ctx: WfContext| async move {
+        let la = ctx.local_activity(LocalActivityOptions {
+            activity_type: "echo".to_string(),
+            input: "hi".as_json_payload().expect("serializes fine"),
+            cancel_type,
+            ..Default::default()
+        });
+        la.cancel(&ctx);
+        let resolution = la.await;
+        assert!(resolution.cancelled());
+        Ok(().into())
+    });
 
-    /// See [Self::run_until_done], but allows configuration of some low-level interception.
-    pub async fn run_until_done_intercepted(
-        &mut self,
-        interceptor: Option<impl WorkerInterceptor + 'static>,
-    ) -> Result<(), anyhow::Error> {
-        let mut iceptor = self.iceptor.take().unwrap();
-        // Automatically use results-based complete detection if we have a client
-        if self.fetch_results {
-            if let Some(c) = self.client.clone() {
-                iceptor.condition = TestWorkerShutdownCond::GetResults(
-                    std::mem::take(&mut self.started_workflows.lock()),
-                    c,
-                );
+    // If we don't use this, we'd hang on shutdown for abandon cancel modes.
+    let manual_cancel = CancellationToken::new();
+    let manual_cancel_act = manual_cancel.clone();
+
+    worker.register_activity("echo", move |ctx: ActContext, _: String| {
+        let manual_cancel_act = manual_cancel_act.clone();
+        async move {
+            tokio::select! {
+                _ = tokio::time::sleep(Duration::from_secs(10)) => {},
+                _ = ctx.cancelled() => {
+                    return Err(anyhow!(ActivityCancelledError::default()))
+                }
+                _ = manual_cancel_act.cancelled() => {}
             }
+            Ok(())
         }
-        iceptor.next = interceptor.map(|i| Box::new(i) as Box<dyn WorkerInterceptor>);
-        let get_results_waiter = iceptor.wait_all_wfs();
-        self.inner.set_worker_interceptor(Box::new(iceptor));
-        tokio::try_join!(self.inner.run(), get_results_waiter)?;
-        Ok(())
-    }
-}
-
-pub type BoxDynActivationHook = Box<dyn Fn(&WorkflowActivationCompletion)>;
+    });
 
-pub enum TestWorkerShutdownCond {
-    GetResults(Vec<WorkflowExecutionInfo>, Arc<RetryClient<Client>>),
-    NoAutoShutdown,
-}
-/// Implements calling the shutdown handle when the expected number of test workflows has completed
-pub struct TestWorkerCompletionIceptor {
-    condition: TestWorkerShutdownCond,
-    shutdown_handle: Arc<dyn Fn()>,
-    every_activation: Option<BoxDynActivationHook>,
-    next: Option<Box<dyn WorkerInterceptor>>,
-}
-impl TestWorkerCompletionIceptor {
-    pub fn new(condition: TestWorkerShutdownCond, shutdown_handle: Arc<dyn Fn()>) -> Self {
-        Self {
-            condition,
-            shutdown_handle,
-            every_activation: None,
-            next: None,
-        }
-    }
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker
+        .run_until_done_intercepted(Some(LACancellerInterceptor {
+            cancel_on_workflow_completed: false,
+            token: manual_cancel,
+        }))
+        .await
+        .unwrap();
+}
 
-    fn wait_all_wfs(&mut self) -> impl Future<Output = Result<(), anyhow::Error>> + 'static {
-        if let TestWorkerShutdownCond::GetResults(ref mut wfs, ref client) = self.condition {
-            let wfs = std::mem::take(wfs);
-            let shutdown_h = self.shutdown_handle.clone();
-            let client = (**client).clone();
-            let stream = stream::iter(
-                wfs.into_iter()
-                    .map(move |info| info.bind_untyped(client.clone())),
-            )
-            .map(Ok);
-            future::Either::Left(async move {
-                stream
-                    .try_for_each_concurrent(None, |wh| async move {
-                        wh.get_workflow_result(Default::default()).await?;
-                        Ok::<_, anyhow::Error>(())
-                    })
-                    .await?;
-                shutdown_h();
-                Ok(())
-            })
-        } else {
-            future::Either::Right(future::ready(Ok(())))
-        }
-    }
+struct LACancellerInterceptor {
+    token: CancellationToken,
+    cancel_on_workflow_completed: bool,
 }
 #[async_trait::async_trait(?Send)]
-impl WorkerInterceptor for TestWorkerCompletionIceptor {
+impl WorkerInterceptor for LACancellerInterceptor {
     async fn on_workflow_activation_completion(&self, completion: &WorkflowActivationCompletion) {
-        if let Some(func) = self.every_activation.as_ref() {
-            func(completion);
+        if !self.cancel_on_workflow_completed {
+            return;
         }
-        if completion.has_execution_ending() {
-            info!("Workflow {} says it's finishing", &completion.run_id);
+        if let Some(workflow_activation_completion::Status::Successful(
+            workflow_completion::Success { commands, .. },
+        )) = completion.status.as_ref()
+        {
+            if let Some(&Variant::CompleteWorkflowExecution(_)) =
+                commands.last().and_then(|v| v.variant.as_ref())
+            {
+                self.token.cancel();
+            }
         }
-        if let Some(n) = self.next.as_ref() {
-            n.on_workflow_activation_completion(completion).await;
+    }
+    fn on_shutdown(&self, _: &temporal_sdk::Worker) {
+        if !self.cancel_on_workflow_completed {
+            self.token.cancel()
         }
     }
+}
+
+#[rstest::rstest]
+#[case::while_running(None)]
+#[case::while_backing_off(Some(Duration::from_millis(1500)))]
+#[case::while_backing_off_locally(Some(Duration::from_millis(150)))]
+#[tokio::test]
+async fn cancel_after_act_starts(
+    #[case] cancel_on_backoff: Option<Duration>,
+    #[values(
+        ActivityCancellationType::WaitCancellationCompleted,
+        ActivityCancellationType::TryCancel,
+        ActivityCancellationType::Abandon
+    )]
+    cancel_type: ActivityCancellationType,
+) {
+    let wf_name = format!("cancel_after_act_starts_{cancel_on_backoff:?}_{cancel_type:?}");
+    let mut starter = CoreWfStarter::new(&wf_name);
+    starter.workflow_options.task_timeout = Some(Duration::from_secs(1));
+    let mut worker = starter.worker().await;
+    let bo_dur = cancel_on_backoff.unwrap_or_else(|| Duration::from_secs(1));
+    worker.register_wf(&wf_name, move |ctx: WfContext| async move {
+        let la = ctx.local_activity(LocalActivityOptions {
+            activity_type: "echo".to_string(),
+            input: "hi".as_json_payload().expect("serializes fine"),
+            retry_policy: RetryPolicy {
+                initial_interval: Some(bo_dur.try_into().unwrap()),
+                backoff_coefficient: 1.,
+                maximum_interval: Some(bo_dur.try_into().unwrap()),
+                // Retry forever until cancelled
+                ..Default::default()
+            },
+            timer_backoff_threshold: Some(Duration::from_secs(1)),
+            cancel_type,
+            ..Default::default()
+        });
+        ctx.timer(Duration::from_secs(1)).await;
+        // Note that this cancel can't go through for *two* WF tasks, because we do a full heartbeat
+        // before the timer (LA hasn't resolved), and then the timer fired event won't appear in
+        // history until *after* the next WFT because we force generated it when we sent the timer
+        // command.
+        la.cancel(&ctx);
+        // This extra timer is here to ensure the presence of another WF task doesn't mess up
+        // resolving the LA with cancel on replay
+        ctx.timer(Duration::from_secs(1)).await;
+        let resolution = la.await;
+        assert!(resolution.cancelled());
+        Ok(().into())
+    });
 
-    fn on_shutdown(&self, sdk_worker: &Worker) {
-        if let Some(n) = self.next.as_ref() {
-            n.on_shutdown(sdk_worker);
+    // If we don't use this, we'd hang on shutdown for abandon cancel modes.
+    let manual_cancel = CancellationToken::new();
+    let manual_cancel_act = manual_cancel.clone();
+
+    worker.register_activity("echo", move |ctx: ActContext, _: String| {
+        let manual_cancel_act = manual_cancel_act.clone();
+        async move {
+            if cancel_on_backoff.is_some() {
+                if ctx.is_cancelled() {
+                    return Err(anyhow!(ActivityCancelledError::default()));
+                }
+                // Just fail constantly so we get stuck on the backoff timer
+                return Err(anyhow!("Oh no I failed!"));
+            } else {
+                tokio::select! {
+                    _ = tokio::time::sleep(Duration::from_secs(100)) => {},
+                    _ = ctx.cancelled() => {
+                        return Err(anyhow!(ActivityCancelledError::default()))
+                    }
+                    _ = manual_cancel_act.cancelled() => {
+                        return Ok(())
+                    }
+                }
+            }
+            Err(anyhow!("Oh no I failed!"))
         }
-    }
+    });
+
+    starter.start_with_worker(&wf_name, &mut worker).await;
+    worker
+        .run_until_done_intercepted(Some(LACancellerInterceptor {
+            token: manual_cancel,
+            // Only needed for this one case since the activity is not drained and prevents worker from shutting down.
+            cancel_on_workflow_completed: matches!(cancel_type, ActivityCancellationType::Abandon)
+                && cancel_on_backoff.is_none(),
+        }))
+        .await
+        .unwrap();
+    starter.shutdown().await;
 }
 
-/// Returns the client options used to connect to the server used for integration tests.
-pub fn get_integ_server_options() -> ClientOptions {
-    let temporal_server_address = match env::var(INTEG_SERVER_TARGET_ENV_VAR) {
-        Ok(addr) => addr,
-        Err(_) => "http://localhost:7233".to_owned(),
+#[rstest::rstest]
+#[case::schedule(true)]
+#[case::start(false)]
+#[tokio::test]
+async fn x_to_close_timeout(#[case] is_schedule: bool) {
+    let wf_name = format!(
+        "{}_to_close_timeout",
+        if is_schedule { "schedule" } else { "start" }
+    );
+    let mut starter = CoreWfStarter::new(&wf_name);
+    let mut worker = starter.worker().await;
+    let (sched, start) = if is_schedule {
+        (Some(Duration::from_secs(2)), None)
+    } else {
+        (None, Some(Duration::from_secs(2)))
+    };
+    let timeout_type = if is_schedule {
+        TimeoutType::ScheduleToClose
+    } else {
+        TimeoutType::StartToClose
     };
-    let url = Url::try_from(&*temporal_server_address).unwrap();
-    ClientOptionsBuilder::default()
-        .identity("integ_tester".to_string())
-        .target_url(url)
-        .client_name("temporal-core".to_string())
-        .client_version("0.1.0".to_string())
-        .build()
-        .unwrap()
-}
-
-pub fn get_integ_telem_options() -> TelemetryOptions {
-    let mut ob = TelemetryOptionsBuilder::default();
-    let filter_string =
-        env::var("RUST_LOG").unwrap_or_else(|_| "temporal_sdk_core=INFO".to_string());
-    if let Some(url) = env::var(OTEL_URL_ENV_VAR)
-        .ok()
-        .map(|x| x.parse::<Url>().unwrap())
-    {
-        let opts = OtelCollectorOptions {
-            url,
-            headers: Default::default(),
-            metric_periodicity: None,
+
+    worker.register_wf(wf_name.to_owned(), move |ctx: WfContext| async move {
+        let res = ctx
+            .local_activity(LocalActivityOptions {
+                activity_type: "echo".to_string(),
+                input: "hi".as_json_payload().expect("serializes fine"),
+                retry_policy: RetryPolicy {
+                    initial_interval: Some(prost_dur!(from_micros(15))),
+                    backoff_coefficient: 1_000.,
+                    maximum_interval: Some(prost_dur!(from_millis(1500))),
+                    maximum_attempts: 4,
+                    non_retryable_error_types: vec![],
+                },
+                timer_backoff_threshold: Some(Duration::from_secs(1)),
+                schedule_to_close_timeout: sched,
+                start_to_close_timeout: start,
+                ..Default::default()
+            })
+            .await;
+        assert_eq!(res.timed_out(), Some(timeout_type));
+        Ok(().into())
+    });
+    worker.register_activity("echo", |ctx: ActContext, _: String| async move {
+        tokio::select! {
+            _ = tokio::time::sleep(Duration::from_secs(100)) => {},
+            _ = ctx.cancelled() => {
+                return Err(anyhow!(ActivityCancelledError::default()))
+            }
         };
-        ob.tracing(TraceExportConfig {
-            filter: filter_string.clone(),
-            exporter: TraceExporter::Otel(opts.clone()),
-        });
-        ob.metrics(MetricsExporter::Otel(opts));
-    }
-    if let Some(addr) = env::var(PROM_ENABLE_ENV_VAR)
-        .ok()
-        .map(|x| SocketAddr::new([127, 0, 0, 1].into(), x.parse().unwrap()))
-    {
-        ob.metrics(MetricsExporter::Prometheus(addr));
-    }
-    ob.logging(Logger::Console {
-        filter: filter_string,
-    })
-    .build()
-    .unwrap()
-}
+        Ok(())
+    });
 
-pub fn default_cached_download() -> EphemeralExe {
-    EphemeralExe::CachedDownload {
-        version: EphemeralExeVersion::Default {
-            sdk_name: "sdk-rust".to_string(),
-            sdk_version: "0.1.0".to_string(),
-        },
-        dest_dir: None,
-    }
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
 }
 
-pub fn schedule_activity_cmd(
-    seq: u32,
-    task_q: &str,
-    activity_id: &str,
-    cancellation_type: ActivityCancellationType,
-    activity_timeout: Duration,
-    heartbeat_timeout: Duration,
-) -> workflow_command::Variant {
-    ScheduleActivity {
-        seq,
-        activity_id: activity_id.to_string(),
-        activity_type: "test_activity".to_string(),
-        task_queue: task_q.to_owned(),
-        schedule_to_start_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        start_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        schedule_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        heartbeat_timeout: Some(heartbeat_timeout.try_into().expect("duration fits")),
-        cancellation_type: cancellation_type as i32,
-        ..Default::default()
-    }
-    .into()
-}
+#[rstest::rstest]
+#[case::cached(true)]
+#[case::not_cached(false)]
+#[tokio::test]
+async fn schedule_to_close_timeout_across_timer_backoff(#[case] cached: bool) {
+    let wf_name = format!(
+        "schedule_to_close_timeout_across_timer_backoff_{}",
+        if cached { "cached" } else { "not_cached" }
+    );
+    let mut starter = CoreWfStarter::new(&wf_name);
+    if !cached {
+        starter.max_cached_workflows(0);
+    }
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        let res = ctx
+            .local_activity(LocalActivityOptions {
+                activity_type: "echo".to_string(),
+                input: "hi".as_json_payload().expect("serializes fine"),
+                retry_policy: RetryPolicy {
+                    initial_interval: Some(prost_dur!(from_millis(15))),
+                    backoff_coefficient: 1_000.,
+                    maximum_interval: Some(prost_dur!(from_millis(1000))),
+                    maximum_attempts: 40,
+                    non_retryable_error_types: vec![],
+                },
+                timer_backoff_threshold: Some(Duration::from_millis(500)),
+                schedule_to_close_timeout: Some(Duration::from_secs(2)),
+                ..Default::default()
+            })
+            .await;
+        assert_eq!(res.timed_out(), Some(TimeoutType::ScheduleToClose));
+        Ok(().into())
+    });
+    let num_attempts: &'static _ = Box::leak(Box::new(AtomicU8::new(0)));
+    worker.register_activity("echo", move |_: ActContext, _: String| async {
+        num_attempts.fetch_add(1, Ordering::Relaxed);
+        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
+    });
 
-pub fn schedule_local_activity_cmd(
-    seq: u32,
-    activity_id: &str,
-    cancellation_type: ActivityCancellationType,
-    activity_timeout: Duration,
-) -> workflow_command::Variant {
-    ScheduleLocalActivity {
-        seq,
-        activity_id: activity_id.to_string(),
-        activity_type: "test_activity".to_string(),
-        schedule_to_start_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        start_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        schedule_to_close_timeout: Some(activity_timeout.try_into().expect("duration fits")),
-        cancellation_type: cancellation_type as i32,
-        ..Default::default()
-    }
-    .into()
-}
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+    // 3 attempts b/c first backoff is very small, then the next 2 attempts take at least 2 seconds
+    // b/c of timer backoff.
+    assert_eq!(3, num_attempts.load(Ordering::Relaxed));
+}
+
+#[rstest::rstest]
+#[tokio::test]
+async fn eviction_wont_make_local_act_get_dropped(#[values(true, false)] short_wft_timeout: bool) {
+    let wf_name = format!("eviction_wont_make_local_act_get_dropped_{short_wft_timeout}");
+    let mut starter = CoreWfStarter::new(&wf_name);
+    starter.max_cached_workflows(0);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
+    worker.register_activity("echo_activity", |_ctx: ActContext, str: String| async {
+        tokio::time::sleep(Duration::from_secs(4)).await;
+        Ok(str)
+    });
 
-pub fn start_timer_cmd(seq: u32, duration: Duration) -> workflow_command::Variant {
-    StartTimer {
-        seq,
-        start_to_fire_timeout: Some(duration.try_into().expect("duration fits")),
-    }
-    .into()
+    let opts = if short_wft_timeout {
+        WorkflowOptions {
+            task_timeout: Some(Duration::from_secs(1)),
+            ..Default::default()
+        }
+    } else {
+        Default::default()
+    };
+    worker
+        .submit_wf(wf_name.to_owned(), wf_name.to_owned(), vec![], opts)
+        .await
+        .unwrap();
+    worker.run_until_done().await.unwrap();
 }
 
-/// Given a desired number of concurrent executions and a provided function that produces a future,
-/// run that many instances of the future concurrently.
-///
-/// Annoyingly, because of a sorta-bug in the way async blocks work, the async block produced by
-/// the closure must be `async move` if it uses the provided iteration number. On the plus side,
-/// since you're usually just accessing core in the closure, if core is a reference everything just
-/// works. See <https://github.com/rust-lang/rust/issues/81653>
-pub async fn fanout_tasks<FutureMaker, Fut>(num: usize, fm: FutureMaker)
-where
-    FutureMaker: Fn(usize) -> Fut,
-    Fut: Future,
-{
-    let mut tasks = FuturesUnordered::new();
-    for i in 0..num {
-        tasks.push(fm(i));
-    }
+#[tokio::test]
+async fn timer_backoff_concurrent_with_non_timer_backoff() {
+    let wf_name = "timer_backoff_concurrent_with_non_timer_backoff";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        let r1 = ctx.local_activity(LocalActivityOptions {
+            activity_type: "echo".to_string(),
+            input: "hi".as_json_payload().expect("serializes fine"),
+            retry_policy: RetryPolicy {
+                initial_interval: Some(prost_dur!(from_micros(15))),
+                backoff_coefficient: 1_000.,
+                maximum_interval: Some(prost_dur!(from_millis(1500))),
+                maximum_attempts: 4,
+                non_retryable_error_types: vec![],
+            },
+            timer_backoff_threshold: Some(Duration::from_secs(1)),
+            ..Default::default()
+        });
+        let r2 = ctx.local_activity(LocalActivityOptions {
+            activity_type: "echo".to_string(),
+            input: "hi".as_json_payload().expect("serializes fine"),
+            retry_policy: RetryPolicy {
+                initial_interval: Some(prost_dur!(from_millis(15))),
+                backoff_coefficient: 10.,
+                maximum_interval: Some(prost_dur!(from_millis(1500))),
+                maximum_attempts: 4,
+                non_retryable_error_types: vec![],
+            },
+            timer_backoff_threshold: Some(Duration::from_secs(10)),
+            ..Default::default()
+        });
+        let (r1, r2) = tokio::join!(r1, r2);
+        assert!(r1.failed());
+        assert!(r2.failed());
+        Ok(().into())
+    });
+    worker.register_activity("echo", |_: ActContext, _: String| async {
+        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
+    });
 
-    while tasks.next().await.is_some() {}
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
 }
 
-#[async_trait::async_trait]
-pub trait WorkerTestHelpers {
-    async fn complete_execution(&self, run_id: &str);
-    async fn complete_timer(&self, run_id: &str, seq: u32, duration: Duration);
-}
-
-#[async_trait::async_trait]
-impl<T> WorkerTestHelpers for T
-where
-    T: CoreWorker + ?Sized,
-{
-    async fn complete_execution(&self, run_id: &str) {
-        self.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
-            run_id.to_string(),
-            vec![CompleteWorkflowExecution { result: None }.into()],
-        ))
+#[tokio::test]
+async fn repro_nondeterminism_with_timer_bug() {
+    let wf_name = "repro_nondeterminism_with_timer_bug";
+    let mut starter = CoreWfStarter::new(wf_name);
+    let mut worker = starter.worker().await;
+
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        let t1 = ctx.timer(Duration::from_secs(30));
+        let r1 = ctx.local_activity(LocalActivityOptions {
+            activity_type: "delay".to_string(),
+            input: "hi".as_json_payload().expect("serializes fine"),
+            retry_policy: RetryPolicy {
+                initial_interval: Some(prost_dur!(from_micros(15))),
+                backoff_coefficient: 1_000.,
+                maximum_interval: Some(prost_dur!(from_millis(1500))),
+                maximum_attempts: 4,
+                non_retryable_error_types: vec![],
+            },
+            timer_backoff_threshold: Some(Duration::from_secs(1)),
+            ..Default::default()
+        });
+        tokio::pin!(t1);
+        tokio::select! {
+            _ = &mut t1 => {},
+            _ = r1 => {
+                t1.cancel(&ctx);
+            },
+        }
+        ctx.timer(Duration::from_secs(1)).await;
+        Ok(().into())
+    });
+    worker.register_activity("delay", |_: ActContext, _: String| async {
+        tokio::time::sleep(Duration::from_secs(2)).await;
+        Ok(())
+    });
+
+    let run_id = worker
+        .submit_wf(
+            wf_name.to_owned(),
+            wf_name.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
         .await
         .unwrap();
-    }
-
-    async fn complete_timer(&self, run_id: &str, seq: u32, duration: Duration) {
-        self.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
-            run_id.to_string(),
-            vec![StartTimer {
-                seq,
-                start_to_fire_timeout: Some(duration.try_into().expect("duration fits")),
-            }
-            .into()],
-        ))
+    worker.run_until_done().await.unwrap();
+    starter
+        .fetch_history_and_replay(wf_name, run_id, worker.inner_mut())
         .await
         .unwrap();
-    }
+}
+
+#[rstest::rstest]
+#[tokio::test]
+async fn weird_la_nondeterminism_repro(#[values(true, false)] fix_hist: bool) {
+    init_integ_telem();
+    let mut hist = history_from_proto_binary(
+        "histories/evict_while_la_running_no_interference-85_history.bin",
+    )
+    .await
+    .unwrap();
+    if fix_hist {
+        // Replace broken ending with accurate ending
+        hist.events.truncate(20);
+        let mut thb = TestHistoryBuilder::from_history(hist.events);
+        thb.add_workflow_task_completed();
+        thb.add_workflow_execution_completed();
+        hist = thb.get_full_history_info().unwrap().into();
+    }
+
+    let mut worker = replay_sdk_worker([HistoryForReplay::new(hist, "fake".to_owned())]);
+    worker.register_wf(
+        "evict_while_la_running_no_interference",
+        la_problem_workflow,
+    );
+    worker.register_activity("delay", |_: ActContext, _: String| async {
+        tokio::time::sleep(Duration::from_secs(15)).await;
+        Ok(())
+    });
+    worker.run().await.unwrap();
+}
+
+#[tokio::test]
+async fn second_weird_la_nondeterminism_repro() {
+    init_integ_telem();
+    let mut hist = history_from_proto_binary(
+        "histories/evict_while_la_running_no_interference-23_history.bin",
+    )
+    .await
+    .unwrap();
+    // Chop off uninteresting ending
+    hist.events.truncate(24);
+    let mut thb = TestHistoryBuilder::from_history(hist.events);
+    thb.add_workflow_execution_completed();
+    hist = thb.get_full_history_info().unwrap().into();
+
+    let mut worker = replay_sdk_worker([HistoryForReplay::new(hist, "fake".to_owned())]);
+    worker.register_wf(
+        "evict_while_la_running_no_interference",
+        la_problem_workflow,
+    );
+    worker.register_activity("delay", |_: ActContext, _: String| async {
+        tokio::time::sleep(Duration::from_secs(15)).await;
+        Ok(())
+    });
+    worker.run().await.unwrap();
+}
+
+#[tokio::test]
+async fn third_weird_la_nondeterminism_repro() {
+    init_integ_telem();
+    let mut hist = history_from_proto_binary(
+        "histories/evict_while_la_running_no_interference-16_history.bin",
+    )
+    .await
+    .unwrap();
+    let mut thb = TestHistoryBuilder::from_history(hist.events);
+    thb.add_workflow_task_scheduled_and_started();
+    hist = thb.get_full_history_info().unwrap().into();
+
+    let mut worker = replay_sdk_worker([HistoryForReplay::new(hist, "fake".to_owned())]);
+    worker.register_wf(
+        "evict_while_la_running_no_interference",
+        la_problem_workflow,
+    );
+    worker.register_activity("delay", |_: ActContext, _: String| async {
+        tokio::time::sleep(Duration::from_secs(15)).await;
+        Ok(())
+    });
+    worker.run().await.unwrap();
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/client_tests.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/ephemeral_server_tests.rs`

 * *Files 15% similar despite different names*

```diff
@@ -1,32 +1,54 @@
 use std::time::{SystemTime, UNIX_EPOCH};
 use temporal_client::{ClientOptionsBuilder, TestService, WorkflowService};
 use temporal_sdk_core::ephemeral_server::{
-    EphemeralExe, EphemeralExeVersion, EphemeralServer, TemporaliteConfigBuilder,
-    TestServerConfigBuilder,
+    EphemeralExe, EphemeralExeVersion, EphemeralServer, TemporalDevServerConfigBuilder,
+    TemporaliteConfigBuilder, TestServerConfigBuilder,
 };
 use temporal_sdk_core_protos::temporal::api::workflowservice::v1::DescribeNamespaceRequest;
 use temporal_sdk_core_test_utils::{default_cached_download, NAMESPACE};
 use url::Url;
 
 #[tokio::test]
+async fn temporal_cli_default() {
+    let config = TemporalDevServerConfigBuilder::default()
+        .exe(default_cached_download())
+        .build()
+        .unwrap();
+    let mut server = config.start_server().await.unwrap();
+    assert_ephemeral_server(&server).await;
+    server.shutdown().await.unwrap();
+}
+
+#[tokio::test]
+async fn temporal_cli_fixed() {
+    let config = TemporalDevServerConfigBuilder::default()
+        .exe(fixed_cached_download("v0.4.0"))
+        .build()
+        .unwrap();
+    let mut server = config.start_server().await.unwrap();
+    assert_ephemeral_server(&server).await;
+    server.shutdown().await.unwrap();
+}
+
+#[tokio::test]
 async fn temporalite_default() {
     let config = TemporaliteConfigBuilder::default()
         .exe(default_cached_download())
         .build()
         .unwrap();
     let mut server = config.start_server().await.unwrap();
     assert_ephemeral_server(&server).await;
     server.shutdown().await.unwrap();
 }
 
 #[tokio::test]
 async fn temporalite_fixed() {
     let config = TemporaliteConfigBuilder::default()
-        .exe(fixed_cached_download("v0.1.1"))
+        .exe(fixed_cached_download("v0.2.0"))
         .build()
         .unwrap();
     let mut server = config.start_server().await.unwrap();
     assert_ephemeral_server(&server).await;
     server.shutdown().await.unwrap();
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/heartbeat_tests.rs`

 * *Files 2% similar despite different names*

```diff
@@ -13,17 +13,19 @@
         workflow_completion::WorkflowActivationCompletion,
         ActivityHeartbeat, ActivityTaskCompletion, AsJsonPayloadExt, IntoCompletion,
     },
     temporal::api::{
         common::v1::{Payload, RetryPolicy},
         enums::v1::TimeoutType,
     },
+    DEFAULT_ACTIVITY_TYPE,
 };
 use temporal_sdk_core_test_utils::{
-    init_core_and_create_wf, schedule_activity_cmd, CoreWfStarter, WorkerTestHelpers,
+    drain_pollers_and_shutdown, init_core_and_create_wf, schedule_activity_cmd, CoreWfStarter,
+    WorkerTestHelpers,
 };
 use tokio::time::sleep;
 
 #[tokio::test]
 async fn activity_heartbeat() {
     let mut starter = init_core_and_create_wf("activity_heartbeat").await;
     let core = starter.get_worker().await;
@@ -45,15 +47,15 @@
     .await
     .unwrap();
     // Poll activity and verify that it's been scheduled with correct parameters
     let task = core.poll_activity_task().await.unwrap();
     assert_matches!(
         task.variant,
         Some(activity_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
+            assert_eq!(start_activity.activity_type, DEFAULT_ACTIVITY_TYPE.to_string())
         }
     );
     // Heartbeat timeout is set to 1 second, this loop is going to send heartbeat every 100ms.
     // Activity shouldn't timeout since we are sending heartbeats regularly, however if we didn't
     // send heartbeats activity would have timed out as it takes 2 sec to execute this loop.
     for _ in 0u8..20 {
         sleep(Duration::from_millis(100)).await;
@@ -165,15 +167,15 @@
                     }),
                     ..
                 }
             )),
         },]
     );
     core.complete_execution(&task.run_id).await;
-    core.shutdown().await;
+    drain_pollers_and_shutdown(&core).await;
 }
 
 #[tokio::test]
 async fn activity_doesnt_heartbeat_hits_timeout_then_completes() {
     let wf_name = "activity_doesnt_heartbeat_hits_timeout_then_completes";
     let mut starter = CoreWfStarter::new(wf_name);
     let mut worker = starter.worker().await;
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/polling_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/visibility_tests.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,133 +1,151 @@
 use assert_matches::assert_matches;
-use futures::future::join_all;
-use std::time::Duration;
-use temporal_client::WorkflowOptions;
-use temporal_sdk::{WfContext, WorkflowResult};
-use temporal_sdk_core_protos::coresdk::{
-    activity_task::activity_task as act_task,
-    workflow_activation::{workflow_activation_job, FireTimer, WorkflowActivationJob},
-    workflow_commands::{ActivityCancellationType, RequestCancelActivity, StartTimer},
-    workflow_completion::WorkflowActivationCompletion,
-    IntoCompletion,
+use std::{sync::Arc, time::Duration};
+use temporal_client::{
+    ListClosedFilters, ListOpenFilters, Namespace, RegisterNamespaceOptions, StartTimeFilter,
+    WorkflowClientTrait, WorkflowExecutionFilter,
+};
+use temporal_sdk_core_protos::coresdk::workflow_activation::{
+    workflow_activation_job, WorkflowActivationJob,
 };
 use temporal_sdk_core_test_utils::{
-    init_core_and_create_wf, schedule_activity_cmd, CoreWfStarter, WorkerTestHelpers,
+    drain_pollers_and_shutdown, get_integ_server_options, CoreWfStarter, WorkerTestHelpers,
+    NAMESPACE,
 };
-use tokio::time::timeout;
+use tokio::time::sleep;
 
 #[tokio::test]
-async fn out_of_order_completion_doesnt_hang() {
-    let mut starter = init_core_and_create_wf("out_of_order_completion_doesnt_hang").await;
+async fn client_list_open_closed_workflow_executions() {
+    let wf_name = "client_list_open_closed_workflow_executions".to_owned();
+    let mut starter = CoreWfStarter::new(&wf_name);
     let core = starter.get_worker().await;
-    let task_q = starter.get_task_queue();
-    let activity_id = "act-1";
-    let task = core.poll_workflow_activation().await.unwrap();
-    // Complete workflow task and schedule activity and a timer that fires immediately
-    core.complete_workflow_activation(
-        vec![
-            schedule_activity_cmd(
-                0,
-                task_q,
-                activity_id,
-                ActivityCancellationType::TryCancel,
-                Duration::from_secs(60),
-                Duration::from_secs(60),
-            ),
-            StartTimer {
-                seq: 1,
-                start_to_fire_timeout: Some(prost_dur!(from_millis(50))),
-            }
-            .into(),
-        ]
-        .into_completion(task.run_id),
-    )
-    .await
-    .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters, we don't expect to
-    // complete it in this test as activity is try-cancelled.
-    let activity_task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        activity_task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
-    // Poll workflow task and verify that activity has failed.
+    let client = starter.get_client().await;
+
+    let earliest = std::time::SystemTime::now();
+    let latest = earliest + Duration::from_secs(60);
+
+    // start workflow
+    let run_id = starter.start_wf_with_id(wf_name.to_owned()).await;
     let task = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         task.jobs.as_slice(),
-        [
-            WorkflowActivationJob {
-                variant: Some(workflow_activation_job::Variant::FireTimer(
-                    FireTimer { seq: t_seq }
-                )),
-            },
-        ] => {
-            assert_eq!(*t_seq, 1);
-        }
+        [WorkflowActivationJob {
+            variant: Some(workflow_activation_job::Variant::StartWorkflow(_)),
+        }]
     );
 
-    // Start polling again *before* we complete the WFT
-    let cc = core.clone();
-    let jh = tokio::spawn(async move {
-        // We want to fail the test if this takes too long -- we should not hit long poll timeout
-        let task = timeout(Duration::from_secs(1), cc.poll_workflow_activation())
+    // List above OPEN workflow
+    let start_time_filter = StartTimeFilter {
+        earliest_time: Some(earliest).and_then(|t| t.try_into().ok()),
+        latest_time: Some(latest).and_then(|t| t.try_into().ok()),
+    };
+    let filter = ListOpenFilters::ExecutionFilter(WorkflowExecutionFilter {
+        workflow_id: wf_name.clone(),
+        run_id: "".to_owned(),
+    });
+    let open_workflows = client
+        .list_open_workflow_executions(1, Default::default(), Some(start_time_filter), Some(filter))
+        .await
+        .unwrap();
+    assert_eq!(open_workflows.executions.len(), 1);
+    let workflow = open_workflows.executions[0].clone();
+    assert_eq!(workflow.execution.as_ref().unwrap().workflow_id, wf_name);
+
+    // Complete workflow
+    core.complete_execution(&task.run_id).await;
+    drain_pollers_and_shutdown(&core).await;
+
+    // List above CLOSED workflow. Visibility doesn't always update immediately so we give this a
+    // few tries.
+    let mut passed = false;
+    for _ in 1..=5 {
+        let closed_workflows = client
+            .list_closed_workflow_executions(
+                1,
+                Default::default(),
+                Some(StartTimeFilter {
+                    earliest_time: Some(earliest).and_then(|t| t.try_into().ok()),
+                    latest_time: Some(latest).and_then(|t| t.try_into().ok()),
+                }),
+                Some(ListClosedFilters::ExecutionFilter(
+                    WorkflowExecutionFilter {
+                        workflow_id: wf_name.clone(),
+                        run_id: run_id.clone(),
+                    },
+                )),
+            )
             .await
-            .expect("Poll should come back right away")
             .unwrap();
-        assert_matches!(
-            task.jobs.as_slice(),
-            [WorkflowActivationJob {
-                variant: Some(workflow_activation_job::Variant::ResolveActivity(_)),
-            }]
-        );
-        cc.complete_execution(&task.run_id).await;
-    });
+        if closed_workflows.executions.len() == 1 {
+            let workflow = &closed_workflows.executions[0];
+            if workflow.execution.as_ref().unwrap().workflow_id == wf_name {
+                passed = true;
+                break;
+            }
+        }
+        sleep(Duration::from_millis(100)).await;
+    }
+    assert!(passed);
+}
 
-    tokio::time::sleep(Duration::from_millis(100)).await;
-    // Then complete the (last) WFT with a request to cancel the AT, which should produce a
-    // pending activation, unblocking the (already started) poll
-    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
-        task.run_id,
-        vec![RequestCancelActivity { seq: 0 }.into()],
-    ))
-    .await
-    .unwrap();
+#[tokio::test]
+async fn client_create_namespace() {
+    let client = Arc::new(
+        get_integ_server_options()
+            .connect(NAMESPACE.to_owned(), None, None)
+            .await
+            .expect("Must connect"),
+    );
 
-    jh.await.unwrap();
-}
+    let register_options = RegisterNamespaceOptions::builder()
+        .namespace("test-create-namespace")
+        .description("it's alive")
+        .build()
+        .unwrap();
 
-pub async fn many_parallel_timers_longhist(ctx: WfContext) -> WorkflowResult<()> {
-    for _ in 0..20 {
-        let mut futs = vec![];
-        for _ in 0..1000 {
-            futs.push(ctx.timer(Duration::from_millis(100)));
+    client
+        .register_namespace(register_options.clone())
+        .await
+        .unwrap();
+
+    //#Hack, not sure how else to wait for a proper response.  RegisterNamespace isn't safe to read
+    //after write
+    let mut attempts = 0;
+    let wait_time = Duration::from_secs(1);
+    loop {
+        attempts += 1;
+        let resp = client
+            .describe_namespace(Namespace::Name(register_options.namespace.clone()))
+            .await;
+
+        match resp {
+            Ok(n) => {
+                let namespace_info = n.namespace_info.unwrap();
+                assert_eq!(namespace_info.name, register_options.namespace);
+                assert_eq!(namespace_info.description, register_options.description);
+                return;
+            }
+            _ => {
+                if attempts == 12 {
+                    panic!("failed to query registered namespace");
+                }
+                sleep(wait_time).await
+            }
         }
-        join_all(futs).await;
     }
-    Ok(().into())
 }
 
-// Ignored for now because I can't actually get this to produce pages. Need to generate some
-// large payloads I think.
 #[tokio::test]
-#[ignore]
-async fn can_paginate_long_history() {
-    let wf_name = "can_paginate_long_history";
-    let mut starter = CoreWfStarter::new(wf_name);
-    // Do not use sticky queues so we are forced to paginate once history gets long
-    starter.max_cached_workflows(0);
-
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), many_parallel_timers_longhist);
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
+async fn client_describe_namespace() {
+    let client = Arc::new(
+        get_integ_server_options()
+            .connect(NAMESPACE.to_owned(), None, None)
+            .await
+            .expect("Must connect"),
+    );
+
+    let namespace_result = client
+        .describe_namespace(Namespace::Name(NAMESPACE.to_owned()))
         .await
         .unwrap();
-    worker.run_until_done().await.unwrap();
+    assert_eq!(namespace_result.namespace_info.unwrap().name, NAMESPACE);
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/queries_tests.rs`

 * *Files 12% similar despite different names*

```diff
@@ -6,15 +6,17 @@
     coresdk::{
         workflow_activation::{workflow_activation_job, WorkflowActivationJob},
         workflow_commands::{QueryResult, QuerySuccess, StartTimer},
         workflow_completion::WorkflowActivationCompletion,
     },
     temporal::api::{failure::v1::Failure, query::v1::WorkflowQuery},
 };
-use temporal_sdk_core_test_utils::{init_core_and_create_wf, CoreWfStarter, WorkerTestHelpers};
+use temporal_sdk_core_test_utils::{
+    drain_pollers_and_shutdown, init_core_and_create_wf, WorkerTestHelpers,
+};
 
 #[tokio::test]
 async fn simple_query_legacy() {
     let query_resp = b"response";
     let mut starter = init_core_and_create_wf("simple_query_legacy").await;
     let core = starter.get_worker().await;
     let workflow_id = starter.get_task_queue().to_string();
@@ -108,15 +110,15 @@
 #[rstest]
 #[case::no_eviction(false)]
 #[case::with_eviction(true)]
 #[tokio::test]
 async fn query_after_execution_complete(#[case] do_evict: bool) {
     let query_resp = b"response";
     let mut starter =
-        init_core_and_create_wf(&format!("query_after_execution_complete-{}", do_evict)).await;
+        init_core_and_create_wf(&format!("query_after_execution_complete-{do_evict}")).await;
     let core = &starter.get_worker().await;
     let workflow_id = &starter.get_task_queue().to_string();
 
     let do_workflow = |go_until_query: bool| async move {
         loop {
             let task = core.poll_workflow_activation().await.unwrap();
 
@@ -201,140 +203,15 @@
             assert_eq!(q_resp.unwrap()[0].data, query_resp);
         };
 
         query_futs.push(query_fut.boxed());
         query_futs.push(do_workflow(true).map(|_| ()).boxed());
     }
     while query_futs.next().await.is_some() {}
-    core.shutdown().await;
-}
-
-#[ignore]
-#[tokio::test]
-async fn repros_query_dropped_on_floor() {
-    // This test reliably repros the server dropping one of the two simultaneously issued queries.
-    let q1_resp = b"query_1_resp";
-    let q2_resp = b"query_2_resp";
-    let mut wf_starter = CoreWfStarter::new("repros_query_dropped_on_floor");
-    // Easiest way I discovered to reliably trigger new query path is with a WFT timeout
-    wf_starter.wft_timeout(Duration::from_secs(1));
-    let core = wf_starter.get_worker().await;
-    let task_q = wf_starter.get_task_queue().to_string();
-    wf_starter.start_wf().await;
-    let client = wf_starter.get_client().await;
-
-    let task = core.poll_workflow_activation().await.unwrap();
-    core.complete_timer(&task.run_id, 1, Duration::from_millis(500))
-        .await;
-
-    // Poll for a task we will time out
-    let task = core.poll_workflow_activation().await.unwrap();
-    tokio::time::sleep(Duration::from_secs(2)).await;
-    // Complete now-timed-out task (add a new timer)
-    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
-        task.run_id.clone(),
-        vec![],
-    ))
-    .await
-    .unwrap();
-
-    let run_id = task.run_id.to_string();
-    let q1_fut = async {
-        client
-            .query_workflow_execution(
-                task_q.clone(),
-                run_id,
-                WorkflowQuery {
-                    query_type: "query_1".to_string(),
-                    query_args: Some(b"hi 1".into()),
-                    header: None,
-                },
-            )
-            .await
-            .unwrap()
-    };
-    let run_id = task.run_id.to_string();
-    let q2_fut = async {
-        client
-            .query_workflow_execution(
-                task_q.clone(),
-                run_id,
-                WorkflowQuery {
-                    query_type: "query_2".to_string(),
-                    query_args: Some(b"hi 2".into()),
-                    header: None,
-                },
-            )
-            .await
-            .unwrap()
-    };
-    let workflow_completions_future = async {
-        let mut seen_q1 = false;
-        let mut seen_q2 = false;
-        while !seen_q1 || !seen_q2 {
-            let task = core.poll_workflow_activation().await.unwrap();
-
-            if matches!(
-                task.jobs[0],
-                WorkflowActivationJob {
-                    variant: Some(workflow_activation_job::Variant::RemoveFromCache(_)),
-                }
-            ) {
-                let task = core.poll_workflow_activation().await.unwrap();
-                core.complete_timer(&task.run_id, 1, Duration::from_millis(500))
-                    .await;
-                continue;
-            }
-
-            if matches!(
-                task.jobs[0],
-                WorkflowActivationJob {
-                    variant: Some(workflow_activation_job::Variant::FireTimer(_)),
-                }
-            ) {
-                // If we get the timer firing after replay, be done.
-                core.complete_execution(&task.run_id).await;
-            }
-
-            // There should be a query job (really, there should be both... server only sends one?)
-            let query = assert_matches!(
-                task.jobs.as_slice(),
-                [WorkflowActivationJob {
-                    variant: Some(workflow_activation_job::Variant::QueryWorkflow(q)),
-                }] => q
-            );
-            let resp = if query.query_type == "query_1" {
-                seen_q1 = true;
-                q1_resp
-            } else {
-                seen_q2 = true;
-                q2_resp
-            };
-            // Complete the query
-            core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
-                task.run_id,
-                vec![QueryResult {
-                    query_id: query.query_id.clone(),
-                    variant: Some(
-                        QuerySuccess {
-                            response: Some(resp.into()),
-                        }
-                        .into(),
-                    ),
-                }
-                .into()],
-            ))
-            .await
-            .unwrap();
-        }
-    };
-    let (q1_res, q2_res, _) = tokio::join!(q1_fut, q2_fut, workflow_completions_future);
-    // Ensure query responses are as expected
-    assert_eq!(&q1_res.unwrap()[0].data, q1_resp);
-    assert_eq!(&q2_res.unwrap()[0].data, q2_resp);
+    drain_pollers_and_shutdown(core).await;
 }
 
 #[tokio::test]
 async fn fail_legacy_query() {
     let query_err = "oh no broken";
     let mut starter = init_core_and_create_wf("fail_legacy_query").await;
     let core = starter.get_worker().await;
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/activities.rs`

 * *Files 3% similar despite different names*

```diff
@@ -1,13 +1,16 @@
+use crate::integ_tests::activity_functions::echo;
 use anyhow::anyhow;
 use assert_matches::assert_matches;
+use futures_util::future::join_all;
 use std::time::Duration;
 use temporal_client::{WfClientExt, WorkflowClientTrait, WorkflowExecutionResult, WorkflowOptions};
 use temporal_sdk::{
-    ActContext, ActExitValue, ActivityOptions, CancellableFuture, WfContext, WorkflowResult,
+    ActContext, ActExitValue, ActivityCancelledError, ActivityOptions, CancellableFuture,
+    WfContext, WorkflowResult,
 };
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::{
             self, activity_resolution as act_res, ActivityExecutionResult, ActivityResolution,
         },
         activity_task::activity_task as act_task,
@@ -16,24 +19,25 @@
         },
         workflow_commands::{ActivityCancellationType, RequestCancelActivity, StartTimer},
         workflow_completion::WorkflowActivationCompletion,
         ActivityHeartbeat, ActivityTaskCompletion, AsJsonPayloadExt, FromJsonPayloadExt,
         IntoCompletion,
     },
     temporal::api::{
-        common::v1::{ActivityType, Payload, Payloads},
+        common::v1::{ActivityType, Payload, Payloads, RetryPolicy},
         enums::v1::RetryState,
         failure::v1::{failure::FailureInfo, ActivityFailureInfo, Failure},
     },
-    TaskToken,
+    TaskToken, DEFAULT_ACTIVITY_TYPE,
 };
 use temporal_sdk_core_test_utils::{
-    init_core_and_create_wf, schedule_activity_cmd, CoreWfStarter, WorkerTestHelpers,
+    drain_pollers_and_shutdown, init_core_and_create_wf, schedule_activity_cmd, CoreWfStarter,
+    WorkerTestHelpers,
 };
-use tokio::time::sleep;
+use tokio::{join, sync::Semaphore, time::sleep};
 
 pub async fn one_activity_wf(ctx: WfContext) -> WorkflowResult<()> {
     ctx.activity(ActivityOptions {
         activity_type: "echo_activity".to_string(),
         start_to_close_timeout: Some(Duration::from_secs(5)),
         input: "hi!".as_json_payload().expect("serializes fine"),
         ..Default::default()
@@ -45,18 +49,15 @@
 #[tokio::test]
 async fn one_activity() {
     let wf_name = "one_activity";
     let mut starter = CoreWfStarter::new(wf_name);
     let mut worker = starter.worker().await;
     let client = starter.get_client().await;
     worker.register_wf(wf_name.to_owned(), one_activity_wf);
-    worker.register_activity(
-        "echo_activity",
-        |_ctx: ActContext, echo_me: String| async move { Ok(echo_me) },
-    );
+    worker.register_activity("echo_activity", echo);
 
     let run_id = worker
         .submit_wf(
             wf_name.to_owned(),
             wf_name.to_owned(),
             vec![],
             WorkflowOptions::default(),
@@ -94,15 +95,15 @@
     .await
     .unwrap();
     // Poll activity and verify that it's been scheduled with correct parameters
     let task = core.poll_activity_task().await.unwrap();
     assert_matches!(
         task.variant,
         Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
+            assert_eq!(start_activity.activity_type, DEFAULT_ACTIVITY_TYPE.to_string())
         }
     );
     let response_payload = Payload {
         data: b"hello ".to_vec(),
         metadata: Default::default(),
     };
     // Complete activity successfully.
@@ -151,22 +152,17 @@
             Duration::from_secs(60),
             Duration::from_secs(60),
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters
+    // Poll activity and verify that it's been scheduled
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Fail activity with non-retryable error
     let failure = Failure::application_failure("activity failed".to_string(), true);
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token,
         result: Some(ActivityExecutionResult::fail(failure.clone())),
     })
     .await
@@ -188,15 +184,15 @@
             assert_eq!(*seq, 0);
             assert_eq!(f, &Failure{
                 message: "Activity task failed".to_owned(),
                 cause: Some(Box::new(failure)),
                 failure_info: Some(FailureInfo::ActivityFailureInfo(ActivityFailureInfo{
                     activity_id: "act-1".to_owned(),
                     activity_type: Some(ActivityType {
-                        name: "test_activity".to_owned(),
+                        name: DEFAULT_ACTIVITY_TYPE.to_owned(),
                     }),
                     scheduled_event_id: 5,
                     started_event_id: 6,
                     identity: "integ_tester".to_owned(),
                     retry_state: RetryState::NonRetryableFailure as i32,
                 })),
                 ..Default::default()
@@ -223,22 +219,17 @@
             Duration::from_secs(60),
             Duration::from_secs(60),
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters
+    // Poll activity and verify that it's been scheduled
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Fail activity with non-retryable error
     let failure = Failure::application_failure_from_error(anyhow!("activity failed"), true);
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token,
         result: Some(ActivityExecutionResult::fail(failure.clone())),
     })
     .await
@@ -260,15 +251,15 @@
             assert_eq!(*seq, 0);
             assert_eq!(f, &Failure{
                 message: "Activity task failed".to_owned(),
                 cause: Some(Box::new(failure)),
                 failure_info: Some(FailureInfo::ActivityFailureInfo(ActivityFailureInfo{
                     activity_id: "act-1".to_owned(),
                     activity_type: Some(ActivityType {
-                        name: "test_activity".to_owned(),
+                        name: DEFAULT_ACTIVITY_TYPE.to_owned(),
                     }),
                     scheduled_event_id: 5,
                     started_event_id: 6,
                     identity: "integ_tester".to_owned(),
                     retry_state: RetryState::NonRetryableFailure as i32,
                 })),
                 ..Default::default()
@@ -297,36 +288,26 @@
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
     // Poll activity 1st time
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Fail activity with retryable error
     let failure = Failure::application_failure("activity failed".to_string(), false);
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token,
         result: Some(ActivityExecutionResult::fail(failure)),
     })
     .await
     .unwrap();
     // Poll 2nd time
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Complete activity successfully
     let response_payload = Payload {
         data: b"hello ".to_vec(),
         metadata: Default::default(),
     };
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token,
@@ -377,23 +358,18 @@
             }
             .into(),
         ]
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters, we don't expect to
-    // complete it in this test as activity is try-cancelled.
+    // Poll activity and verify that it's been scheduled, we don't expect to complete it in this
+    // test as activity is try-cancelled.
     let activity_task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        activity_task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(activity_task.variant, Some(act_task::Variant::Start(_)));
     // Poll workflow task and verify that activity has failed.
     let task = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         task.jobs.as_slice(),
         [
             WorkflowActivationJob {
                 variant: Some(workflow_activation_job::Variant::FireTimer(
@@ -522,23 +498,18 @@
             Duration::from_secs(1),
             Duration::from_secs(60),
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters, we don't expect to
-    // complete it in this test as activity is timed out after 1 second.
+    // Poll activity and verify that it's been scheduled, we don't expect to complete it in this
+    // test as activity is timed out after 1 second.
     let activity_task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        activity_task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(activity_task.variant, Some(act_task::Variant::Start(_)));
     let task = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         task.jobs.as_slice(),
         [
             WorkflowActivationJob {
                 variant: Some(workflow_activation_job::Variant::ResolveActivity(
                     ResolveActivity {
@@ -586,23 +557,18 @@
             }
             .into(),
         ]
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters, we don't expect to
-    // complete it in this test as activity is wait-cancelled.
+    // Poll activity and verify that it's been scheduled, we don't expect to complete it in this
+    // test as activity is wait-cancelled.
     let activity_task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        activity_task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(activity_task.variant, Some(act_task::Variant::Start(_)));
     // Poll workflow task and verify that activity has failed.
     let task = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         task.jobs.as_slice(),
         [
             WorkflowActivationJob {
                 variant: Some(workflow_activation_job::Variant::FireTimer(
@@ -653,23 +619,18 @@
             }
             .into(),
         ]
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters, we don't expect to
-    // complete it in this test as activity is abandoned.
+    // Poll activity and verify that it's been scheduled, we don't expect to complete it in this
+    // test as activity is abandoned.
     let activity_task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        activity_task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(activity_task.variant, Some(act_task::Variant::Start(_)));
     // Poll workflow task and verify that activity has failed.
     let task = core.poll_workflow_activation().await.unwrap();
     assert_matches!(
         task.jobs.as_slice(),
         [
             WorkflowActivationJob {
                 variant: Some(workflow_activation_job::Variant::FireTimer(
@@ -709,22 +670,17 @@
             Duration::from_secs(60),
             Duration::from_secs(60),
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters
+    // Poll activity and verify that it's been scheduled
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     let response_payload = Payload {
         data: b"hello ".to_vec(),
         metadata: Default::default(),
     };
     // Complete activity asynchronously.
     core.complete_activity_task(ActivityTaskCompletion {
         task_token: task.task_token.clone(),
@@ -781,22 +737,17 @@
             Duration::from_secs(60),
             Duration::from_secs(1),
         )
         .into_completion(task.run_id),
     )
     .await
     .unwrap();
-    // Poll activity and verify that it's been scheduled with correct parameters
+    // Poll activity and verify that it's been scheduled
     let task = core.poll_activity_task().await.unwrap();
-    assert_matches!(
-        task.variant,
-        Some(act_task::Variant::Start(start_activity)) => {
-            assert_eq!(start_activity.activity_type, "test_activity".to_string())
-        }
-    );
+    assert_matches!(task.variant, Some(act_task::Variant::Start(_)));
     // Delay the heartbeat
     sleep(Duration::from_secs(2)).await;
     core.record_activity_heartbeat(ActivityHeartbeat {
         task_token: task.task_token.clone(),
         details: vec![],
     });
 
@@ -810,15 +761,15 @@
         task_token: task.task_token.clone(),
         result: Some(ActivityExecutionResult::cancel_from_details(None)),
     })
     .await
     .unwrap();
 
     // Verify shutdown completes
-    core.shutdown().await;
+    drain_pollers_and_shutdown(&core).await;
     // Cleanup just in case
     starter
         .get_client()
         .await
         .terminate_workflow_execution(task_q.clone(), None)
         .await
         .unwrap();
@@ -891,15 +842,15 @@
             })
             .await;
 
         let res = match activity_resolution.status {
             Some(act_res::Status::Completed(activity_result::Success { result })) => result
                 .map(|p| String::from_json_payload(&p).unwrap())
                 .unwrap(),
-            _ => panic!("activity task failed {:?}", activity_resolution),
+            _ => panic!("activity task failed {activity_resolution:?}"),
         };
 
         assert_eq!(&res, async_response);
         Ok(().into())
     });
 
     let shared_token_ref = shared_token.clone();
@@ -945,7 +896,70 @@
             WorkflowOptions::default(),
         )
         .await
         .unwrap();
 
     worker.run_until_done().await.unwrap();
 }
+
+#[tokio::test]
+async fn graceful_shutdown() {
+    let wf_name = "graceful_shutdown";
+    let mut starter = CoreWfStarter::new(wf_name);
+    starter.worker_config.graceful_shutdown_period = Some(Duration::from_millis(500));
+    let mut worker = starter.worker().await;
+    let client = starter.get_client().await;
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        let act_futs = (1..=10).map(|_| {
+            ctx.activity(ActivityOptions {
+                activity_type: "sleeper".to_string(),
+                start_to_close_timeout: Some(Duration::from_secs(5)),
+                retry_policy: Some(RetryPolicy {
+                    maximum_attempts: 1,
+                    ..Default::default()
+                }),
+                cancellation_type: ActivityCancellationType::WaitCancellationCompleted,
+                input: "hi".as_json_payload().unwrap(),
+                ..Default::default()
+            })
+        });
+        join_all(act_futs).await;
+        Ok(().into())
+    });
+    static ACTS_STARTED: Semaphore = Semaphore::const_new(0);
+    static ACTS_DONE: Semaphore = Semaphore::const_new(0);
+    worker.register_activity("sleeper", |ctx: ActContext, _: String| async move {
+        ACTS_STARTED.add_permits(1);
+        // just wait to be cancelled
+        ctx.cancelled().await;
+        ACTS_DONE.add_permits(1);
+        Result::<(), _>::Err(ActivityCancelledError::default().into())
+    });
+
+    worker
+        .submit_wf(
+            wf_name.to_owned(),
+            wf_name.to_owned(),
+            vec![],
+            WorkflowOptions::default(),
+        )
+        .await
+        .unwrap();
+
+    let handle = worker.inner_mut().shutdown_handle();
+    let shutdowner = async {
+        // Wait for all acts to be started before initiating shutdown
+        let _ = ACTS_STARTED.acquire_many(10).await;
+        handle();
+        // Kill workflow once all acts are cancelled. This also ensures we actually see all the
+        // cancels, otherwise run_until_done will hang since the workflow won't complete.
+        let _ = ACTS_DONE.acquire_many(10).await;
+        client
+            .terminate_workflow_execution(wf_name.to_owned(), None)
+            .await
+            .unwrap();
+    };
+    let runner = async {
+        worker.run_until_done().await.unwrap();
+    };
+    join!(shutdowner, runner);
+}
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/appdata_propagation.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_external.rs`

 * *Files 2% similar despite different names*

```diff
@@ -29,14 +29,15 @@
     ctx.cancelled().await;
     Ok(().into())
 }
 
 #[tokio::test]
 async fn sends_cancel_to_other_wf() {
     let mut starter = CoreWfStarter::new("sends_cancel_to_other_wf");
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf("sender", cancel_sender);
     worker.register_wf("receiver", cancel_receiver);
 
     let receiver_run_id = worker
         .submit_wf(
             RECEIVER_WFID,
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/cancel_wf.rs`

 * *Files 17% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 use std::time::Duration;
-use temporal_client::{WorkflowClientTrait, WorkflowOptions};
+use temporal_client::WorkflowClientTrait;
 use temporal_sdk::{WfContext, WfExitValue, WorkflowResult};
 use temporal_sdk_core_protos::temporal::api::enums::v1::WorkflowExecutionStatus;
 use temporal_sdk_core_test_utils::CoreWfStarter;
 
 async fn cancelled_wf(mut ctx: WfContext) -> WorkflowResult<()> {
     let cancelled = tokio::select! {
         _ = ctx.timer(Duration::from_secs(500)) => false,
@@ -17,41 +17,34 @@
     }
 }
 
 #[tokio::test]
 async fn cancel_during_timer() {
     let wf_name = "cancel_during_timer";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     let client = starter.get_client().await;
     worker.register_wf(wf_name.to_string(), cancelled_wf);
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
+    let wf_id = starter.get_task_queue().to_string();
 
     let canceller = async {
         tokio::time::sleep(Duration::from_millis(500)).await;
         // Cancel the workflow externally
         client
-            .cancel_workflow_execution(wf_name.to_string(), None, "Dieee".to_string(), None)
+            .cancel_workflow_execution(wf_id.clone(), None, "Dieee".to_string(), None)
             .await
             .unwrap();
     };
 
     let (_, res) = tokio::join!(canceller, worker.run_until_done());
     res.unwrap();
     let desc = client
-        .describe_workflow_execution(wf_name.to_string(), None)
+        .describe_workflow_execution(wf_id, None)
         .await
         .unwrap();
 
     assert_eq!(
         desc.workflow_execution_info.unwrap().status,
         WorkflowExecutionStatus::Canceled as i32
     );
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/continue_as_new.rs`

 * *Files 7% similar despite different names*

```diff
@@ -17,14 +17,15 @@
     })
 }
 
 #[tokio::test]
 async fn continue_as_new_happy_path() {
     let wf_name = "continue_as_new_happy_path";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_string(), continue_as_new_wf);
 
     worker
         .submit_wf(
             wf_name.to_string(),
             wf_name.to_string(),
@@ -36,19 +37,22 @@
     worker.run_until_done().await.unwrap();
 }
 
 #[tokio::test]
 async fn continue_as_new_multiple_concurrent() {
     let wf_name = "continue_as_new_multiple_concurrent";
     let mut starter = CoreWfStarter::new(wf_name);
-    starter.max_cached_workflows(3).max_wft(3);
+    starter
+        .no_remote_activities()
+        .max_cached_workflows(3)
+        .max_wft(3);
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_string(), continue_as_new_wf);
 
-    let wf_names = (1..=20).map(|i| format!("{}-{}", wf_name, i));
+    let wf_names = (1..=20).map(|i| format!("{wf_name}-{i}"));
     for name in wf_names.clone() {
         worker
             .submit_wf(
                 name.to_string(),
                 wf_name.to_string(),
                 vec![[1].into()],
                 WorkflowOptions::default(),
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/determinism.rs`

 * *Files 9% similar despite different names*

```diff
@@ -1,12 +1,11 @@
 use std::{
     sync::atomic::{AtomicUsize, Ordering},
     time::Duration,
 };
-use temporal_client::WorkflowOptions;
 use temporal_sdk::{ActivityOptions, WfContext, WorkflowResult};
 use temporal_sdk_core_test_utils::CoreWfStarter;
 
 static RUN_CT: AtomicUsize = AtomicUsize::new(1);
 pub async fn timer_wf_nondeterministic(ctx: WfContext) -> WorkflowResult<()> {
     let run_ct = RUN_CT.fetch_add(1, Ordering::Relaxed);
 
@@ -32,23 +31,16 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn test_determinism_error_then_recovers() {
     let wf_name = "test_determinism_error_then_recovers";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
 
     worker.register_wf(wf_name.to_owned(), timer_wf_nondeterministic);
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
     // 4 because we still add on the 3rd and final attempt
     assert_eq!(RUN_CT.load(Ordering::Relaxed), 4);
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/local_activities.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/core/src/worker/activities.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,788 +1,666 @@
-use anyhow::anyhow;
-use futures::future::join_all;
-use futures_util::stream::{FuturesUnordered, StreamExt};
-use std::{
-    sync::atomic::{AtomicU8, Ordering},
-    time::Duration,
+mod activity_heartbeat_manager;
+mod activity_task_poller_stream;
+mod local_activities;
+
+pub(crate) use local_activities::{
+    DispatchOrTimeoutLA, ExecutingLAId, LACompleteAction, LocalActRequest,
+    LocalActivityExecutionResult, LocalActivityManager, LocalActivityResolution,
+    LocalInFlightActInfo, NewLocalAct,
+};
+
+use crate::{
+    abstractions::{
+        ClosableMeteredSemaphore, MeteredSemaphore, OwnedMeteredSemPermit,
+        TrackedOwnedMeteredSemPermit, UsedMeteredSemPermit,
+    },
+    pollers::BoxedActPoller,
+    telemetry::metrics::{
+        activity_type, activity_worker_type, eager, workflow_type, MetricsContext,
+    },
+    worker::{
+        activities::{
+            activity_heartbeat_manager::ActivityHeartbeatError,
+            activity_task_poller_stream::new_activity_task_poller,
+        },
+        client::WorkerClient,
+    },
+    PollActivityError, TaskToken,
+};
+use activity_heartbeat_manager::ActivityHeartbeatManager;
+use dashmap::DashMap;
+use futures::{
+    stream,
+    stream::{BoxStream, PollNext},
+    Stream, StreamExt,
 };
-use temporal_client::{WorkflowClientTrait, WorkflowOptions};
-use temporal_sdk::{
-    interceptors::WorkerInterceptor, ActContext, ActivityCancelledError, ActivityOptions,
-    CancellableFuture, LocalActivityOptions, WfContext, WorkflowResult,
+use governor::{Quota, RateLimiter};
+use std::{
+    convert::TryInto,
+    future,
+    sync::{
+        atomic::{AtomicBool, Ordering},
+        Arc,
+    },
+    time::{Duration, Instant},
 };
-use temporal_sdk_core::replay::HistoryForReplay;
 use temporal_sdk_core_protos::{
     coresdk::{
-        workflow_commands::ActivityCancellationType,
-        workflow_completion::WorkflowActivationCompletion, AsJsonPayloadExt,
+        activity_result::{self as ar, activity_execution_result as aer},
+        activity_task::{ActivityCancelReason, ActivityTask},
+        ActivityHeartbeat,
+    },
+    temporal::api::{
+        failure::v1::{failure::FailureInfo, ApplicationFailureInfo, CanceledFailureInfo, Failure},
+        workflowservice::v1::PollActivityTaskQueueResponse,
     },
-    temporal::api::{common::v1::RetryPolicy, enums::v1::TimeoutType},
-    TestHistoryBuilder,
 };
-use temporal_sdk_core_test_utils::{
-    history_from_proto_binary, init_integ_telem, replay_sdk_worker, CoreWfStarter,
+use tokio::{
+    join,
+    sync::{
+        mpsc::{unbounded_channel, UnboundedReceiver, UnboundedSender},
+        Mutex, Notify,
+    },
 };
+use tokio_stream::wrappers::UnboundedReceiverStream;
 use tokio_util::sync::CancellationToken;
+use tracing::Span;
 
-pub async fn echo(_ctx: ActContext, e: String) -> anyhow::Result<String> {
-    Ok(e)
+type OutstandingActMap = Arc<DashMap<TaskToken, RemoteInFlightActInfo>>;
+
+#[derive(Debug, derive_more::Constructor)]
+struct PendingActivityCancel {
+    task_token: TaskToken,
+    reason: ActivityCancelReason,
+}
+
+/// Contains details that core wants to store while an activity is running.
+#[derive(Debug)]
+struct InFlightActInfo {
+    pub activity_type: String,
+    pub workflow_type: String,
+    /// Only kept for logging reasons
+    pub workflow_id: String,
+    /// Only kept for logging reasons
+    pub workflow_run_id: String,
+    start_time: Instant,
+}
+
+/// Augments [InFlightActInfo] with details specific to remote activities
+struct RemoteInFlightActInfo {
+    pub base: InFlightActInfo,
+    /// Used to calculate aggregation delay between activity heartbeats.
+    pub heartbeat_timeout: Option<prost_types::Duration>,
+    /// Set if we have already issued a cancellation activation to lang for this activity, with
+    /// the original reason we issued the cancel.
+    pub issued_cancel_to_lang: Option<ActivityCancelReason>,
+    /// Set to true if we have already learned from the server this activity doesn't exist. EX:
+    /// we have learned from heartbeating and issued a cancel task, in which case we may simply
+    /// discard the reply.
+    pub known_not_found: bool,
+    /// The permit from the max concurrent semaphore
+    _permit: UsedMeteredSemPermit,
+}
+impl RemoteInFlightActInfo {
+    fn new(poll_resp: &PollActivityTaskQueueResponse, permit: UsedMeteredSemPermit) -> Self {
+        let wec = poll_resp.workflow_execution.clone().unwrap_or_default();
+        Self {
+            base: InFlightActInfo {
+                activity_type: poll_resp.activity_type.clone().unwrap_or_default().name,
+                workflow_type: poll_resp.workflow_type.clone().unwrap_or_default().name,
+                workflow_id: wec.workflow_id,
+                workflow_run_id: wec.run_id,
+                start_time: Instant::now(),
+            },
+            heartbeat_timeout: poll_resp.heartbeat_timeout.clone(),
+            issued_cancel_to_lang: None,
+            known_not_found: false,
+            _permit: permit,
+        }
+    }
 }
 
-pub async fn one_local_activity_wf(ctx: WfContext) -> WorkflowResult<()> {
-    let initial_workflow_time = ctx.workflow_time().expect("Workflow time should be set");
-    ctx.local_activity(LocalActivityOptions {
-        activity_type: "echo_activity".to_string(),
-        input: "hi!".as_json_payload().expect("serializes fine"),
-        ..Default::default()
-    })
-    .await;
-    // Verify LA execution advances the clock
-    assert!(initial_workflow_time < ctx.workflow_time().unwrap());
-    Ok(().into())
-}
-
-#[tokio::test]
-async fn one_local_activity() {
-    let wf_name = "one_local_activity";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), one_local_activity_wf);
-    worker.register_activity("echo_activity", echo);
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-pub async fn local_act_concurrent_with_timer_wf(ctx: WfContext) -> WorkflowResult<()> {
-    let la = ctx.local_activity(LocalActivityOptions {
-        activity_type: "echo_activity".to_string(),
-        input: "hi!".as_json_payload().expect("serializes fine"),
-        ..Default::default()
-    });
-    let timer = ctx.timer(Duration::from_secs(1));
-    tokio::join!(la, timer);
-    Ok(().into())
-}
-
-#[tokio::test]
-async fn local_act_concurrent_with_timer() {
-    let wf_name = "local_act_concurrent_with_timer";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), local_act_concurrent_with_timer_wf);
-    worker.register_activity("echo_activity", echo);
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-pub async fn local_act_then_timer_then_wait(ctx: WfContext) -> WorkflowResult<()> {
-    let la = ctx.local_activity(LocalActivityOptions {
-        activity_type: "echo_activity".to_string(),
-        input: "hi!".as_json_payload().expect("serializes fine"),
-        ..Default::default()
-    });
-    ctx.timer(Duration::from_secs(1)).await;
-    let res = la.await;
-    assert!(res.completed_ok());
-    Ok(().into())
-}
-
-#[tokio::test]
-async fn local_act_then_timer_then_wait_result() {
-    let wf_name = "local_act_then_timer_then_wait_result";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
-    worker.register_activity("echo_activity", echo);
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-#[tokio::test]
-async fn long_running_local_act_with_timer() {
-    let wf_name = "long_running_local_act_with_timer";
-    let mut starter = CoreWfStarter::new(wf_name);
-    starter.wft_timeout(Duration::from_secs(1));
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
-    worker.register_activity("echo_activity", |_ctx: ActContext, str: String| async {
-        tokio::time::sleep(Duration::from_secs(4)).await;
-        Ok(str)
-    });
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-pub async fn local_act_fanout_wf(ctx: WfContext) -> WorkflowResult<()> {
-    let las: Vec<_> = (1..=50)
-        .map(|i| {
-            ctx.local_activity(LocalActivityOptions {
-                activity_type: "echo_activity".to_string(),
-                input: format!("Hi {}", i)
-                    .as_json_payload()
-                    .expect("serializes fine"),
-                ..Default::default()
-            })
-        })
-        .collect();
-    ctx.timer(Duration::from_secs(1)).await;
-    join_all(las).await;
-    Ok(().into())
-}
-
-#[tokio::test]
-async fn local_act_fanout() {
-    let wf_name = "local_act_fanout";
-    let mut starter = CoreWfStarter::new(wf_name);
-    starter.max_local_at(1);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), local_act_fanout_wf);
-    worker.register_activity("echo_activity", echo);
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-#[tokio::test]
-async fn local_act_retry_timer_backoff() {
-    let wf_name = "local_act_retry_timer_backoff";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
-        let res = ctx
-            .local_activity(LocalActivityOptions {
-                activity_type: "echo".to_string(),
-                input: "hi".as_json_payload().expect("serializes fine"),
-                retry_policy: RetryPolicy {
-                    initial_interval: Some(prost_dur!(from_micros(15))),
-                    // We want two local backoffs that are short. Third backoff will use timer
-                    backoff_coefficient: 1_000.,
-                    maximum_interval: Some(prost_dur!(from_millis(1500))),
-                    maximum_attempts: 4,
-                    non_retryable_error_types: vec![],
-                },
-                timer_backoff_threshold: Some(Duration::from_secs(1)),
-                ..Default::default()
-            })
-            .await;
-        assert!(res.failed());
-        Ok(().into())
-    });
-    worker.register_activity("echo", |_: ActContext, _: String| async {
-        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
-    });
-
-    let run_id = worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-    starter
-        .fetch_history_and_replay(wf_name, run_id, worker.inner_mut())
-        .await
-        .unwrap();
-}
-
-#[rstest::rstest]
-#[case::wait(ActivityCancellationType::WaitCancellationCompleted)]
-#[case::try_cancel(ActivityCancellationType::TryCancel)]
-#[case::abandon(ActivityCancellationType::Abandon)]
-#[tokio::test]
-async fn cancel_immediate(#[case] cancel_type: ActivityCancellationType) {
-    let wf_name = format!("cancel_immediate_{:?}", cancel_type);
-    let mut starter = CoreWfStarter::new(&wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(&wf_name, move |ctx: WfContext| async move {
-        let la = ctx.local_activity(LocalActivityOptions {
-            activity_type: "echo".to_string(),
-            input: "hi".as_json_payload().expect("serializes fine"),
-            cancel_type,
-            ..Default::default()
+pub(crate) struct WorkerActivityTasks {
+    /// Token which is cancelled once shutdown is beginning
+    shutdown_initiated_token: CancellationToken,
+    /// Centralizes management of heartbeat issuing / throttling
+    heartbeat_manager: ActivityHeartbeatManager,
+    /// Combined stream for any ActivityTask producing source (polls, eager activities,
+    /// cancellations)
+    activity_task_stream: Mutex<BoxStream<'static, Result<ActivityTask, PollActivityError>>>,
+    /// Activities that have been issued to lang but not yet completed
+    outstanding_activity_tasks: OutstandingActMap,
+    /// Ensures we don't exceed this worker's maximum concurrent activity limit for activities. This
+    /// semaphore is used to limit eager activities but shares the same underlying
+    /// [MeteredSemaphore] that is used to limit the concurrency for non-eager activities.
+    eager_activities_semaphore: Arc<ClosableMeteredSemaphore>,
+    /// Holds activity tasks we have received in direct response to workflow task completion (a.k.a
+    /// eager activities). Tasks received in this stream hold a "tracked" permit that is issued by
+    /// the `eager_activities_semaphore`.
+    eager_activities_tx: UnboundedSender<TrackedPermittedTqResp>,
+
+    metrics: MetricsContext,
+
+    max_heartbeat_throttle_interval: Duration,
+    default_heartbeat_throttle_interval: Duration,
+
+    /// Wakes every time an activity is removed from the outstanding map
+    complete_notify: Arc<Notify>,
+    /// Token to notify when poll returned a shutdown error
+    poll_returned_shutdown_token: CancellationToken,
+}
+
+#[derive(derive_more::From)]
+enum ActivityTaskSource {
+    PendingCancel(PendingActivityCancel),
+    PendingStart(Result<(PermittedTqResp, bool), PollActivityError>),
+}
+
+impl WorkerActivityTasks {
+    #[allow(clippy::too_many_arguments)]
+    pub(crate) fn new(
+        max_activity_tasks: usize,
+        max_worker_act_per_sec: Option<f64>,
+        poller: BoxedActPoller,
+        client: Arc<dyn WorkerClient>,
+        metrics: MetricsContext,
+        max_heartbeat_throttle_interval: Duration,
+        default_heartbeat_throttle_interval: Duration,
+        graceful_shutdown: Option<Duration>,
+    ) -> Self {
+        let semaphore = Arc::new(MeteredSemaphore::new(
+            max_activity_tasks,
+            metrics.with_new_attrs([activity_worker_type()]),
+            MetricsContext::available_task_slots,
+        ));
+        let shutdown_initiated_token = CancellationToken::new();
+        let rate_limiter = max_worker_act_per_sec.and_then(|ps| {
+            Quota::with_period(Duration::from_secs_f64(ps.recip())).map(RateLimiter::direct)
         });
-        la.cancel(&ctx);
-        let resolution = la.await;
-        assert!(resolution.cancelled());
-        Ok(().into())
-    });
-
-    // If we don't use this, we'd hang on shutdown for abandon cancel modes.
-    let manual_cancel = CancellationToken::new();
-    let manual_cancel_act = manual_cancel.clone();
-
-    worker.register_activity("echo", move |ctx: ActContext, _: String| {
-        let manual_cancel_act = manual_cancel_act.clone();
-        async move {
-            tokio::select! {
-                _ = tokio::time::sleep(Duration::from_secs(10)) => {},
-                _ = ctx.cancelled() => {
-                    return Err(anyhow!(ActivityCancelledError::default()))
-                }
-                _ = manual_cancel_act.cancelled() => {}
-            }
-            Ok(())
+        let outstanding_activity_tasks = Arc::new(DashMap::new());
+        let server_poller_stream = new_activity_task_poller(
+            poller,
+            semaphore.clone(),
+            rate_limiter,
+            metrics.clone(),
+            shutdown_initiated_token.clone(),
+        );
+        let (eager_activities_tx, eager_activities_rx) = unbounded_channel();
+        let eager_activities_semaphore = ClosableMeteredSemaphore::new_arc(semaphore);
+
+        let start_tasks_stream_complete = CancellationToken::new();
+        let starts_stream = Self::merge_start_task_sources(
+            eager_activities_rx,
+            server_poller_stream,
+            eager_activities_semaphore.clone(),
+            start_tasks_stream_complete.clone(),
+        );
+        let (cancels_tx, cancels_rx) = unbounded_channel();
+        let heartbeat_manager = ActivityHeartbeatManager::new(client, cancels_tx.clone());
+        let complete_notify = Arc::new(Notify::new());
+        let source_stream = stream::select_with_strategy(
+            UnboundedReceiverStream::new(cancels_rx).map(ActivityTaskSource::from),
+            starts_stream.map(ActivityTaskSource::from),
+            |_: &mut ()| PollNext::Left,
+        );
+
+        let activity_task_stream = ActivityTaskStream {
+            source_stream,
+            outstanding_tasks: outstanding_activity_tasks.clone(),
+            start_tasks_stream_complete,
+            complete_notify: complete_notify.clone(),
+            grace_period: graceful_shutdown,
+            cancels_tx,
+            shutdown_initiated_token: shutdown_initiated_token.clone(),
+            metrics: metrics.clone(),
         }
-    });
+        .streamify();
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker
-        .run_until_done_intercepted(Some(LACancellerInterceptor {
-            token: manual_cancel,
-        }))
-        .await
-        .unwrap();
-}
-
-struct LACancellerInterceptor {
-    token: CancellationToken,
-}
-#[async_trait::async_trait(?Send)]
-impl WorkerInterceptor for LACancellerInterceptor {
-    async fn on_workflow_activation_completion(&self, _: &WorkflowActivationCompletion) {}
-    fn on_shutdown(&self, _: &temporal_sdk::Worker) {
-        self.token.cancel()
+        Self {
+            shutdown_initiated_token,
+            eager_activities_tx,
+            heartbeat_manager,
+            activity_task_stream: Mutex::new(activity_task_stream.boxed()),
+            eager_activities_semaphore,
+            complete_notify,
+            metrics,
+            max_heartbeat_throttle_interval,
+            default_heartbeat_throttle_interval,
+            poll_returned_shutdown_token: CancellationToken::new(),
+            outstanding_activity_tasks,
+        }
     }
-}
 
-#[rstest::rstest]
-#[case::while_running(None)]
-#[case::while_backing_off(Some(Duration::from_millis(1500)))]
-#[case::while_backing_off_locally(Some(Duration::from_millis(150)))]
-#[tokio::test]
-async fn cancel_after_act_starts(
-    #[case] cancel_on_backoff: Option<Duration>,
-    #[values(
-        ActivityCancellationType::WaitCancellationCompleted,
-        ActivityCancellationType::TryCancel,
-        ActivityCancellationType::Abandon
-    )]
-    cancel_type: ActivityCancellationType,
-) {
-    let wf_name = format!(
-        "cancel_after_act_starts_timer_{:?}_{:?}",
-        cancel_on_backoff, cancel_type
-    );
-    let mut starter = CoreWfStarter::new(&wf_name);
-    starter.wft_timeout(Duration::from_secs(1));
-    let mut worker = starter.worker().await;
-    let bo_dur = cancel_on_backoff.unwrap_or_else(|| Duration::from_secs(1));
-    worker.register_wf(&wf_name, move |ctx: WfContext| async move {
-        let la = ctx.local_activity(LocalActivityOptions {
-            activity_type: "echo".to_string(),
-            input: "hi".as_json_payload().expect("serializes fine"),
-            retry_policy: RetryPolicy {
-                initial_interval: Some(bo_dur.try_into().unwrap()),
-                backoff_coefficient: 1.,
-                maximum_interval: Some(bo_dur.try_into().unwrap()),
-                // Retry forever until cancelled
-                ..Default::default()
-            },
-            timer_backoff_threshold: Some(Duration::from_secs(1)),
-            cancel_type,
-            ..Default::default()
-        });
-        ctx.timer(Duration::from_secs(1)).await;
-        // Note that this cancel can't go through for *two* WF tasks, because we do a full heartbeat
-        // before the timer (LA hasn't resolved), and then the timer fired event won't appear in
-        // history until *after* the next WFT because we force generated it when we sent the timer
-        // command.
-        la.cancel(&ctx);
-        // This extra timer is here to ensure the presence of another WF task doesn't mess up
-        // resolving the LA with cancel on replay
-        ctx.timer(Duration::from_secs(1)).await;
-        let resolution = la.await;
-        assert!(resolution.cancelled());
-        Ok(().into())
-    });
-
-    // If we don't use this, we'd hang on shutdown for abandon cancel modes.
-    let manual_cancel = CancellationToken::new();
-    let manual_cancel_act = manual_cancel.clone();
-
-    worker.register_activity("echo", move |ctx: ActContext, _: String| {
-        let manual_cancel_act = manual_cancel_act.clone();
-        async move {
-            if cancel_on_backoff.is_some() {
-                if ctx.is_cancelled() {
-                    return Err(anyhow!(ActivityCancelledError::default()));
+    /// Merges the server poll and eager [ActivityTask] sources
+    fn merge_start_task_sources(
+        non_poll_tasks_rx: UnboundedReceiver<TrackedPermittedTqResp>,
+        poller_stream: impl Stream<Item = Result<PermittedTqResp, tonic::Status>>,
+        eager_activities_semaphore: Arc<ClosableMeteredSemaphore>,
+        on_complete_token: CancellationToken,
+    ) -> impl Stream<Item = Result<(PermittedTqResp, bool), PollActivityError>> {
+        let non_poll_stream = stream::unfold(
+            (non_poll_tasks_rx, eager_activities_semaphore),
+            |(mut non_poll_tasks_rx, eager_activities_semaphore)| async move {
+                loop {
+                    tokio::select! {
+                        biased;
+
+                        task_opt = non_poll_tasks_rx.recv() => {
+                            // Add is_eager true and wrap in Result
+                            return task_opt.map(|task| (
+                                Ok((PermittedTqResp{ permit: task.permit.into(), resp: task.resp },
+                                    true)),
+                                (non_poll_tasks_rx, eager_activities_semaphore)));
+                        }
+                        _ = eager_activities_semaphore.close_complete() => {
+                            // Once shutting down, we stop accepting eager activities
+                            non_poll_tasks_rx.close();
+                            continue;
+                        }
+                    }
                 }
-                // Just fail constantly so we get stuck on the backoff timer
-                return Err(anyhow!("Oh no I failed!"));
-            } else {
-                tokio::select! {
-                    _ = tokio::time::sleep(Duration::from_secs(100)) => {},
-                    _ = ctx.cancelled() => {
-                        return Err(anyhow!(ActivityCancelledError::default()))
+            },
+        );
+        // Add is_eager false
+        let poller_stream = poller_stream.map(|res| res.map(|task| (task, false)));
+
+        // Prefer eager activities over polling the server
+        stream::select_with_strategy(non_poll_stream, poller_stream, |_: &mut ()| PollNext::Left)
+            .map(|res| Some(res.map_err(Into::into)))
+            .chain(futures::stream::once(async move {
+                on_complete_token.cancel();
+                None
+            }))
+            .filter_map(future::ready)
+    }
+
+    pub(crate) fn initiate_shutdown(&self) {
+        self.shutdown_initiated_token.cancel();
+        self.eager_activities_semaphore.close();
+    }
+
+    pub(crate) async fn shutdown(&self) {
+        self.initiate_shutdown();
+        self.poll_returned_shutdown_token.cancelled().await;
+        self.heartbeat_manager.shutdown().await;
+    }
+
+    /// Exclusive poll for activity tasks
+    ///
+    /// Polls the various task sources (server polls, eager activities, cancellations) while
+    /// respecting the provided rate limits and allowed concurrency. Returns
+    /// [PollActivityError::ShutDown] after shutdown is completed and all tasks sources are
+    /// depleted.
+    pub(crate) async fn poll(&self) -> Result<ActivityTask, PollActivityError> {
+        let mut poller_stream = self.activity_task_stream.lock().await;
+        poller_stream.next().await.unwrap_or_else(|| {
+            self.poll_returned_shutdown_token.cancel();
+            Err(PollActivityError::ShutDown)
+        })
+    }
+
+    pub(crate) async fn complete(
+        &self,
+        task_token: TaskToken,
+        status: aer::Status,
+        client: &dyn WorkerClient,
+    ) {
+        if let Some((_, act_info)) = self.outstanding_activity_tasks.remove(&task_token) {
+            let act_metrics = self.metrics.with_new_attrs([
+                activity_type(act_info.base.activity_type),
+                workflow_type(act_info.base.workflow_type),
+            ]);
+            Span::current().record("workflow_id", act_info.base.workflow_id);
+            Span::current().record("run_id", act_info.base.workflow_run_id);
+            act_metrics.act_execution_latency(act_info.base.start_time.elapsed());
+            let known_not_found = act_info.known_not_found;
+
+            self.heartbeat_manager.evict(task_token.clone()).await;
+            self.complete_notify.notify_waiters();
+
+            // No need to report activities which we already know the server doesn't care about
+            if !known_not_found {
+                let maybe_net_err = match status {
+                    aer::Status::WillCompleteAsync(_) => None,
+                    aer::Status::Completed(ar::Success { result }) => client
+                        .complete_activity_task(task_token.clone(), result.map(Into::into))
+                        .await
+                        .err(),
+                    aer::Status::Failed(ar::Failure { failure }) => {
+                        act_metrics.act_execution_failed();
+                        client
+                            .fail_activity_task(task_token.clone(), failure.map(Into::into))
+                            .await
+                            .err()
                     }
-                    _ = manual_cancel_act.cancelled() => {
-                        return Ok(())
+                    aer::Status::Cancelled(ar::Cancellation { failure }) => {
+                        if matches!(
+                            act_info.issued_cancel_to_lang,
+                            Some(ActivityCancelReason::WorkerShutdown),
+                        ) {
+                            // We don't report cancels for graceful shutdown as failures, so we
+                            // don't wait for the whole timeout to elapse, which is what would
+                            // happen anyway.
+                            client
+                                .fail_activity_task(
+                                    task_token.clone(),
+                                    Some(worker_shutdown_failure()),
+                                )
+                                .await
+                                .err()
+                        } else {
+                            let details = if let Some(Failure {
+                                failure_info:
+                                    Some(FailureInfo::CanceledFailureInfo(CanceledFailureInfo {
+                                        details,
+                                    })),
+                                ..
+                            }) = failure
+                            {
+                                details
+                            } else {
+                                warn!(task_token = ? task_token,
+                                "Expected activity cancelled status with CanceledFailureInfo");
+                                None
+                            };
+                            client
+                                .cancel_activity_task(task_token.clone(), details.map(Into::into))
+                                .await
+                                .err()
+                        }
                     }
-                }
-            }
-            Err(anyhow!("Oh no I failed!"))
-        }
-    });
+                };
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker
-        .run_until_done_intercepted(Some(LACancellerInterceptor {
-            token: manual_cancel,
-        }))
-        .await
-        .unwrap();
-}
-
-#[rstest::rstest]
-#[case::schedule(true)]
-#[case::start(false)]
-#[tokio::test]
-async fn x_to_close_timeout(#[case] is_schedule: bool) {
-    let wf_name = format!(
-        "{}_to_close_timeout",
-        if is_schedule { "schedule" } else { "start" }
-    );
-    let mut starter = CoreWfStarter::new(&wf_name);
-    let mut worker = starter.worker().await;
-    let (sched, start) = if is_schedule {
-        (Some(Duration::from_secs(2)), None)
-    } else {
-        (None, Some(Duration::from_secs(2)))
-    };
-    let timeout_type = if is_schedule {
-        TimeoutType::ScheduleToClose
-    } else {
-        TimeoutType::StartToClose
-    };
+                if let Some(e) = maybe_net_err {
+                    if e.code() == tonic::Code::NotFound {
+                        warn!(task_token = ?task_token, details = ?e, "Activity not found on \
+                        completion. This may happen if the activity has already been cancelled but \
+                        completed anyway.");
+                    } else {
+                        warn!(error=?e, "Network error while completing activity");
+                    };
+                };
+            };
+        } else {
+            warn!(
+                "Attempted to complete activity task {} but we were not tracking it",
+                &task_token
+            );
+        }
+    }
 
-    worker.register_wf(wf_name.to_owned(), move |ctx: WfContext| async move {
-        let res = ctx
-            .local_activity(LocalActivityOptions {
-                activity_type: "echo".to_string(),
-                input: "hi".as_json_payload().expect("serializes fine"),
-                retry_policy: RetryPolicy {
-                    initial_interval: Some(prost_dur!(from_micros(15))),
-                    backoff_coefficient: 1_000.,
-                    maximum_interval: Some(prost_dur!(from_millis(1500))),
-                    maximum_attempts: 4,
-                    non_retryable_error_types: vec![],
-                },
-                timer_backoff_threshold: Some(Duration::from_secs(1)),
-                schedule_to_close_timeout: sched,
-                start_to_close_timeout: start,
-                ..Default::default()
-            })
-            .await;
-        assert_eq!(res.timed_out(), Some(timeout_type));
-        Ok(().into())
-    });
-    worker.register_activity("echo", |ctx: ActContext, _: String| async move {
-        tokio::select! {
-            _ = tokio::time::sleep(Duration::from_secs(100)) => {},
-            _ = ctx.cancelled() => {
-                return Err(anyhow!(ActivityCancelledError::default()))
-            }
+    /// Attempt to record an activity heartbeat
+    pub(crate) fn record_heartbeat(
+        &self,
+        details: ActivityHeartbeat,
+    ) -> Result<(), ActivityHeartbeatError> {
+        // TODO: Propagate these back as cancels. Silent fails is too nonobvious
+        let heartbeat_timeout: Duration = self
+            .outstanding_activity_tasks
+            .get(&TaskToken(details.task_token.clone()))
+            .ok_or(ActivityHeartbeatError::UnknownActivity)?
+            .heartbeat_timeout
+            .clone()
+            // We treat None as 0 (even though heartbeat_timeout is never set to None by the server)
+            .unwrap_or_default()
+            .try_into()
+            // This technically should never happen since prost duration should be directly mappable
+            // to std::time::Duration.
+            .or(Err(ActivityHeartbeatError::InvalidHeartbeatTimeout))?;
+
+        // There is a bug in the server that translates non-set heartbeat timeouts into 0 duration.
+        // That's why we treat 0 the same way as None, otherwise we wouldn't know which aggregation
+        // delay to use, and using 0 is not a good idea as SDK would hammer the server too hard.
+        let throttle_interval = if heartbeat_timeout.as_millis() == 0 {
+            self.default_heartbeat_throttle_interval
+        } else {
+            heartbeat_timeout.mul_f64(0.8)
         };
-        Ok(())
-    });
+        let throttle_interval =
+            std::cmp::min(throttle_interval, self.max_heartbeat_throttle_interval);
+        self.heartbeat_manager.record(details, throttle_interval)
+    }
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-#[rstest::rstest]
-#[case::cached(true)]
-#[case::not_cached(false)]
-#[tokio::test]
-async fn schedule_to_close_timeout_across_timer_backoff(#[case] cached: bool) {
-    let wf_name = format!(
-        "schedule_to_close_timeout_across_timer_backoff_{}",
-        if cached { "cached" } else { "not_cached" }
-    );
-    let mut starter = CoreWfStarter::new(&wf_name);
-    if !cached {
-        starter.max_cached_workflows(0);
-    }
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
-        let res = ctx
-            .local_activity(LocalActivityOptions {
-                activity_type: "echo".to_string(),
-                input: "hi".as_json_payload().expect("serializes fine"),
-                retry_policy: RetryPolicy {
-                    initial_interval: Some(prost_dur!(from_millis(15))),
-                    backoff_coefficient: 1_000.,
-                    maximum_interval: Some(prost_dur!(from_millis(1000))),
-                    maximum_attempts: 40,
-                    non_retryable_error_types: vec![],
-                },
-                timer_backoff_threshold: Some(Duration::from_millis(500)),
-                schedule_to_close_timeout: Some(Duration::from_secs(2)),
-                ..Default::default()
+    /// Returns a handle that the workflows management side can use to interact with this manager
+    pub(crate) fn get_handle_for_workflows(&self) -> ActivitiesFromWFTsHandle {
+        ActivitiesFromWFTsHandle {
+            sem: self.eager_activities_semaphore.clone(),
+            tx: self.eager_activities_tx.clone(),
+        }
+    }
+
+    #[cfg(test)]
+    pub(crate) fn remaining_activity_capacity(&self) -> usize {
+        self.eager_activities_semaphore.available_permits()
+    }
+}
+
+struct ActivityTaskStream<SrcStrm> {
+    source_stream: SrcStrm,
+    outstanding_tasks: Arc<DashMap<TaskToken, RemoteInFlightActInfo>>,
+    start_tasks_stream_complete: CancellationToken,
+    complete_notify: Arc<Notify>,
+    grace_period: Option<Duration>,
+    cancels_tx: UnboundedSender<PendingActivityCancel>,
+    /// Token which is cancelled once shutdown is beginning
+    shutdown_initiated_token: CancellationToken,
+    metrics: MetricsContext,
+}
+
+impl<SrcStrm> ActivityTaskStream<SrcStrm>
+where
+    SrcStrm: Stream<Item = ActivityTaskSource>,
+{
+    /// Create a task stream composed of (in poll preference order):
+    ///  cancels_stream ------------------------------+--- activity_task_stream
+    ///  eager_activities_rx ---+--- starts_stream ---|
+    ///  server_poll_stream  ---|
+    fn streamify(self) -> impl Stream<Item = Result<ActivityTask, PollActivityError>> {
+        let outstanding_tasks_clone = self.outstanding_tasks.clone();
+        let should_issue_immediate_cancel = Arc::new(AtomicBool::new(false));
+        let should_issue_immediate_cancel_clone = should_issue_immediate_cancel.clone();
+        let cancels_tx = self.cancels_tx.clone();
+        self.source_stream
+            .filter_map(move |source| {
+                let res = match source {
+                    ActivityTaskSource::PendingCancel(next_pc) => {
+                        // It's possible that activity has been completed and we no longer have
+                        // an outstanding activity task. This is fine because it means that we
+                        // no longer need to cancel this activity, so we'll just ignore such
+                        // orphaned cancellations.
+                        if let Some(mut details) =
+                            self.outstanding_tasks.get_mut(&next_pc.task_token)
+                        {
+                            if details.issued_cancel_to_lang.is_some() {
+                                // Don't double-issue cancellations
+                                None
+                            } else {
+                                details.issued_cancel_to_lang = Some(next_pc.reason);
+                                if next_pc.reason == ActivityCancelReason::NotFound {
+                                    details.known_not_found = true;
+                                }
+                                Some(Ok(ActivityTask::cancel_from_ids(
+                                    next_pc.task_token.0,
+                                    next_pc.reason,
+                                )))
+                            }
+                        } else {
+                            debug!(task_token = ?next_pc.task_token,
+                                   "Unknown activity task when issuing cancel");
+                            // If we can't find the activity here, it's already been completed,
+                            // in which case issuing a cancel again is pointless.
+                            None
+                        }
+                    }
+                    ActivityTaskSource::PendingStart(res) => {
+                        Some(res.map(|(task, is_eager)| {
+                            if let Some(ref act_type) = task.resp.activity_type {
+                                if let Some(ref wf_type) = task.resp.workflow_type {
+                                    self.metrics
+                                        .with_new_attrs([
+                                            activity_type(act_type.name.clone()),
+                                            workflow_type(wf_type.name.clone()),
+                                            eager(is_eager),
+                                        ])
+                                        .act_task_received();
+                                }
+                            }
+                            // There could be an else statement here but since the response
+                            // should always contain both activity_type and workflow_type, we
+                            // won't bother.
+
+                            if let Some(dur) = task.resp.sched_to_start() {
+                                self.metrics.act_sched_to_start_latency(dur);
+                            };
+
+                            let tt: TaskToken = task.resp.task_token.clone().into();
+                            self.outstanding_tasks.insert(
+                                tt.clone(),
+                                RemoteInFlightActInfo::new(&task.resp, task.permit.into_used()),
+                            );
+                            // If we have already waited the grace period and issued cancels,
+                            // this will have been set true, indicating anything that happened
+                            // to be buffered/in-flight/etc should get an immediate cancel. This
+                            // is to allow the user to potentially decide to ignore cancels and
+                            // do work on polls that got received during shutdown.
+                            if should_issue_immediate_cancel.load(Ordering::Acquire) {
+                                let _ = cancels_tx.send(PendingActivityCancel::new(
+                                    tt,
+                                    ActivityCancelReason::WorkerShutdown,
+                                ));
+                            }
+
+                            ActivityTask::start_from_poll_resp(task.resp)
+                        }))
+                    }
+                };
+                async move { res }
+            })
+            .take_until(async move {
+                // Once we've been told to begin cancelling, wait the grace period and then start
+                // cancelling anything outstanding.
+                let (grace_killer, stop_grace) = futures_util::future::abortable(async {
+                    if let Some(gp) = self.grace_period {
+                        self.shutdown_initiated_token.cancelled().await;
+                        tokio::time::sleep(gp).await;
+                        should_issue_immediate_cancel_clone.store(true, Ordering::Release);
+                        for mapref in outstanding_tasks_clone.iter() {
+                            let _ = self.cancels_tx.send(PendingActivityCancel::new(
+                                mapref.key().clone(),
+                                ActivityCancelReason::WorkerShutdown,
+                            ));
+                        }
+                    }
+                });
+                join!(
+                    async {
+                        self.start_tasks_stream_complete.cancelled().await;
+                        while !outstanding_tasks_clone.is_empty() {
+                            self.complete_notify.notified().await
+                        }
+                        // If we were waiting for the grace period but everything already finished,
+                        // we don't need to keep waiting.
+                        stop_grace.abort();
+                    },
+                    grace_killer
+                )
             })
-            .await;
-        assert_eq!(res.timed_out(), Some(TimeoutType::ScheduleToClose));
-        Ok(().into())
-    });
-    let num_attempts: &'static _ = Box::leak(Box::new(AtomicU8::new(0)));
-    worker.register_activity("echo", move |_: ActContext, _: String| async {
-        num_attempts.fetch_add(1, Ordering::Relaxed);
-        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
-    });
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-    // 3 attempts b/c first backoff is very small, then the next 2 attempts take at least 2 seconds
-    // b/c of timer backoff.
-    assert_eq!(3, num_attempts.load(Ordering::Relaxed));
-}
-
-#[rstest::rstest]
-#[tokio::test]
-async fn eviction_wont_make_local_act_get_dropped(#[values(true, false)] short_wft_timeout: bool) {
-    let wf_name = format!(
-        "eviction_wont_make_local_act_get_dropped_{}",
-        short_wft_timeout
-    );
-    let mut starter = CoreWfStarter::new(&wf_name);
-    starter.max_cached_workflows(0);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), local_act_then_timer_then_wait);
-    worker.register_activity("echo_activity", |_ctx: ActContext, str: String| async {
-        tokio::time::sleep(Duration::from_secs(4)).await;
-        Ok(str)
-    });
-
-    let opts = if short_wft_timeout {
-        WorkflowOptions {
-            task_timeout: Some(Duration::from_secs(1)),
-            ..Default::default()
+    }
+}
+
+/// Provides facilities for the workflow side of things to interact with the activity manager.
+/// Allows for the handling of activities returned by WFT completions.
+pub(crate) struct ActivitiesFromWFTsHandle {
+    sem: Arc<ClosableMeteredSemaphore>,
+    tx: UnboundedSender<TrackedPermittedTqResp>,
+}
+
+impl ActivitiesFromWFTsHandle {
+    /// Returns a handle that can be used to reserve an activity slot. EX: When requesting eager
+    /// dispatch of an activity to this worker upon workflow task completion
+    pub(crate) fn reserve_slot(&self) -> Option<TrackedOwnedMeteredSemPermit> {
+        // TODO: check if rate limit is not exceeded and count this reservation towards the rate limit
+        self.sem.try_acquire_owned().ok()
+    }
+
+    /// Queue new activity tasks for dispatch received from non-polling sources (ex: eager returns
+    /// from WFT completion)
+    pub(crate) fn add_tasks(&self, tasks: impl IntoIterator<Item = TrackedPermittedTqResp>) {
+        for t in tasks.into_iter() {
+            // Technically we should be reporting `activity_task_received` here, but for simplicity
+            // and time insensitivity, that metric is tracked in `about_to_issue_task`.
+            self.tx.send(t).expect("Receive half cannot be dropped");
         }
-    } else {
-        Default::default()
-    };
-    worker
-        .submit_wf(wf_name.to_owned(), wf_name.to_owned(), vec![], opts)
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-#[tokio::test]
-async fn timer_backoff_concurrent_with_non_timer_backoff() {
-    let wf_name = "timer_backoff_concurrent_with_non_timer_backoff";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
-        let r1 = ctx.local_activity(LocalActivityOptions {
-            activity_type: "echo".to_string(),
-            input: "hi".as_json_payload().expect("serializes fine"),
-            retry_policy: RetryPolicy {
-                initial_interval: Some(prost_dur!(from_micros(15))),
-                backoff_coefficient: 1_000.,
-                maximum_interval: Some(prost_dur!(from_millis(1500))),
-                maximum_attempts: 4,
-                non_retryable_error_types: vec![],
-            },
-            timer_backoff_threshold: Some(Duration::from_secs(1)),
-            ..Default::default()
-        });
-        let r2 = ctx.local_activity(LocalActivityOptions {
-            activity_type: "echo".to_string(),
-            input: "hi".as_json_payload().expect("serializes fine"),
-            retry_policy: RetryPolicy {
-                initial_interval: Some(prost_dur!(from_millis(15))),
-                backoff_coefficient: 10.,
-                maximum_interval: Some(prost_dur!(from_millis(1500))),
-                maximum_attempts: 4,
-                non_retryable_error_types: vec![],
-            },
-            timer_backoff_threshold: Some(Duration::from_secs(10)),
-            ..Default::default()
-        });
-        let (r1, r2) = tokio::join!(r1, r2);
-        assert!(r1.failed());
-        assert!(r2.failed());
-        Ok(().into())
-    });
-    worker.register_activity("echo", |_: ActContext, _: String| async {
-        Result::<(), _>::Err(anyhow!("Oh no I failed!"))
-    });
-
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-}
-
-#[tokio::test]
-async fn repro_nondeterminism_with_timer_bug() {
-    let wf_name = "repro_nondeterminism_with_timer_bug";
-    let mut starter = CoreWfStarter::new(wf_name);
-    let mut worker = starter.worker().await;
-
-    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
-        let t1 = ctx.timer(Duration::from_secs(30));
-        let r1 = ctx.local_activity(LocalActivityOptions {
-            activity_type: "delay".to_string(),
-            input: "hi".as_json_payload().expect("serializes fine"),
-            retry_policy: RetryPolicy {
-                initial_interval: Some(prost_dur!(from_micros(15))),
-                backoff_coefficient: 1_000.,
-                maximum_interval: Some(prost_dur!(from_millis(1500))),
-                maximum_attempts: 4,
-                non_retryable_error_types: vec![],
-            },
-            timer_backoff_threshold: Some(Duration::from_secs(1)),
-            ..Default::default()
-        });
-        tokio::pin!(t1);
-        tokio::select! {
-            _ = &mut t1 => {},
-            _ = r1 => {
-                t1.cancel(&ctx);
+    }
+}
+
+#[derive(Debug)]
+pub(crate) struct PermittedTqResp {
+    pub permit: OwnedMeteredSemPermit,
+    pub resp: PollActivityTaskQueueResponse,
+}
+
+#[derive(Debug)]
+pub(crate) struct TrackedPermittedTqResp {
+    pub permit: TrackedOwnedMeteredSemPermit,
+    pub resp: PollActivityTaskQueueResponse,
+}
+
+fn worker_shutdown_failure() -> Failure {
+    Failure {
+        message: "Worker is shutting down and this activity did not complete in time".to_string(),
+        source: "".to_string(),
+        stack_trace: "".to_string(),
+        encoded_attributes: None,
+        cause: None,
+        failure_info: Some(FailureInfo::ApplicationFailureInfo(
+            ApplicationFailureInfo {
+                r#type: "WorkerShutdown".to_string(),
+                non_retryable: false,
+                details: None,
             },
-        };
-        ctx.timer(Duration::from_secs(1)).await;
-        Ok(().into())
-    });
-    worker.register_activity("delay", |_: ActContext, _: String| async {
-        tokio::time::sleep(Duration::from_secs(2)).await;
-        Ok(())
-    });
-
-    let run_id = worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
-    worker.run_until_done().await.unwrap();
-    starter
-        .fetch_history_and_replay(wf_name, run_id, worker.inner_mut())
-        .await
-        .unwrap();
-}
-
-async fn la_problem_workflow(ctx: WfContext) -> WorkflowResult<()> {
-    ctx.local_activity(LocalActivityOptions {
-        activity_type: "delay".to_string(),
-        input: "hi".as_json_payload().expect("serializes fine"),
-        retry_policy: RetryPolicy {
-            initial_interval: Some(prost_dur!(from_micros(15))),
-            backoff_coefficient: 1_000.,
-            maximum_interval: Some(prost_dur!(from_millis(1500))),
-            maximum_attempts: 4,
-            non_retryable_error_types: vec![],
-        },
-        timer_backoff_threshold: Some(Duration::from_secs(1)),
-        ..Default::default()
-    })
-    .await;
-    ctx.activity(ActivityOptions {
-        activity_type: "delay".to_string(),
-        start_to_close_timeout: Some(Duration::from_secs(20)),
-        input: "hi!".as_json_payload().expect("serializes fine"),
-        ..Default::default()
-    })
-    .await;
-    Ok(().into())
-}
-
-// Expensive to run - worth enabling on a stress/regression pipeline.
-#[ignore]
-#[tokio::test(flavor = "multi_thread", worker_threads = 4)]
-async fn evict_while_la_running_no_interference() {
-    let wf_name = "evict_while_la_running_no_interference";
-    let mut starter = CoreWfStarter::new(wf_name);
-    starter.max_local_at(20);
-    starter.max_cached_workflows(20);
-    let mut worker = starter.worker().await;
-
-    worker.register_wf(wf_name.to_owned(), la_problem_workflow);
-    worker.register_activity("delay", |_: ActContext, _: String| async {
-        tokio::time::sleep(Duration::from_secs(15)).await;
-        Ok(())
-    });
-
-    let client = starter.get_client().await;
-    let subfs = FuturesUnordered::new();
-    for i in 1..100 {
-        let wf_id = format!("{}-{}", wf_name, i);
-        let run_id = worker
-            .submit_wf(
-                &wf_id,
-                wf_name.to_owned(),
-                vec![],
-                WorkflowOptions::default(),
-            )
-            .await
-            .unwrap();
-        let cw = worker.core_worker.clone();
-        let client = client.clone();
-        subfs.push(async move {
-            // Evict the workflow
-            tokio::time::sleep(Duration::from_secs(1)).await;
-            cw.request_workflow_eviction(&run_id);
-            // Wake up workflow by sending signal
-            client
-                .signal_workflow_execution(
-                    wf_id,
-                    run_id.clone(),
-                    "whaatever".to_string(),
-                    None,
-                    None,
-                )
-                .await
-                .unwrap();
-        });
+        )),
     }
-    let runf = async {
-        worker.run_until_done().await.unwrap();
-    };
-    tokio::join!(subfs.collect::<Vec<_>>(), runf);
 }
 
-#[rstest::rstest]
-#[tokio::test]
-async fn weird_la_nondeterminism_repro(#[values(true, false)] fix_hist: bool) {
-    init_integ_telem();
-    let mut hist = history_from_proto_binary(
-        "histories/evict_while_la_running_no_interference-85_history.bin",
-    )
-    .await
-    .unwrap();
-    if fix_hist {
-        // Replace broken ending with accurate ending
-        hist.events.truncate(20);
-        let mut thb = TestHistoryBuilder::from_history(hist.events);
-        thb.add_workflow_task_completed();
-        thb.add_workflow_execution_completed();
-        hist = thb.get_full_history_info().unwrap().into();
-    }
-
-    let mut worker = replay_sdk_worker([HistoryForReplay::new(hist, "fake".to_owned())]);
-    worker.register_wf(
-        "evict_while_la_running_no_interference",
-        la_problem_workflow,
-    );
-    worker.register_activity("delay", |_: ActContext, _: String| async {
-        tokio::time::sleep(Duration::from_secs(15)).await;
-        Ok(())
-    });
-    worker.run().await.unwrap();
-}
-
-#[tokio::test]
-async fn second_weird_la_nondeterminism_repro() {
-    init_integ_telem();
-    let mut hist = history_from_proto_binary(
-        "histories/evict_while_la_running_no_interference-23_history.bin",
-    )
-    .await
-    .unwrap();
-    // Chop off uninteresting ending
-    hist.events.truncate(24);
-    let mut thb = TestHistoryBuilder::from_history(hist.events);
-    // thb.add_workflow_task_completed();
-    thb.add_workflow_execution_completed();
-    hist = thb.get_full_history_info().unwrap().into();
-
-    let mut worker = replay_sdk_worker([HistoryForReplay::new(hist, "fake".to_owned())]);
-    worker.register_wf(
-        "evict_while_la_running_no_interference",
-        la_problem_workflow,
-    );
-    worker.register_activity("delay", |_: ActContext, _: String| async {
-        tokio::time::sleep(Duration::from_secs(15)).await;
-        Ok(())
-    });
-    worker.run().await.unwrap();
+#[cfg(test)]
+mod tests {
+    use super::*;
+    use crate::{
+        test_help::mock_poller_from_resps, worker::client::mocks::mock_manual_workflow_client,
+    };
+
+    #[tokio::test]
+    async fn per_worker_ratelimit() {
+        let poller = mock_poller_from_resps([
+            PollActivityTaskQueueResponse {
+                task_token: vec![1],
+                activity_id: "act1".to_string(),
+                ..Default::default()
+            }
+            .into(),
+            PollActivityTaskQueueResponse {
+                task_token: vec![2],
+                activity_id: "act2".to_string(),
+                ..Default::default()
+            }
+            .into(),
+        ]);
+        let atm = WorkerActivityTasks::new(
+            10,
+            Some(2.0),
+            poller,
+            Arc::new(mock_manual_workflow_client()),
+            MetricsContext::no_op(),
+            Duration::from_secs(1),
+            Duration::from_secs(1),
+            None,
+        );
+        let start = Instant::now();
+        atm.poll().await.unwrap();
+        atm.poll().await.unwrap();
+        // At least half a second will have elapsed since we only allow 2 tasks per second.
+        // With no ratelimit, even on a slow CI server with lots of load, this would typically take
+        // low single digit ms or less.
+        assert!(start.elapsed() > Duration::from_secs_f64(0.5));
+    }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/modify_wf_properties.rs`

 * *Files 8% similar despite different names*

```diff
@@ -16,14 +16,15 @@
 }
 
 #[tokio::test]
 async fn sends_modify_wf_props() {
     let wf_name = "can_upsert_memo";
     let wf_id = Uuid::new_v4();
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
 
     worker.register_wf(wf_name, memo_upserter);
     let run_id = worker
         .submit_wf(wf_id.to_string(), wf_name, vec![], Default::default())
         .await
         .unwrap();
@@ -39,15 +40,12 @@
         .unwrap()
         .memo
         .unwrap()
         .fields;
     let catname = memo.get(FIELD_A).unwrap();
     let cuteness = memo.get(FIELD_B).unwrap();
     for payload in [catname, cuteness] {
-        assert_eq!(
-            &b"json/plain".to_vec(),
-            payload.metadata.get("encoding").unwrap()
-        );
+        assert!(payload.is_json_payload());
     }
     assert_eq!("enchi", String::from_json_payload(catname).unwrap());
     assert_eq!(9001, usize::from_json_payload(cuteness).unwrap());
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/patches.rs`

 * *Files 25% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 use std::{
     sync::atomic::{AtomicBool, Ordering},
     time::Duration,
 };
-use temporal_client::WorkflowOptions;
+
 use temporal_sdk::{WfContext, WorkflowResult};
 use temporal_sdk_core_test_utils::CoreWfStarter;
 
 const MY_PATCH_ID: &str = "integ_test_change_name";
 
 pub async fn changes_wf(ctx: WfContext) -> WorkflowResult<()> {
     if ctx.patched(MY_PATCH_ID) {
@@ -23,26 +23,19 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn writes_change_markers() {
     let wf_name = "writes_change_markers";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), changes_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
 
 /// This one simulates a run as if the worker had the "old" code, then it fails at the end as
 /// a cheapo way of being re-run, at which point it runs with change checks and the "new" code.
 static DID_DIE: AtomicBool = AtomicBool::new(false);
 pub async fn no_change_then_change_wf(ctx: WfContext) -> WorkflowResult<()> {
@@ -63,26 +56,19 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn can_add_change_markers() {
     let wf_name = "can_add_change_markers";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), no_change_then_change_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
 
 static DID_DIE_2: AtomicBool = AtomicBool::new(false);
 pub async fn replay_with_change_marker_wf(ctx: WfContext) -> WorkflowResult<()> {
     assert!(ctx.patched(MY_PATCH_ID));
     ctx.timer(Duration::from_millis(200)).await;
@@ -93,21 +79,41 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn replaying_with_patch_marker() {
     let wf_name = "replaying_with_patch_marker";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), replay_with_change_marker_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
+    worker.run_until_done().await.unwrap();
+}
+
+/// Test that the internal patching mechanism works on the second workflow task when replaying.
+/// Used as regression test for a bug that detected that we did not look ahead far enough to find
+/// the next workflow task completion, which the flags are attached to.
+#[tokio::test]
+async fn patched_on_second_workflow_task_is_deterministic() {
+    let wf_name = "timer_patched_timer";
+    let mut starter = CoreWfStarter::new(wf_name);
+    // Disable caching to force replay from beginning
+    starter.max_cached_workflows(0).no_remote_activities();
+    let mut worker = starter.worker().await;
+    // Include a task failure as well to make sure that works
+    static FAIL_ONCE: AtomicBool = AtomicBool::new(true);
+    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
+        ctx.timer(Duration::from_millis(1)).await;
+        if FAIL_ONCE.load(Ordering::Acquire) {
+            FAIL_ONCE.store(false, Ordering::Release);
+            panic!("Enchi is hungry!");
+        }
+        assert!(ctx.patched(MY_PATCH_ID));
+        ctx.timer(Duration::from_millis(1)).await;
+        Ok(().into())
+    });
+
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/replay.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,19 +1,21 @@
+use crate::integ_tests::workflow_tests::patches::changes_wf;
 use assert_matches::assert_matches;
 use parking_lot::Mutex;
 use std::{collections::HashSet, sync::Arc, time::Duration};
 use temporal_sdk::{interceptors::WorkerInterceptor, WfContext, Worker, WorkflowFunction};
 use temporal_sdk_core::replay::{HistoryFeeder, HistoryForReplay};
 use temporal_sdk_core_api::errors::{PollActivityError, PollWfError};
 use temporal_sdk_core_protos::{
     coresdk::{
         workflow_activation::remove_from_cache::EvictionReason,
         workflow_commands::{ScheduleActivity, StartTimer},
         workflow_completion::WorkflowActivationCompletion,
     },
+    temporal::api::enums::v1::EventType,
     TestHistoryBuilder, DEFAULT_WORKFLOW_TYPE,
 };
 use temporal_sdk_core_test_utils::{
     canned_histories, history_from_proto_binary, init_core_replay_preloaded, replay_sdk_worker,
     replay_sdk_worker_stream, WorkerTestHelpers,
 };
 use tokio::join;
@@ -126,25 +128,47 @@
     let func = timers_wf(num_timers);
     let mut worker = replay_sdk_worker([test_hist_to_replay(t)]);
     worker.register_wf(DEFAULT_WORKFLOW_TYPE, func);
     worker.run().await.unwrap();
 }
 
 #[tokio::test]
-async fn replay_ok_ending_with_terminated_or_timed_out() {
+async fn replay_ending_wft_complete_with_commands_but_no_scheduled_started() {
+    let mut t = TestHistoryBuilder::default();
+    t.add_by_type(EventType::WorkflowExecutionStarted);
+    t.add_full_wf_task();
+
+    for i in 1..=2 {
+        let timer_started_event_id = t.add_by_type(EventType::TimerStarted);
+        t.add_timer_fired(timer_started_event_id, i.to_string());
+        t.add_full_wf_task();
+    }
+    let func = timers_wf(3);
+    let mut worker = replay_sdk_worker([test_hist_to_replay(t)]);
+    worker.register_wf(DEFAULT_WORKFLOW_TYPE, func);
+    worker.run().await.unwrap();
+}
+
+async fn replay_abrupt_ending(t: TestHistoryBuilder) {
+    let func = timers_wf(1);
+    let mut worker = replay_sdk_worker([test_hist_to_replay(t)]);
+    worker.register_wf(DEFAULT_WORKFLOW_TYPE, func);
+    worker.run().await.unwrap();
+}
+#[tokio::test]
+async fn replay_ok_ending_with_terminated() {
     let mut t1 = canned_histories::single_timer("1");
     t1.add_workflow_execution_terminated();
+    replay_abrupt_ending(t1).await;
+}
+#[tokio::test]
+async fn replay_ok_ending_with_timed_out() {
     let mut t2 = canned_histories::single_timer("1");
     t2.add_workflow_execution_timed_out();
-    for t in [t1, t2] {
-        let func = timers_wf(1);
-        let mut worker = replay_sdk_worker([test_hist_to_replay(t)]);
-        worker.register_wf(DEFAULT_WORKFLOW_TYPE, func);
-        worker.run().await.unwrap();
-    }
+    replay_abrupt_ending(t2).await;
 }
 
 #[rstest::rstest]
 #[tokio::test]
 async fn multiple_histories_replay(#[values(false, true)] use_feeder: bool) {
     let num_timers = 10;
     let seq_timer_wf = timers_wf(num_timers);
@@ -196,14 +220,59 @@
         test_hist_to_replay(hist1.clone()),
         test_hist_to_replay(hist1),
     ]);
     worker.register_wf("onetimer", timers_wf(1));
     worker.run().await.unwrap();
 }
 
+// Verifies SDK can decode patch markers before changing them to use json encoding
+#[tokio::test]
+async fn replay_old_patch_format() {
+    let mut worker = replay_sdk_worker([HistoryForReplay::new(
+        history_from_proto_binary("histories/old_change_marker_format.bin")
+            .await
+            .unwrap(),
+        "fake".to_owned(),
+    )]);
+    worker.register_wf("writes_change_markers", changes_wf);
+    worker.run().await.unwrap();
+}
+
+#[tokio::test]
+async fn replay_ends_with_empty_wft() {
+    let core = init_core_replay_preloaded(
+        "SayHelloWorkflow",
+        [HistoryForReplay::new(
+            history_from_proto_binary("histories/ends_empty_wft_complete.bin")
+                .await
+                .unwrap(),
+            "fake".to_owned(),
+        )],
+    );
+    let task = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
+        task.run_id,
+        vec![ScheduleActivity {
+            seq: 1,
+            activity_id: "1".to_string(),
+            activity_type: "say_hello".to_string(),
+            ..Default::default()
+        }
+        .into()],
+    ))
+    .await
+    .unwrap();
+    let task = core.poll_workflow_activation().await.unwrap();
+    core.complete_workflow_activation(WorkflowActivationCompletion::empty(task.run_id))
+        .await
+        .unwrap();
+    let task = core.poll_workflow_activation().await.unwrap();
+    assert!(task.eviction_reason().is_some());
+}
+
 fn timers_wf(num_timers: u32) -> WorkflowFunction {
     WorkflowFunction::new(move |ctx: WfContext| async move {
         for _ in 1..=num_timers {
             ctx.timer(Duration::from_secs(1)).await;
         }
         Ok(().into())
     })
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/resets.rs`

 * *Files 8% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 
 const POST_RESET_SIG: &str = "post-reset";
 
 #[tokio::test]
 async fn reset_workflow() {
     let wf_name = "reset_me_wf";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.fetch_results = false;
     let notify = Arc::new(Notify::new());
 
     let wf_notify = notify.clone();
     worker.register_wf(wf_name.to_owned(), move |ctx: WfContext| {
         let notify = wf_notify.clone();
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/signals.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,11 +1,13 @@
 use std::collections::HashMap;
 
 use futures::StreamExt;
-use temporal_client::{WorkflowClientTrait, WorkflowExecutionInfo, WorkflowOptions};
+use temporal_client::{
+    SignalWithStartOptions, WorkflowClientTrait, WorkflowExecutionInfo, WorkflowOptions,
+};
 use temporal_sdk::{
     ChildWorkflowOptions, Signal, SignalWorkflowOptions, WfContext, WorkflowResult,
 };
 use temporal_sdk_core_protos::{coresdk::IntoPayloadsExt, temporal::api::common::v1::Payload};
 use temporal_sdk_core_test_utils::CoreWfStarter;
 use uuid::Uuid;
 
@@ -28,14 +30,15 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn sends_signal_to_missing_wf() {
     let wf_name = "sends_signal_to_missing_wf";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), signal_sender);
 
     worker
         .submit_wf(
             wf_name,
             wf_name,
@@ -55,26 +58,26 @@
         b"shakur".into()
     );
     Ok(().into())
 }
 
 async fn signal_with_create_wf_receiver(ctx: WfContext) -> WorkflowResult<()> {
     let res = ctx.make_signal_channel(SIGNAME).next().await.unwrap();
-    println!("HEADER: {:?}", res.headers);
     assert_eq!(&res.input, &[b"tada".into()]);
     assert_eq!(
         *res.headers.get("tupac").expect("tupac header exists"),
         b"shakur".into()
     );
     Ok(().into())
 }
 
 #[tokio::test]
 async fn sends_signal_to_other_wf() {
     let mut starter = CoreWfStarter::new("sends_signal_to_other_wf");
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf("sender", signal_sender);
     worker.register_wf("receiver", signal_receiver);
 
     let receiver_run_id = worker
         .submit_wf(
             RECEIVER_WFID,
@@ -95,32 +98,32 @@
         .unwrap();
     worker.run_until_done().await.unwrap();
 }
 
 #[tokio::test]
 async fn sends_signal_with_create_wf() {
     let mut starter = CoreWfStarter::new("sends_signal_with_create_wf");
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
-    worker.register_wf("receiversignal", signal_with_create_wf_receiver);
+    worker.register_wf("receiver_signal", signal_with_create_wf_receiver);
 
     let client = starter.get_client().await;
     let mut header: HashMap<String, Payload> = HashMap::new();
     header.insert("tupac".into(), "shakur".into());
+    let options = SignalWithStartOptions::builder()
+        .task_queue(worker.inner_mut().task_queue())
+        .workflow_id("sends_signal_with_create_wf")
+        .workflow_type("receiver_signal")
+        .signal_name(SIGNAME)
+        .signal_input(vec![b"tada".into()].into_payloads())
+        .signal_header(header.into())
+        .build()
+        .unwrap();
     let res = client
-        .signal_with_start_workflow_execution(
-            None,
-            worker.inner_mut().task_queue().to_owned(),
-            "sends_signal_with_create_wf".to_owned(),
-            "receiversignal".to_owned(),
-            None,
-            WorkflowOptions::default(),
-            SIGNAME.to_owned(),
-            vec![b"tada".into()].into_payloads(),
-            Some(header.into()),
-        )
+        .signal_with_start_workflow_execution(options, WorkflowOptions::default())
         .await
         .expect("request succeeds.qed");
 
     worker.started_workflows.lock().push(WorkflowExecutionInfo {
         namespace: client.namespace().to_string(),
         workflow_id: "sends_signal_with_create_wf".to_owned(),
         run_id: Some(res.run_id.clone()),
@@ -146,14 +149,15 @@
     started_child.result().await.status.unwrap();
     Ok(().into())
 }
 
 #[tokio::test]
 async fn sends_signal_to_child() {
     let mut starter = CoreWfStarter::new("sends_signal_to_child");
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf("child_signaler", signals_child);
     worker.register_wf("child_receiver", signal_receiver);
 
     worker
         .submit_wf(
             "sends-signal-to-child",
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/stickyness.rs`

 * *Files 6% similar despite different names*

```diff
@@ -8,27 +8,20 @@
 use temporal_sdk_core_test_utils::CoreWfStarter;
 use tokio::sync::Barrier;
 
 #[tokio::test]
 async fn timer_workflow_not_sticky() {
     let wf_name = "timer_wf_not_sticky";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     starter.max_cached_workflows(0);
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), timer_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
 
 static TIMED_OUT_ONCE: AtomicBool = AtomicBool::new(false);
 static RUN_CT: AtomicUsize = AtomicUsize::new(0);
 async fn timer_timeout_wf(ctx: WfContext) -> WorkflowResult<()> {
     RUN_CT.fetch_add(1, Ordering::SeqCst);
@@ -43,37 +36,30 @@
 
 #[tokio::test]
 async fn timer_workflow_timeout_on_sticky() {
     // This test intentionally times out a workflow task in order to make the next task be scheduled
     // on a not-sticky queue
     let wf_name = "timer_workflow_timeout_on_sticky";
     let mut starter = CoreWfStarter::new(wf_name);
-    starter.wft_timeout(Duration::from_secs(2));
+    starter.no_remote_activities();
+    starter.workflow_options.task_timeout = Some(Duration::from_secs(2));
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), timer_timeout_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
     // If it didn't run twice it didn't time out
     assert_eq!(RUN_CT.load(Ordering::SeqCst), 2);
 }
 
 #[tokio::test]
 async fn cache_miss_ok() {
     let wf_name = "cache_miss_ok";
     let mut starter = CoreWfStarter::new(wf_name);
-    starter.max_wft(1);
+    starter.no_remote_activities().max_wft(1);
     let mut worker = starter.worker().await;
 
     let barr: &'static Barrier = Box::leak(Box::new(Barrier::new(2)));
     worker.register_wf(wf_name.to_owned(), move |ctx: WfContext| async move {
         barr.wait().await;
         ctx.timer(Duration::from_secs(1)).await;
         Ok(().into())
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/timers.rs`

 * *Files 8% similar despite different names*

```diff
@@ -1,66 +1,62 @@
 use std::time::Duration;
-use temporal_client::WorkflowOptions;
+
 use temporal_sdk::{WfContext, WorkflowResult};
 use temporal_sdk_core_protos::coresdk::{
     workflow_commands::{CancelTimer, CompleteWorkflowExecution, StartTimer},
     workflow_completion::WorkflowActivationCompletion,
 };
 use temporal_sdk_core_test_utils::{
-    init_core_and_create_wf, start_timer_cmd, CoreWfStarter, WorkerTestHelpers,
+    drain_pollers_and_shutdown, init_core_and_create_wf, start_timer_cmd, CoreWfStarter,
+    WorkerTestHelpers,
 };
 
 pub async fn timer_wf(command_sink: WfContext) -> WorkflowResult<()> {
     command_sink.timer(Duration::from_secs(1)).await;
     Ok(().into())
 }
 
 #[tokio::test]
 async fn timer_workflow_workflow_driver() {
     let wf_name = "timer_wf_new";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), timer_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
 
 #[tokio::test]
 async fn timer_workflow_manual() {
     let mut starter = init_core_and_create_wf("timer_workflow").await;
     let core = starter.get_worker().await;
+    starter.no_remote_activities();
     let task = core.poll_workflow_activation().await.unwrap();
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
         task.run_id,
         vec![StartTimer {
             seq: 0,
             start_to_fire_timeout: Some(prost_dur!(from_secs(1))),
         }
         .into()],
     ))
     .await
     .unwrap();
     let task = core.poll_workflow_activation().await.unwrap();
     core.complete_execution(&task.run_id).await;
-    core.shutdown().await;
+    drain_pollers_and_shutdown(&core).await;
 }
 
 #[tokio::test]
 async fn timer_cancel_workflow() {
     let mut starter = init_core_and_create_wf("timer_cancel_workflow").await;
     let core = starter.get_worker().await;
+    starter.no_remote_activities();
     let task = core.poll_workflow_activation().await.unwrap();
     core.complete_workflow_activation(WorkflowActivationCompletion::from_cmds(
         task.run_id,
         vec![
             StartTimer {
                 seq: 0,
                 start_to_fire_timeout: Some(prost_dur!(from_millis(50))),
@@ -111,21 +107,14 @@
     Ok(().into())
 }
 
 #[tokio::test]
 async fn parallel_timers() {
     let wf_name = "parallel_timers";
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
     worker.register_wf(wf_name.to_owned(), parallel_timer_wf);
 
-    worker
-        .submit_wf(
-            wf_name.to_owned(),
-            wf_name.to_owned(),
-            vec![],
-            WorkflowOptions::default(),
-        )
-        .await
-        .unwrap();
+    starter.start_with_worker(wf_name, &mut worker).await;
     worker.run_until_done().await.unwrap();
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests/upsert_search_attrs.rs`

 * *Files 10% similar despite different names*

```diff
@@ -1,13 +1,13 @@
-use log::warn;
 use std::{collections::HashMap, env};
 use temporal_client::{WorkflowClientTrait, WorkflowOptions};
 use temporal_sdk::{WfContext, WorkflowResult};
 use temporal_sdk_core_protos::coresdk::{AsJsonPayloadExt, FromJsonPayloadExt};
-use temporal_sdk_core_test_utils::{CoreWfStarter, INTEG_TEMPORALITE_USED_ENV_VAR};
+use temporal_sdk_core_test_utils::{CoreWfStarter, INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR};
+use tracing::warn;
 use uuid::Uuid;
 
 // These are initialized on the server as part of the autosetup container which we
 // use for integration tests.
 static TXT_ATTR: &str = "CustomTextField";
 static INT_ATTR: &str = "CustomIntField";
 
@@ -20,17 +20,19 @@
 }
 
 #[tokio::test]
 async fn sends_upsert() {
     let wf_name = "sends_upsert_search_attrs";
     let wf_id = Uuid::new_v4();
     let mut starter = CoreWfStarter::new(wf_name);
+    starter.no_remote_activities();
     let mut worker = starter.worker().await;
-    if env::var(INTEG_TEMPORALITE_USED_ENV_VAR).is_ok() {
-        warn!("skipping sends_upsert -- does not work on temporalite");
+    // TODO: this should be supported in server 1.20, remove this condition when CLI is upgraded.
+    if env::var(INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR).is_ok() {
+        warn!("skipping sends_upsert -- does not work on temporal dev server");
         return;
     }
 
     worker.register_wf(wf_name, search_attr_updater);
     let run_id = worker
         .submit_wf(
             wf_id.to_string(),
@@ -58,18 +60,15 @@
         .unwrap()
         .search_attributes
         .unwrap()
         .indexed_fields;
     let txt_attr_payload = search_attrs.get(TXT_ATTR).unwrap();
     let int_attr_payload = search_attrs.get(INT_ATTR).unwrap();
     for payload in [txt_attr_payload, int_attr_payload] {
-        assert_eq!(
-            &b"json/plain".to_vec(),
-            payload.metadata.get("encoding").unwrap()
-        );
+        assert!(payload.is_json_payload());
     }
     assert_eq!(
         "goodbye",
         String::from_json_payload(txt_attr_payload).unwrap()
     );
     assert_eq!(98, usize::from_json_payload(int_attr_payload).unwrap());
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/integ_tests/workflow_tests.rs`

 * *Files 2% similar despite different names*

```diff
@@ -11,59 +11,57 @@
 mod replay;
 mod resets;
 mod signals;
 mod stickyness;
 mod timers;
 mod upsert_search_attrs;
 
+use crate::integ_tests::activity_functions::echo;
 use assert_matches::assert_matches;
 use futures::{channel::mpsc::UnboundedReceiver, future, SinkExt, StreamExt};
 use std::{
     collections::HashMap,
     sync::{
         atomic::{AtomicUsize, Ordering},
         Arc,
     },
     time::Duration,
 };
 use temporal_client::{WorkflowClientTrait, WorkflowOptions};
-use temporal_sdk::{
-    interceptors::WorkerInterceptor, ActContext, ActivityOptions, WfContext, WorkflowResult,
-};
+use temporal_sdk::{interceptors::WorkerInterceptor, ActivityOptions, WfContext, WorkflowResult};
 use temporal_sdk_core::replay::HistoryForReplay;
 use temporal_sdk_core_api::{errors::PollWfError, Worker};
 use temporal_sdk_core_protos::{
     coresdk::{
         activity_result::ActivityExecutionResult,
         workflow_activation::{workflow_activation_job, WorkflowActivation, WorkflowActivationJob},
         workflow_commands::{ActivityCancellationType, FailWorkflowExecution, StartTimer},
         workflow_completion::WorkflowActivationCompletion,
         ActivityTaskCompletion, AsJsonPayloadExt, IntoCompletion,
     },
     temporal::api::{failure::v1::Failure, history::v1::history_event},
 };
 use temporal_sdk_core_test_utils::{
-    history_from_proto_binary, init_core_and_create_wf, init_core_replay_preloaded,
-    schedule_activity_cmd, CoreWfStarter, WorkerTestHelpers,
+    drain_pollers_and_shutdown, history_from_proto_binary, init_core_and_create_wf,
+    init_core_replay_preloaded, schedule_activity_cmd, CoreWfStarter, WorkerTestHelpers,
 };
 use tokio::time::sleep;
 use uuid::Uuid;
 
 // TODO: We should get expected histories for these tests and confirm that the history at the end
 //  matches.
 
 #[tokio::test]
 async fn parallel_workflows_same_queue() {
     let mut starter = CoreWfStarter::new("parallel_workflows_same_queue");
     let core = starter.get_worker().await;
     let num_workflows = 25usize;
 
     let run_ids: Vec<_> = future::join_all(
-        (0..num_workflows)
-            .map(|i| starter.start_wf_with_id(format!("wf-id-{}", i), WorkflowOptions::default())),
+        (0..num_workflows).map(|i| starter.start_wf_with_id(format!("wf-id-{i}"))),
     )
     .await;
 
     let mut send_chans = HashMap::new();
     async fn wf_task(
         worker: Arc<dyn Worker>,
         mut task_chan: UnboundedReceiver<WorkflowActivation>,
@@ -100,29 +98,29 @@
             .await
             .unwrap();
     }
 
     for handle in handles {
         handle.await.unwrap()
     }
-    core.shutdown().await;
+    drain_pollers_and_shutdown(&core).await;
 }
 
 static RUN_CT: AtomicUsize = AtomicUsize::new(0);
 pub async fn cache_evictions_wf(command_sink: WfContext) -> WorkflowResult<()> {
     RUN_CT.fetch_add(1, Ordering::SeqCst);
     command_sink.timer(Duration::from_secs(1)).await;
     Ok(().into())
 }
 
 #[tokio::test]
 async fn workflow_lru_cache_evictions() {
     let wf_type = "workflow_lru_cache_evictions";
     let mut starter = CoreWfStarter::new(wf_type);
-    starter.max_cached_workflows(1);
+    starter.no_remote_activities().max_cached_workflows(1);
     let mut worker = starter.worker().await;
     worker.register_wf(wf_type.to_string(), cache_evictions_wf);
 
     let n_workflows = 3;
     for _ in 0..n_workflows {
         worker
             .submit_wf(
@@ -159,15 +157,15 @@
 async fn shutdown_aborts_actively_blocked_poll() {
     let mut starter = CoreWfStarter::new("shutdown_aborts_actively_blocked_poll");
     let core = starter.get_worker().await;
     // Begin the poll, and request shutdown from another thread after a small period of time.
     let tcore = core.clone();
     let handle = tokio::spawn(async move {
         std::thread::sleep(Duration::from_millis(100));
-        tcore.shutdown().await;
+        drain_pollers_and_shutdown(&tcore).await;
     });
     assert_matches!(
         core.poll_workflow_activation().await.unwrap_err(),
         PollWfError::ShutDown
     );
     handle.await.unwrap();
     // Ensure double-shutdown doesn't explode
@@ -411,19 +409,19 @@
         }
 
         // On the second attempt, we will see the signal we failed to handle as well as the timer
         assert_matches!(
             res.jobs.as_slice(),
             [
                 WorkflowActivationJob {
-                    variant: Some(workflow_activation_job::Variant::FireTimer(_)),
+                    variant: Some(workflow_activation_job::Variant::SignalWorkflow(_)),
                 },
                 WorkflowActivationJob {
-                    variant: Some(workflow_activation_job::Variant::SignalWorkflow(_)),
-                }
+                    variant: Some(workflow_activation_job::Variant::FireTimer(_)),
+                },
             ]
         );
         core.complete_execution(&res.run_id).await;
     }
 }
 
 #[tokio::test]
@@ -431,16 +429,16 @@
     let activity_id = "act-1";
     let signal_at_start = "at-start";
     let signal_at_complete = "at-complete";
     let mut wf_starter = CoreWfStarter::new("wft_timeout_doesnt_create_unsolvable_autocomplete");
     wf_starter
         // Test needs eviction on and a short timeout
         .max_cached_workflows(0)
-        .max_wft(1)
-        .wft_timeout(Duration::from_secs(1));
+        .max_wft(1);
+    wf_starter.workflow_options.task_timeout = Some(Duration::from_secs(1));
     let core = wf_starter.get_worker().await;
     let client = wf_starter.get_client().await;
     let task_q = wf_starter.get_task_queue();
     let wf_id = &wf_starter.get_wf_id().to_owned();
 
     // Set up some helpers for polling and completing
     let poll_sched_act = || async {
@@ -456,15 +454,15 @@
             )
             .into_completion(wf_task.run_id.clone()),
         )
         .await
         .unwrap();
         wf_task
     };
-    wf_starter.start_wf().await;
+    wf_starter.start_wf_with_id(wf_id.to_string()).await;
 
     // Poll and schedule the activity
     let wf_task = poll_sched_act().await;
     // Before polling for a task again, we start and complete the activity and send the
     // corresponding signals.
     let ac_task = core.poll_activity_task().await.unwrap();
     let rid = wf_task.run_id.clone();
@@ -561,22 +559,19 @@
                 ..Default::default()
             })
             .await;
             ctx.timer(Duration::from_secs(1)).await;
         }
         Ok(().into())
     });
-    worker.register_activity(
-        "echo_activity",
-        |_ctx: ActContext, echo_me: String| async move { Ok(echo_me) },
-    );
+    worker.register_activity("echo_activity", echo);
     for i in 0..20 {
         worker
             .submit_wf(
-                format!("{}_{}", wf_name, i),
+                format!("{wf_name}_{i}"),
                 wf_name.to_owned(),
                 vec![],
                 WorkflowOptions::default(),
             )
             .await
             .unwrap();
     }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/load_tests.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/fuzzy_workflow.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,191 +1,130 @@
-use assert_matches::assert_matches;
-use futures::{future::join_all, sink, stream::FuturesUnordered, StreamExt};
-use std::time::{Duration, Instant};
+use futures_util::{sink, stream::FuturesUnordered, FutureExt, StreamExt};
+use rand::{prelude::Distribution, rngs::SmallRng, Rng, SeedableRng};
+use std::{future, time::Duration};
 use temporal_client::{WfClientExt, WorkflowClientTrait, WorkflowOptions};
-use temporal_sdk::{ActContext, ActivityOptions, WfContext};
-use temporal_sdk_core_protos::coresdk::{
-    activity_result::ActivityExecutionResult, activity_task::activity_task as act_task,
-    workflow_commands::ActivityCancellationType, ActivityTaskCompletion, AsJsonPayloadExt,
-};
+use temporal_sdk::{ActContext, ActivityOptions, LocalActivityOptions, WfContext, WorkflowResult};
+use temporal_sdk_core_protos::coresdk::{AsJsonPayloadExt, FromJsonPayloadExt, IntoPayloadsExt};
 use temporal_sdk_core_test_utils::CoreWfStarter;
+use tokio_util::sync::CancellationToken;
 
-#[tokio::test]
-async fn activity_load() {
-    const CONCURRENCY: usize = 1000;
-
-    let mut starter = CoreWfStarter::new("activity_load");
-    starter
-        .max_wft(CONCURRENCY)
-        .max_cached_workflows(CONCURRENCY)
-        .max_at_polls(10)
-        .max_at(CONCURRENCY);
-    let mut worker = starter.worker().await;
+const FUZZY_SIG: &str = "fuzzy_sig";
 
-    let activity_id = "act-1";
-    let activity_timeout = Duration::from_secs(8);
-    let payload_dat = b"hello".to_vec();
-    let task_queue = starter.get_task_queue().to_owned();
-
-    let pd = payload_dat.clone();
-    let wf_fn = move |ctx: WfContext| {
-        let task_queue = task_queue.clone();
-        let payload_dat = pd.clone();
-
-        async move {
-            let activity = ActivityOptions {
-                activity_id: Some(activity_id.to_string()),
-                activity_type: "test_activity".to_string(),
-                task_queue,
-                schedule_to_start_timeout: Some(activity_timeout),
-                start_to_close_timeout: Some(activity_timeout),
-                schedule_to_close_timeout: Some(activity_timeout),
-                heartbeat_timeout: Some(activity_timeout),
-                cancellation_type: ActivityCancellationType::TryCancel,
-                ..Default::default()
-            };
-            let res = ctx.activity(activity).await.unwrap_ok_payload();
-            assert_eq!(res.data, payload_dat);
-            Ok(().into())
-        }
-    };
+#[derive(serde::Serialize, serde::Deserialize, Copy, Clone)]
+enum FuzzyWfAction {
+    Shutdown,
+    DoAct,
+    DoLocalAct,
+}
 
-    let starting = Instant::now();
-    let wf_type = "activity_load";
-    worker.register_wf(wf_type.to_owned(), wf_fn);
-    join_all((0..CONCURRENCY).map(|i| {
-        let worker = &worker;
-        let wf_id = format!("activity_load_{}", i);
-        async move {
-            worker
-                .submit_wf(
-                    wf_id,
-                    wf_type.to_owned(),
-                    vec![],
-                    WorkflowOptions::default(),
-                )
-                .await
-                .unwrap();
+struct FuzzyWfActionSampler;
+impl Distribution<FuzzyWfAction> for FuzzyWfActionSampler {
+    fn sample<R: Rng + ?Sized>(&self, rng: &mut R) -> FuzzyWfAction {
+        let v: u8 = rng.gen_range(1..=2);
+        match v {
+            1 => FuzzyWfAction::DoAct,
+            2 => FuzzyWfAction::DoLocalAct,
+            _ => unreachable!(),
         }
-    }))
-    .await;
-    dbg!(starting.elapsed());
-
-    let running = Instant::now();
-    let core = starter.get_worker().await;
-
-    // Poll for and complete all activities
-    let c2 = core.clone();
-    let all_acts = async move {
-        let mut act_complete_futs = vec![];
-        for _ in 0..CONCURRENCY {
-            let task = c2.poll_activity_task().await.unwrap();
-            assert_matches!(
-                task.variant,
-                Some(act_task::Variant::Start(ref start_activity)) => {
-                    assert_eq!(start_activity.activity_type, "test_activity")
+    }
+}
+
+async fn echo(_ctx: ActContext, echo_me: String) -> Result<String, anyhow::Error> {
+    Ok(echo_me)
+}
+
+async fn fuzzy_wf_def(ctx: WfContext) -> WorkflowResult<()> {
+    let sigchan = ctx
+        .make_signal_channel(FUZZY_SIG)
+        .map(|sd| FuzzyWfAction::from_json_payload(&sd.input[0]).expect("Can deserialize signal"));
+    let done = CancellationToken::new();
+    let done_setter = done.clone();
+
+    sigchan
+        .take_until(done.cancelled())
+        .for_each_concurrent(None, |action| {
+            let fut = match action {
+                FuzzyWfAction::DoAct => ctx
+                    .activity(ActivityOptions {
+                        activity_type: "echo_activity".to_string(),
+                        start_to_close_timeout: Some(Duration::from_secs(5)),
+                        input: "hi!".as_json_payload().expect("serializes fine"),
+                        ..Default::default()
+                    })
+                    .map(|_| ())
+                    .boxed(),
+                FuzzyWfAction::DoLocalAct => ctx
+                    .local_activity(LocalActivityOptions {
+                        activity_type: "echo_activity".to_string(),
+                        start_to_close_timeout: Some(Duration::from_secs(5)),
+                        input: "hi!".as_json_payload().expect("serializes fine"),
+                        ..Default::default()
+                    })
+                    .map(|_| ())
+                    .boxed(),
+                FuzzyWfAction::Shutdown => {
+                    done_setter.cancel();
+                    future::ready(()).boxed()
                 }
-            );
-            let pd = payload_dat.clone();
-            let core = c2.clone();
-            act_complete_futs.push(tokio::spawn(async move {
-                core.complete_activity_task(ActivityTaskCompletion {
-                    task_token: task.task_token,
-                    result: Some(ActivityExecutionResult::ok(pd.into())),
-                })
-                .await
-                .unwrap()
-            }));
-        }
-        join_all(act_complete_futs)
-            .await
-            .into_iter()
-            .for_each(|h| h.unwrap());
-    };
-    tokio::join! {
-        async {
-            worker.run_until_done().await.unwrap();
-        },
-        all_acts
-    };
-    dbg!(running.elapsed());
+            };
+            fut
+        })
+        .await;
+
+    Ok(().into())
 }
 
 #[tokio::test(flavor = "multi_thread", worker_threads = 4)]
-async fn workflow_load() {
-    const SIGNAME: &str = "signame";
+async fn fuzzy_workflow() {
     let num_workflows = 200;
-    let wf_name = "workflow_load";
-    let mut starter = CoreWfStarter::new("workflow_load");
-    starter
-        .max_wft(5)
-        .max_cached_workflows(5)
-        .max_at_polls(10)
-        .max_at(100);
+    let wf_name = "fuzzy_wf";
+    let mut starter = CoreWfStarter::new("fuzzy_workflow");
+    starter.max_wft(25).max_cached_workflows(25).max_at(25);
+    // .enable_wf_state_input_recording();
     let mut worker = starter.worker().await;
-    worker.register_wf(wf_name.to_owned(), |ctx: WfContext| async move {
-        let sigchan = ctx.make_signal_channel(SIGNAME).map(Ok);
-        let drained_fut = sigchan.forward(sink::drain());
-
-        let real_stuff = async move {
-            for _ in 0..20 {
-                ctx.activity(ActivityOptions {
-                    activity_type: "echo_activity".to_string(),
-                    start_to_close_timeout: Some(Duration::from_secs(5)),
-                    input: "hi!".as_json_payload().expect("serializes fine"),
-                    ..Default::default()
-                })
-                .await;
-                ctx.timer(Duration::from_secs(1)).await;
-            }
-        };
-        tokio::select! {
-            _ = drained_fut => {}
-            _ = real_stuff => {}
-        }
-
-        Ok(().into())
-    });
-    worker.register_activity(
-        "echo_activity",
-        |_ctx: ActContext, echo_me: String| async move { Ok(echo_me) },
-    );
+    worker.register_wf(wf_name.to_owned(), fuzzy_wf_def);
+    worker.register_activity("echo_activity", echo);
     let client = starter.get_client().await;
 
     let mut workflow_handles = vec![];
     for i in 0..num_workflows {
-        let wfid = format!("{}_{}", wf_name, i);
+        let wfid = format!("{wf_name}_{i}");
         let rid = worker
             .submit_wf(
                 wfid.clone(),
                 wf_name.to_owned(),
                 vec![],
                 WorkflowOptions::default(),
             )
             .await
             .unwrap();
         workflow_handles.push(client.get_untyped_workflow_handle(wfid, rid));
     }
 
+    let rng = SmallRng::seed_from_u64(523189);
+    let mut actions: Vec<FuzzyWfAction> = rng.sample_iter(FuzzyWfActionSampler).take(15).collect();
+    actions.push(FuzzyWfAction::Shutdown);
+
     let sig_sender = async {
-        loop {
+        for action in actions {
             let sends: FuturesUnordered<_> = (0..num_workflows)
                 .map(|i| {
                     client.signal_workflow_execution(
-                        format!("{}_{}", wf_name, i),
+                        format!("{wf_name}_{i}"),
                         "".to_string(),
-                        SIGNAME.to_string(),
-                        None,
+                        FUZZY_SIG.to_string(),
+                        [action.as_json_payload().expect("Serializes ok")].into_payloads(),
                         None,
                     )
                 })
                 .collect();
             sends
                 .map(|_| Ok(()))
                 .forward(sink::drain())
                 .await
                 .expect("Sending signals works");
-            tokio::time::sleep(Duration::from_secs(2)).await;
+            tokio::time::sleep(Duration::from_secs(1)).await;
         }
     };
-    tokio::select! { r1 = worker.run_until_done() => {r1.unwrap()}, _ = sig_sender => {}};
+    let (r1, _) = tokio::join!(worker.run_until_done(), sig_sender);
+    r1.unwrap();
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/main.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/main.rs`

 * *Files 23% similar despite different names*

```diff
@@ -1,26 +1,17 @@
 //! Integration tests
-//!
-//! Note that integ tests which want to use the server (nearly all of them) *need* to use the
-//! `#[rstest]` macro and accept the TODO fixture to support auto setup & teardown of ephemeral
-//! local servers.
 
 #[macro_use]
 extern crate rstest;
+#[macro_use]
+extern crate temporal_sdk_core_test_utils;
 
 #[cfg(test)]
 mod integ_tests {
-    #[macro_export]
-    macro_rules! prost_dur {
-        ($dur_call:ident $args:tt) => {
-            std::time::Duration::$dur_call$args
-                .try_into()
-                .expect("test duration fits")
-        };
-    }
+    mod activity_functions;
     mod client_tests;
     mod ephemeral_server_tests;
     mod heartbeat_tests;
     mod metrics_tests;
     mod polling_tests;
     mod queries_tests;
     mod visibility_tests;
@@ -31,26 +22,26 @@
     use temporal_sdk_core::{
         init_worker, ClientOptionsBuilder, ClientTlsConfig, CoreRuntime, TlsConfig,
         WorkflowClientTrait,
     };
     use temporal_sdk_core_api::worker::WorkerConfigBuilder;
     use temporal_sdk_core_protos::temporal::api::workflowservice::v1::ListNamespacesRequest;
     use temporal_sdk_core_test_utils::{
-        get_integ_server_options, get_integ_telem_options, NAMESPACE,
+        get_integ_server_options, get_integ_telem_options, init_integ_telem,
     };
     use url::Url;
 
     // Create a worker like a bridge would (unwraps aside)
     #[tokio::test]
     #[ignore] // Really a compile time check more than anything
     async fn lang_bridge_example() {
         let opts = get_integ_server_options();
         let runtime = CoreRuntime::new_assume_tokio(get_integ_telem_options()).unwrap();
         let mut retrying_client = opts
-            .connect_no_namespace(runtime.metric_meter(), None)
+            .connect_no_namespace(runtime.metric_meter().as_deref(), None)
             .await
             .unwrap();
 
         let _worker = init_worker(
             &runtime,
             WorkerConfigBuilder::default()
                 .namespace("default")
@@ -64,50 +55,41 @@
 
         // Do things with worker or client
         let _ = retrying_client
             .list_namespaces(ListNamespacesRequest::default())
             .await;
     }
 
-    // TODO: Currently ignored because starting up the docker image with TLS requires some hoop
-    //  jumping. We should upgrade CI to be able to do that but this was manually run against
-    //  https://github.com/temporalio/customization-samples/tree/master/tls/tls-simple
+    // Manually run to verify tls works against cloud. You will need certs in place in the
+    // indicated directory.
     #[tokio::test]
     #[ignore]
     async fn tls_test() {
-        // Load certs/keys
-        let root = tokio::fs::read(
-            "/home/sushi/dev/temporal/customization-samples/tls/tls-simple/certs/ca.cert",
-        )
-        .await
-        .unwrap();
-        let client_cert = tokio::fs::read(
-            "/home/sushi/dev/temporal/customization-samples/tls/tls-simple/certs/client.pem",
-        )
-        .await
-        .unwrap();
-        let client_private_key = tokio::fs::read(
-            "/home/sushi/dev/temporal/customization-samples/tls/tls-simple/certs/client.key",
-        )
-        .await
-        .unwrap();
+        init_integ_telem();
+        let root = tokio::fs::read("../.cloud_certs/ca.pem").await.unwrap();
+        let client_cert = tokio::fs::read("../.cloud_certs/client.pem").await.unwrap();
+        let client_private_key = tokio::fs::read("../.cloud_certs/client.key").await.unwrap();
         let sgo = ClientOptionsBuilder::default()
-            .target_url(Url::from_str("https://localhost:7233").unwrap())
+            .target_url(Url::from_str("https://spencer.temporal-dev.tmprl.cloud:7233").unwrap())
             .client_name("tls_tester")
             .client_version("clientver")
             .tls_cfg(TlsConfig {
                 server_root_ca_cert: Some(root),
-                domain: Some("tls-sample".to_string()),
+                // Not necessary, but illustrates functionality for people using proxies, etc.
+                domain: Some("spencer.temporal-dev.tmprl.cloud".to_string()),
                 client_tls_config: Some(ClientTlsConfig {
                     client_cert,
                     client_private_key,
                 }),
             })
             .build()
             .unwrap();
         let con = sgo
-            .connect(NAMESPACE.to_string(), None, None)
+            .connect("spencer.temporal-dev".to_string(), None, None)
             .await
             .unwrap();
-        con.list_namespaces().await.unwrap();
+        dbg!(con
+            .list_workflow_executions(100, vec![], "".to_string())
+            .await
+            .unwrap());
     }
 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/sdk-core/tests/runner.rs` & `temporalio-1.2.0/temporalio/bridge/sdk-core/tests/runner.rs`

 * *Files 26% similar despite different names*

```diff
@@ -1,79 +1,118 @@
 use anyhow::{anyhow, bail};
+use clap::Parser;
 use std::{
     env,
-    env::args,
     path::{Path, PathBuf},
     process::Stdio,
 };
-use temporal_sdk_core::ephemeral_server::{TemporaliteConfigBuilder, TestServerConfigBuilder};
+use temporal_sdk_core::ephemeral_server::{
+    TemporalDevServerConfigBuilder, TestServerConfigBuilder,
+};
 use temporal_sdk_core_test_utils::{
-    default_cached_download, INTEG_SERVER_TARGET_ENV_VAR, INTEG_TEMPORALITE_USED_ENV_VAR,
+    default_cached_download, INTEG_SERVER_TARGET_ENV_VAR, INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR,
     INTEG_TEST_SERVER_USED_ENV_VAR,
 };
 use tokio::{self, process::Command};
 
+#[derive(clap::Parser)]
+#[command(author, version, about, long_about = None)]
+struct Cli {
+    /// Test harness to run. Anything defined as a `[[test]]` in core's `Cargo.toml` is valid.
+    #[arg(short, long, default_value = "integ_tests")]
+    test_name: String,
+
+    /// What kind of server to auto-launch, if any
+    #[arg(short, long, value_enum, default_value = "temporal-cli")]
+    server_kind: ServerKind,
+
+    /// Arguments to pass through to the `cargo test` command. Ex: `--release`
+    #[arg(short, long, allow_hyphen_values(true))]
+    cargo_test_args: Vec<String>,
+
+    /// The rest of the arguments will be passed through to the test harness
+    harness_args: Vec<String>,
+}
+
+#[derive(Copy, Clone, PartialEq, Eq, clap::ValueEnum)]
+enum ServerKind {
+    /// Use Temporal-cli
+    TemporalCLI,
+    /// Use the Java test server
+    TestServer,
+    /// Do not automatically start any server
+    External,
+}
+
 #[tokio::main]
 async fn main() -> Result<(), anyhow::Error> {
+    let Cli {
+        test_name,
+        server_kind,
+        cargo_test_args,
+        harness_args,
+    } = Cli::parse();
     let cargo = env::var("CARGO").unwrap_or_else(|_| "cargo".to_string());
-    let server_type = env::var("INTEG_SERVER_TYPE")
-        .unwrap_or_else(|_| "temporalite".to_string())
-        .to_lowercase();
     // Try building first, so that we error early on build failures & don't start server
+    let test_args_preamble = ["test", "--test", &test_name]
+        .into_iter()
+        .map(ToString::to_string)
+        .chain(cargo_test_args)
+        .collect::<Vec<_>>();
     let status = Command::new(&cargo)
-        .args(["test", "--test", "integ_tests", "--no-run"])
+        .args([test_args_preamble.as_slice(), &["--no-run".to_string()]].concat())
         .status()
         .await?;
     if !status.success() {
         bail!("Building integration tests failed!");
     }
 
-    // Move to clap if we start doing any more complicated input
-    let (server, envs) = if server_type == "test-server" {
-        let config = TestServerConfigBuilder::default()
-            .exe(default_cached_download())
-            .build()?;
-        println!("Using java test server");
-        (
-            Some(config.start_server_with_output(Stdio::null()).await?),
-            vec![(INTEG_TEST_SERVER_USED_ENV_VAR, "true")],
-        )
-    } else if server_type == "temporalite" {
-        let config = TemporaliteConfigBuilder::default()
-            .exe(default_cached_download())
-            .build()?;
-        println!("Using temporalite");
-        (
-            Some(config.start_server_with_output(Stdio::null()).await?),
-            vec![(INTEG_TEMPORALITE_USED_ENV_VAR, "true")],
-        )
-    } else {
-        println!("Not starting up a server. One should be running already.");
-        (None, vec![])
+    let (server, envs) = match server_kind {
+        ServerKind::TemporalCLI => {
+            let config = TemporalDevServerConfigBuilder::default()
+                .exe(default_cached_download())
+                .build()?;
+            println!("Using temporal CLI");
+            (
+                Some(config.start_server_with_output(Stdio::null()).await?),
+                vec![(INTEG_TEMPORAL_DEV_SERVER_USED_ENV_VAR, "true")],
+            )
+        }
+        ServerKind::TestServer => {
+            let config = TestServerConfigBuilder::default()
+                .exe(default_cached_download())
+                .build()?;
+            println!("Using java test server");
+            (
+                Some(config.start_server_with_output(Stdio::null()).await?),
+                vec![(INTEG_TEST_SERVER_USED_ENV_VAR, "true")],
+            )
+        }
+        ServerKind::External => {
+            println!("Not starting up a server. One should be running already.");
+            (None, vec![])
+        }
     };
 
-    // Run the integ tests, passing through arguments
-    let mut args = args();
-    // Shift off binary name
-    args.next();
     let mut cmd = Command::new(&cargo);
     if let Some(srv) = server.as_ref() {
+        println!("Running on {}", srv.target);
         cmd.env(
             INTEG_SERVER_TARGET_ENV_VAR,
             format!("http://{}", &srv.target),
         );
     }
     let status = cmd
         .envs(envs)
         .current_dir(project_root())
         .args(
-            ["test", "--test", "integ_tests"]
+            test_args_preamble
                 .into_iter()
-                .map(ToString::to_string)
-                .chain(args),
+                .chain(["--".to_string()])
+                .chain(harness_args),
         )
         .status()
         .await?;
 
     if let Some(mut srv) = server {
         srv.shutdown().await?;
     }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/src/client.rs` & `temporalio-1.2.0/temporalio/bridge/src/client.rs`

 * *Files 2% similar despite different names*

```diff
@@ -74,15 +74,15 @@
         Some(Arc::new(RwLock::new(config.metadata.clone())))
     };
     let opts: ClientOptions = config.try_into()?;
     let runtime = runtime_ref.runtime.clone();
     runtime_ref.runtime.future_into_py(py, async move {
         Ok(ClientRef {
             retry_client: opts
-                .connect_no_namespace(runtime.core.metric_meter(), headers)
+                .connect_no_namespace(runtime.core.metric_meter().as_deref(), headers)
                 .await
                 .map_err(|err| {
                     PyRuntimeError::new_err(format!("Failed client connect: {}", err))
                 })?,
             runtime,
         })
     })
@@ -125,16 +125,16 @@
                     rpc_call!(retry_client, call, describe_workflow_execution)
                 }
                 "get_cluster_info" => rpc_call!(retry_client, call, get_cluster_info),
                 "get_search_attributes" => {
                     rpc_call!(retry_client, call, get_search_attributes)
                 }
                 "get_system_info" => rpc_call!(retry_client, call, get_system_info),
-                "get_worker_build_id_ordering" => {
-                    rpc_call!(retry_client, call, get_worker_build_id_ordering)
+                "get_worker_build_id_compatibility" => {
+                    rpc_call!(retry_client, call, get_worker_build_id_compatibility)
                 }
                 "get_workflow_execution_history" => {
                     rpc_call!(retry_client, call, get_workflow_execution_history)
                 }
                 "get_workflow_execution_history_reverse" => {
                     rpc_call!(retry_client, call, get_workflow_execution_history_reverse)
                 }
@@ -162,14 +162,17 @@
                 }
                 "patch_schedule" => {
                     rpc_call!(retry_client, call, patch_schedule)
                 }
                 "poll_activity_task_queue" => {
                     rpc_call!(retry_client, call, poll_activity_task_queue)
                 }
+                "poll_workflow_execution_update" => {
+                    rpc_call!(retry_client, call, poll_workflow_execution_update)
+                }
                 "poll_workflow_task_queue" => {
                     rpc_call!(retry_client, call, poll_workflow_task_queue)
                 }
                 "query_workflow" => rpc_call!(retry_client, call, query_workflow),
                 "record_activity_task_heartbeat" => {
                     rpc_call!(retry_client, call, record_activity_task_heartbeat)
                 }
@@ -226,17 +229,19 @@
                     rpc_call!(retry_client, call, start_workflow_execution)
                 }
                 "terminate_workflow_execution" => {
                     rpc_call!(retry_client, call, terminate_workflow_execution)
                 }
                 "update_namespace" => rpc_call!(retry_client, call, update_namespace),
                 "update_schedule" => rpc_call!(retry_client, call, update_schedule),
-                "update_workflow" => rpc_call!(retry_client, call, update_workflow),
-                "update_worker_build_id_ordering" => {
-                    rpc_call!(retry_client, call, update_worker_build_id_ordering)
+                "update_workflow_execution" => {
+                    rpc_call!(retry_client, call, update_workflow_execution)
+                }
+                "update_worker_build_id_compatibility" => {
+                    rpc_call!(retry_client, call, update_worker_build_id_compatibility)
                 }
                 _ => {
                     return Err(PyValueError::new_err(format!(
                         "Unknown RPC call {}",
                         call.rpc
                     )))
                 }
```

### Comparing `temporalio-1.1.0/temporalio/bridge/src/lib.rs` & `temporalio-1.2.0/temporalio/bridge/src/lib.rs`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/src/runtime.rs` & `temporalio-1.2.0/temporalio/bridge/src/runtime.rs`

 * *Files 1% similar despite different names*

```diff
@@ -26,14 +26,15 @@
 }
 
 #[derive(FromPyObject)]
 pub struct TelemetryConfig {
     tracing: Option<TracingConfig>,
     logging: Option<LoggingConfig>,
     metrics: Option<MetricsConfig>,
+    global_tags: Option<HashMap<String, String>>
 }
 
 #[derive(FromPyObject)]
 pub struct TracingConfig {
     filter: String,
     opentelemetry: OpenTelemetryConfig,
 }
@@ -125,14 +126,17 @@
                 )?)
             } else {
                 return Err(PyValueError::new_err(
                     "Either OpenTelemetry or Prometheus config must be provided",
                 ));
             });
         }
+        if let Some(v) = conf.global_tags {
+            build.global_tags(v);
+        }
         build
             .build()
             .map_err(|err| PyValueError::new_err(format!("Invalid telemetry config: {}", err)))
     }
 }
 
 impl TryFrom<OpenTelemetryConfig> for OtelCollectorOptions {
```

### Comparing `temporalio-1.1.0/temporalio/bridge/src/testing.rs` & `temporalio-1.2.0/temporalio/bridge/src/testing.rs`

 * *Files 2% similar despite different names*

```diff
@@ -113,15 +113,15 @@
             .exe(if let Some(existing_path) = conf.existing_path {
                 ephemeral_server::EphemeralExe::ExistingPath(existing_path.to_owned())
             } else {
                 ephemeral_server::EphemeralExe::CachedDownload {
                     version: if conf.download_version != "default" {
                         ephemeral_server::EphemeralExeVersion::Fixed(conf.download_version)
                     } else {
-                        ephemeral_server::EphemeralExeVersion::Default {
+                        ephemeral_server::EphemeralExeVersion::SDKDefault {
                             sdk_name: conf.sdk_name,
                             sdk_version: conf.sdk_version,
                         }
                     },
                     dest_dir: conf.download_dest_dir,
                 }
             })
@@ -145,15 +145,15 @@
             .exe(if let Some(existing_path) = conf.existing_path {
                 ephemeral_server::EphemeralExe::ExistingPath(existing_path.to_owned())
             } else {
                 ephemeral_server::EphemeralExe::CachedDownload {
                     version: if conf.download_version != "default" {
                         ephemeral_server::EphemeralExeVersion::Fixed(conf.download_version)
                     } else {
-                        ephemeral_server::EphemeralExeVersion::Default {
+                        ephemeral_server::EphemeralExeVersion::SDKDefault {
                             sdk_name: conf.sdk_name,
                             sdk_version: conf.sdk_version,
                         }
                     },
                     dest_dir: conf.download_dest_dir,
                 }
             })
```

### Comparing `temporalio-1.1.0/temporalio/bridge/src/worker.rs` & `temporalio-1.2.0/temporalio/bridge/src/worker.rs`

 * *Files 6% similar despite different names*

```diff
@@ -39,14 +39,15 @@
     max_concurrent_activity_task_polls: usize,
     no_remote_activities: bool,
     sticky_queue_schedule_to_start_timeout_millis: u64,
     max_heartbeat_throttle_interval_millis: u64,
     default_heartbeat_throttle_interval_millis: u64,
     max_activities_per_second: Option<f64>,
     max_task_queue_activities_per_second: Option<f64>,
+    graceful_shutdown_period_millis: u64,
 }
 
 macro_rules! enter_sync {
     ($runtime:expr) => {
         temporal_sdk_core::telemetry::set_trace_subscriber_for_current_thread(
             $runtime.core.trace_subscriber(),
         );
@@ -173,20 +174,18 @@
         self.worker
             .as_ref()
             .unwrap()
             .request_workflow_eviction(run_id);
         Ok(())
     }
 
-    fn shutdown<'p>(&self, py: Python<'p>) -> PyResult<&'p PyAny> {
+    fn initiate_shutdown(&self) -> PyResult<()> {
         let worker = self.worker.as_ref().unwrap().clone();
-        self.runtime.future_into_py(py, async move {
-            worker.shutdown().await;
-            Ok(())
-        })
+        worker.initiate_shutdown();
+        Ok(())
     }
 
     fn finalize_shutdown<'p>(&mut self, py: Python<'p>) -> PyResult<&'p PyAny> {
         // Take the worker out of the option and leave None. This should be the
         // only reference remaining to the worker so try_unwrap will work.
         let worker = Arc::try_unwrap(self.worker.take().unwrap()).map_err(|arc| {
             PyValueError::new_err(format!(
@@ -225,14 +224,18 @@
                 conf.max_heartbeat_throttle_interval_millis,
             ))
             .default_heartbeat_throttle_interval(Duration::from_millis(
                 conf.default_heartbeat_throttle_interval_millis,
             ))
             .max_worker_activities_per_second(conf.max_activities_per_second)
             .max_task_queue_activities_per_second(conf.max_task_queue_activities_per_second)
+            // Even though grace period is optional, if it is not set then the
+            // auto-cancel-activity behavior of shutdown will not occur, so we
+            // always set it even if 0.
+            .graceful_shutdown_period(Duration::from_millis(conf.graceful_shutdown_period_millis))
             .build()
             .map_err(|err| PyValueError::new_err(format!("Invalid worker config: {}", err)))
     }
 }
 
 /// For feeding histories into core during replay
 #[pyclass]
```

### Comparing `temporalio-1.1.0/temporalio/bridge/testing.py` & `temporalio-1.2.0/temporalio/bridge/testing.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/bridge/worker.py` & `temporalio-1.2.0/temporalio/bridge/worker.py`

 * *Files 2% similar despite different names*

```diff
@@ -42,14 +42,15 @@
     max_concurrent_activity_task_polls: int
     no_remote_activities: bool
     sticky_queue_schedule_to_start_timeout_millis: int
     max_heartbeat_throttle_interval_millis: int
     default_heartbeat_throttle_interval_millis: int
     max_activities_per_second: Optional[float]
     max_task_queue_activities_per_second: Optional[float]
+    graceful_shutdown_period_millis: int
 
 
 class Worker:
     """SDK Core worker."""
 
     @staticmethod
     def create(client: temporalio.bridge.client.Client, config: WorkerConfig) -> Worker:
@@ -115,17 +116,17 @@
         """Record an activity heartbeat."""
         self._ref.record_activity_heartbeat(comp.SerializeToString())
 
     def request_workflow_eviction(self, run_id: str) -> None:
         """Request a workflow be evicted."""
         self._ref.request_workflow_eviction(run_id)
 
-    async def shutdown(self) -> None:
-        """Shutdown the worker, waiting for completion."""
-        await self._ref.shutdown()
+    def initiate_shutdown(self) -> None:
+        """Start shutdown of the worker."""
+        self._ref.initiate_shutdown()
 
     async def finalize_shutdown(self) -> None:
         """Finalize the worker.
 
         This will fail if shutdown hasn't completed fully due to internal
         reference count checks.
         """
```

### Comparing `temporalio-1.1.0/temporalio/client.py` & `temporalio-1.2.0/temporalio/client.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/common.py` & `temporalio-1.2.0/temporalio/common.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/contrib/opentelemetry.py` & `temporalio-1.2.0/temporalio/contrib/opentelemetry.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/converter.py` & `temporalio-1.2.0/temporalio/converter.py`

 * *Files 0% similar despite different names*

```diff
@@ -1205,15 +1205,15 @@
         return None
 
     # NewType. Note we cannot simply check isinstance NewType here because it's
     # only been a class since 3.10. Instead we'll just check for the presence
     # of a supertype.
     supertype = getattr(hint, "__supertype__", None)
     if supertype:
-        return value_to_type(supertype, value)
+        return value_to_type(supertype, value, custom_converters)
 
     # Load origin for other checks
     origin = getattr(hint, "__origin__", hint)
     type_args: Tuple = getattr(hint, "__args__", ())
 
     # Literal
     if origin is Literal:
@@ -1226,15 +1226,15 @@
         is_union = is_union or isinstance(origin, UnionType)
 
     # Union
     if is_union:
         # Try each one. Note, Optional is just a union w/ none.
         for arg in type_args:
             try:
-                return value_to_type(arg, value)
+                return value_to_type(arg, value, custom_converters)
             except Exception:
                 pass
         raise TypeError(f"Failed converting to {hint} from {value}")
 
     # Mapping
     if inspect.isclass(origin) and issubclass(origin, collections.abc.Mapping):
         if not isinstance(value, collections.abc.Mapping):
@@ -1261,25 +1261,25 @@
             and not isinstance(type_args[1], TypeVar)
             else None
         )
         # Convert each key/value
         for key, value in value.items():
             if key_type:
                 try:
-                    key = value_to_type(key_type, key)
+                    key = value_to_type(key_type, key, custom_converters)
                 except Exception as err:
                     raise TypeError(f"Failed converting key {key} on {hint}") from err
             # If there are per-key types, use it instead of single type
             this_value_type = value_type
             if per_key_types:
                 # TODO(cretz): Strict mode would fail an unknown key
                 this_value_type = per_key_types.get(key)
             if this_value_type:
                 try:
-                    value = value_to_type(this_value_type, value)
+                    value = value_to_type(this_value_type, value, custom_converters)
                 except Exception as err:
                     raise TypeError(
                         f"Failed converting value for key {key} on {hint}"
                     ) from err
             ret_dict[key] = value
         # If there are per-key types, it's a typed dict and we want to attempt
         # instantiation to get its validation
@@ -1303,15 +1303,15 @@
             field_value = value.get(field.name, dataclasses.MISSING)
             # We do not check whether field is required here. Rather, we let the
             # attempted instantiation of the dataclass raise if a field is
             # missing
             if field_value is not dataclasses.MISSING:
                 try:
                     field_values[field.name] = value_to_type(
-                        field_hints[field.name], field_value
+                        field_hints[field.name], field_value, custom_converters
                     )
                 except Exception as err:
                     raise TypeError(
                         f"Failed converting field {field.name} on dataclass {hint}"
                     ) from err
         # Simply instantiate the dataclass. This will fail as expected when
         # missing required fields.
@@ -1375,15 +1375,15 @@
                     # Ellipsis means use the second to last one
                     arg_type = type_args[-2]
                 else:
                     raise TypeError(
                         f"Type {hint} only expecting {len(type_args)} values, got at least {i + 1}"
                     )
                 try:
-                    ret_list.append(value_to_type(arg_type, item))
+                    ret_list.append(value_to_type(arg_type, item, custom_converters))
                 except Exception as err:
                     raise TypeError(f"Failed converting {hint} index {i}") from err
         # If tuple, set, or deque convert back to that type
         if origin is tuple:
             return tuple(ret_list)
         elif origin is set:
             return set(ret_list)
```

### Comparing `temporalio-1.1.0/temporalio/exceptions.py` & `temporalio-1.2.0/temporalio/exceptions.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/runtime.py` & `temporalio-1.2.0/temporalio/runtime.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 """Runtime for clients and workers. (experimental)
 
 This module is currently experimental. The API may change.
 """
 
 from __future__ import annotations
 
-from dataclasses import dataclass
+from dataclasses import dataclass, field
 from datetime import timedelta
 from typing import ClassVar, Mapping, Optional, Union
 
 import temporalio.bridge.runtime
 
 _default_runtime: Optional[Runtime] = None
 
@@ -171,22 +171,26 @@
 
     logging: Optional[LoggingConfig] = LoggingConfig.default
     """Logging configuration."""
 
     metrics: Optional[Union[OpenTelemetryConfig, PrometheusConfig]] = None
     """Metrics configuration."""
 
+    global_tags: Mapping[str, str] = field(default_factory=dict)
+    """OTel resource tags to be applied to all metrics and traces"""
+
     def _to_bridge_config(self) -> temporalio.bridge.runtime.TelemetryConfig:
         return temporalio.bridge.runtime.TelemetryConfig(
             tracing=None if not self.tracing else self.tracing._to_bridge_config(),
             logging=None if not self.logging else self.logging._to_bridge_config(),
             metrics=None
             if not self.metrics
             else temporalio.bridge.runtime.MetricsConfig(
                 opentelemetry=None
                 if not isinstance(self.metrics, OpenTelemetryConfig)
                 else self.metrics._to_bridge_config(),
                 prometheus=None
                 if not isinstance(self.metrics, PrometheusConfig)
                 else self.metrics._to_bridge_config(),
             ),
+            global_tags=self.global_tags,
         )
```

### Comparing `temporalio-1.1.0/temporalio/service.py` & `temporalio-1.2.0/temporalio/service.py`

 * *Files 2% similar despite different names*

```diff
@@ -21,15 +21,15 @@
 import temporalio.api.testservice.v1
 import temporalio.api.workflowservice.v1
 import temporalio.bridge.client
 import temporalio.bridge.proto.health.v1
 import temporalio.exceptions
 import temporalio.runtime
 
-__version__ = "1.1.0"
+__version__ = "1.2.0"
 
 ServiceRequest = TypeVar("ServiceRequest", bound=google.protobuf.message.Message)
 ServiceResponse = TypeVar("ServiceResponse", bound=google.protobuf.message.Message)
 
 logger = logging.getLogger(__name__)
 
 # Set to true to log all requests and responses
@@ -304,18 +304,18 @@
             wsv1.GetSearchAttributesResponse,
         )
         self.get_system_info = client._new_call(
             "get_system_info",
             wsv1.GetSystemInfoRequest,
             wsv1.GetSystemInfoResponse,
         )
-        self.get_worker_build_id_ordering = client._new_call(
-            "get_worker_build_id_ordering",
-            wsv1.GetWorkerBuildIdOrderingRequest,
-            wsv1.GetWorkerBuildIdOrderingResponse,
+        self.get_worker_build_id_compatibility = client._new_call(
+            "get_worker_build_id_compatibility",
+            wsv1.GetWorkerBuildIdCompatibilityRequest,
+            wsv1.GetWorkerBuildIdCompatibilityResponse,
         )
         self.get_workflow_execution_history = client._new_call(
             "get_workflow_execution_history",
             wsv1.GetWorkflowExecutionHistoryRequest,
             wsv1.GetWorkflowExecutionHistoryResponse,
         )
         self.get_workflow_execution_history_reverse = client._new_call(
@@ -374,14 +374,19 @@
             wsv1.PatchScheduleResponse,
         )
         self.poll_activity_task_queue = client._new_call(
             "poll_activity_task_queue",
             wsv1.PollActivityTaskQueueRequest,
             wsv1.PollActivityTaskQueueResponse,
         )
+        self.poll_workflow_execution_update = client._new_call(
+            "poll_workflow_execution_update",
+            wsv1.PollWorkflowExecutionUpdateRequest,
+            wsv1.PollWorkflowExecutionUpdateResponse,
+        )
         self.poll_workflow_task_queue = client._new_call(
             "poll_workflow_task_queue",
             wsv1.PollWorkflowTaskQueueRequest,
             wsv1.PollWorkflowTaskQueueResponse,
         )
         self.query_workflow = client._new_call(
             "query_workflow",
@@ -504,23 +509,23 @@
             wsv1.UpdateNamespaceResponse,
         )
         self.update_schedule = client._new_call(
             "update_schedule",
             wsv1.UpdateScheduleRequest,
             wsv1.UpdateScheduleResponse,
         )
-        self.update_workflow = client._new_call(
-            "update_workflow",
-            wsv1.UpdateWorkflowRequest,
-            wsv1.UpdateWorkflowResponse,
-        )
-        self.update_worker_build_id_ordering = client._new_call(
-            "update_worker_build_id_ordering",
-            wsv1.UpdateWorkerBuildIdOrderingRequest,
-            wsv1.UpdateWorkerBuildIdOrderingResponse,
+        self.update_workflow_execution = client._new_call(
+            "update_workflow_execution",
+            wsv1.UpdateWorkflowExecutionRequest,
+            wsv1.UpdateWorkflowExecutionResponse,
+        )
+        self.update_worker_build_id_compatibility = client._new_call(
+            "update_worker_build_id_compatibility",
+            wsv1.UpdateWorkerBuildIdCompatibilityRequest,
+            wsv1.UpdateWorkerBuildIdCompatibilityResponse,
         )
 
 
 class OperatorService:
     """Client to the Temporal server's operator service."""
 
     def __init__(self, client: ServiceClient) -> None:
```

### Comparing `temporalio-1.1.0/temporalio/testing/_activity.py` & `temporalio-1.2.0/temporalio/testing/_activity.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/testing/_workflow.py` & `temporalio-1.2.0/temporalio/testing/_workflow.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/types.py` & `temporalio-1.2.0/temporalio/types.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/__init__.py` & `temporalio-1.2.0/temporalio/worker/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -15,29 +15,36 @@
     StartActivityInput,
     StartChildWorkflowInput,
     StartLocalActivityInput,
     WorkflowInboundInterceptor,
     WorkflowInterceptorClassInput,
     WorkflowOutboundInterceptor,
 )
-from ._replayer import Replayer, ReplayerConfig
+from ._replayer import (
+    Replayer,
+    ReplayerConfig,
+    WorkflowReplayResult,
+    WorkflowReplayResults,
+)
 from ._worker import Worker, WorkerConfig
 from ._workflow_instance import (
     UnsandboxedWorkflowRunner,
     WorkflowInstance,
     WorkflowInstanceDetails,
     WorkflowRunner,
 )
 
 __all__ = [
     # Primary types
     "Worker",
     "WorkerConfig",
     "Replayer",
     "ReplayerConfig",
+    "WorkflowReplayResult",
+    "WorkflowReplayResults",
     # Interceptor base classes
     "Interceptor",
     "ActivityInboundInterceptor",
     "ActivityOutboundInterceptor",
     "WorkflowInboundInterceptor",
     "WorkflowOutboundInterceptor",
     # Interceptor input
```

### Comparing `temporalio-1.1.0/temporalio/worker/_activity.py` & `temporalio-1.2.0/temporalio/worker/_activity.py`

 * *Files 4% similar despite different names*

```diff
@@ -167,52 +167,31 @@
             except temporalio.bridge.worker.PollShutdownError:
                 exception_task.cancel()
                 return
             except Exception as err:
                 exception_task.cancel()
                 raise RuntimeError("Activity worker failed") from err
 
-    async def shutdown(self, after_graceful_timeout: timedelta) -> None:
-        # Set event that we're shutting down (updates all activity tasks)
+    def notify_shutdown(self) -> None:
         if self._worker_shutdown_event:
             self._worker_shutdown_event.set()
-        # Collect all still running activity tasks or exit if none
-        activity_tasks = [
-            activity.task
-            for activity in self._running_activities.values()
-            if activity.task
-        ]
-        if not activity_tasks:
-            return
-        # Wait for any still running after graceful timeout and exit if none
-        _, still_running = await asyncio.wait(
-            activity_tasks, timeout=after_graceful_timeout.total_seconds()
-        )
-        if not still_running:
-            return
-        # Cancel all still running
-        if len(still_running) == 1:
-            logger.info(f"Cancelling 1 activity that is still running")
-        else:
-            logger.info(
-                f"Cancelling {len(still_running)} activities that are still running"
-            )
-        for task in still_running:
-            # We have to find the running activity that's associated with
-            # the task so that we can cancel through that. It's ok if the
-            # activity is already gone.
-            for activity in self._running_activities.values():
-                if activity.info and activity.task is task:
-                    logger.info(
-                        f"Cancelling still-running activity: {activity.info._logger_details()}"
-                    )
-                    activity.cancel()
-                    break
-        # Now we have to wait on them to complete
-        await asyncio.wait(still_running)
+
+    # Only call this if run() raised an error
+    async def drain_poll_queue(self) -> None:
+        while True:
+            try:
+                # Just take all tasks and say we can't handle them
+                task = await self._bridge_worker().poll_activity_task()
+                completion = temporalio.bridge.proto.ActivityTaskCompletion(
+                    task_token=task.task_token
+                )
+                completion.result.failed.failure.message = "Worker shutting down"
+                await self._bridge_worker().complete_activity_task(completion)
+            except temporalio.bridge.worker.PollShutdownError:
+                return
 
     def _cancel(
         self, task_token: bytes, cancel: temporalio.bridge.proto.activity_task.Cancel
     ) -> None:
         activity = self._running_activities.get(task_token)
         if not activity:
             warnings.warn(f"Cannot find activity to cancel for token {task_token!r}")
@@ -479,29 +458,14 @@
                         temporalio.exceptions.CancelledError("Cancelled"),
                         completion.result.cancelled.failure,
                     )
                 else:
                     temporalio.activity.logger.warning(
                         "Completing activity as failed", exc_info=True
                     )
-                    # In some cases, like worker shutdown of an sync activity,
-                    # this results in a CancelledError, but the server will fail
-                    # if you send a cancelled error outside of a requested
-                    # cancellation. So we wrap as a retryable application error.
-                    if isinstance(
-                        err,
-                        (asyncio.CancelledError, temporalio.exceptions.CancelledError),
-                    ):
-                        new_err = temporalio.exceptions.ApplicationError(
-                            "Cancelled without request, possibly due to worker shutdown",
-                            type="CancelledError",
-                        )
-                        new_err.__traceback__ = err.__traceback__
-                        new_err.__cause__ = err.__cause__
-                        err = new_err
                     await self._data_converter.encode_failure(
                         err, completion.result.failed.failure
                     )
 
                     # For broken executors, we have to fail the entire worker
                     if isinstance(err, concurrent.futures.BrokenExecutor):
                         self._fail_worker_exception_queue.put_nowait(err)
```

### Comparing `temporalio-1.1.0/temporalio/worker/_interceptor.py` & `temporalio-1.2.0/temporalio/worker/_interceptor.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/_replayer.py` & `temporalio-1.2.0/temporalio/worker/_replayer.py`

 * *Files 0% similar despite different names*

```diff
@@ -171,14 +171,15 @@
                 max_concurrent_activity_task_polls=1,
                 no_remote_activities=True,
                 sticky_queue_schedule_to_start_timeout_millis=1000,
                 max_heartbeat_throttle_interval_millis=1000,
                 default_heartbeat_throttle_interval_millis=1000,
                 max_activities_per_second=None,
                 max_task_queue_activities_per_second=None,
+                graceful_shutdown_period_millis=0,
             ),
         )
 
         try:
             last_replay_failure: Optional[Exception]
             last_replay_complete = asyncio.Event()
 
@@ -269,16 +270,17 @@
             # If the workflow worker task is not done, wait for it
             try:
                 if not workflow_worker_task.done():
                     await workflow_worker_task
             except Exception:
                 logger.warning("Failed to shutdown worker", exc_info=True)
             finally:
-                # We must finalize shutdown here
+                # We must shutdown here
                 try:
+                    bridge_worker.initiate_shutdown()
                     await bridge_worker.finalize_shutdown()
                 except Exception:
                     logger.warning("Failed to finalize shutdown", exc_info=True)
 
 
 class ReplayerConfig(TypedDict, total=False):
     """TypedDict of config originally passed to :py:class:`Replayer`."""
```

### Comparing `temporalio-1.1.0/temporalio/worker/_worker.py` & `temporalio-1.2.0/temporalio/worker/_worker.py`

 * *Files 2% similar despite different names*

```diff
@@ -302,26 +302,32 @@
                 max_cached_workflows=max_cached_workflows,
                 max_outstanding_workflow_tasks=max_concurrent_workflow_tasks,
                 max_outstanding_activities=max_concurrent_activities,
                 max_outstanding_local_activities=max_concurrent_local_activities,
                 max_concurrent_workflow_task_polls=max_concurrent_workflow_task_polls,
                 nonsticky_to_sticky_poll_ratio=nonsticky_to_sticky_poll_ratio,
                 max_concurrent_activity_task_polls=max_concurrent_activity_task_polls,
-                no_remote_activities=no_remote_activities,
+                # We have to disable remote activities if a user asks _or_ if we
+                # are not running an activity worker at all. Otherwise shutdown
+                # will not proceed properly.
+                no_remote_activities=no_remote_activities or not activities,
                 sticky_queue_schedule_to_start_timeout_millis=int(
                     1000 * sticky_queue_schedule_to_start_timeout.total_seconds()
                 ),
                 max_heartbeat_throttle_interval_millis=int(
                     1000 * max_heartbeat_throttle_interval.total_seconds()
                 ),
                 default_heartbeat_throttle_interval_millis=int(
                     1000 * default_heartbeat_throttle_interval.total_seconds()
                 ),
                 max_activities_per_second=max_activities_per_second,
                 max_task_queue_activities_per_second=max_task_queue_activities_per_second,
+                graceful_shutdown_period_millis=int(
+                    1000 * graceful_shutdown_timeout.total_seconds()
+                ),
             ),
         )
 
     def config(self) -> WorkerConfig:
         """Config, as a dictionary, used to create this worker.
 
         Returns:
@@ -415,31 +421,44 @@
 
         # Cancel the shutdown task (safe if already done)
         tasks[0].cancel()
         graceful_timeout = self._config["graceful_shutdown_timeout"]
         logger.info(
             f"Beginning worker shutdown, will wait {graceful_timeout} before cancelling activities"
         )
-        # Start shutdown of the bridge
-        bridge_shutdown_task = asyncio.create_task(self._bridge_worker.shutdown())
+
+        # Initiate core worker shutdown
+        self._bridge_worker.initiate_shutdown()
+
+        # If any worker task had an exception, replace that task with a queue
+        # drain (task at index 1 can be activity or workflow worker, task at
+        # index 2 must be workflow worker if present)
+        if tasks[1].done() and tasks[1].exception():
+            if self._activity_worker:
+                tasks[1] = asyncio.create_task(self._activity_worker.drain_poll_queue())
+            else:
+                assert self._workflow_worker
+                tasks[1] = asyncio.create_task(self._workflow_worker.drain_poll_queue())
+        if len(tasks) > 2 and tasks[2].done() and tasks[2].exception():
+            assert self._workflow_worker
+            tasks[2] = asyncio.create_task(self._workflow_worker.drain_poll_queue())
+
+        # Set worker-shutdown event
+        if self._activity_worker:
+            self._activity_worker.notify_shutdown()
 
         # Wait for all tasks to complete (i.e. for poller loops to stop)
         await asyncio.wait(tasks)
         # Sometimes both workers throw an exception and since we only take the
         # first, Python may complain with "Task exception was never retrieved"
         # if we don't get the others. Therefore we call cancel on each task
         # which suppresses this.
         for task in tasks:
             task.cancel()
 
-        # Shutdown the activity worker (there is no workflow worker shutdown)
-        if self._activity_worker:
-            await self._activity_worker.shutdown(graceful_timeout)
-        # Wait for the bridge to report everything is completed
-        await bridge_shutdown_task
         # Do final shutdown
         try:
             await self._bridge_worker.finalize_shutdown()
         except:
             # Ignore errors here that can arise in some tests where the bridge
             # worker still has a reference
             pass
```

### Comparing `temporalio-1.1.0/temporalio/worker/_workflow.py` & `temporalio-1.2.0/temporalio/worker/_workflow.py`

 * *Files 2% similar despite different names*

```diff
@@ -140,14 +140,28 @@
             # Shutdown the thread pool executor if we created it
             if not self._workflow_task_executor_user_provided:
                 self._workflow_task_executor.shutdown()
 
         if self._throw_after_activation:
             raise self._throw_after_activation
 
+    # Only call this if run() raised an error
+    async def drain_poll_queue(self) -> None:
+        while True:
+            try:
+                # Just take all tasks and say we can't handle them
+                act = await self._bridge_worker().poll_workflow_activation()
+                completion = temporalio.bridge.proto.workflow_completion.WorkflowActivationCompletion(
+                    run_id=act.run_id
+                )
+                completion.failed.failure.message = "Worker shutting down"
+                await self._bridge_worker().complete_workflow_activation(completion)
+            except temporalio.bridge.worker.PollShutdownError:
+                return
+
     async def _handle_activation(
         self, act: temporalio.bridge.proto.workflow_activation.WorkflowActivation
     ) -> None:
         global LOG_PROTOS
 
         # Build default success completion (e.g. remove-job-only activations)
         completion = (
@@ -259,15 +273,15 @@
             # entire worker
             if self._on_eviction_hook is not None:
                 try:
                     self._on_eviction_hook(act.run_id, remove_job.remove_from_cache)
                 except Exception as e:
                     self._throw_after_activation = e
                     logger.debug("Shutting down worker on eviction")
-                    asyncio.create_task(self._bridge_worker().shutdown())
+                    self._bridge_worker().initiate_shutdown()
 
     def _create_workflow_instance(
         self, act: temporalio.bridge.proto.workflow_activation.WorkflowActivation
     ) -> WorkflowInstance:
         # First find the start workflow job
         start_job = next((j for j in act.jobs if j.HasField("start_workflow")), None)
         if not start_job:
```

### Comparing `temporalio-1.1.0/temporalio/worker/_workflow_instance.py` & `temporalio-1.2.0/temporalio/worker/_workflow_instance.py`

 * *Ordering differences only*

 * *Files 0% similar despite different names*

```diff
@@ -796,22 +796,22 @@
         else:
             self._signals.pop(name, None)
 
     def workflow_start_activity(
         self,
         activity: Any,
         *args: Any,
-        activity_id: Optional[str],
         task_queue: Optional[str],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         heartbeat_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cancellation_type: temporalio.workflow.ActivityCancellationType,
+        activity_id: Optional[str],
     ) -> temporalio.workflow.ActivityHandle[Any]:
         # Get activity definition if it's callable
         name: str
         arg_types: Optional[List[Type]] = None
         ret_type: Optional[Type] = None
         if isinstance(activity, str):
             name = activity
@@ -895,21 +895,21 @@
             )
         )
 
     def workflow_start_local_activity(
         self,
         activity: Any,
         *args: Any,
-        activity_id: Optional[str],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         local_retry_threshold: Optional[timedelta],
         cancellation_type: temporalio.workflow.ActivityCancellationType,
+        activity_id: Optional[str],
     ) -> temporalio.workflow.ActivityHandle[Any]:
         # Get activity definition if it's callable
         name: str
         arg_types: Optional[List[Type]] = None
         ret_type: Optional[Type] = None
         if isinstance(activity, str):
             name = activity
```

### Comparing `temporalio-1.1.0/temporalio/worker/workflow_sandbox/__init__.py` & `temporalio-1.2.0/temporalio/worker/workflow_sandbox/__init__.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/workflow_sandbox/_importer.py` & `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_importer.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/workflow_sandbox/_in_sandbox.py` & `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_in_sandbox.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/workflow_sandbox/_restrictions.py` & `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_restrictions.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/worker/workflow_sandbox/_runner.py` & `temporalio-1.2.0/temporalio/worker/workflow_sandbox/_runner.py`

 * *Files identical despite different names*

### Comparing `temporalio-1.1.0/temporalio/workflow.py` & `temporalio-1.2.0/temporalio/workflow.py`

 * *Files 1% similar despite different names*

```diff
@@ -441,22 +441,22 @@
         ...
 
     @abstractmethod
     def workflow_start_activity(
         self,
         activity: Any,
         *args: Any,
-        activity_id: Optional[str],
         task_queue: Optional[str],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         heartbeat_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         cancellation_type: ActivityCancellationType,
+        activity_id: Optional[str],
     ) -> ActivityHandle[Any]:
         ...
 
     @abstractmethod
     async def workflow_start_child_workflow(
         self,
         workflow: Any,
@@ -477,21 +477,21 @@
         ...
 
     @abstractmethod
     def workflow_start_local_activity(
         self,
         activity: Any,
         *args: Any,
-        activity_id: Optional[str],
         schedule_to_close_timeout: Optional[timedelta],
         schedule_to_start_timeout: Optional[timedelta],
         start_to_close_timeout: Optional[timedelta],
         retry_policy: Optional[temporalio.common.RetryPolicy],
         local_retry_threshold: Optional[timedelta],
         cancellation_type: ActivityCancellationType,
+        activity_id: Optional[str],
     ) -> ActivityHandle[Any]:
         ...
 
     @abstractmethod
     def workflow_time_ns(self) -> int:
         ...
 
@@ -1137,173 +1137,172 @@
 
 
 class ActivityConfig(TypedDict, total=False):
     """TypedDict of config that can be used for :py:func:`start_activity` and
     :py:func:`execute_activity`.
     """
 
-    activity_id: Optional[str]
     task_queue: Optional[str]
     schedule_to_close_timeout: Optional[timedelta]
     schedule_to_start_timeout: Optional[timedelta]
     start_to_close_timeout: Optional[timedelta]
     heartbeat_timeout: Optional[timedelta]
     retry_policy: Optional[temporalio.common.RetryPolicy]
     cancellation_type: ActivityCancellationType
+    activity_id: Optional[str]
 
 
 # Overload for async no-param activity
 @overload
 def start_activity(
     activity: CallableAsyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity(
     activity: CallableSyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity(
     activity: CallableAsyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity(
     activity: CallableSyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity(
     activity: Callable[..., Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity(
     activity: Callable[..., ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for string-name activity
 @overload
 def start_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     ...
 
 
 def start_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity and return its handle.
 
     At least one of ``schedule_to_close_timeout`` or ``start_to_close_timeout``
     must be present.
 
     Args:
         activity: Activity name or function reference.
         arg: Single argument to the activity.
         args: Multiple arguments to the activity. Cannot be set if arg is.
-        activity_id: Optional unique identifier for the activity.
         task_queue: Task queue to run the activity on. Defaults to the current
             workflow's task queue.
         schedule_to_close_timeout: Max amount of time the activity can take from
             first being scheduled to being completed before it times out. This
             is inclusive of all retries.
         schedule_to_start_timeout: Max amount of time the activity can take to
             be started from first being scheduled.
@@ -1312,771 +1311,774 @@
         heartbeat_timeout: How frequently an activity must invoke heartbeat
             while running before it is considered timed out.
         retry_policy: How an activity is retried on failure. If unset, a
             server-defined default is used. Set maximum attempts to 1 to disable
             retries.
         cancellation_type: How the activity is treated when it is cancelled from
             the workflow.
+        activity_id: Optional unique identifier for the activity. This is an
+            advanced setting that should not be set unless users are sure they
+            need to. Contact Temporal before setting this value.
 
     Returns:
         An activity handle to the activity which is an async task.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity(
     activity: CallableAsyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity(
     activity: CallableSyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity(
     activity: CallableAsyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity(
     activity: CallableSyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity(
     activity: Callable[..., Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity(
     activity: Callable[..., ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for string-name activity
 @overload
 async def execute_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     ...
 
 
 async def execute_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start an activity and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity`.
     """
     # We call the runtime directly instead of top-level start_activity to ensure
     # we don't miss new parameters
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity_class(
     activity: Type[CallableSyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity_class(
     activity: Type[CallableAsyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity_class(
     activity: Type[CallableSyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity_class(
     activity: Type[Callable[..., Awaitable[ReturnType]]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity_class(
     activity: Type[Callable[..., ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity from a callable class.
 
     See :py:meth:`start_activity` for parameter and return details.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity_class(
     activity: Type[CallableSyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity_class(
     activity: Type[CallableAsyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity_class(
     activity: Type[CallableSyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity_class(
     activity: Type[Callable[..., Awaitable[ReturnType]]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity_class(
     activity: Type[Callable[..., ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start an activity from a callable class and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity_class`.
     """
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_activity_method(
     activity: MethodSyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_activity_method(
     activity: MethodAsyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_activity_method(
     activity: MethodSyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start an activity from a method.
 
     See :py:meth:`start_activity` for parameter and return details.
     """
     return _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_activity_method(
     activity: MethodSyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_activity_method(
     activity: MethodAsyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_activity_method(
     activity: MethodSyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     task_queue: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     heartbeat_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start an activity from a method and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_activity_method`.
     """
     # We call the runtime directly instead of top-level start_activity to ensure
     # we don't miss new parameters
     return await _Runtime.current().workflow_start_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         task_queue=task_queue,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         heartbeat_timeout=heartbeat_timeout,
         retry_policy=retry_policy,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 class LocalActivityConfig(TypedDict, total=False):
     """TypedDict of config that can be used for :py:func:`start_local_activity`
     and :py:func:`execute_local_activity`.
     """
 
-    activity_id: Optional[str]
     schedule_to_close_timeout: Optional[timedelta]
     schedule_to_start_timeout: Optional[timedelta]
     start_to_close_timeout: Optional[timedelta]
     retry_policy: Optional[temporalio.common.RetryPolicy]
     local_retry_threshold: Optional[timedelta]
     cancellation_type: ActivityCancellationType
+    activity_id: Optional[str]
 
 
 # Overload for async no-param activity
 @overload
 def start_local_activity(
     activity: CallableAsyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_local_activity(
@@ -2095,106 +2097,106 @@
 
 # Overload for async single-param activity
 @overload
 def start_local_activity(
     activity: CallableAsyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_local_activity(
     activity: CallableSyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_local_activity(
     activity: Callable[..., Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_local_activity(
     activity: Callable[..., ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for string-name activity
 @overload
 def start_local_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     ...
 
 
 def start_local_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start a local activity and return its handle.
 
     At least one of ``schedule_to_close_timeout`` or ``start_to_close_timeout``
     must be present.
 
     .. warning::
@@ -2213,717 +2215,720 @@
         start_to_close_timeout: Max amount of time a single activity run can
             take from when it starts to when it completes. This is per retry.
         retry_policy: How an activity is retried on failure. If unset, an
             SDK-defined default is used. Set maximum attempts to 1 to disable
             retries.
         cancellation_type: How the activity is treated when it is cancelled from
             the workflow.
+        activity_id: Optional unique identifier for the activity. This is an
+            advanced setting that should not be set unless users are sure they
+            need to. Contact Temporal before setting this value.
 
     Returns:
         An activity handle to the activity which is an async task.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_local_activity(
     activity: CallableAsyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_local_activity(
     activity: CallableSyncNoParam[ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_local_activity(
     activity: CallableAsyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_local_activity(
     activity: CallableSyncSingleParam[ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_local_activity(
     activity: Callable[..., Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_local_activity(
     activity: Callable[..., ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for string-name activity
 @overload
 async def execute_local_activity(
     activity: str,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     ...
 
 
 async def execute_local_activity(
     activity: Any,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start a local activity and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_local_activity`.
 
     .. warning::
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_local_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_local_activity_class(
     activity: Type[CallableSyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_local_activity_class(
     activity: Type[CallableAsyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_local_activity_class(
     activity: Type[CallableSyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_local_activity_class(
     activity: Type[Callable[..., Awaitable[ReturnType]]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_local_activity_class(
     activity: Type[Callable[..., ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_local_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start a local activity from a callable class.
 
     See :py:meth:`start_local_activity` for parameter and return details.
 
     .. warning::
         Local activities are currently experimental.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[CallableAsyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[CallableSyncNoParam[ReturnType]],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[CallableAsyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[CallableSyncSingleParam[ParamType, ReturnType]],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[Callable[..., Awaitable[ReturnType]]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_local_activity_class(
     activity: Type[Callable[..., ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_local_activity_class(
     activity: Type[Callable],
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start a local activity from a callable class and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_local_activity_class`.
 
     .. warning::
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 def start_local_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 def start_local_activity_method(
     activity: MethodSyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async single-param activity
 @overload
 def start_local_activity_method(
     activity: MethodAsyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 def start_local_activity_method(
     activity: MethodSyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 def start_local_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 def start_local_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[ReturnType]:
     ...
 
 
 def start_local_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ActivityHandle[Any]:
     """Start a local activity from a method.
 
     See :py:meth:`start_local_activity` for parameter and return details.
 
     .. warning::
         Local activities are currently experimental.
     """
     return _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 # Overload for async no-param activity
 @overload
 async def execute_local_activity_method(
     activity: MethodAsyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync no-param activity
 @overload
 async def execute_local_activity_method(
     activity: MethodSyncNoParam[SelfType, ReturnType],
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async single-param activity
 @overload
 async def execute_local_activity_method(
     activity: MethodAsyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync single-param activity
 @overload
 async def execute_local_activity_method(
     activity: MethodSyncSingleParam[SelfType, ParamType, ReturnType],
     arg: ParamType,
     *,
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for async multi-param activity
 @overload
 async def execute_local_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], Awaitable[ReturnType]],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 # Overload for sync multi-param activity
 @overload
 async def execute_local_activity_method(
     activity: Callable[Concatenate[SelfType, MultiParamSpec], ReturnType],
     *,
     args: Sequence[Any],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> ReturnType:
     ...
 
 
 async def execute_local_activity_method(
     activity: Callable,
     arg: Any = temporalio.common._arg_unset,
     *,
     args: Sequence[Any] = [],
-    activity_id: Optional[str] = None,
     schedule_to_close_timeout: Optional[timedelta] = None,
     schedule_to_start_timeout: Optional[timedelta] = None,
     start_to_close_timeout: Optional[timedelta] = None,
     retry_policy: Optional[temporalio.common.RetryPolicy] = None,
     local_retry_threshold: Optional[timedelta] = None,
     cancellation_type: ActivityCancellationType = ActivityCancellationType.TRY_CANCEL,
+    activity_id: Optional[str] = None,
 ) -> Any:
     """Start a local activity from a method and wait for completion.
 
     This is a shortcut for ``await`` :py:meth:`start_local_activity_method`.
 
     .. warning::
         Local activities are currently experimental.
     """
     # We call the runtime directly instead of top-level start_local_activity to
     # ensure we don't miss new parameters
     return await _Runtime.current().workflow_start_local_activity(
         activity,
         *temporalio.common._arg_or_args(arg, args),
-        activity_id=activity_id,
         schedule_to_close_timeout=schedule_to_close_timeout,
         schedule_to_start_timeout=schedule_to_start_timeout,
         start_to_close_timeout=start_to_close_timeout,
         retry_policy=retry_policy,
         local_retry_threshold=local_retry_threshold,
         cancellation_type=cancellation_type,
+        activity_id=activity_id,
     )
 
 
 class ChildWorkflowHandle(_AsyncioTask[ReturnType], Generic[SelfType, ReturnType]):  # type: ignore[type-var]
     """Handle for interacting with a child workflow.
 
     This is created via :py:func:`start_child_workflow`.
```

### Comparing `temporalio-1.1.0/setup.py` & `temporalio-1.2.0/setup.py`

 * *Files 2% similar despite different names*

```diff
@@ -26,20 +26,24 @@
  'temporalio.api.history.v1',
  'temporalio.api.interaction',
  'temporalio.api.interaction.v1',
  'temporalio.api.namespace',
  'temporalio.api.namespace.v1',
  'temporalio.api.operatorservice',
  'temporalio.api.operatorservice.v1',
+ 'temporalio.api.protocol',
+ 'temporalio.api.protocol.v1',
  'temporalio.api.query',
  'temporalio.api.query.v1',
  'temporalio.api.replication',
  'temporalio.api.replication.v1',
  'temporalio.api.schedule',
  'temporalio.api.schedule.v1',
+ 'temporalio.api.sdk',
+ 'temporalio.api.sdk.v1',
  'temporalio.api.taskqueue',
  'temporalio.api.taskqueue.v1',
  'temporalio.api.testservice',
  'temporalio.api.testservice.v1',
  'temporalio.api.update',
  'temporalio.api.update.v1',
  'temporalio.api.version',
@@ -68,38 +72,41 @@
 
 package_data = \
 {'': ['*'],
  'temporalio.bridge': ['sdk-core/*',
                        'sdk-core/.buildkite/*',
                        'sdk-core/.buildkite/docker/*',
                        'sdk-core/.cargo/*',
+                       'sdk-core/.github/workflows/*',
                        'sdk-core/arch_docs/*',
                        'sdk-core/arch_docs/diagrams/*',
                        'sdk-core/client/*',
                        'sdk-core/client/src/*',
                        'sdk-core/client/src/workflow_handle/*',
                        'sdk-core/core-api/*',
                        'sdk-core/core-api/src/*',
                        'sdk-core/core/*',
                        'sdk-core/core/benches/*',
                        'sdk-core/core/src/*',
+                       'sdk-core/core/src/abstractions/*',
                        'sdk-core/core/src/core_tests/*',
                        'sdk-core/core/src/ephemeral_server/*',
                        'sdk-core/core/src/pollers/*',
                        'sdk-core/core/src/protosext/*',
                        'sdk-core/core/src/replay/*',
                        'sdk-core/core/src/telemetry/*',
                        'sdk-core/core/src/test_help/*',
                        'sdk-core/core/src/worker/*',
                        'sdk-core/core/src/worker/activities/*',
                        'sdk-core/core/src/worker/client/*',
                        'sdk-core/core/src/worker/workflow/*',
                        'sdk-core/core/src/worker/workflow/machines/*',
                        'sdk-core/core/src/worker/workflow/machines/workflow_machines/*',
                        'sdk-core/core/src/worker/workflow/managed_run/*',
+                       'sdk-core/core/src/worker/workflow/workflow_stream/*',
                        'sdk-core/etc/*',
                        'sdk-core/fsm/*',
                        'sdk-core/fsm/rustfsm_procmacro/*',
                        'sdk-core/fsm/rustfsm_procmacro/src/*',
                        'sdk-core/fsm/rustfsm_procmacro/tests/*',
                        'sdk-core/fsm/rustfsm_procmacro/tests/trybuild/*',
                        'sdk-core/fsm/rustfsm_trait/*',
@@ -116,21 +123,23 @@
                        'sdk-core/protos/api_upstream/temporal/api/command/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/common/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/enums/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/errordetails/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/failure/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/filter/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/history/v1/*',
-                       'sdk-core/protos/api_upstream/temporal/api/interaction/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/namespace/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/operatorservice/v1/*',
+                       'sdk-core/protos/api_upstream/temporal/api/protocol/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/query/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/replication/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/schedule/v1/*',
+                       'sdk-core/protos/api_upstream/temporal/api/sdk/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/taskqueue/v1/*',
+                       'sdk-core/protos/api_upstream/temporal/api/update/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/version/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/workflow/v1/*',
                        'sdk-core/protos/api_upstream/temporal/api/workflowservice/v1/*',
                        'sdk-core/protos/grpc/health/v1/*',
                        'sdk-core/protos/local/temporal/sdk/core/*',
                        'sdk-core/protos/local/temporal/sdk/core/activity_result/*',
                        'sdk-core/protos/local/temporal/sdk/core/activity_task/*',
@@ -162,17 +171,17 @@
 {':python_version < "3.11"': ['python-dateutil>=2.8.2,<3.0.0'],
  'grpc': ['grpcio>=1.48.0,<2.0.0'],
  'opentelemetry': ['opentelemetry-api>=1.11.1,<2.0.0',
                    'opentelemetry-sdk>=1.11.1,<2.0.0']}
 
 setup_kwargs = {
     'name': 'temporalio',
-    'version': '1.1.0',
+    'version': '1.2.0',
     'description': 'Temporal.io Python SDK',
-    'long_description': '![Temporal Python SDK](scripts/_img/banner.svg)\n\n[![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)\n\n[Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to\nexecute asynchronous, long-running business logic in a scalable and resilient way.\n\n"Temporal Python SDK" is the framework for authoring workflows and activities using the Python programming language.\n\nAlso see:\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) - Once you\'ve tried our [Quick Start](#quick-start), check out our guide on how to use Temporal in your Python applications, including information around Temporal core concepts.\n* [Python Code Samples](https://github.com/temporalio/samples-python)\n* [API Documentation](https://python.temporal.io) - Complete Temporal Python SDK Package reference.\n\nIn addition to features common across all Temporal SDKs, the Python SDK also has the following interesting features:\n\n**Type Safe**\n\nThis library uses the latest typing and MyPy support with generics to ensure all calls can be typed. For example,\nstarting a workflow with an `int` parameter when it accepts a `str` parameter would cause MyPy to fail.\n\n**Different Activity Types**\n\nThe activity worker has been developed to work with `async def`, threaded, and multiprocess activities. While\n`async def` activities are the easiest and recommended, care has been taken to make heartbeating and cancellation also\nwork across threads/processes.\n\n**Custom `asyncio` Event Loop**\n\nThe workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant\nevent loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with\n`asyncio` concepts.\n\n---\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Contents**\n\n- [Quick Start](#quick-start)\n  - [Installation](#installation)\n  - [Implementing a Workflow](#implementing-a-workflow)\n  - [Running a Workflow](#running-a-workflow)\n  - [Next Steps](#next-steps)\n- [Usage](#usage)\n    - [Client](#client)\n      - [Data Conversion](#data-conversion)\n        - [Custom Type Data Conversion](#custom-type-data-conversion)\n    - [Workers](#workers)\n    - [Workflows](#workflows)\n      - [Definition](#definition)\n      - [Running](#running)\n      - [Invoking Activities](#invoking-activities)\n      - [Invoking Child Workflows](#invoking-child-workflows)\n      - [Timers](#timers)\n      - [Conditions](#conditions)\n      - [Asyncio and Cancellation](#asyncio-and-cancellation)\n      - [Workflow Utilities](#workflow-utilities)\n      - [Exceptions](#exceptions)\n      - [External Workflows](#external-workflows)\n      - [Testing](#testing)\n        - [Automatic Time Skipping](#automatic-time-skipping)\n        - [Manual Time Skipping](#manual-time-skipping)\n        - [Mocking Activities](#mocking-activities)\n      - [Workflow Sandbox](#workflow-sandbox)\n        - [How the Sandbox Works](#how-the-sandbox-works)\n        - [Avoiding the Sandbox](#avoiding-the-sandbox)\n        - [Customizing the Sandbox](#customizing-the-sandbox)\n          - [Passthrough Modules](#passthrough-modules)\n          - [Invalid Module Members](#invalid-module-members)\n        - [Known Sandbox Issues](#known-sandbox-issues)\n          - [Global Import/Builtins](#global-importbuiltins)\n          - [Sandbox is not Secure](#sandbox-is-not-secure)\n          - [Sandbox Performance](#sandbox-performance)\n          - [Extending Restricted Classes](#extending-restricted-classes)\n          - [Certain Standard Library Calls on Restricted Objects](#certain-standard-library-calls-on-restricted-objects)\n          - [is_subclass of ABC-based Restricted Classes](#is_subclass-of-abc-based-restricted-classes)\n          - [Compiled Pydantic Sometimes Using Wrong Types](#compiled-pydantic-sometimes-using-wrong-types)\n    - [Activities](#activities)\n      - [Definition](#definition-1)\n      - [Types of Activities](#types-of-activities)\n        - [Asynchronous Activities](#asynchronous-activities)\n        - [Synchronous Activities](#synchronous-activities)\n          - [Synchronous Multithreaded Activities](#synchronous-multithreaded-activities)\n          - [Synchronous Multiprocess/Other Activities](#synchronous-multiprocessother-activities)\n      - [Activity Context](#activity-context)\n        - [Heartbeating and Cancellation](#heartbeating-and-cancellation)\n        - [Worker Shutdown](#worker-shutdown)\n      - [Testing](#testing-1)\n    - [Workflow Replay](#workflow-replay)\n    - [OpenTelemetry Support](#opentelemetry-support)\n    - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)\n- [Development](#development)\n    - [Building](#building)\n      - [Prepare](#prepare)\n      - [Build](#build)\n      - [Use](#use)\n    - [Local SDK development environment](#local-sdk-development-environment)\n      - [Testing](#testing-2)\n      - [Proto Generation and Testing](#proto-generation-and-testing)\n    - [Style](#style)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n# Quick Start\n\nWe will guide you through the Temporal basics to create a "hello, world!" script on your machine. It is not intended as one of the ways to use Temporal, but in reality it is very simplified and decidedly not "the only way" to use Temporal. For more information, check out the docs references in "Next Steps" below the quick start.\n\n## Installation\n\nInstall the `temporalio` package from [PyPI](https://pypi.org/project/temporalio).\n\nThese steps can be followed to use with a virtual environment and `pip`:\n\n* [Create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\n* Update `pip` - `python -m pip install -U pip`\n  * Needed because older versions of `pip` may not pick the right wheel\n* Install Temporal SDK - `python -m pip install temporalio`\n\nThe SDK is now ready for use. To build from source, see "Building" near the end of this documentation.\n\n**NOTE: This README is for the current branch and not necessarily what\'s released on `PyPI`.**\n\n## Implementing a Workflow\n\nCreate the following in `activities.py`:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nCreate the following in `workflows.py`:\n\n```python\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Import our activity, passing it through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .activities import say_hello\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return await workflow.execute_activity(\n            say_hello, name, schedule_to_close_timeout=timedelta(seconds=5)\n        )\n```\n\nCreate the following in `run_worker.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n# Import the activity and workflow from our other files\nfrom .activities import say_hello\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Run the worker\n    worker = Worker(client, task_queue="my-task-queue", workflows=[SayHello], activities=[say_hello])\n    await worker.run()\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have a [Temporal server running on localhost](https://docs.temporal.io/docs/server/quick-install/), this\nwill run the worker:\n\n    python run_worker.py\n\n## Running a Workflow\n\nCreate the following script at `run_workflow.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\n\n# Import the workflow from the previous code\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Execute a workflow\n    result = await client.execute_workflow(SayHello.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n\n    print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have `run_worker.py` running from before, this will run the workflow:\n\n    python run_workflow.py\n\nThe output will be:\n\n    Result: Hello, my-name!\n\n## Next Steps\n\nTemporal can be implemented in your code in many different ways, to suit your application\'s needs. The links below will\ngive you much more information about how Temporal works with Python:\n\n* [Code Samples](https://github.com/temporalio/samples-python) - If you want to start with some code, we have provided\n  some pre-built samples.\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) Our Python specific\n  Developer\'s Guide will give you much more information on how to build with Temporal in your Python applications than\n  our SDK README ever could (or should).\n* [API Documentation](https://python.temporal.io) - Full Temporal Python SDK package documentation.\n\n---\n\n# Usage\n\nFrom here, you will find reference documentation about specific pieces of the Temporal Python SDK that were built around Temporal concepts. \n*This section is not intended as a how-to guide* -- For more how-to oriented information, check out the links in the [Next Steps](#next-steps) section above.\n\n### Client\n\nA client can be created and used to start a workflow like so:\n\n```python\nfrom temporalio.client import Client\n\nasync def main():\n    # Create client connected to server at the given address and namespace\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Start a workflow\n    handle = await client.start_workflow(MyWorkflow.run, "some arg", id="my-workflow-id", task_queue="my-task-queue")\n\n    # Wait for result\n    result = await handle.result()\n    print(f"Result: {result}")\n```\n\nSome things to note about the above code:\n\n* A `Client` does not have an explicit "close"\n* To enable TLS, the `tls` argument to `connect` can be set to `True` or a `TLSConfig` object\n* A single positional argument can be passed to `start_workflow`. If there are multiple arguments, only the\n  non-type-safe form of `start_workflow` can be used (i.e. the one accepting a string workflow name) and it must be in\n  the `args` keyword argument.\n* The `handle` represents the workflow that was started and can be used for more than just getting the result\n* Since we are just getting the handle and waiting on the result, we could have called `client.execute_workflow` which\n  does the same thing\n* Clients can have many more options not shown here (e.g. data converters and interceptors)\n* A string can be used instead of the method reference to call a workflow by name (e.g. if defined in another language)\n\nClients also provide a shallow copy of their config for use in making slightly different clients backed by the same\nconnection. For instance, given the `client` above, this is how to have a client in another namespace:\n\n```python\nconfig = client.config()\nconfig["namespace"] = "my-other-namespace"\nother_ns_client = Client(**config)\n```\n\n#### Data Conversion\n\nData converters are used to convert raw Temporal payloads to/from actual Python types. A custom data converter of type\n`temporalio.converter.DataConverter` can be set via the `data_converter` client parameter. Data converters are a\ncombination of payload converters, payload codecs, and failure converters. Payload converters convert Python values\nto/from serialized bytes. Payload codecs convert bytes to bytes (e.g. for compression or encryption). Failure converters\nconvert exceptions to/from serialized failures.\n\nThe default data converter supports converting multiple types including:\n\n* `None`\n* `bytes`\n* `google.protobuf.message.Message` - As JSON when encoding, but has ability to decode binary proto from other languages\n* Anything that can be converted to JSON including:\n  * Anything that [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) supports natively\n  * [dataclasses](https://docs.python.org/3/library/dataclasses.html)\n  * Iterables including ones JSON dump may not support by default, e.g. `set`\n  * Any class with a `dict()` method and a static `parse_obj()` method, e.g.\n    [Pydantic models](https://pydantic-docs.helpmanual.io/usage/models)\n    * The default data converter is deprecated for Pydantic models and will warn if used since not all fields work.\n      See [this sample](https://github.com/temporalio/samples-python/tree/main/pydantic_converter) for the recommended\n      approach.\n  * [IntEnum, StrEnum](https://docs.python.org/3/library/enum.html) based enumerates\n  * [UUID](https://docs.python.org/3/library/uuid.html)\n\nThis notably doesn\'t include any `date`, `time`, or `datetime` objects as they may not work across SDKs.\n\nUsers are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be\neasily added without breaking compatibility.\n\nClasses with generics may not have the generics properly resolved. The current implementation, similar to Pydantic, does\nnot have generic type resolution. Users should use concrete types.\n\n##### Custom Type Data Conversion\n\nFor converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has\nbeen taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,\netc in addition to the regular JSON values mentioned before.\n\nData converters contain a reference to a payload converter class that is used to convert to/from payloads/values. This\nis a class and not an instance because it is instantiated on every workflow run inside the sandbox. The payload\nconverter is usually a `CompositePayloadConverter` which contains a multiple `EncodingPayloadConverter`s it uses to try\nto serialize/deserialize payloads. Upon serialization, each `EncodingPayloadConverter` is tried until one succeeds. The\n`EncodingPayloadConverter` provides an "encoding" string serialized onto the payload so that, upon deserialization, the\nspecific `EncodingPayloadConverter` for the given "encoding" is used.\n\nThe default data converter uses the `DefaultPayloadConverter` which is simply a `CompositePayloadConverter` with a known\nset of default `EncodingPayloadConverter`s. To implement a custom encoding for a custom type, a new\n`EncodingPayloadConverter` can be created for the new type. For example, to support `IPv4Address` types:\n\n```python\nclass IPv4AddressEncodingPayloadConverter(EncodingPayloadConverter):\n    @property\n    def encoding(self) -> str:\n        return "text/ipv4-address"\n\n    def to_payload(self, value: Any) -> Optional[Payload]:\n        if isinstance(value, ipaddress.IPv4Address):\n            return Payload(\n                metadata={"encoding": self.encoding.encode()},\n                data=str(value).encode(),\n            )\n        else:\n            return None\n\n    def from_payload(self, payload: Payload, type_hint: Optional[Type] = None) -> Any:\n        assert not type_hint or type_hint is ipaddress.IPv4Address\n        return ipaddress.IPv4Address(payload.data.decode())\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Just add ours as first before the defaults\n        super().__init__(\n            IPv4AddressEncodingPayloadConverter(),\n            *DefaultPayloadConverter.default_encoding_payload_converters,\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nImports are left off for brevity.\n\nThis is good for many custom types. However, sometimes you want to override the behavior of the just the existing JSON\nencoding payload converter to support a new type. It is already the last encoding data converter in the list, so it\'s\nthe fall-through behavior for any otherwise unknown type. Customizing the existing JSON converter has the benefit of\nmaking the type work in lists, unions, etc.\n\nThe `JSONPlainPayloadConverter` uses the Python [json](https://docs.python.org/3/library/json.html) library with an\nadvanced JSON encoder by default and a custom value conversion method to turn `json.load`ed values to their type hints.\nThe conversion can be customized for serialization with a custom `json.JSONEncoder` and deserialization with a custom\n`JSONTypeConverter`. For example, to support `IPv4Address` types in existing JSON conversion:\n\n```python\nclass IPv4AddressJSONEncoder(AdvancedJSONEncoder):\n    def default(self, o: Any) -> Any:\n        if isinstance(o, ipaddress.IPv4Address):\n            return str(o)\n        return super().default(o)\nclass IPv4AddressJSONTypeConverter(JSONTypeConverter):\n    def to_typed_value(\n        self, hint: Type, value: Any\n    ) -> Union[Optional[Any], _JSONTypeConverterUnhandled]:\n        if issubclass(hint, ipaddress.IPv4Address):\n            return ipaddress.IPv4Address(value)\n        return JSONTypeConverter.Unhandled\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Replace default JSON plain with our own that has our encoder and type\n        # converter\n        json_converter = JSONPlainPayloadConverter(\n            encoder=IPv4AddressJSONEncoder,\n            custom_type_converters=[IPv4AddressJSONTypeConverter()],\n        )\n        super().__init__(\n            *[\n                c if not isinstance(c, JSONPlainPayloadConverter) else json_converter\n                for c in DefaultPayloadConverter.default_encoding_payload_converters\n            ]\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nNow `IPv4Address` can be used in type hints including collections, optionals, etc.\n\n### Workers\n\nWorkers host workflows and/or activities. Here\'s how to run a worker:\n\n```python\nimport asyncio\nimport logging\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n# Import your own workflows and activities\nfrom my_workflow_package import MyWorkflow, my_activity\n\nasync def run_worker(stop_event: asyncio.Event):\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Run the worker until the event is set\n    worker = Worker(client, task_queue="my-task-queue", workflows=[MyWorkflow], activities=[my_activity])\n    async with worker:\n        await stop_event.wait()\n```\n\nSome things to note about the above code:\n\n* This creates/uses the same client that is used for starting workflows\n* While this example accepts a stop event and uses `async with`, `run()` and `shutdown()` may be used instead\n* Workers can have many more options not shown here (e.g. data converters and interceptors)\n\n### Workflows\n\n#### Definition\n\nWorkflows are defined as classes decorated with `@workflow.defn`. The method invoked for the workflow is decorated with\n`@workflow.run`. Methods for signals and queries are decorated with `@workflow.signal` and `@workflow.query`\nrespectively. Here\'s an example of a workflow:\n\n```python\nimport asyncio\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Pass the activities through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .my_activities import GreetingInfo, create_greeting_activity\n\n@workflow.defn\nclass GreetingWorkflow:\n    def __init__() -> None:\n        self._current_greeting = "<unset>"\n        self._greeting_info = GreetingInfo()\n        self._greeting_info_update = asyncio.Event()\n        self._complete = asyncio.Event()\n\n    @workflow.run\n    async def run(self, name: str) -> str:\n        self._greeting_info.name = name\n        while True:\n            # Store greeting\n            self._current_greeting = await workflow.execute_activity(\n                create_greeting_activity,\n                self._greeting_info,\n                start_to_close_timeout=timedelta(seconds=5),\n            )\n            workflow.logger.debug("Greeting set to %s", self._current_greeting)\n            \n            # Wait for salutation update or complete signal (this can be\n            # cancelled)\n            await asyncio.wait(\n                [\n                    asyncio.create_task(self._greeting_info_update.wait()),\n                    asyncio.create_task(self._complete.wait()),\n                ],\n                return_when=asyncio.FIRST_COMPLETED,\n            )\n            if self._complete.is_set():\n                return self._current_greeting\n            self._greeting_info_update.clear()\n\n    @workflow.signal\n    async def update_salutation(self, salutation: str) -> None:\n        self._greeting_info.salutation = salutation\n        self._greeting_info_update.set()\n\n    @workflow.signal\n    async def complete_with_greeting(self) -> None:\n        self._complete.set()\n\n    @workflow.query\n    async def current_greeting(self) -> str:\n        return self._current_greeting\n\n```\n\nThis assumes there\'s an activity in `my_activities.py` like:\n\n```python\nfrom dataclasses import dataclass\nfrom temporalio import workflow\n\n@dataclass\nclass GreetingInfo:\n    salutation: str = "Hello"\n    name: str = "<unknown>"\n\n@activity.defn\nasync def create_greeting_activity(info: GreetingInfo) -> str:\n    return f"{info.salutation}, {info.name}!"\n```\n\nSome things to note about the above workflow code:\n\n* Workflows run in a sandbox by default.\n  * Users are encouraged to define workflows in files with no side effects or other complicated code or unnecessary\n    imports to other third party libraries.\n  * Non-standard-library, non-`temporalio` imports should usually be "passed through" the sandbox. See the\n    [Workflow Sandbox](#workflow-sandbox) section for more details.\n* This workflow continually updates the queryable current greeting when signalled and can complete with the greeting on\n  a different signal\n* Workflows are always classes and must have a single `@workflow.run` which is an `async def` function\n* Workflow code must be deterministic. This means no threading, no randomness, no external calls to processes, no\n  network IO, and no global state mutation. All code must run in the implicit `asyncio` event loop and be deterministic.\n* `@activity.defn` is explained in a later section. For normal simple string concatenation, this would just be done in\n  the workflow. The activity is for demonstration purposes only.\n* `workflow.execute_activity(create_greeting_activity, ...` is actually a typed signature, and MyPy will fail if the\n  `self._greeting_info` parameter is not a `GreetingInfo`\n\nHere are the decorators that can be applied:\n\n* `@workflow.defn` - Defines a workflow class\n  * Must be defined on the class given to the worker (ignored if present on a base class)\n  * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name\n* `@workflow.run` - Defines the primary workflow run method\n  * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same\n    method of a base class)\n  * Exactly one method name must have this decorator, no more or less\n  * Must be defined on an `async def` method\n  * The method\'s arguments are the workflow\'s arguments\n  * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single\n    argument that is an object/dataclass of fields that can be added to as needed.\n* `@workflow.signal` - Defines a method as a signal\n  * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,\n    the override must also be decorated\n  * The method\'s arguments are the signal\'s arguments\n  * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name\n  * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have\n    `name` argument, and method parameters must be `self`, a string signal name, and a `*args` varargs param.\n  * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an\n    object/dataclass of fields that can be added to as needed.\n  * Return value is ignored\n* `@workflow.query` - Defines a method as a query\n  * All the same constraints as `@workflow.signal` but should return a value\n  * Temporal queries should never mutate anything in the workflow\n\n#### Running\n\nTo start a locally-defined workflow from a client, you can simply reference its method like so:\n\n```python\nfrom temporalio.client import Client\nfrom my_workflow_package import GreetingWorkflow\n\nasync def create_greeting(client: Client) -> str:\n    # Start the workflow\n    handle = await client.start_workflow(GreetingWorkflow.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n    # Change the salutation\n    await handle.signal(GreetingWorkflow.update_salutation, "Aloha")\n    # Tell it to complete\n    await handle.signal(GreetingWorkflow.complete_with_greeting)\n    # Wait and return result\n    return await handle.result()\n```\n\nSome things to note about the above code:\n\n* This uses the `GreetingWorkflow` from the previous section\n* The result of calling this function is `"Aloha, my name!"`\n* `id` and `task_queue` are required for running a workflow\n* `client.start_workflow` is typed, so MyPy would fail if `"my name"` were something besides a string\n* `handle.signal` is typed, so MyPy would fail if `"Aloha"` were something besides a string or if we provided a\n  parameter to the parameterless `complete_with_greeting`\n* `handle.result` is typed to the workflow itself, so MyPy would fail if we said this `create_greeting` returned\n  something besides a string\n\n#### Invoking Activities\n\n* Activities are started with non-async `workflow.start_activity()` which accepts either an activity function reference\n  or a string name.\n* A single argument to the activity is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute activity and must be supplied via the `args` keyword argument.\n* Activity options are set as keyword arguments after the activity arguments. At least one of `start_to_close_timeout`\n  or `schedule_to_close_timeout` must be provided.\n* The result is an activity handle which is an `asyncio.Task` and supports basic task features\n* An async `workflow.execute_activity()` helper is provided which takes the same arguments as\n  `workflow.start_activity()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n* Local activities work very similarly except the functions are `workflow.start_local_activity()` and\n  `workflow.execute_local_activity()`\n  * ⚠️Local activities are currently experimental\n* Activities can be methods of a class. Invokers should use `workflow.start_activity_method()`,\n  `workflow.execute_activity_method()`, `workflow.start_local_activity_method()`, and\n  `workflow.execute_local_activity_method()` instead.\n* Activities can callable classes (i.e. that define `__call__`). Invokers should use `workflow.start_activity_class()`,\n  `workflow.execute_activity_class()`, `workflow.start_local_activity_class()`, and\n  `workflow.execute_local_activity_class()` instead.\n\n#### Invoking Child Workflows\n\n* Child workflows are started with async `workflow.start_child_workflow()` which accepts either a workflow run method\n  reference or a string name. The arguments to the workflow are positional.\n* A single argument to the child workflow is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute child workflow and must be supplied via the `args` keyword argument.\n* Child workflow options are set as keyword arguments after the arguments. At least `id` must be provided.\n* The `await` of the start does not complete until the start has been accepted by the server\n* The result is a child workflow handle which is an `asyncio.Task` and supports basic task features. The handle also has\n  some child info and supports signalling the child workflow\n* An async `workflow.execute_child_workflow()` helper is provided which takes the same arguments as\n  `workflow.start_child_workflow()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n\n#### Timers\n\n* A timer is represented by normal `asyncio.sleep()`\n* Timers are also implicitly started on any `asyncio` calls with timeouts (e.g. `asyncio.wait_for`)\n* Timers are Temporal server timers, not local ones, so sub-second resolution rarely has value\n\n#### Conditions\n\n* `workflow.wait_condition` is an async function that doesn\'t return until a provided callback returns true\n* A `timeout` can optionally be provided which will throw a `asyncio.TimeoutError` if reached (internally backed by\n  `asyncio.wait_for` which uses a timer)\n\n#### Asyncio and Cancellation\n\nWorkflows are backed by a custom [asyncio](https://docs.python.org/3/library/asyncio.html) event loop. This means many\nof the common `asyncio` calls work as normal. Some asyncio features are disabled such as:\n\n* Thread related calls such as `to_thread()`, `run_coroutine_threadsafe()`, `loop.run_in_executor()`, etc\n* Calls that alter the event loop such as `loop.close()`, `loop.stop()`, `loop.run_forever()`,\n  `loop.set_task_factory()`, etc\n* Calls that use a specific time such as `loop.call_at()`\n* Calls that use anything external such as networking, subprocesses, disk IO, etc\n\nCancellation is done the same way as `asyncio`. Specifically, a task can be requested to be cancelled but does not\nnecessarily have to respect that cancellation immediately. This also means that `asyncio.shield()` can be used to\nprotect against cancellation. The following tasks, when cancelled, perform a Temporal cancellation:\n\n* Activities - when the task executing an activity is cancelled, a cancellation request is sent to the activity\n* Child workflows - when the task starting or executing a child workflow is cancelled, a cancellation request is sent to\n  cancel the child workflow\n* Timers - when the task executing a timer is cancelled (whether started via sleep or timeout), the timer is cancelled\n\nWhen the workflow itself is requested to cancel, `Task.cancel` is called on the main workflow task. Therefore,\n`asyncio.CancelledError` can be caught in order to handle the cancel gracefully.\n\nWorkflows follow `asyncio` cancellation rules exactly which can cause confusion among Python developers. Cancelling a\ntask doesn\'t always cancel the thing it created. For example, given\n`task = asyncio.create_task(workflow.start_child_workflow(...`, calling `task.cancel` does not cancel the child\nworkflow, it only cancels the starting of it, which has no effect if it has already started. However, cancelling the\nresult of `handle = await workflow.start_child_workflow(...` or\n`task = asyncio.create_task(workflow.execute_child_workflow(...` _does_ cancel the child workflow.\n\nAlso, due to Temporal rules, a cancellation request is a state not an event. Therefore, repeated cancellation requests\nare not delivered, only the first. If the workflow chooses swallow a cancellation, it cannot be requested again.\n\n#### Workflow Utilities\n\nWhile running in a workflow, in addition to features documented elsewhere, the following items are available from the\n`temporalio.workflow` package:\n\n* `continue_as_new()` - Async function to stop the workflow immediately and continue as new\n* `info()` - Returns information about the current workflow\n* `logger` - A logger for use in a workflow (properly skips logging on replay)\n* `now()` - Returns the "current time" from the workflow\'s perspective\n\n#### Exceptions\n\n* Workflows can raise exceptions to fail the workflow or the "workflow task" (i.e. suspend the workflow retrying).\n* Exceptions that are instances of `temporalio.exceptions.FailureError` will fail the workflow with that exception\n  * For failing the workflow explicitly with a user exception, use `temporalio.exceptions.ApplicationError`. This can\n    be marked non-retryable or include details as needed.\n  * Other exceptions that come from activity execution, child execution, cancellation, etc are already instances of\n    `FailureError` and will fail the workflow when uncaught.\n* All other exceptions fail the "workflow task" which means the workflow will continually retry until the workflow is\n  fixed. This is helpful for bad code or other non-predictable exceptions. To actually fail the workflow, use an\n  `ApplicationError` as mentioned above.\n\n#### External Workflows\n\n* `workflow.get_external_workflow_handle()` inside a workflow returns a handle to interact with another workflow\n* `workflow.get_external_workflow_handle_for()` can be used instead for a type safe handle\n* `await handle.signal()` can be called on the handle to signal the external workflow\n* `await handle.cancel()` can be called on the handle to send a cancel to the external workflow\n\n#### Testing\n\nWorkflow testing can be done in an integration-test fashion against a real server, however it is hard to simulate\ntimeouts and other long time-based code. Using the time-skipping workflow test environment can help there.\n\nThe time-skipping `temporalio.testing.WorkflowEnvironment` can be created via the static async `start_time_skipping()`.\nThis internally downloads the Temporal time-skipping test server to a temporary directory if it doesn\'t already exist,\nthen starts the test server which has special APIs for skipping time.\n\n##### Automatic Time Skipping\n\nAnytime a workflow result is waited on, the time-skipping server automatically advances to the next event it can. To\nmanually advance time before waiting on the result of a workflow, the `WorkflowEnvironment.sleep` method can be used.\n\nHere\'s a simple example of a workflow that sleeps for 24 hours:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass WaitADayWorkflow:\n    @workflow.run\n    async def run(self) -> str:\n        await asyncio.sleep(24 * 60 * 60)\n        return "all done"\n```\n\nAn integration test of this workflow would be way too slow. However the time-skipping server automatically skips to the\nnext event when we wait on the result. Here\'s a test for that workflow:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_wait_a_day_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[WaitADayWorkflow]):\n            assert "all done" == await env.client.execute_workflow(WaitADayWorkflow.run, id="wf1", task_queue="tq1")\n```\n\nThat test will run almost instantly. This is because by calling `execute_workflow` on our client, we have asked the\nenvironment to automatically skip time as much as it can (basically until the end of the workflow or until an activity\nis run).\n\nTo disable automatic time-skipping while waiting for a workflow result, run code inside a\n`with env.auto_time_skipping_disabled():` block.\n\n##### Manual Time Skipping\n\nUntil a workflow is waited on, all time skipping in the time-skipping environment is done manually via\n`WorkflowEnvironment.sleep`.\n\nHere\'s workflow that waits for a signal or times out:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass SignalWorkflow:\n    def __init__(self) -> None:\n        self.signal_received = False\n\n    @workflow.run\n    async def run(self) -> str:\n        # Wait for signal or timeout in 45 seconds\n        try:\n            await workflow.wait_condition(lambda: self.signal_received, timeout=45)\n            return "got signal"\n        except asyncio.TimeoutError:\n            return "got timeout"\n\n    @workflow.signal\n    def some_signal(self) -> None:\n        self.signal_received = True\n```\n\nTo test a normal signal, you might:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, send signal, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await handle.signal(SignalWorkflow.some_signal)\n            assert "got signal" == await handle.result()\n```\n\nBut how would you test the timeout part? Like so:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow_timeout():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, advance time past timeout, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await env.sleep(50)\n            assert "got timeout" == await handle.result()\n```\n\nAlso, the current time of the workflow environment can be obtained via the async `WorkflowEnvironment.get_current_time`\nmethod.\n\n##### Mocking Activities\n\nActivities are just functions decorated with `@activity.defn`. Simply write different ones and pass those to the worker\nto have different activities called during the test.\n\n#### Workflow Sandbox\n\nBy default workflows are run in a sandbox to help avoid non-deterministic code. If a call that is known to be\nnon-deterministic is performed, an exception will be thrown in the workflow which will "fail the task" which means the\nworkflow will not progress until fixed.\n\nThe sandbox is not foolproof and non-determinism can still occur. It is simply a best-effort way to catch bad code\nearly. Users are encouraged to define their workflows in files with no other side effects.\n\nThe sandbox offers a mechanism to pass through modules from outside the sandbox. By default this already includes all\nstandard library modules and Temporal modules. **For performance and behavior reasons, users are encouraged to pass\nthrough all third party modules whose calls will be deterministic.** This includes modules containing the activities to\nbe referenced in workflows. See "Passthrough Modules" below on how to do this.\n\nIf you are getting an error like:\n\n> temporalio.worker.workflow_sandbox._restrictions.RestrictedWorkflowAccessError: Cannot access\n> http.client.IncompleteRead.\\_\\_mro_entries\\_\\_ from inside a workflow. If this is code from a module not used in a\n> workflow or known to only be used deterministically from a workflow, mark the import as pass through.\n\nThen you are either using an invalid construct from the workflow, this is a known limitation of the sandbox, or most\ncommonly this is from a module that is safe to pass through (see "Passthrough Modules" section below).\n\n##### How the Sandbox Works\n\nThe sandbox is made up of two components that work closely together:\n\n* Global state isolation\n* Restrictions preventing known non-deterministic library calls\n\nGlobal state isolation is performed by using `exec`. Upon workflow start, the file that the workflow is defined in is\nimported into a new sandbox created for that workflow run. In order to keep the sandbox performant a known set of\n"passthrough modules" are passed through from outside of the sandbox when they are imported. These are expected to be\nside-effect free on import and have their non-deterministic aspects restricted. By default the entire Python standard\nlibrary, `temporalio`, and a couple of other modules are passed through from outside of the sandbox. To update this\nlist, see "Customizing the Sandbox".\n\nRestrictions preventing known non-deterministic library calls are achieved using proxy objects on modules wrapped around\nthe custom importer set in the sandbox. Many restrictions apply at workflow import time and workflow run time, while\nsome restrictions only apply at workflow run time. A default set of restrictions is included that prevents most\ndangerous standard library calls. However it is known in Python that some otherwise-non-deterministic invocations, like\nreading a file from disk via `open` or using `os.environ`, are done as part of importing modules. To customize what is\nand isn\'t restricted, see "Customizing the Sandbox".\n\n##### Avoiding the Sandbox\n\nThere are three increasingly-scoped ways to avoid the sandbox. Users are discouraged from avoiding the sandbox if\npossible.\n\nTo remove restrictions around a particular block of code, use `with temporalio.workflow.unsafe.sandbox_unrestricted():`.\nThe workflow will still be running in the sandbox, but no restrictions for invalid library calls will be applied.\n\nTo run an entire workflow outside of a sandbox, set `sandboxed=False` on the `@workflow.defn` decorator when defining\nit. This will run the entire workflow outside of the workflow which means it can share global state and other bad\nthings.\n\nTo disable the sandbox entirely for a worker, set the `Worker` init\'s `workflow_runner` keyword argument to \n`temporalio.worker.UnsandboxedWorkflowRunner()`. This value is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()` so by changing it to the unsandboxed runner, the sandbox\nwill not be used at all.\n\n##### Customizing the Sandbox\n\n⚠️ WARNING: APIs in the `temporalio.worker.workflow_sandbox` module are not yet considered stable and may change in\nfuture releases.\n\nWhen creating the `Worker`, the `workflow_runner` is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()`. The `SandboxedWorkflowRunner`\'s init accepts a\n`restrictions` keyword argument that is defaulted to `SandboxRestrictions.default`. The `SandboxRestrictions` dataclass\nis immutable and contains three fields that can be customized, but only two have notable value. See below.\n\n###### Passthrough Modules\n\nBy default the sandbox completely reloads non-standard-library and non-Temporal modules for every workflow run. To make\nthe sandbox quicker and use less memory when importing known-side-effect-free third party modules, they can be marked\nas passthrough modules.\n\n**For performance and behavior reasons, users are encouraged to pass through all third party modules whose calls will be\ndeterministic.**\n\nOne way to pass through a module is at import time in the workflow file using the `imports_passed_through` context\nmanager like so:\n\n```python\n# my_workflow_file.py\n\nfrom temporalio import workflow\n\nwith workflow.unsafe.imports_passed_through():\n    import pydantic\n\n@workflow.defn\nclass MyWorkflow:\n    ...\n```\n\nAlternatively, this can be done at worker creation time by customizing the runner\'s restrictions. For example:\n\n```python\nmy_worker = Worker(\n  ...,\n  workflow_runner=SandboxedWorkflowRunner(\n    restrictions=SandboxRestrictions.default.with_passthrough_modules("pydantic")\n  )\n)\n```\n\nIn both of these cases, now the `pydantic` module will be passed through from outside of the sandbox instead of\nbeing reloaded for every workflow run.\n\n###### Invalid Module Members\n\n`SandboxRestrictions.invalid_module_members` contains a root matcher that applies to all module members. This already\nhas a default set which includes things like `datetime.date.today()` which should never be called from a workflow. To\nremove this restriction:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default.with_child_unrestricted(\n      "datetime", "date", "today",\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nRestrictions can also be added by `|`\'ing together matchers, for example to restrict the `datetime.date` class from\nbeing used altogether:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default | SandboxMatcher(\n      children={"datetime": SandboxMatcher(use={"date"})},\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nSee the API for more details on exact fields and their meaning.\n\n##### Known Sandbox Issues\n\nBelow are known sandbox issues. As the sandbox is developed and matures, some may be resolved.\n\n###### Global Import/Builtins\n\nCurrently the sandbox references/alters the global `sys.modules` and `builtins` fields while running workflow code. In\norder to prevent affecting other sandboxed code, thread locals are leveraged to only intercept these values during the\nworkflow thread running. Therefore, technically if top-level import code starts a thread, it may lose sandbox\nprotection.\n\n###### Sandbox is not Secure\n\nThe sandbox is built to catch many non-deterministic and state sharing issues, but it is not secure. Some known bad\ncalls are intercepted, but for performance reasons, every single attribute get/set cannot be checked. Therefore a simple\ncall like `setattr(temporalio.common, "__my_key", "my value")` will leak across sandbox runs.\n\nThe sandbox is only a helper, it does not provide full protection.\n\n###### Sandbox Performance\n\nThe sandbox does not add significant CPU or memory overhead for workflows that are in files which only import standard\nlibrary modules. This is because they are passed through from outside of the sandbox. However, every\nnon-standard-library import that is performed at the top of the same file the workflow is in will add CPU overhead (the\nmodule is re-imported every workflow run) and memory overhead (each module independently cached as part of the workflow\nrun for isolation reasons). This becomes more apparent for large numbers of workflow runs.\n\nTo mitigate this, users should:\n\n* Define workflows in files that have as few non-standard-library imports as possible\n* Alter the max workflow cache and/or max concurrent workflows settings if memory grows too large\n* Set third-party libraries as passthrough modules if they are known to be side-effect free\n\n###### Extending Restricted Classes\n\nExtending a restricted class causes Python to instantiate the restricted metaclass which is unsupported. Therefore if\nyou attempt to use a class in the sandbox that extends a restricted class, it will fail. For example, if you have a\n`class MyZipFile(zipfile.ZipFile)` and try to use that class inside a workflow, it will fail.\n\nClasses used inside the workflow should not extend restricted classes. For situations where third-party modules need to\nat import time, they should be marked as pass through modules.\n\n###### Certain Standard Library Calls on Restricted Objects\n\nIf an object is restricted, internal C Python validation may fail in some cases. For example, running\n`dict.items(os.__dict__)` will fail with:\n\n> descriptor \'items\' for \'dict\' objects doesn\'t apply to a \'_RestrictedProxy\' object\n\nThis is a low-level check that cannot be subverted. The solution is to not use restricted objects inside the sandbox.\nFor situations where third-party modules need to at import time, they should be marked as pass through modules.\n\n###### is_subclass of ABC-based Restricted Classes\n\nDue to [https://bugs.python.org/issue44847](https://bugs.python.org/issue44847), classes that are wrapped and then\nchecked to see if they are subclasses of another via `is_subclass` may fail (see also\n[this wrapt issue](https://github.com/GrahamDumpleton/wrapt/issues/130)).\n\n###### Compiled Pydantic Sometimes Using Wrong Types\n\nIf the Pydantic dependency is in compiled form (the default) and you are using a Pydantic model inside a workflow\nsandbox that uses a `datetime` type, it will grab the wrong validator and use `date` instead. This is because our\npatched form of `issubclass` is bypassed by compiled Pydantic.\n\nTo work around, either don\'t use `datetime`-based Pydantic model fields in workflows, or mark `datetime` library as\npassthrough (means you lose protection against calling the non-deterministic `now()`), or use non-compiled Pydantic\ndependency.\n\n### Activities\n\n#### Definition\n\nActivities are decorated with `@activity.defn` like so:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello_activity(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nSome things to note about activity definitions:\n\n* The `say_hello_activity` is `async` which is the recommended activity type (see "Types of Activities" below)\n* A custom name for the activity can be set with a decorator argument, e.g. `@activity.defn(name="my activity")`\n* Long running activities should regularly heartbeat and handle cancellation\n* Activities can only have positional arguments. Best practice is to only take a single argument that is an\n  object/dataclass of fields that can be added to as needed.\n* Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an\n  activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.\n* Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be\n  what is registered with the worker.\n\n#### Types of Activities\n\nThere are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and\nsynchronous multiprocess/other. Only positional parameters are allowed in activity callables.\n\n##### Asynchronous Activities\n\nAsynchronous activities, i.e. functions using `async def`, are the recommended activity type. When using asynchronous\nactivities no special worker parameters are needed.\n\nCancellation for asynchronous activities is done via\n[`asyncio.Task.cancel`](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel). This means that\n`asyncio.CancelledError` will be raised (and can be caught, but it is not recommended). A non-local activity must\nheartbeat to receive cancellation and there are other ways to be notified about cancellation (see "Activity Context" and\n"Heartbeating and Cancellation" later).\n\n##### Synchronous Activities\n\nSynchronous activities, i.e. functions that do not have `async def`, can be used with workers, but the\n`activity_executor` worker parameter must be set with a `concurrent.futures.Executor` instance to use for executing the\nactivities.\n\nAll long running, non-local activities should heartbeat so they can be cancelled. Cancellation in threaded activities\nthrows but multiprocess/other activities does not. The sections below on each synchronous type explain further. There\nare also calls on the context that can check for cancellation. For more information, see "Activity Context" and\n"Heartbeating and Cancellation" sections later.\n\nNote, all calls from an activity to functions in the `temporalio.activity` package are powered by\n[contextvars](https://docs.python.org/3/library/contextvars.html). Therefore, new threads starting _inside_ of\nactivities must `copy_context()` and then `.run()` manually to ensure `temporalio.activity` calls like `heartbeat` still\nfunction in the new threads.\n\nIf any activity ever throws a `concurrent.futures.BrokenExecutor`, the failure is consisted unrecoverable and the worker\nwill fail and shutdown.\n\n###### Synchronous Multithreaded Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.ThreadPoolExecutor` then the synchronous activities\nare considered multithreaded activities. Besides `activity_executor`, no other worker parameters are required for\nsynchronous multithreaded activities.\n\nBy default, cancellation of a synchronous multithreaded activity is done via a `temporalio.exceptions.CancelledError`\nthrown into the activity thread. Activities that do not wish to have cancellation thrown can set\n`no_thread_cancel_exception=True` in the `@activity.defn` decorator.\n\nCode that wishes to be temporarily shielded from the cancellation exception can run inside\n`with activity.shield_thread_cancel_exception():`. But once the last nested form of that block is finished, even if\nthere is a return statement within, it will throw the cancellation if there was one. A `try` +\n`except temporalio.exceptions.CancelledError` would have to surround the `with` to handle the cancellation explicitly.\n\n###### Synchronous Multiprocess/Other Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.Executor` that is _not_\n`concurrent.futures.ThreadPoolExecutor`, then the synchronous activities are considered multiprocess/other activities.\n\nThese require special primitives for heartbeating and cancellation. The `shared_state_manager` worker parameter must be\nset to an instance of `temporalio.worker.SharedStateManager`. The most common implementation can be created by passing a\n`multiprocessing.managers.SyncManager` (i.e. result of `multiprocessing.managers.Manager()`) to\n`temporalio.worker.SharedStateManager.create_from_multiprocessing()`.\n\nAlso, all of these activity functions must be\n["picklable"](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled).\n\n#### Activity Context\n\nDuring activity execution, an implicit activity context is set as a\n[context variable](https://docs.python.org/3/library/contextvars.html). The context variable itself is not visible, but\ncalls in the `temporalio.activity` package make use of it. Specifically:\n\n* `in_activity()` - Whether an activity context is present\n* `info()` - Returns the immutable info of the currently running activity\n* `heartbeat(*details)` - Record a heartbeat\n* `is_cancelled()` - Whether a cancellation has been requested on this activity\n* `wait_for_cancelled()` - `async` call to wait for cancellation request\n* `wait_for_cancelled_sync(timeout)` - Synchronous blocking call to wait for cancellation request\n* `shield_thread_cancel_exception()` - Context manager for use in `with` clauses by synchronous multithreaded activities\n  to prevent cancel exception from being thrown during the block of code\n* `is_worker_shutdown()` - Whether the worker has started graceful shutdown\n* `wait_for_worker_shutdown()` - `async` call to wait for start of graceful worker shutdown\n* `wait_for_worker_shutdown_sync(timeout)` - Synchronous blocking call to wait for start of graceful worker shutdown\n* `raise_complete_async()` - Raise an error that this activity will be completed asynchronously (i.e. after return of\n  the activity function in a separate client call)\n\nWith the exception of `in_activity()`, if any of the functions are called outside of an activity context, an error\noccurs. Synchronous activities cannot call any of the `async` functions.\n\n##### Heartbeating and Cancellation\n\nIn order for a non-local activity to be notified of cancellation requests, it must be given a `heartbeat_timeout` at\ninvocation time and invoke `temporalio.activity.heartbeat()` inside the activity. It is strongly recommended that all\nbut the fastest executing activities call this function regularly. "Types of Activities" has specifics on cancellation\nfor asynchronous and synchronous activities.\n\nIn addition to obtaining cancellation information, heartbeats also support detail data that is persisted on the server\nfor retrieval during activity retry. If an activity calls `temporalio.activity.heartbeat(123, 456)` and then fails and\nis retried, `temporalio.activity.info().heartbeat_details` will return an iterable containing `123` and `456` on the\nnext run.\n\nHeartbeating has no effect on local activities.\n\n##### Worker Shutdown\n\nAn activity can react to a worker shutdown. Using `is_worker_shutdown` or one of the `wait_for_worker_shutdown`\nfunctions an activity can react to a shutdown.\n\nWhen the `graceful_shutdown_timeout` worker parameter is given a `datetime.timedelta`, on shutdown the worker will\nnotify activities of the graceful shutdown. Once that timeout has passed (or if wasn\'t set), the worker will perform\ncancellation of all outstanding activities.\n\nThe `shutdown()` invocation will wait on all activities to complete, so if a long-running activity does not at least\nrespect cancellation, the shutdown may never complete.\n\n#### Testing\n\nUnit testing an activity or any code that could run in an activity is done via the\n`temporalio.testing.ActivityEnvironment` class. Simply instantiate this and any callable + params passed to `run` will\nbe invoked inside the activity context. The following are attributes/methods on the environment that can be used to\naffect calls activity code might make to functions on the `temporalio.activity` package.\n\n* `info` property can be set to customize what is returned from `activity.info()`\n* `on_heartbeat` property can be set to handle `activity.heartbeat()` calls\n* `cancel()` can be invoked to simulate a cancellation of the activity\n* `worker_shutdown()` can be invoked to simulate a worker shutdown during execution of the activity\n\n### Workflow Replay\n\nGiven a workflow\'s history, it can be replayed locally to check for things like non-determinism errors. For example,\nassuming `history_str` is populated with a JSON string history either exported from the web UI or from `tctl`, the\nfollowing function will replay it:\n\n```python\nfrom temporalio.client import WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def run_replayer(history_str: str):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflow(WorkflowHistory.from_json(history_str))\n```\n\nThis will throw an error if any non-determinism is detected.\n\nReplaying from workflow history is a powerful concept that many use to test that workflow alterations won\'t cause\nnon-determinisms with past-complete workflows. The following code will make sure that all workflow histories for a\ncertain workflow type (i.e. workflow class) are safe with the current code.\n\n```python\nfrom temporalio.client import Client, WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def check_past_histories(my_client: Client):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflows(\n    await my_client.list_workflows("WorkflowType = \'SayHello\'").map_histories(),\n  )\n```\n\n### OpenTelemetry Support\n\nOpenTelemetry support requires the optional `opentelemetry` dependencies which are part of the `opentelemetry` extra.\nWhen using `pip`, running\n\n    pip install temporalio[opentelemetry]\n\nwill install needed dependencies. Then the `temporalio.contrib.opentelemetry.TracingInterceptor` can be created and set\nas an interceptor on the `interceptors` argument of `Client.connect`. When set, spans will be created for all client\ncalls and for all activity and workflow invocations on the worker, spans will be created and properly serialized through\nthe server to give one proper trace for a workflow execution.\n\n### Protobuf 3.x vs 4.x\n\nPython currently has two somewhat-incompatible protobuf library versions - the 3.x series and the 4.x series. Python\ncurrently recommends 4.x and that is the primary supported version. Some libraries like\n[Pulumi](https://github.com/pulumi/pulumi) require 4.x. Other libraries such as [ONNX](https://github.com/onnx/onnx) and\n[Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.\n\nTo support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python\nversions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest\nprotobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as\n[Passthrough Modules](#passthrough-modules).\n\n# Development\n\nThe Python SDK is built to work with Python 3.7 and newer. It is built using\n[SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.\n\n### Building\n\n#### Prepare\n\nTo build the SDK from source for use as a dependency, the following prerequisites are required:\n\n* [Python](https://www.python.org/) >= 3.7\n* [Rust](https://www.rust-lang.org/)\n* [poetry](https://github.com/python-poetry/poetry) (e.g. `python -m pip install poetry`)\n* [poe](https://github.com/nat-n/poethepoet) (e.g. `python -m pip install poethepoet`)\n\nmacOS note: If errors are encountered, it may be better to install Python and Rust as recommended from their websites\ninstead of via `brew`.\n\nWith the prerequisites installed, first clone the SDK repository recursively:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\n```\n\nUse `poetry` to install the dependencies with `--no-root` to not install this package (because we still need to build\nit):\n\n```bash\npoetry install --no-root\n```\n\n#### Build\n\nNow perform the release build:\n\n> This will take a while because Rust will compile the core project in release mode (see [Local SDK development\nenvironment](#local-sdk-development-environment) for the quicker approach to local development).\n\n```bash\npoetry build\n```\n\nThe compiled wheel doesn\'t have the exact right tags yet for use, so run this script to fix it:\n\n```bash\npoe fix-wheel\n```\n\nThe `whl` wheel file in `dist/` is now ready to use.\n\n#### Use\n\nThe wheel can now be installed into any virtual environment.\n\nFor example,\n[create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\nsomewhere and then run the following inside the virtual environment:\n\n```bash\npip install wheel\n```\n\n```bash\npip install /path/to/cloned/sdk-python/dist/*.whl\n```\n\nCreate this Python file at `example.py`:\n\n```python\nimport asyncio\nfrom temporalio import workflow, activity\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return f"Hello, {name}!"\n\nasync def main():\n    client = await Client.connect("localhost:7233")\n    async with Worker(client, task_queue="my-task-queue", workflows=[SayHello]):\n        result = await client.execute_workflow(SayHello.run, "Temporal",\n            id="my-workflow-id", task_queue="my-task-queue")\n        print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming there is a [local Temporal server](https://docs.temporal.io/docs/server/quick-install/) running, execute the\nfile with `python` (or `python3` if necessary):\n\n```bash\npython example.py\n```\n\nIt should output:\n\n    Result: Hello, Temporal!\n\n### Local SDK development environment\n\nFor local development, it is often quicker to use debug builds and a local virtual environment.\n\nWhile not required, it often helps IDEs if we put the virtual environment `.venv` directory in the project itself. This\ncan be configured system-wide via:\n\n```bash\npoetry config virtualenvs.in-project true\n```\n\nNow perform the same steps as the "Prepare" section above by installing the prerequisites, cloning the project,\ninstalling dependencies, and generating the protobuf code:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\npoetry install --no-root\n```\n\nNow compile the Rust extension in develop mode which is quicker than release mode:\n\n```bash\npoe build-develop\n```\n\nThat step can be repeated for any Rust changes made.\n\nThe environment is now ready to develop in.\n\n#### Testing\n\nTo execute tests:\n\n```bash\npoe test\n```\n\nThis runs against [Temporalite](https://github.com/temporalio/temporalite). To run against the time-skipping test\nserver, pass `--workflow-environment time-skipping`. To run against the `default` namespace of an already-running\nserver, pass the `host:port` to `--workflow-environment`. Can also use regular pytest arguments. For example, here\'s how\nto run a single test with debug logs on the console:\n\n```bash\npoe test -s --log-cli-level=DEBUG -k test_sync_activity_thread_cancel_caught\n```\n\n#### Proto Generation and Testing\n\nTo allow for backwards compatibility, protobuf code is generated on the 3.x series of the protobuf library. To generate\nprotobuf code, you must be on Python <= 3.10, and then run `poetry add "protobuf<4"`. Then the protobuf files can be\ngenerated via `poe gen-protos`. Tests can be run for protobuf version 3 by setting the `TEMPORAL_TEST_PROTO3` env var\nto `1` prior to running tests.\n\nDo not commit `poetry.lock` or `pyproject.toml` changes. To go back from this downgrade, restore `pyproject.toml` and\nrun `poetry update protobuf grpcio-tools`.\n\n### Style\n\n* Mostly [Google Style Guide](https://google.github.io/styleguide/pyguide.html). Notable exceptions:\n  * We use [Black](https://github.com/psf/black) for formatting, so that takes precedence\n  * In tests and example code, can import individual classes/functions to make it more readable. Can also do this for\n    rarely in library code for some Python common items (e.g. `dataclass` or `partial`), but not allowed to do this for\n    any `temporalio` packages (except `temporalio.types`) or any classes/functions that aren\'t clear when unqualified.\n  * We allow relative imports for private packages\n  * We allow `@staticmethod`\n',
+    'long_description': '![Temporal Python SDK](https://assets.temporal.io/w/py-banner.svg)\n\n[![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)\n[![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)\n\n[Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to\nexecute asynchronous, long-running business logic in a scalable and resilient way.\n\n"Temporal Python SDK" is the framework for authoring workflows and activities using the Python programming language.\n\nAlso see:\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) - Once you\'ve tried our [Quick Start](#quick-start), check out our guide on how to use Temporal in your Python applications, including information around Temporal core concepts.\n* [Python Code Samples](https://github.com/temporalio/samples-python)\n* [API Documentation](https://python.temporal.io) - Complete Temporal Python SDK Package reference.\n\nIn addition to features common across all Temporal SDKs, the Python SDK also has the following interesting features:\n\n**Type Safe**\n\nThis library uses the latest typing and MyPy support with generics to ensure all calls can be typed. For example,\nstarting a workflow with an `int` parameter when it accepts a `str` parameter would cause MyPy to fail.\n\n**Different Activity Types**\n\nThe activity worker has been developed to work with `async def`, threaded, and multiprocess activities. While\n`async def` activities are the easiest and recommended, care has been taken to make heartbeating and cancellation also\nwork across threads/processes.\n\n**Custom `asyncio` Event Loop**\n\nThe workflow implementation basically turns `async def` functions into workflows backed by a distributed, fault-tolerant\nevent loop. This means task management, sleep, cancellation, etc have all been developed to seamlessly integrate with\n`asyncio` concepts.\n\n---\n\n<!-- START doctoc generated TOC please keep comment here to allow auto update -->\n<!-- DON\'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->\n**Contents**\n\n- [Quick Start](#quick-start)\n  - [Installation](#installation)\n  - [Implementing a Workflow](#implementing-a-workflow)\n  - [Running a Workflow](#running-a-workflow)\n  - [Next Steps](#next-steps)\n- [Usage](#usage)\n    - [Client](#client)\n      - [Data Conversion](#data-conversion)\n        - [Custom Type Data Conversion](#custom-type-data-conversion)\n    - [Workers](#workers)\n    - [Workflows](#workflows)\n      - [Definition](#definition)\n      - [Running](#running)\n      - [Invoking Activities](#invoking-activities)\n      - [Invoking Child Workflows](#invoking-child-workflows)\n      - [Timers](#timers)\n      - [Conditions](#conditions)\n      - [Asyncio and Cancellation](#asyncio-and-cancellation)\n      - [Workflow Utilities](#workflow-utilities)\n      - [Exceptions](#exceptions)\n      - [External Workflows](#external-workflows)\n      - [Testing](#testing)\n        - [Automatic Time Skipping](#automatic-time-skipping)\n        - [Manual Time Skipping](#manual-time-skipping)\n        - [Mocking Activities](#mocking-activities)\n      - [Workflow Sandbox](#workflow-sandbox)\n        - [How the Sandbox Works](#how-the-sandbox-works)\n        - [Avoiding the Sandbox](#avoiding-the-sandbox)\n        - [Customizing the Sandbox](#customizing-the-sandbox)\n          - [Passthrough Modules](#passthrough-modules)\n          - [Invalid Module Members](#invalid-module-members)\n        - [Known Sandbox Issues](#known-sandbox-issues)\n          - [Global Import/Builtins](#global-importbuiltins)\n          - [Sandbox is not Secure](#sandbox-is-not-secure)\n          - [Sandbox Performance](#sandbox-performance)\n          - [Extending Restricted Classes](#extending-restricted-classes)\n          - [Certain Standard Library Calls on Restricted Objects](#certain-standard-library-calls-on-restricted-objects)\n          - [is_subclass of ABC-based Restricted Classes](#is_subclass-of-abc-based-restricted-classes)\n          - [Compiled Pydantic Sometimes Using Wrong Types](#compiled-pydantic-sometimes-using-wrong-types)\n    - [Activities](#activities)\n      - [Definition](#definition-1)\n      - [Types of Activities](#types-of-activities)\n        - [Asynchronous Activities](#asynchronous-activities)\n        - [Synchronous Activities](#synchronous-activities)\n          - [Synchronous Multithreaded Activities](#synchronous-multithreaded-activities)\n          - [Synchronous Multiprocess/Other Activities](#synchronous-multiprocessother-activities)\n      - [Activity Context](#activity-context)\n        - [Heartbeating and Cancellation](#heartbeating-and-cancellation)\n        - [Worker Shutdown](#worker-shutdown)\n      - [Testing](#testing-1)\n    - [Workflow Replay](#workflow-replay)\n    - [OpenTelemetry Support](#opentelemetry-support)\n    - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)\n    - [Known Compatibility Issues](#known-compatibility-issues)\n      - [gevent Patching](#gevent-patching)\n- [Development](#development)\n    - [Building](#building)\n      - [Prepare](#prepare)\n      - [Build](#build)\n      - [Use](#use)\n    - [Local SDK development environment](#local-sdk-development-environment)\n      - [Testing](#testing-2)\n      - [Proto Generation and Testing](#proto-generation-and-testing)\n    - [Style](#style)\n\n<!-- END doctoc generated TOC please keep comment here to allow auto update -->\n\n# Quick Start\n\nWe will guide you through the Temporal basics to create a "hello, world!" script on your machine. It is not intended as one of the ways to use Temporal, but in reality it is very simplified and decidedly not "the only way" to use Temporal. For more information, check out the docs references in "Next Steps" below the quick start.\n\n## Installation\n\nInstall the `temporalio` package from [PyPI](https://pypi.org/project/temporalio).\n\nThese steps can be followed to use with a virtual environment and `pip`:\n\n* [Create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\n* Update `pip` - `python -m pip install -U pip`\n  * Needed because older versions of `pip` may not pick the right wheel\n* Install Temporal SDK - `python -m pip install temporalio`\n\nThe SDK is now ready for use. To build from source, see "Building" near the end of this documentation.\n\n**NOTE: This README is for the current branch and not necessarily what\'s released on `PyPI`.**\n\n## Implementing a Workflow\n\nCreate the following in `activities.py`:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nCreate the following in `workflows.py`:\n\n```python\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Import our activity, passing it through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .activities import say_hello\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return await workflow.execute_activity(\n            say_hello, name, schedule_to_close_timeout=timedelta(seconds=5)\n        )\n```\n\nCreate the following in `run_worker.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n# Import the activity and workflow from our other files\nfrom .activities import say_hello\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Run the worker\n    worker = Worker(client, task_queue="my-task-queue", workflows=[SayHello], activities=[say_hello])\n    await worker.run()\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have a [Temporal server running on localhost](https://docs.temporal.io/docs/server/quick-install/), this\nwill run the worker:\n\n    python run_worker.py\n\n## Running a Workflow\n\nCreate the following script at `run_workflow.py`:\n\n```python\nimport asyncio\nfrom temporalio.client import Client\n\n# Import the workflow from the previous code\nfrom .workflows import SayHello\n\nasync def main():\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233")\n\n    # Execute a workflow\n    result = await client.execute_workflow(SayHello.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n\n    print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming you have `run_worker.py` running from before, this will run the workflow:\n\n    python run_workflow.py\n\nThe output will be:\n\n    Result: Hello, my-name!\n\n## Next Steps\n\nTemporal can be implemented in your code in many different ways, to suit your application\'s needs. The links below will\ngive you much more information about how Temporal works with Python:\n\n* [Code Samples](https://github.com/temporalio/samples-python) - If you want to start with some code, we have provided\n  some pre-built samples.\n* [Application Development Guide](https://docs.temporal.io/application-development?lang=python) Our Python specific\n  Developer\'s Guide will give you much more information on how to build with Temporal in your Python applications than\n  our SDK README ever could (or should).\n* [API Documentation](https://python.temporal.io) - Full Temporal Python SDK package documentation.\n\n---\n\n# Usage\n\nFrom here, you will find reference documentation about specific pieces of the Temporal Python SDK that were built around Temporal concepts. \n*This section is not intended as a how-to guide* -- For more how-to oriented information, check out the links in the [Next Steps](#next-steps) section above.\n\n### Client\n\nA client can be created and used to start a workflow like so:\n\n```python\nfrom temporalio.client import Client\n\nasync def main():\n    # Create client connected to server at the given address and namespace\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Start a workflow\n    handle = await client.start_workflow(MyWorkflow.run, "some arg", id="my-workflow-id", task_queue="my-task-queue")\n\n    # Wait for result\n    result = await handle.result()\n    print(f"Result: {result}")\n```\n\nSome things to note about the above code:\n\n* A `Client` does not have an explicit "close"\n* To enable TLS, the `tls` argument to `connect` can be set to `True` or a `TLSConfig` object\n* A single positional argument can be passed to `start_workflow`. If there are multiple arguments, only the\n  non-type-safe form of `start_workflow` can be used (i.e. the one accepting a string workflow name) and it must be in\n  the `args` keyword argument.\n* The `handle` represents the workflow that was started and can be used for more than just getting the result\n* Since we are just getting the handle and waiting on the result, we could have called `client.execute_workflow` which\n  does the same thing\n* Clients can have many more options not shown here (e.g. data converters and interceptors)\n* A string can be used instead of the method reference to call a workflow by name (e.g. if defined in another language)\n\nClients also provide a shallow copy of their config for use in making slightly different clients backed by the same\nconnection. For instance, given the `client` above, this is how to have a client in another namespace:\n\n```python\nconfig = client.config()\nconfig["namespace"] = "my-other-namespace"\nother_ns_client = Client(**config)\n```\n\n#### Data Conversion\n\nData converters are used to convert raw Temporal payloads to/from actual Python types. A custom data converter of type\n`temporalio.converter.DataConverter` can be set via the `data_converter` client parameter. Data converters are a\ncombination of payload converters, payload codecs, and failure converters. Payload converters convert Python values\nto/from serialized bytes. Payload codecs convert bytes to bytes (e.g. for compression or encryption). Failure converters\nconvert exceptions to/from serialized failures.\n\nThe default data converter supports converting multiple types including:\n\n* `None`\n* `bytes`\n* `google.protobuf.message.Message` - As JSON when encoding, but has ability to decode binary proto from other languages\n* Anything that can be converted to JSON including:\n  * Anything that [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) supports natively\n  * [dataclasses](https://docs.python.org/3/library/dataclasses.html)\n  * Iterables including ones JSON dump may not support by default, e.g. `set`\n  * Any class with a `dict()` method and a static `parse_obj()` method, e.g.\n    [Pydantic models](https://pydantic-docs.helpmanual.io/usage/models)\n    * The default data converter is deprecated for Pydantic models and will warn if used since not all fields work.\n      See [this sample](https://github.com/temporalio/samples-python/tree/main/pydantic_converter) for the recommended\n      approach.\n  * [IntEnum, StrEnum](https://docs.python.org/3/library/enum.html) based enumerates\n  * [UUID](https://docs.python.org/3/library/uuid.html)\n\nThis notably doesn\'t include any `date`, `time`, or `datetime` objects as they may not work across SDKs.\n\nUsers are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be\neasily added without breaking compatibility.\n\nClasses with generics may not have the generics properly resolved. The current implementation, similar to Pydantic, does\nnot have generic type resolution. Users should use concrete types.\n\n##### Custom Type Data Conversion\n\nFor converting from JSON, the workflow/activity type hint is taken into account to convert to the proper type. Care has\nbeen taken to support all common typings including `Optional`, `Union`, all forms of iterables and mappings, `NewType`,\netc in addition to the regular JSON values mentioned before.\n\nData converters contain a reference to a payload converter class that is used to convert to/from payloads/values. This\nis a class and not an instance because it is instantiated on every workflow run inside the sandbox. The payload\nconverter is usually a `CompositePayloadConverter` which contains a multiple `EncodingPayloadConverter`s it uses to try\nto serialize/deserialize payloads. Upon serialization, each `EncodingPayloadConverter` is tried until one succeeds. The\n`EncodingPayloadConverter` provides an "encoding" string serialized onto the payload so that, upon deserialization, the\nspecific `EncodingPayloadConverter` for the given "encoding" is used.\n\nThe default data converter uses the `DefaultPayloadConverter` which is simply a `CompositePayloadConverter` with a known\nset of default `EncodingPayloadConverter`s. To implement a custom encoding for a custom type, a new\n`EncodingPayloadConverter` can be created for the new type. For example, to support `IPv4Address` types:\n\n```python\nclass IPv4AddressEncodingPayloadConverter(EncodingPayloadConverter):\n    @property\n    def encoding(self) -> str:\n        return "text/ipv4-address"\n\n    def to_payload(self, value: Any) -> Optional[Payload]:\n        if isinstance(value, ipaddress.IPv4Address):\n            return Payload(\n                metadata={"encoding": self.encoding.encode()},\n                data=str(value).encode(),\n            )\n        else:\n            return None\n\n    def from_payload(self, payload: Payload, type_hint: Optional[Type] = None) -> Any:\n        assert not type_hint or type_hint is ipaddress.IPv4Address\n        return ipaddress.IPv4Address(payload.data.decode())\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Just add ours as first before the defaults\n        super().__init__(\n            IPv4AddressEncodingPayloadConverter(),\n            *DefaultPayloadConverter.default_encoding_payload_converters,\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nImports are left off for brevity.\n\nThis is good for many custom types. However, sometimes you want to override the behavior of the just the existing JSON\nencoding payload converter to support a new type. It is already the last encoding data converter in the list, so it\'s\nthe fall-through behavior for any otherwise unknown type. Customizing the existing JSON converter has the benefit of\nmaking the type work in lists, unions, etc.\n\nThe `JSONPlainPayloadConverter` uses the Python [json](https://docs.python.org/3/library/json.html) library with an\nadvanced JSON encoder by default and a custom value conversion method to turn `json.load`ed values to their type hints.\nThe conversion can be customized for serialization with a custom `json.JSONEncoder` and deserialization with a custom\n`JSONTypeConverter`. For example, to support `IPv4Address` types in existing JSON conversion:\n\n```python\nclass IPv4AddressJSONEncoder(AdvancedJSONEncoder):\n    def default(self, o: Any) -> Any:\n        if isinstance(o, ipaddress.IPv4Address):\n            return str(o)\n        return super().default(o)\nclass IPv4AddressJSONTypeConverter(JSONTypeConverter):\n    def to_typed_value(\n        self, hint: Type, value: Any\n    ) -> Union[Optional[Any], _JSONTypeConverterUnhandled]:\n        if issubclass(hint, ipaddress.IPv4Address):\n            return ipaddress.IPv4Address(value)\n        return JSONTypeConverter.Unhandled\n\nclass IPv4AddressPayloadConverter(CompositePayloadConverter):\n    def __init__(self) -> None:\n        # Replace default JSON plain with our own that has our encoder and type\n        # converter\n        json_converter = JSONPlainPayloadConverter(\n            encoder=IPv4AddressJSONEncoder,\n            custom_type_converters=[IPv4AddressJSONTypeConverter()],\n        )\n        super().__init__(\n            *[\n                c if not isinstance(c, JSONPlainPayloadConverter) else json_converter\n                for c in DefaultPayloadConverter.default_encoding_payload_converters\n            ]\n        )\n\nmy_data_converter = dataclasses.replace(\n    DataConverter.default,\n    payload_converter_class=IPv4AddressPayloadConverter,\n)\n```\n\nNow `IPv4Address` can be used in type hints including collections, optionals, etc.\n\n### Workers\n\nWorkers host workflows and/or activities. Here\'s how to run a worker:\n\n```python\nimport asyncio\nimport logging\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n# Import your own workflows and activities\nfrom my_workflow_package import MyWorkflow, my_activity\n\nasync def run_worker(stop_event: asyncio.Event):\n    # Create client connected to server at the given address\n    client = await Client.connect("localhost:7233", namespace="my-namespace")\n\n    # Run the worker until the event is set\n    worker = Worker(client, task_queue="my-task-queue", workflows=[MyWorkflow], activities=[my_activity])\n    async with worker:\n        await stop_event.wait()\n```\n\nSome things to note about the above code:\n\n* This creates/uses the same client that is used for starting workflows\n* While this example accepts a stop event and uses `async with`, `run()` and `shutdown()` may be used instead\n* Workers can have many more options not shown here (e.g. data converters and interceptors)\n\n### Workflows\n\n#### Definition\n\nWorkflows are defined as classes decorated with `@workflow.defn`. The method invoked for the workflow is decorated with\n`@workflow.run`. Methods for signals and queries are decorated with `@workflow.signal` and `@workflow.query`\nrespectively. Here\'s an example of a workflow:\n\n```python\nimport asyncio\nfrom datetime import timedelta\nfrom temporalio import workflow\n\n# Pass the activities through the sandbox\nwith workflow.unsafe.imports_passed_through():\n    from .my_activities import GreetingInfo, create_greeting_activity\n\n@workflow.defn\nclass GreetingWorkflow:\n    def __init__() -> None:\n        self._current_greeting = "<unset>"\n        self._greeting_info = GreetingInfo()\n        self._greeting_info_update = asyncio.Event()\n        self._complete = asyncio.Event()\n\n    @workflow.run\n    async def run(self, name: str) -> str:\n        self._greeting_info.name = name\n        while True:\n            # Store greeting\n            self._current_greeting = await workflow.execute_activity(\n                create_greeting_activity,\n                self._greeting_info,\n                start_to_close_timeout=timedelta(seconds=5),\n            )\n            workflow.logger.debug("Greeting set to %s", self._current_greeting)\n            \n            # Wait for salutation update or complete signal (this can be\n            # cancelled)\n            await asyncio.wait(\n                [\n                    asyncio.create_task(self._greeting_info_update.wait()),\n                    asyncio.create_task(self._complete.wait()),\n                ],\n                return_when=asyncio.FIRST_COMPLETED,\n            )\n            if self._complete.is_set():\n                return self._current_greeting\n            self._greeting_info_update.clear()\n\n    @workflow.signal\n    async def update_salutation(self, salutation: str) -> None:\n        self._greeting_info.salutation = salutation\n        self._greeting_info_update.set()\n\n    @workflow.signal\n    async def complete_with_greeting(self) -> None:\n        self._complete.set()\n\n    @workflow.query\n    async def current_greeting(self) -> str:\n        return self._current_greeting\n\n```\n\nThis assumes there\'s an activity in `my_activities.py` like:\n\n```python\nfrom dataclasses import dataclass\nfrom temporalio import workflow\n\n@dataclass\nclass GreetingInfo:\n    salutation: str = "Hello"\n    name: str = "<unknown>"\n\n@activity.defn\nasync def create_greeting_activity(info: GreetingInfo) -> str:\n    return f"{info.salutation}, {info.name}!"\n```\n\nSome things to note about the above workflow code:\n\n* Workflows run in a sandbox by default.\n  * Users are encouraged to define workflows in files with no side effects or other complicated code or unnecessary\n    imports to other third party libraries.\n  * Non-standard-library, non-`temporalio` imports should usually be "passed through" the sandbox. See the\n    [Workflow Sandbox](#workflow-sandbox) section for more details.\n* This workflow continually updates the queryable current greeting when signalled and can complete with the greeting on\n  a different signal\n* Workflows are always classes and must have a single `@workflow.run` which is an `async def` function\n* Workflow code must be deterministic. This means no threading, no randomness, no external calls to processes, no\n  network IO, and no global state mutation. All code must run in the implicit `asyncio` event loop and be deterministic.\n* `@activity.defn` is explained in a later section. For normal simple string concatenation, this would just be done in\n  the workflow. The activity is for demonstration purposes only.\n* `workflow.execute_activity(create_greeting_activity, ...` is actually a typed signature, and MyPy will fail if the\n  `self._greeting_info` parameter is not a `GreetingInfo`\n\nHere are the decorators that can be applied:\n\n* `@workflow.defn` - Defines a workflow class\n  * Must be defined on the class given to the worker (ignored if present on a base class)\n  * Can have a `name` param to customize the workflow name, otherwise it defaults to the unqualified class name\n* `@workflow.run` - Defines the primary workflow run method\n  * Must be defined on the same class as `@workflow.defn`, not a base class (but can _also_ be defined on the same\n    method of a base class)\n  * Exactly one method name must have this decorator, no more or less\n  * Must be defined on an `async def` method\n  * The method\'s arguments are the workflow\'s arguments\n  * The first parameter must be `self`, followed by positional arguments. Best practice is to only take a single\n    argument that is an object/dataclass of fields that can be added to as needed.\n* `@workflow.signal` - Defines a method as a signal\n  * Can be defined on an `async` or non-`async` function at any hierarchy depth, but if decorated method is overridden,\n    the override must also be decorated\n  * The method\'s arguments are the signal\'s arguments\n  * Can have a `name` param to customize the signal name, otherwise it defaults to the unqualified method name\n  * Can have `dynamic=True` which means all otherwise unhandled signals fall through to this. If present, cannot have\n    `name` argument, and method parameters must be `self`, a string signal name, and a `*args` varargs param.\n  * Non-dynamic method can only have positional arguments. Best practice is to only take a single argument that is an\n    object/dataclass of fields that can be added to as needed.\n  * Return value is ignored\n* `@workflow.query` - Defines a method as a query\n  * All the same constraints as `@workflow.signal` but should return a value\n  * Temporal queries should never mutate anything in the workflow\n\n#### Running\n\nTo start a locally-defined workflow from a client, you can simply reference its method like so:\n\n```python\nfrom temporalio.client import Client\nfrom my_workflow_package import GreetingWorkflow\n\nasync def create_greeting(client: Client) -> str:\n    # Start the workflow\n    handle = await client.start_workflow(GreetingWorkflow.run, "my name", id="my-workflow-id", task_queue="my-task-queue")\n    # Change the salutation\n    await handle.signal(GreetingWorkflow.update_salutation, "Aloha")\n    # Tell it to complete\n    await handle.signal(GreetingWorkflow.complete_with_greeting)\n    # Wait and return result\n    return await handle.result()\n```\n\nSome things to note about the above code:\n\n* This uses the `GreetingWorkflow` from the previous section\n* The result of calling this function is `"Aloha, my name!"`\n* `id` and `task_queue` are required for running a workflow\n* `client.start_workflow` is typed, so MyPy would fail if `"my name"` were something besides a string\n* `handle.signal` is typed, so MyPy would fail if `"Aloha"` were something besides a string or if we provided a\n  parameter to the parameterless `complete_with_greeting`\n* `handle.result` is typed to the workflow itself, so MyPy would fail if we said this `create_greeting` returned\n  something besides a string\n\n#### Invoking Activities\n\n* Activities are started with non-async `workflow.start_activity()` which accepts either an activity function reference\n  or a string name.\n* A single argument to the activity is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute activity and must be supplied via the `args` keyword argument.\n* Activity options are set as keyword arguments after the activity arguments. At least one of `start_to_close_timeout`\n  or `schedule_to_close_timeout` must be provided.\n* The result is an activity handle which is an `asyncio.Task` and supports basic task features\n* An async `workflow.execute_activity()` helper is provided which takes the same arguments as\n  `workflow.start_activity()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n* Local activities work very similarly except the functions are `workflow.start_local_activity()` and\n  `workflow.execute_local_activity()`\n  * ⚠️Local activities are currently experimental\n* Activities can be methods of a class. Invokers should use `workflow.start_activity_method()`,\n  `workflow.execute_activity_method()`, `workflow.start_local_activity_method()`, and\n  `workflow.execute_local_activity_method()` instead.\n* Activities can callable classes (i.e. that define `__call__`). Invokers should use `workflow.start_activity_class()`,\n  `workflow.execute_activity_class()`, `workflow.start_local_activity_class()`, and\n  `workflow.execute_local_activity_class()` instead.\n\n#### Invoking Child Workflows\n\n* Child workflows are started with async `workflow.start_child_workflow()` which accepts either a workflow run method\n  reference or a string name. The arguments to the workflow are positional.\n* A single argument to the child workflow is positional. Multiple arguments are not supported in the type-safe form of\n  start/execute child workflow and must be supplied via the `args` keyword argument.\n* Child workflow options are set as keyword arguments after the arguments. At least `id` must be provided.\n* The `await` of the start does not complete until the start has been accepted by the server\n* The result is a child workflow handle which is an `asyncio.Task` and supports basic task features. The handle also has\n  some child info and supports signalling the child workflow\n* An async `workflow.execute_child_workflow()` helper is provided which takes the same arguments as\n  `workflow.start_child_workflow()` and `await`s on the result. This should be used in most cases unless advanced task\n  capabilities are needed.\n\n#### Timers\n\n* A timer is represented by normal `asyncio.sleep()`\n* Timers are also implicitly started on any `asyncio` calls with timeouts (e.g. `asyncio.wait_for`)\n* Timers are Temporal server timers, not local ones, so sub-second resolution rarely has value\n\n#### Conditions\n\n* `workflow.wait_condition` is an async function that doesn\'t return until a provided callback returns true\n* A `timeout` can optionally be provided which will throw a `asyncio.TimeoutError` if reached (internally backed by\n  `asyncio.wait_for` which uses a timer)\n\n#### Asyncio and Cancellation\n\nWorkflows are backed by a custom [asyncio](https://docs.python.org/3/library/asyncio.html) event loop. This means many\nof the common `asyncio` calls work as normal. Some asyncio features are disabled such as:\n\n* Thread related calls such as `to_thread()`, `run_coroutine_threadsafe()`, `loop.run_in_executor()`, etc\n* Calls that alter the event loop such as `loop.close()`, `loop.stop()`, `loop.run_forever()`,\n  `loop.set_task_factory()`, etc\n* Calls that use a specific time such as `loop.call_at()`\n* Calls that use anything external such as networking, subprocesses, disk IO, etc\n\nCancellation is done the same way as `asyncio`. Specifically, a task can be requested to be cancelled but does not\nnecessarily have to respect that cancellation immediately. This also means that `asyncio.shield()` can be used to\nprotect against cancellation. The following tasks, when cancelled, perform a Temporal cancellation:\n\n* Activities - when the task executing an activity is cancelled, a cancellation request is sent to the activity\n* Child workflows - when the task starting or executing a child workflow is cancelled, a cancellation request is sent to\n  cancel the child workflow\n* Timers - when the task executing a timer is cancelled (whether started via sleep or timeout), the timer is cancelled\n\nWhen the workflow itself is requested to cancel, `Task.cancel` is called on the main workflow task. Therefore,\n`asyncio.CancelledError` can be caught in order to handle the cancel gracefully.\n\nWorkflows follow `asyncio` cancellation rules exactly which can cause confusion among Python developers. Cancelling a\ntask doesn\'t always cancel the thing it created. For example, given\n`task = asyncio.create_task(workflow.start_child_workflow(...`, calling `task.cancel` does not cancel the child\nworkflow, it only cancels the starting of it, which has no effect if it has already started. However, cancelling the\nresult of `handle = await workflow.start_child_workflow(...` or\n`task = asyncio.create_task(workflow.execute_child_workflow(...` _does_ cancel the child workflow.\n\nAlso, due to Temporal rules, a cancellation request is a state not an event. Therefore, repeated cancellation requests\nare not delivered, only the first. If the workflow chooses swallow a cancellation, it cannot be requested again.\n\n#### Workflow Utilities\n\nWhile running in a workflow, in addition to features documented elsewhere, the following items are available from the\n`temporalio.workflow` package:\n\n* `continue_as_new()` - Async function to stop the workflow immediately and continue as new\n* `info()` - Returns information about the current workflow\n* `logger` - A logger for use in a workflow (properly skips logging on replay)\n* `now()` - Returns the "current time" from the workflow\'s perspective\n\n#### Exceptions\n\n* Workflows can raise exceptions to fail the workflow or the "workflow task" (i.e. suspend the workflow retrying).\n* Exceptions that are instances of `temporalio.exceptions.FailureError` will fail the workflow with that exception\n  * For failing the workflow explicitly with a user exception, use `temporalio.exceptions.ApplicationError`. This can\n    be marked non-retryable or include details as needed.\n  * Other exceptions that come from activity execution, child execution, cancellation, etc are already instances of\n    `FailureError` and will fail the workflow when uncaught.\n* All other exceptions fail the "workflow task" which means the workflow will continually retry until the workflow is\n  fixed. This is helpful for bad code or other non-predictable exceptions. To actually fail the workflow, use an\n  `ApplicationError` as mentioned above.\n\n#### External Workflows\n\n* `workflow.get_external_workflow_handle()` inside a workflow returns a handle to interact with another workflow\n* `workflow.get_external_workflow_handle_for()` can be used instead for a type safe handle\n* `await handle.signal()` can be called on the handle to signal the external workflow\n* `await handle.cancel()` can be called on the handle to send a cancel to the external workflow\n\n#### Testing\n\nWorkflow testing can be done in an integration-test fashion against a real server, however it is hard to simulate\ntimeouts and other long time-based code. Using the time-skipping workflow test environment can help there.\n\nThe time-skipping `temporalio.testing.WorkflowEnvironment` can be created via the static async `start_time_skipping()`.\nThis internally downloads the Temporal time-skipping test server to a temporary directory if it doesn\'t already exist,\nthen starts the test server which has special APIs for skipping time.\n\n##### Automatic Time Skipping\n\nAnytime a workflow result is waited on, the time-skipping server automatically advances to the next event it can. To\nmanually advance time before waiting on the result of a workflow, the `WorkflowEnvironment.sleep` method can be used.\n\nHere\'s a simple example of a workflow that sleeps for 24 hours:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass WaitADayWorkflow:\n    @workflow.run\n    async def run(self) -> str:\n        await asyncio.sleep(24 * 60 * 60)\n        return "all done"\n```\n\nAn integration test of this workflow would be way too slow. However the time-skipping server automatically skips to the\nnext event when we wait on the result. Here\'s a test for that workflow:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_wait_a_day_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[WaitADayWorkflow]):\n            assert "all done" == await env.client.execute_workflow(WaitADayWorkflow.run, id="wf1", task_queue="tq1")\n```\n\nThat test will run almost instantly. This is because by calling `execute_workflow` on our client, we have asked the\nenvironment to automatically skip time as much as it can (basically until the end of the workflow or until an activity\nis run).\n\nTo disable automatic time-skipping while waiting for a workflow result, run code inside a\n`with env.auto_time_skipping_disabled():` block.\n\n##### Manual Time Skipping\n\nUntil a workflow is waited on, all time skipping in the time-skipping environment is done manually via\n`WorkflowEnvironment.sleep`.\n\nHere\'s workflow that waits for a signal or times out:\n\n```python\nimport asyncio\nfrom temporalio import workflow\n\n@workflow.defn\nclass SignalWorkflow:\n    def __init__(self) -> None:\n        self.signal_received = False\n\n    @workflow.run\n    async def run(self) -> str:\n        # Wait for signal or timeout in 45 seconds\n        try:\n            await workflow.wait_condition(lambda: self.signal_received, timeout=45)\n            return "got signal"\n        except asyncio.TimeoutError:\n            return "got timeout"\n\n    @workflow.signal\n    def some_signal(self) -> None:\n        self.signal_received = True\n```\n\nTo test a normal signal, you might:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, send signal, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await handle.signal(SignalWorkflow.some_signal)\n            assert "got signal" == await handle.result()\n```\n\nBut how would you test the timeout part? Like so:\n\n```python\nfrom temporalio.testing import WorkflowEnvironment\nfrom temporalio.worker import Worker\n\nasync def test_signal_workflow_timeout():\n    async with await WorkflowEnvironment.start_time_skipping() as env:\n        async with Worker(env.client, task_queue="tq1", workflows=[SignalWorkflow]):\n            # Start workflow, advance time past timeout, check result\n            handle = await env.client.start_workflow(SignalWorkflow.run, id="wf1", task_queue="tq1")\n            await env.sleep(50)\n            assert "got timeout" == await handle.result()\n```\n\nAlso, the current time of the workflow environment can be obtained via the async `WorkflowEnvironment.get_current_time`\nmethod.\n\n##### Mocking Activities\n\nActivities are just functions decorated with `@activity.defn`. Simply write different ones and pass those to the worker\nto have different activities called during the test.\n\n#### Workflow Sandbox\n\nBy default workflows are run in a sandbox to help avoid non-deterministic code. If a call that is known to be\nnon-deterministic is performed, an exception will be thrown in the workflow which will "fail the task" which means the\nworkflow will not progress until fixed.\n\nThe sandbox is not foolproof and non-determinism can still occur. It is simply a best-effort way to catch bad code\nearly. Users are encouraged to define their workflows in files with no other side effects.\n\nThe sandbox offers a mechanism to pass through modules from outside the sandbox. By default this already includes all\nstandard library modules and Temporal modules. **For performance and behavior reasons, users are encouraged to pass\nthrough all third party modules whose calls will be deterministic.** This includes modules containing the activities to\nbe referenced in workflows. See "Passthrough Modules" below on how to do this.\n\nIf you are getting an error like:\n\n> temporalio.worker.workflow_sandbox._restrictions.RestrictedWorkflowAccessError: Cannot access\n> http.client.IncompleteRead.\\_\\_mro_entries\\_\\_ from inside a workflow. If this is code from a module not used in a\n> workflow or known to only be used deterministically from a workflow, mark the import as pass through.\n\nThen you are either using an invalid construct from the workflow, this is a known limitation of the sandbox, or most\ncommonly this is from a module that is safe to pass through (see "Passthrough Modules" section below).\n\n##### How the Sandbox Works\n\nThe sandbox is made up of two components that work closely together:\n\n* Global state isolation\n* Restrictions preventing known non-deterministic library calls\n\nGlobal state isolation is performed by using `exec`. Upon workflow start, the file that the workflow is defined in is\nimported into a new sandbox created for that workflow run. In order to keep the sandbox performant a known set of\n"passthrough modules" are passed through from outside of the sandbox when they are imported. These are expected to be\nside-effect free on import and have their non-deterministic aspects restricted. By default the entire Python standard\nlibrary, `temporalio`, and a couple of other modules are passed through from outside of the sandbox. To update this\nlist, see "Customizing the Sandbox".\n\nRestrictions preventing known non-deterministic library calls are achieved using proxy objects on modules wrapped around\nthe custom importer set in the sandbox. Many restrictions apply at workflow import time and workflow run time, while\nsome restrictions only apply at workflow run time. A default set of restrictions is included that prevents most\ndangerous standard library calls. However it is known in Python that some otherwise-non-deterministic invocations, like\nreading a file from disk via `open` or using `os.environ`, are done as part of importing modules. To customize what is\nand isn\'t restricted, see "Customizing the Sandbox".\n\n##### Avoiding the Sandbox\n\nThere are three increasingly-scoped ways to avoid the sandbox. Users are discouraged from avoiding the sandbox if\npossible.\n\nTo remove restrictions around a particular block of code, use `with temporalio.workflow.unsafe.sandbox_unrestricted():`.\nThe workflow will still be running in the sandbox, but no restrictions for invalid library calls will be applied.\n\nTo run an entire workflow outside of a sandbox, set `sandboxed=False` on the `@workflow.defn` decorator when defining\nit. This will run the entire workflow outside of the workflow which means it can share global state and other bad\nthings.\n\nTo disable the sandbox entirely for a worker, set the `Worker` init\'s `workflow_runner` keyword argument to \n`temporalio.worker.UnsandboxedWorkflowRunner()`. This value is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()` so by changing it to the unsandboxed runner, the sandbox\nwill not be used at all.\n\n##### Customizing the Sandbox\n\n⚠️ WARNING: APIs in the `temporalio.worker.workflow_sandbox` module are not yet considered stable and may change in\nfuture releases.\n\nWhen creating the `Worker`, the `workflow_runner` is defaulted to\n`temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner()`. The `SandboxedWorkflowRunner`\'s init accepts a\n`restrictions` keyword argument that is defaulted to `SandboxRestrictions.default`. The `SandboxRestrictions` dataclass\nis immutable and contains three fields that can be customized, but only two have notable value. See below.\n\n###### Passthrough Modules\n\nBy default the sandbox completely reloads non-standard-library and non-Temporal modules for every workflow run. To make\nthe sandbox quicker and use less memory when importing known-side-effect-free third party modules, they can be marked\nas passthrough modules.\n\n**For performance and behavior reasons, users are encouraged to pass through all third party modules whose calls will be\ndeterministic.**\n\nOne way to pass through a module is at import time in the workflow file using the `imports_passed_through` context\nmanager like so:\n\n```python\n# my_workflow_file.py\n\nfrom temporalio import workflow\n\nwith workflow.unsafe.imports_passed_through():\n    import pydantic\n\n@workflow.defn\nclass MyWorkflow:\n    ...\n```\n\nAlternatively, this can be done at worker creation time by customizing the runner\'s restrictions. For example:\n\n```python\nmy_worker = Worker(\n  ...,\n  workflow_runner=SandboxedWorkflowRunner(\n    restrictions=SandboxRestrictions.default.with_passthrough_modules("pydantic")\n  )\n)\n```\n\nIn both of these cases, now the `pydantic` module will be passed through from outside of the sandbox instead of\nbeing reloaded for every workflow run.\n\n###### Invalid Module Members\n\n`SandboxRestrictions.invalid_module_members` contains a root matcher that applies to all module members. This already\nhas a default set which includes things like `datetime.date.today()` which should never be called from a workflow. To\nremove this restriction:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default.with_child_unrestricted(\n      "datetime", "date", "today",\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nRestrictions can also be added by `|`\'ing together matchers, for example to restrict the `datetime.date` class from\nbeing used altogether:\n\n```python\nmy_restrictions = dataclasses.replace(\n    SandboxRestrictions.default,\n    invalid_module_members=SandboxRestrictions.invalid_module_members_default | SandboxMatcher(\n      children={"datetime": SandboxMatcher(use={"date"})},\n    ),\n)\nmy_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))\n```\n\nSee the API for more details on exact fields and their meaning.\n\n##### Known Sandbox Issues\n\nBelow are known sandbox issues. As the sandbox is developed and matures, some may be resolved.\n\n###### Global Import/Builtins\n\nCurrently the sandbox references/alters the global `sys.modules` and `builtins` fields while running workflow code. In\norder to prevent affecting other sandboxed code, thread locals are leveraged to only intercept these values during the\nworkflow thread running. Therefore, technically if top-level import code starts a thread, it may lose sandbox\nprotection.\n\n###### Sandbox is not Secure\n\nThe sandbox is built to catch many non-deterministic and state sharing issues, but it is not secure. Some known bad\ncalls are intercepted, but for performance reasons, every single attribute get/set cannot be checked. Therefore a simple\ncall like `setattr(temporalio.common, "__my_key", "my value")` will leak across sandbox runs.\n\nThe sandbox is only a helper, it does not provide full protection.\n\n###### Sandbox Performance\n\nThe sandbox does not add significant CPU or memory overhead for workflows that are in files which only import standard\nlibrary modules. This is because they are passed through from outside of the sandbox. However, every\nnon-standard-library import that is performed at the top of the same file the workflow is in will add CPU overhead (the\nmodule is re-imported every workflow run) and memory overhead (each module independently cached as part of the workflow\nrun for isolation reasons). This becomes more apparent for large numbers of workflow runs.\n\nTo mitigate this, users should:\n\n* Define workflows in files that have as few non-standard-library imports as possible\n* Alter the max workflow cache and/or max concurrent workflows settings if memory grows too large\n* Set third-party libraries as passthrough modules if they are known to be side-effect free\n\n###### Extending Restricted Classes\n\nExtending a restricted class causes Python to instantiate the restricted metaclass which is unsupported. Therefore if\nyou attempt to use a class in the sandbox that extends a restricted class, it will fail. For example, if you have a\n`class MyZipFile(zipfile.ZipFile)` and try to use that class inside a workflow, it will fail.\n\nClasses used inside the workflow should not extend restricted classes. For situations where third-party modules need to\nat import time, they should be marked as pass through modules.\n\n###### Certain Standard Library Calls on Restricted Objects\n\nIf an object is restricted, internal C Python validation may fail in some cases. For example, running\n`dict.items(os.__dict__)` will fail with:\n\n> descriptor \'items\' for \'dict\' objects doesn\'t apply to a \'_RestrictedProxy\' object\n\nThis is a low-level check that cannot be subverted. The solution is to not use restricted objects inside the sandbox.\nFor situations where third-party modules need to at import time, they should be marked as pass through modules.\n\n###### is_subclass of ABC-based Restricted Classes\n\nDue to [https://bugs.python.org/issue44847](https://bugs.python.org/issue44847), classes that are wrapped and then\nchecked to see if they are subclasses of another via `is_subclass` may fail (see also\n[this wrapt issue](https://github.com/GrahamDumpleton/wrapt/issues/130)).\n\n###### Compiled Pydantic Sometimes Using Wrong Types\n\nIf the Pydantic dependency is in compiled form (the default) and you are using a Pydantic model inside a workflow\nsandbox that uses a `datetime` type, it will grab the wrong validator and use `date` instead. This is because our\npatched form of `issubclass` is bypassed by compiled Pydantic.\n\nTo work around, either don\'t use `datetime`-based Pydantic model fields in workflows, or mark `datetime` library as\npassthrough (means you lose protection against calling the non-deterministic `now()`), or use non-compiled Pydantic\ndependency.\n\n### Activities\n\n#### Definition\n\nActivities are decorated with `@activity.defn` like so:\n\n```python\nfrom temporalio import activity\n\n@activity.defn\nasync def say_hello_activity(name: str) -> str:\n    return f"Hello, {name}!"\n```\n\nSome things to note about activity definitions:\n\n* The `say_hello_activity` is `async` which is the recommended activity type (see "Types of Activities" below)\n* A custom name for the activity can be set with a decorator argument, e.g. `@activity.defn(name="my activity")`\n* Long running activities should regularly heartbeat and handle cancellation\n* Activities can only have positional arguments. Best practice is to only take a single argument that is an\n  object/dataclass of fields that can be added to as needed.\n* Activities can be defined on methods instead of top-level functions. This allows the instance to carry state that an\n  activity may need (e.g. a DB connection). The instance method should be what is registered with the worker.\n* Activities can also be defined on callable classes (i.e. classes with `__call__`). An instance of the class should be\n  what is registered with the worker.\n\n#### Types of Activities\n\nThere are 3 types of activity callables accepted and described below: asynchronous, synchronous multithreaded, and\nsynchronous multiprocess/other. Only positional parameters are allowed in activity callables.\n\n##### Asynchronous Activities\n\nAsynchronous activities, i.e. functions using `async def`, are the recommended activity type. When using asynchronous\nactivities no special worker parameters are needed.\n\nCancellation for asynchronous activities is done via\n[`asyncio.Task.cancel`](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel). This means that\n`asyncio.CancelledError` will be raised (and can be caught, but it is not recommended). A non-local activity must\nheartbeat to receive cancellation and there are other ways to be notified about cancellation (see "Activity Context" and\n"Heartbeating and Cancellation" later).\n\n##### Synchronous Activities\n\nSynchronous activities, i.e. functions that do not have `async def`, can be used with workers, but the\n`activity_executor` worker parameter must be set with a `concurrent.futures.Executor` instance to use for executing the\nactivities.\n\nAll long running, non-local activities should heartbeat so they can be cancelled. Cancellation in threaded activities\nthrows but multiprocess/other activities does not. The sections below on each synchronous type explain further. There\nare also calls on the context that can check for cancellation. For more information, see "Activity Context" and\n"Heartbeating and Cancellation" sections later.\n\nNote, all calls from an activity to functions in the `temporalio.activity` package are powered by\n[contextvars](https://docs.python.org/3/library/contextvars.html). Therefore, new threads starting _inside_ of\nactivities must `copy_context()` and then `.run()` manually to ensure `temporalio.activity` calls like `heartbeat` still\nfunction in the new threads.\n\nIf any activity ever throws a `concurrent.futures.BrokenExecutor`, the failure is consisted unrecoverable and the worker\nwill fail and shutdown.\n\n###### Synchronous Multithreaded Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.ThreadPoolExecutor` then the synchronous activities\nare considered multithreaded activities. Besides `activity_executor`, no other worker parameters are required for\nsynchronous multithreaded activities.\n\nBy default, cancellation of a synchronous multithreaded activity is done via a `temporalio.exceptions.CancelledError`\nthrown into the activity thread. Activities that do not wish to have cancellation thrown can set\n`no_thread_cancel_exception=True` in the `@activity.defn` decorator.\n\nCode that wishes to be temporarily shielded from the cancellation exception can run inside\n`with activity.shield_thread_cancel_exception():`. But once the last nested form of that block is finished, even if\nthere is a return statement within, it will throw the cancellation if there was one. A `try` +\n`except temporalio.exceptions.CancelledError` would have to surround the `with` to handle the cancellation explicitly.\n\n###### Synchronous Multiprocess/Other Activities\n\nIf `activity_executor` is set to an instance of `concurrent.futures.Executor` that is _not_\n`concurrent.futures.ThreadPoolExecutor`, then the synchronous activities are considered multiprocess/other activities.\n\nThese require special primitives for heartbeating and cancellation. The `shared_state_manager` worker parameter must be\nset to an instance of `temporalio.worker.SharedStateManager`. The most common implementation can be created by passing a\n`multiprocessing.managers.SyncManager` (i.e. result of `multiprocessing.managers.Manager()`) to\n`temporalio.worker.SharedStateManager.create_from_multiprocessing()`.\n\nAlso, all of these activity functions must be\n["picklable"](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled).\n\n#### Activity Context\n\nDuring activity execution, an implicit activity context is set as a\n[context variable](https://docs.python.org/3/library/contextvars.html). The context variable itself is not visible, but\ncalls in the `temporalio.activity` package make use of it. Specifically:\n\n* `in_activity()` - Whether an activity context is present\n* `info()` - Returns the immutable info of the currently running activity\n* `heartbeat(*details)` - Record a heartbeat\n* `is_cancelled()` - Whether a cancellation has been requested on this activity\n* `wait_for_cancelled()` - `async` call to wait for cancellation request\n* `wait_for_cancelled_sync(timeout)` - Synchronous blocking call to wait for cancellation request\n* `shield_thread_cancel_exception()` - Context manager for use in `with` clauses by synchronous multithreaded activities\n  to prevent cancel exception from being thrown during the block of code\n* `is_worker_shutdown()` - Whether the worker has started graceful shutdown\n* `wait_for_worker_shutdown()` - `async` call to wait for start of graceful worker shutdown\n* `wait_for_worker_shutdown_sync(timeout)` - Synchronous blocking call to wait for start of graceful worker shutdown\n* `raise_complete_async()` - Raise an error that this activity will be completed asynchronously (i.e. after return of\n  the activity function in a separate client call)\n\nWith the exception of `in_activity()`, if any of the functions are called outside of an activity context, an error\noccurs. Synchronous activities cannot call any of the `async` functions.\n\n##### Heartbeating and Cancellation\n\nIn order for a non-local activity to be notified of cancellation requests, it must be given a `heartbeat_timeout` at\ninvocation time and invoke `temporalio.activity.heartbeat()` inside the activity. It is strongly recommended that all\nbut the fastest executing activities call this function regularly. "Types of Activities" has specifics on cancellation\nfor asynchronous and synchronous activities.\n\nIn addition to obtaining cancellation information, heartbeats also support detail data that is persisted on the server\nfor retrieval during activity retry. If an activity calls `temporalio.activity.heartbeat(123, 456)` and then fails and\nis retried, `temporalio.activity.info().heartbeat_details` will return an iterable containing `123` and `456` on the\nnext run.\n\nHeartbeating has no effect on local activities.\n\n##### Worker Shutdown\n\nAn activity can react to a worker shutdown. Using `is_worker_shutdown` or one of the `wait_for_worker_shutdown`\nfunctions an activity can react to a shutdown.\n\nWhen the `graceful_shutdown_timeout` worker parameter is given a `datetime.timedelta`, on shutdown the worker will\nnotify activities of the graceful shutdown. Once that timeout has passed (or if wasn\'t set), the worker will perform\ncancellation of all outstanding activities.\n\nThe `shutdown()` invocation will wait on all activities to complete, so if a long-running activity does not at least\nrespect cancellation, the shutdown may never complete.\n\n#### Testing\n\nUnit testing an activity or any code that could run in an activity is done via the\n`temporalio.testing.ActivityEnvironment` class. Simply instantiate this and any callable + params passed to `run` will\nbe invoked inside the activity context. The following are attributes/methods on the environment that can be used to\naffect calls activity code might make to functions on the `temporalio.activity` package.\n\n* `info` property can be set to customize what is returned from `activity.info()`\n* `on_heartbeat` property can be set to handle `activity.heartbeat()` calls\n* `cancel()` can be invoked to simulate a cancellation of the activity\n* `worker_shutdown()` can be invoked to simulate a worker shutdown during execution of the activity\n\n### Workflow Replay\n\nGiven a workflow\'s history, it can be replayed locally to check for things like non-determinism errors. For example,\nassuming `history_str` is populated with a JSON string history either exported from the web UI or from `tctl`, the\nfollowing function will replay it:\n\n```python\nfrom temporalio.client import WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def run_replayer(history_str: str):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflow(WorkflowHistory.from_json(history_str))\n```\n\nThis will throw an error if any non-determinism is detected.\n\nReplaying from workflow history is a powerful concept that many use to test that workflow alterations won\'t cause\nnon-determinisms with past-complete workflows. The following code will make sure that all workflow histories for a\ncertain workflow type (i.e. workflow class) are safe with the current code.\n\n```python\nfrom temporalio.client import Client, WorkflowHistory\nfrom temporalio.worker import Replayer\n\nasync def check_past_histories(my_client: Client):\n  replayer = Replayer(workflows=[SayHello])\n  await replayer.replay_workflows(\n    await my_client.list_workflows("WorkflowType = \'SayHello\'").map_histories(),\n  )\n```\n\n### OpenTelemetry Support\n\nOpenTelemetry support requires the optional `opentelemetry` dependencies which are part of the `opentelemetry` extra.\nWhen using `pip`, running\n\n    pip install temporalio[opentelemetry]\n\nwill install needed dependencies. Then the `temporalio.contrib.opentelemetry.TracingInterceptor` can be created and set\nas an interceptor on the `interceptors` argument of `Client.connect`. When set, spans will be created for all client\ncalls and for all activity and workflow invocations on the worker, spans will be created and properly serialized through\nthe server to give one proper trace for a workflow execution.\n\n### Protobuf 3.x vs 4.x\n\nPython currently has two somewhat-incompatible protobuf library versions - the 3.x series and the 4.x series. Python\ncurrently recommends 4.x and that is the primary supported version. Some libraries like\n[Pulumi](https://github.com/pulumi/pulumi) require 4.x. Other libraries such as [ONNX](https://github.com/onnx/onnx) and\n[Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.\n\nTo support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python\nversions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest\nprotobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as\n[Passthrough Modules](#passthrough-modules).\n\n### Known Compatibility Issues\n\nBelow are known compatibility issues with the Python SDK.\n\n#### gevent Patching\n\nWhen using `gevent.monkey.patch_all()`, asyncio event loops can get messed up, especially those using custom event loops\nlike Temporal. See [this gevent issue](https://github.com/gevent/gevent/issues/982) and\n[this Python SDK issue](https://github.com/temporalio/sdk-python/issues/59) for more details.\n\n# Development\n\nThe Python SDK is built to work with Python 3.7 and newer. It is built using\n[SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.\n\n### Building\n\n#### Prepare\n\nTo build the SDK from source for use as a dependency, the following prerequisites are required:\n\n* [Python](https://www.python.org/) >= 3.7\n* [Rust](https://www.rust-lang.org/)\n* [poetry](https://github.com/python-poetry/poetry) (e.g. `python -m pip install poetry`)\n* [poe](https://github.com/nat-n/poethepoet) (e.g. `python -m pip install poethepoet`)\n\nmacOS note: If errors are encountered, it may be better to install Python and Rust as recommended from their websites\ninstead of via `brew`.\n\nWith the prerequisites installed, first clone the SDK repository recursively:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\n```\n\nUse `poetry` to install the dependencies with `--no-root` to not install this package (because we still need to build\nit):\n\n```bash\npoetry install --no-root\n```\n\n#### Build\n\nNow perform the release build:\n\n> This will take a while because Rust will compile the core project in release mode (see [Local SDK development\nenvironment](#local-sdk-development-environment) for the quicker approach to local development).\n\n```bash\npoetry build\n```\n\nThe compiled wheel doesn\'t have the exact right tags yet for use, so run this script to fix it:\n\n```bash\npoe fix-wheel\n```\n\nThe `whl` wheel file in `dist/` is now ready to use.\n\n#### Use\n\nThe wheel can now be installed into any virtual environment.\n\nFor example,\n[create a virtual environment](https://packaging.python.org/en/latest/tutorials/installing-packages/#creating-virtual-environments)\nsomewhere and then run the following inside the virtual environment:\n\n```bash\npip install wheel\n```\n\n```bash\npip install /path/to/cloned/sdk-python/dist/*.whl\n```\n\nCreate this Python file at `example.py`:\n\n```python\nimport asyncio\nfrom temporalio import workflow, activity\nfrom temporalio.client import Client\nfrom temporalio.worker import Worker\n\n@workflow.defn\nclass SayHello:\n    @workflow.run\n    async def run(self, name: str) -> str:\n        return f"Hello, {name}!"\n\nasync def main():\n    client = await Client.connect("localhost:7233")\n    async with Worker(client, task_queue="my-task-queue", workflows=[SayHello]):\n        result = await client.execute_workflow(SayHello.run, "Temporal",\n            id="my-workflow-id", task_queue="my-task-queue")\n        print(f"Result: {result}")\n\nif __name__ == "__main__":\n    asyncio.run(main())\n```\n\nAssuming there is a [local Temporal server](https://docs.temporal.io/docs/server/quick-install/) running, execute the\nfile with `python` (or `python3` if necessary):\n\n```bash\npython example.py\n```\n\nIt should output:\n\n    Result: Hello, Temporal!\n\n### Local SDK development environment\n\nFor local development, it is often quicker to use debug builds and a local virtual environment.\n\nWhile not required, it often helps IDEs if we put the virtual environment `.venv` directory in the project itself. This\ncan be configured system-wide via:\n\n```bash\npoetry config virtualenvs.in-project true\n```\n\nNow perform the same steps as the "Prepare" section above by installing the prerequisites, cloning the project,\ninstalling dependencies, and generating the protobuf code:\n\n```bash\ngit clone --recursive https://github.com/temporalio/sdk-python.git\ncd sdk-python\npoetry install --no-root\n```\n\nNow compile the Rust extension in develop mode which is quicker than release mode:\n\n```bash\npoe build-develop\n```\n\nThat step can be repeated for any Rust changes made.\n\nThe environment is now ready to develop in.\n\n#### Testing\n\nTo execute tests:\n\n```bash\npoe test\n```\n\nThis runs against [Temporalite](https://github.com/temporalio/temporalite). To run against the time-skipping test\nserver, pass `--workflow-environment time-skipping`. To run against the `default` namespace of an already-running\nserver, pass the `host:port` to `--workflow-environment`. Can also use regular pytest arguments. For example, here\'s how\nto run a single test with debug logs on the console:\n\n```bash\npoe test -s --log-cli-level=DEBUG -k test_sync_activity_thread_cancel_caught\n```\n\n#### Proto Generation and Testing\n\nTo allow for backwards compatibility, protobuf code is generated on the 3.x series of the protobuf library. To generate\nprotobuf code, you must be on Python <= 3.10, and then run `poetry add "protobuf<4"`. Then the protobuf files can be\ngenerated via `poe gen-protos`. Tests can be run for protobuf version 3 by setting the `TEMPORAL_TEST_PROTO3` env var\nto `1` prior to running tests.\n\nDo not commit `poetry.lock` or `pyproject.toml` changes. To go back from this downgrade, restore `pyproject.toml` and\nrun `poetry update protobuf grpcio-tools`.\n\n### Style\n\n* Mostly [Google Style Guide](https://google.github.io/styleguide/pyguide.html). Notable exceptions:\n  * We use [Black](https://github.com/psf/black) for formatting, so that takes precedence\n  * In tests and example code, can import individual classes/functions to make it more readable. Can also do this for\n    rarely in library code for some Python common items (e.g. `dataclass` or `partial`), but not allowed to do this for\n    any `temporalio` packages (except `temporalio.types`) or any classes/functions that aren\'t clear when unqualified.\n  * We allow relative imports for private packages\n  * We allow `@staticmethod`\n',
     'author': 'Temporal Technologies Inc',
     'author_email': 'sdk@temporal.io',
     'maintainer': 'None',
     'maintainer_email': 'None',
     'url': 'https://github.com/temporalio/sdk-python',
     'packages': packages,
     'package_data': package_data,
```

### Comparing `temporalio-1.1.0/PKG-INFO` & `temporalio-1.2.0/PKG-INFO`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: temporalio
-Version: 1.1.0
+Version: 1.2.0
 Summary: Temporal.io Python SDK
 Home-page: https://github.com/temporalio/sdk-python
 License: MIT
 Keywords: temporal,workflow
 Author: Temporal Technologies Inc
 Author-email: sdk@temporal.io
 Requires-Python: >=3.7,<4.0
@@ -25,15 +25,15 @@
 Requires-Dist: types-protobuf (>=3.20)
 Requires-Dist: typing-extensions (>=4.2.0,<5.0.0)
 Project-URL: Bug Tracker, https://github.com/temporalio/sdk-python/issues
 Project-URL: Documentation, https://docs.temporal.io/docs/python
 Project-URL: Repository, https://github.com/temporalio/sdk-python
 Description-Content-Type: text/markdown
 
-![Temporal Python SDK](scripts/_img/banner.svg)
+![Temporal Python SDK](https://assets.temporal.io/w/py-banner.svg)
 
 [![Python 3.7+](https://img.shields.io/pypi/pyversions/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)
 [![PyPI](https://img.shields.io/pypi/v/temporalio.svg?style=for-the-badge)](https://pypi.org/project/temporalio)
 [![MIT](https://img.shields.io/pypi/l/temporalio.svg?style=for-the-badge)](LICENSE)
 
 [Temporal](https://temporal.io/) is a distributed, scalable, durable, and highly available orchestration engine used to
 execute asynchronous, long-running business logic in a scalable and resilient way.
@@ -119,14 +119,16 @@
       - [Activity Context](#activity-context)
         - [Heartbeating and Cancellation](#heartbeating-and-cancellation)
         - [Worker Shutdown](#worker-shutdown)
       - [Testing](#testing-1)
     - [Workflow Replay](#workflow-replay)
     - [OpenTelemetry Support](#opentelemetry-support)
     - [Protobuf 3.x vs 4.x](#protobuf-3x-vs-4x)
+    - [Known Compatibility Issues](#known-compatibility-issues)
+      - [gevent Patching](#gevent-patching)
 - [Development](#development)
     - [Building](#building)
       - [Prepare](#prepare)
       - [Build](#build)
       - [Use](#use)
     - [Local SDK development environment](#local-sdk-development-environment)
       - [Testing](#testing-2)
@@ -1257,14 +1259,24 @@
 [Streamlit](https://github.com/streamlit/streamlit), for one reason or another, have/will not leave 3.x.
 
 To support these, Temporal Python SDK allows any protobuf library >= 3.19. However, the C extension in older Python
 versions can cause issues with the sandbox due to global state sharing. Temporal strongly recommends using the latest
 protobuf 4.x library unless you absolutely cannot at which point some proto libraries may have to be marked as
 [Passthrough Modules](#passthrough-modules).
 
+### Known Compatibility Issues
+
+Below are known compatibility issues with the Python SDK.
+
+#### gevent Patching
+
+When using `gevent.monkey.patch_all()`, asyncio event loops can get messed up, especially those using custom event loops
+like Temporal. See [this gevent issue](https://github.com/gevent/gevent/issues/982) and
+[this Python SDK issue](https://github.com/temporalio/sdk-python/issues/59) for more details.
+
 # Development
 
 The Python SDK is built to work with Python 3.7 and newer. It is built using
 [SDK Core](https://github.com/temporalio/sdk-core/) which is written in Rust.
 
 ### Building
```

